<p>In this Spark screencast, we create a standalone Apache Spark job in Scala. In the job, we create a spark context and read a file into an RDD of strings; then apply transformations and actions to the RDD and print out the results.</p>

<div class="video-container video-16x9 shadow"><iframe width="755" height="425" src="http://www.youtube.com/embed/GaBn-YjlR8Q?autohide=0&amp;showinfo=0" frameborder="0" allowfullscreen=""></iframe></div>

<p>For more information and links to other Spark screencasts, check out the <a href="/documentation.html">Spark documentation page</a>.</p>
