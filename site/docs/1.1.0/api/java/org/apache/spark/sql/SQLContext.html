<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Thu Sep 11 01:18:58 UTC 2014 -->
<title>SQLContext (Spark 1.1.1 JavaDoc)</title>
<meta name="date" content="2014-09-11">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SQLContext (Spark 1.1.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SQLContext" class="title">Class SQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SQLContext</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>, <a href="../../../../org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test">TestSQLContext</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SQLContext</span>
extends Object
implements <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, scala.Serializable</pre>
<div class="block">:: AlphaComponent ::
 The entry point for running relational queries using Spark.  Allows the creation of <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>
 objects and the execution of SQL queries.
 <p></div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SQLContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong>org.apache.spark.sql.SQLConf.Deprecated$</strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchema</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;rowRDD,
           org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> from an <code>RDD</code> containing <code>Row</code>s by applying a schema to this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#AUTO_BROADCASTJOIN_THRESHOLD()">AUTO_BROADCASTJOIN_THRESHOLD</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#autoBroadcastJoinThreshold()">autoBroadcastJoinThreshold</a></strong>()</code>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable</a></strong>(String&nbsp;tableName)</code>
<div class="block">Caches the specified table in-memory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#clear()">clear</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#CODEGEN_ENABLED()">CODEGEN_ENABLED</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#codegenEnabled()">codegenEnabled</a></strong>()</code>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#COLUMN_BATCH_SIZE()">COLUMN_BATCH_SIZE</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#columnBatchSize()">columnBatchSize</a></strong>()</code>
<div class="block">The number of rows that will be</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#COMPRESS_CACHED()">COMPRESS_CACHED</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">createParquetFile</a></strong>(String&nbsp;path,
                 boolean&nbsp;allowExisting,
                 org.apache.hadoop.conf.Configuration&nbsp;conf,
                 scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>A</code>, which can be registered as a table.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">createSchemaRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">Creates a SchemaRDD from an RDD of case classes.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#DEFAULT_SIZE_IN_BYTES()">DEFAULT_SIZE_IN_BYTES</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#defaultSizeInBytes()">defaultSizeInBytes</a></strong>()</code>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#dialect()">dialect</a></strong>()</code>
<div class="block">The SQL dialect that is used when parsing queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#DIALECT()">DIALECT</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getAllConfs()">getAllConfs</a></strong>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String)">getConf</a></strong>(String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String, java.lang.String)">getConf</a></strong>(String&nbsp;key,
       String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached</a></strong>(String&nbsp;tableName)</code>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isParquetBinaryAsString()">isParquetBinaryAsString</a></strong>()</code>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a></strong>(String&nbsp;path)</code>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">jsonFile</a></strong>(String&nbsp;path,
        double&nbsp;samplingRatio)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">jsonFile</a></strong>(String&nbsp;path,
        org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json)</code>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
       double&nbsp;samplingRatio)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
       org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">logicalPlanToSparkQuery</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>
<div class="block">:: DeveloperApi ::
 Allows catalyst LogicalPlans to be executed as a SchemaRDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#numShufflePartitions()">numShufflePartitions</a></strong>()</code>
<div class="block">Number of partitions to use for shuffle operators.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#PARQUET_BINARY_AS_STRING()">PARQUET_BINARY_AS_STRING</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#PARQUET_CACHE_METADATA()">PARQUET_CACHE_METADATA</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#PARQUET_COMPRESSION()">PARQUET_COMPRESSION</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parquetCompressionCodec()">parquetCompressionCodec</a></strong>()</code>
<div class="block">The compression codec for writing to a Parquetfile</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String)">parquetFile</a></strong>(String&nbsp;path)</code>
<div class="block">Loads a Parquet file, returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function1&lt;?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$1)</code>
<div class="block">registerFunction 1-22 were generated by this script</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$10)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function11&lt;?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$11)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function12&lt;?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$12)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function13&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$13)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function14&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$14)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function15&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$15)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function16&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$16)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function17&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$17)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function18&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$18)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function19&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$19)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function2&lt;?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$2)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function20&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$20)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function21&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$21)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function22&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$22)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function3&lt;?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function4&lt;?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function5&lt;?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function6&lt;?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$6)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function7&lt;?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$7)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function8&lt;?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$8)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function9&lt;?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$9)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, org.apache.spark.Accumulator, java.lang.String)">registerPython</a></strong>(String&nbsp;name,
              byte[]&nbsp;command,
              java.util.Map&lt;String,String&gt;&nbsp;envVars,
              java.util.List&lt;String&gt;&nbsp;pythonIncludes,
              String&nbsp;pythonExec,
              <a href="../../../../org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a>&lt;java.util.List&lt;byte[]&gt;&gt;&nbsp;accumulator,
              String&nbsp;stringDataType)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">registerRDDAsTable</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;rdd,
                  String&nbsp;tableName)</code>
<div class="block">Registers the given RDD as a temporary table in the catalog.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.util.Properties)">setConf</a></strong>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.lang.String, java.lang.String)">setConf</a></strong>(String&nbsp;key,
       String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#settings()">settings</a></strong>()</code>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SHUFFLE_PARTITIONS()">SHUFFLE_PARTITIONS</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a></strong>(String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a></strong>(String&nbsp;tableName)</code>
<div class="block">Returns the specified table as a SchemaRDD</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#THRIFTSERVER_POOL()">THRIFTSERVER_POOL</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable</a></strong>(String&nbsp;tableName)</code>
<div class="block">Removes the specified table from the in-memory cache.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#useCompression()">useCompression</a></strong>()</code>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initialized()">initialized</a>, <a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#initLock()">initLock</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SQLContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logicalPlanToSparkQuery</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
<div class="block">:: DeveloperApi ::
 Allows catalyst LogicalPlans to be executed as a SchemaRDD.  Note that the LogicalPlan
 interface is considered internal, and thus not guaranteed to be stable.  As a result, using
 them directly is not recommended.</div>
</li>
</ul>
<a name="createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createSchemaRDD</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;createSchemaRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                  scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">Creates a SchemaRDD from an RDD of case classes.
 <p></div>
</li>
</ul>
<a name="applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;rowRDD,
                    org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> from an <code>RDD</code> containing <code>Row</code>s by applying a schema to this RDD.
 It is important to make sure that the structure of every <code>Row</code> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 Example:
 <pre><code>
  import org.apache.spark.sql._
  val sqlContext = new org.apache.spark.sql.SQLContext(sc)

  val schema =
    StructType(
      StructField("name", StringType, false) ::
      StructField("age", IntegerType, true) :: Nil)

  val people =
    sc.textFile("examples/src/main/resources/people.txt").map(
      _.split(",")).map(p =&gt; Row(p(0), p(1).trim.toInt))
  val peopleSchemaRDD = sqlContext. applySchema(people, schema)
  peopleSchemaRDD.printSchema
  // root
  // |-- name: string (nullable = false)
  // |-- age: integer (nullable = true)

    peopleSchemaRDD.registerTempTable("people")
  sqlContext.sql("select name from people").collect.foreach(println)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="parquetFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;parquetFile(String&nbsp;path)</pre>
<div class="block">Loads a Parquet file, returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path)</pre>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path,
                 org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path,
                 double&nbsp;samplingRatio)</pre>
<div class="block">:: Experimental ::</div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json)</pre>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
                org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
                double&nbsp;samplingRatio)</pre>
<div class="block">:: Experimental ::</div>
</li>
</ul>
<a name="createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createParquetFile</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;createParquetFile(String&nbsp;path,
                                                    boolean&nbsp;allowExisting,
                                                    org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>A</code>, which can be registered as a table.
 This registered table can be used as the target of future <code>insertInto</code> operations.
 <p>
 <pre><code>
   val sqlContext = new SQLContext(...)
   import sqlContext._

   case class Person(name: String, age: Int)
   createParquetFile[Person]("path/to/file.parquet").registerTempTable("people")
   sql("INSERT INTO people SELECT 'michael', 29")
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - The path where the directory containing parquet metadata should be created.
             Data inserted into this table will also be stored at this location.</dd><dd><code>allowExisting</code> - When false, an exception will be thrown if this directory already exists.</dd><dd><code>conf</code> - A Hadoop configuration object that can be used to specify options to the parquet
             output format.
 <p></dd></dl>
</li>
</ul>
<a name="registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerRDDAsTable</h4>
<pre>public&nbsp;void&nbsp;registerRDDAsTable(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;rdd,
                      String&nbsp;tableName)</pre>
<div class="block">Registers the given RDD as a temporary table in the catalog.  Temporary tables exist only
 during the lifetime of this instance of SQLContext.
 <p></div>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;sql(String&nbsp;sqlText)</pre>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.  The dialect that is
 used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
</li>
</ul>
<a name="table(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;table(String&nbsp;tableName)</pre>
<div class="block">Returns the specified table as a SchemaRDD</div>
</li>
</ul>
<a name="cacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheTable</h4>
<pre>public&nbsp;void&nbsp;cacheTable(String&nbsp;tableName)</pre>
<div class="block">Caches the specified table in-memory.</div>
</li>
</ul>
<a name="uncacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>uncacheTable</h4>
<pre>public&nbsp;void&nbsp;uncacheTable(String&nbsp;tableName)</pre>
<div class="block">Removes the specified table from the in-memory cache.</div>
</li>
</ul>
<a name="isCached(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isCached</h4>
<pre>public&nbsp;boolean&nbsp;isCached(String&nbsp;tableName)</pre>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</li>
</ul>
<a name="COMPRESS_CACHED()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>COMPRESS_CACHED</h4>
<pre>public&nbsp;String&nbsp;COMPRESS_CACHED()</pre>
</li>
</ul>
<a name="COLUMN_BATCH_SIZE()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>COLUMN_BATCH_SIZE</h4>
<pre>public&nbsp;String&nbsp;COLUMN_BATCH_SIZE()</pre>
</li>
</ul>
<a name="AUTO_BROADCASTJOIN_THRESHOLD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>AUTO_BROADCASTJOIN_THRESHOLD</h4>
<pre>public&nbsp;String&nbsp;AUTO_BROADCASTJOIN_THRESHOLD()</pre>
</li>
</ul>
<a name="DEFAULT_SIZE_IN_BYTES()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DEFAULT_SIZE_IN_BYTES</h4>
<pre>public&nbsp;String&nbsp;DEFAULT_SIZE_IN_BYTES()</pre>
</li>
</ul>
<a name="SHUFFLE_PARTITIONS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SHUFFLE_PARTITIONS</h4>
<pre>public&nbsp;String&nbsp;SHUFFLE_PARTITIONS()</pre>
</li>
</ul>
<a name="CODEGEN_ENABLED()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CODEGEN_ENABLED</h4>
<pre>public&nbsp;String&nbsp;CODEGEN_ENABLED()</pre>
</li>
</ul>
<a name="DIALECT()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DIALECT</h4>
<pre>public&nbsp;String&nbsp;DIALECT()</pre>
</li>
</ul>
<a name="PARQUET_BINARY_AS_STRING()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_BINARY_AS_STRING</h4>
<pre>public&nbsp;String&nbsp;PARQUET_BINARY_AS_STRING()</pre>
</li>
</ul>
<a name="PARQUET_CACHE_METADATA()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_CACHE_METADATA</h4>
<pre>public&nbsp;String&nbsp;PARQUET_CACHE_METADATA()</pre>
</li>
</ul>
<a name="PARQUET_COMPRESSION()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_COMPRESSION</h4>
<pre>public&nbsp;String&nbsp;PARQUET_COMPRESSION()</pre>
</li>
</ul>
<a name="THRIFTSERVER_POOL()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>THRIFTSERVER_POOL</h4>
<pre>public&nbsp;String&nbsp;THRIFTSERVER_POOL()</pre>
</li>
</ul>
<a name="settings()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>settings</h4>
<pre>public&nbsp;java.util.Map&lt;String,String&gt;&nbsp;settings()</pre>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</li>
</ul>
<a name="dialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dialect</h4>
<pre>public&nbsp;String&nbsp;dialect()</pre>
<div class="block">The SQL dialect that is used when parsing queries.  This defaults to 'sql' which uses
 a simple SQL parser provided by Spark SQL.  This is currently the only option for users of
 SQLContext.
 <p>
 When using a HiveContext, this value defaults to 'hiveql', which uses the Hive 0.12.0 HiveQL
 parser.  Users can change this to 'sql' if they want to run queries that aren't supported by
 HiveQL (e.g., SELECT 1).
 <p>
 Note that the choice of dialect does not affect things like what tables are available or
 how query execution is performed.</div>
</li>
</ul>
<a name="useCompression()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useCompression</h4>
<pre>public&nbsp;boolean&nbsp;useCompression()</pre>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</li>
</ul>
<a name="parquetCompressionCodec()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetCompressionCodec</h4>
<pre>public&nbsp;String&nbsp;parquetCompressionCodec()</pre>
<div class="block">The compression codec for writing to a Parquetfile</div>
</li>
</ul>
<a name="columnBatchSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>columnBatchSize</h4>
<pre>public&nbsp;int&nbsp;columnBatchSize()</pre>
<div class="block">The number of rows that will be</div>
</li>
</ul>
<a name="numShufflePartitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numShufflePartitions</h4>
<pre>public&nbsp;int&nbsp;numShufflePartitions()</pre>
<div class="block">Number of partitions to use for shuffle operators.</div>
</li>
</ul>
<a name="codegenEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>codegenEnabled</h4>
<pre>public&nbsp;boolean&nbsp;codegenEnabled()</pre>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.  In general this custom code runs much faster
 than interpreted evaluation, but there are significant start-up costs due to compilation.
 As a result codegen is only beneficial when queries run for a long time, or when the same
 expressions are used multiple times.
 <p>
 Defaults to false as this feature is currently experimental.</div>
</li>
</ul>
<a name="autoBroadcastJoinThreshold()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>autoBroadcastJoinThreshold</h4>
<pre>public&nbsp;int&nbsp;autoBroadcastJoinThreshold()</pre>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.  Setting this to -1
 effectively disables auto conversion.
 <p>
 Hive setting: hive.auto.convert.join.noconditionaltask.size, whose default value is also 10000.</div>
</li>
</ul>
<a name="defaultSizeInBytes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultSizeInBytes</h4>
<pre>public&nbsp;long&nbsp;defaultSizeInBytes()</pre>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.  By default,
 it is set to a larger value than <code>autoBroadcastJoinThreshold</code>, hence any logical operator
 without a properly implemented estimation of this statistic will not be incorrectly broadcasted
 in joins.</div>
</li>
</ul>
<a name="isParquetBinaryAsString()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isParquetBinaryAsString</h4>
<pre>public&nbsp;boolean&nbsp;isParquetBinaryAsString()</pre>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</li>
</ul>
<a name="setConf(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.</div>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(String&nbsp;key,
           String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.</div>
</li>
</ul>
<a name="getConf(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</li>
</ul>
<a name="getConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key,
             String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.</div>
</li>
</ul>
<a name="getAllConfs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;String,String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.</div>
</li>
</ul>
<a name="clear()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
</li>
</ul>
<a name="registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, org.apache.spark.Accumulator, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerPython</h4>
<pre>public&nbsp;void&nbsp;registerPython(String&nbsp;name,
                  byte[]&nbsp;command,
                  java.util.Map&lt;String,String&gt;&nbsp;envVars,
                  java.util.List&lt;String&gt;&nbsp;pythonIncludes,
                  String&nbsp;pythonExec,
                  <a href="../../../../org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a>&lt;java.util.List&lt;byte[]&gt;&gt;&nbsp;accumulator,
                  String&nbsp;stringDataType)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function1&lt;?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$1)</pre>
<div class="block">registerFunction 1-22 were generated by this script
 <p>
   (1 to 22).map { x =>
   val types = (1 to x).map(x => "_").reduce(_ + ", " + _)
   s"""
   def registerFunction[T: TypeTag](name: String, func: Function$x[$types, T]): Unit = {
   def builder(e: Seq[Expression]) =
   ScalaUdf(func, ScalaReflection.schemaFor(typeTag[T]).dataType, e)
   functionRegistry.registerFunction(name, builder)
   }
   """
   }</div>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function2&lt;?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$2)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function3&lt;?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function4&lt;?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function5&lt;?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function6&lt;?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$6)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function7&lt;?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$7)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function8&lt;?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$8)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function9&lt;?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$9)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$10)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function11&lt;?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$11)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function12&lt;?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$12)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function13&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$13)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function14&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$14)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function15&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$15)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function16&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$16)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function17&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$17)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function18&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$18)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function19&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$19)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function20&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$20)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function21&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$21)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function22&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$22)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
