<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Thu Sep 11 01:19:01 UTC 2014 -->
<title>TestSQLContext (Spark 1.1.1 JavaDoc)</title>
<meta name="date" content="2014-09-11">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="TestSQLContext (Spark 1.1.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/test/TestSQLContext.html" target="_top">Frames</a></li>
<li><a href="TestSQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.test</div>
<h2 title="Class TestSQLContext" class="title">Class TestSQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">org.apache.spark.sql.SQLContext</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.test.TestSQLContext</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">TestSQLContext</span>
extends <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></pre>
<div class="block">A SQLContext that can be used for local testing.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../serialized-form.html#org.apache.spark.sql.test.TestSQLContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong>org.apache.spark.sql.SQLConf.Deprecated$</strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#TestSQLContext()">TestSQLContext</a></strong>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#AUTO_BROADCASTJOIN_THRESHOLD()">AUTO_BROADCASTJOIN_THRESHOLD</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#autoBroadcastJoinThreshold()">autoBroadcastJoinThreshold</a></strong>()</code>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#clear()">clear</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#CODEGEN_ENABLED()">CODEGEN_ENABLED</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#codegenEnabled()">codegenEnabled</a></strong>()</code>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#COLUMN_BATCH_SIZE()">COLUMN_BATCH_SIZE</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#columnBatchSize()">columnBatchSize</a></strong>()</code>
<div class="block">The number of rows that will be</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#COMPRESS_CACHED()">COMPRESS_CACHED</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#DEFAULT_SIZE_IN_BYTES()">DEFAULT_SIZE_IN_BYTES</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#defaultSizeInBytes()">defaultSizeInBytes</a></strong>()</code>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#dialect()">dialect</a></strong>()</code>
<div class="block">The SQL dialect that is used when parsing queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#DIALECT()">DIALECT</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#getAllConfs()">getAllConfs</a></strong>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#getConf(java.lang.String)">getConf</a></strong>(String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#getConf(java.lang.String, java.lang.String)">getConf</a></strong>(String&nbsp;key,
       String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#isParquetBinaryAsString()">isParquetBinaryAsString</a></strong>()</code>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#numShufflePartitions()">numShufflePartitions</a></strong>()</code>
<div class="block">Number of partitions to use for shuffle operators.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#PARQUET_BINARY_AS_STRING()">PARQUET_BINARY_AS_STRING</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#PARQUET_CACHE_METADATA()">PARQUET_CACHE_METADATA</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#PARQUET_COMPRESSION()">PARQUET_COMPRESSION</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#parquetCompressionCodec()">parquetCompressionCodec</a></strong>()</code>
<div class="block">The compression codec for writing to a Parquetfile</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function1&lt;?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$1)</code>
<div class="block">registerFunction 1-22 were generated by this script</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$10)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function11&lt;?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$11)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function12&lt;?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$12)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function13&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$13)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function14&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$14)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function15&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$15)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function16&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$16)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function17&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$17)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function18&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$18)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function19&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$19)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function2&lt;?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$2)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function20&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$20)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function21&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$21)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function22&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$22)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function3&lt;?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function4&lt;?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function5&lt;?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function6&lt;?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$6)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function7&lt;?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$7)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function8&lt;?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$8)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a></strong>(String&nbsp;name,
                scala.Function9&lt;?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$9)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, org.apache.spark.Accumulator, java.lang.String)">registerPython</a></strong>(String&nbsp;name,
              byte[]&nbsp;command,
              java.util.Map&lt;String,String&gt;&nbsp;envVars,
              java.util.List&lt;String&gt;&nbsp;pythonIncludes,
              String&nbsp;pythonExec,
              <a href="../../../../../org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a>&lt;java.util.List&lt;byte[]&gt;&gt;&nbsp;accumulator,
              String&nbsp;stringDataType)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#setConf(java.util.Properties)">setConf</a></strong>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#setConf(java.lang.String, java.lang.String)">setConf</a></strong>(String&nbsp;key,
       String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#settings()">settings</a></strong>()</code>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#SHUFFLE_PARTITIONS()">SHUFFLE_PARTITIONS</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#THRIFTSERVER_POOL()">THRIFTSERVER_POOL</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/test/TestSQLContext.html#useCompression()">useCompression</a></strong>()</code>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SQLContext">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">createParquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">createSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">logicalPlanToSparkQuery</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String)">parquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">registerRDDAsTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initialized()">initialized</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#initLock()">initLock</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="TestSQLContext()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>TestSQLContext</h4>
<pre>public&nbsp;TestSQLContext()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="COMPRESS_CACHED()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>COMPRESS_CACHED</h4>
<pre>public&nbsp;String&nbsp;COMPRESS_CACHED()</pre>
</li>
</ul>
<a name="COLUMN_BATCH_SIZE()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>COLUMN_BATCH_SIZE</h4>
<pre>public&nbsp;String&nbsp;COLUMN_BATCH_SIZE()</pre>
</li>
</ul>
<a name="AUTO_BROADCASTJOIN_THRESHOLD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>AUTO_BROADCASTJOIN_THRESHOLD</h4>
<pre>public&nbsp;String&nbsp;AUTO_BROADCASTJOIN_THRESHOLD()</pre>
</li>
</ul>
<a name="DEFAULT_SIZE_IN_BYTES()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DEFAULT_SIZE_IN_BYTES</h4>
<pre>public&nbsp;String&nbsp;DEFAULT_SIZE_IN_BYTES()</pre>
</li>
</ul>
<a name="SHUFFLE_PARTITIONS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SHUFFLE_PARTITIONS</h4>
<pre>public&nbsp;String&nbsp;SHUFFLE_PARTITIONS()</pre>
</li>
</ul>
<a name="CODEGEN_ENABLED()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CODEGEN_ENABLED</h4>
<pre>public&nbsp;String&nbsp;CODEGEN_ENABLED()</pre>
</li>
</ul>
<a name="DIALECT()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DIALECT</h4>
<pre>public&nbsp;String&nbsp;DIALECT()</pre>
</li>
</ul>
<a name="PARQUET_BINARY_AS_STRING()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_BINARY_AS_STRING</h4>
<pre>public&nbsp;String&nbsp;PARQUET_BINARY_AS_STRING()</pre>
</li>
</ul>
<a name="PARQUET_CACHE_METADATA()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_CACHE_METADATA</h4>
<pre>public&nbsp;String&nbsp;PARQUET_CACHE_METADATA()</pre>
</li>
</ul>
<a name="PARQUET_COMPRESSION()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARQUET_COMPRESSION</h4>
<pre>public&nbsp;String&nbsp;PARQUET_COMPRESSION()</pre>
</li>
</ul>
<a name="THRIFTSERVER_POOL()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>THRIFTSERVER_POOL</h4>
<pre>public&nbsp;String&nbsp;THRIFTSERVER_POOL()</pre>
</li>
</ul>
<a name="settings()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>settings</h4>
<pre>public&nbsp;java.util.Map&lt;String,String&gt;&nbsp;settings()</pre>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</li>
</ul>
<a name="dialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dialect</h4>
<pre>public&nbsp;String&nbsp;dialect()</pre>
<div class="block">The SQL dialect that is used when parsing queries.  This defaults to 'sql' which uses
 a simple SQL parser provided by Spark SQL.  This is currently the only option for users of
 SQLContext.
 <p>
 When using a HiveContext, this value defaults to 'hiveql', which uses the Hive 0.12.0 HiveQL
 parser.  Users can change this to 'sql' if they want to run queries that aren't supported by
 HiveQL (e.g., SELECT 1).
 <p>
 Note that the choice of dialect does not affect things like what tables are available or
 how query execution is performed.</div>
</li>
</ul>
<a name="useCompression()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useCompression</h4>
<pre>public&nbsp;boolean&nbsp;useCompression()</pre>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</li>
</ul>
<a name="parquetCompressionCodec()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetCompressionCodec</h4>
<pre>public&nbsp;String&nbsp;parquetCompressionCodec()</pre>
<div class="block">The compression codec for writing to a Parquetfile</div>
</li>
</ul>
<a name="columnBatchSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>columnBatchSize</h4>
<pre>public&nbsp;int&nbsp;columnBatchSize()</pre>
<div class="block">The number of rows that will be</div>
</li>
</ul>
<a name="numShufflePartitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numShufflePartitions</h4>
<pre>public&nbsp;int&nbsp;numShufflePartitions()</pre>
<div class="block">Number of partitions to use for shuffle operators.</div>
</li>
</ul>
<a name="codegenEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>codegenEnabled</h4>
<pre>public&nbsp;boolean&nbsp;codegenEnabled()</pre>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.  In general this custom code runs much faster
 than interpreted evaluation, but there are significant start-up costs due to compilation.
 As a result codegen is only beneficial when queries run for a long time, or when the same
 expressions are used multiple times.
 <p>
 Defaults to false as this feature is currently experimental.</div>
</li>
</ul>
<a name="autoBroadcastJoinThreshold()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>autoBroadcastJoinThreshold</h4>
<pre>public&nbsp;int&nbsp;autoBroadcastJoinThreshold()</pre>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.  Setting this to -1
 effectively disables auto conversion.
 <p>
 Hive setting: hive.auto.convert.join.noconditionaltask.size, whose default value is also 10000.</div>
</li>
</ul>
<a name="defaultSizeInBytes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultSizeInBytes</h4>
<pre>public&nbsp;long&nbsp;defaultSizeInBytes()</pre>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.  By default,
 it is set to a larger value than <code>autoBroadcastJoinThreshold</code>, hence any logical operator
 without a properly implemented estimation of this statistic will not be incorrectly broadcasted
 in joins.</div>
</li>
</ul>
<a name="isParquetBinaryAsString()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isParquetBinaryAsString</h4>
<pre>public&nbsp;boolean&nbsp;isParquetBinaryAsString()</pre>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</li>
</ul>
<a name="setConf(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.</div>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(String&nbsp;key,
           String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.</div>
</li>
</ul>
<a name="getConf(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</li>
</ul>
<a name="getConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key,
             String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.</div>
</li>
</ul>
<a name="getAllConfs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;String,String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.</div>
</li>
</ul>
<a name="clear()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
</li>
</ul>
<a name="registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, org.apache.spark.Accumulator, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerPython</h4>
<pre>public&nbsp;void&nbsp;registerPython(String&nbsp;name,
                  byte[]&nbsp;command,
                  java.util.Map&lt;String,String&gt;&nbsp;envVars,
                  java.util.List&lt;String&gt;&nbsp;pythonIncludes,
                  String&nbsp;pythonExec,
                  <a href="../../../../../org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a>&lt;java.util.List&lt;byte[]&gt;&gt;&nbsp;accumulator,
                  String&nbsp;stringDataType)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function1&lt;?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$1)</pre>
<div class="block">registerFunction 1-22 were generated by this script
 <p>
   (1 to 22).map { x =>
   val types = (1 to x).map(x => "_").reduce(_ + ", " + _)
   s"""
   def registerFunction[T: TypeTag](name: String, func: Function$x[$types, T]): Unit = {
   def builder(e: Seq[Expression]) =
   ScalaUdf(func, ScalaReflection.schemaFor(typeTag[T]).dataType, e)
   functionRegistry.registerFunction(name, builder)
   }
   """
   }</div>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function2&lt;?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$2)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function3&lt;?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function4&lt;?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function5&lt;?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function6&lt;?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$6)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function7&lt;?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$7)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function8&lt;?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$8)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function9&lt;?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$9)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$10)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function11&lt;?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$11)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function12&lt;?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$12)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function13&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$13)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function14&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$14)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function15&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$15)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function16&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$16)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function17&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$17)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function18&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$18)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function19&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$19)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function20&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$20)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function21&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$21)</pre>
</li>
</ul>
<a name="registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>registerFunction</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;void&nbsp;registerFunction(String&nbsp;name,
                        scala.Function22&lt;?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,T&gt;&nbsp;func,
                        scala.reflect.api.TypeTags.TypeTag&lt;T&gt;&nbsp;evidence$22)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/test/TestSQLContext.html" target="_top">Frames</a></li>
<li><a href="TestSQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
