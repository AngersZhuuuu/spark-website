<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Thu Dec 18 23:24:53 UTC 2014 -->
<title>SQLContext (Spark 1.2.1 JavaDoc)</title>
<meta name="date" content="2014-12-18">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SQLContext (Spark 1.2.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SQLContext" class="title">Class SQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SQLContext</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql">CacheManager</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql">UDFRegistration</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>, <a href="../../../../org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test">TestSQLContext</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SQLContext</span>
extends Object
implements <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql">CacheManager</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql">UDFRegistration</a>, scala.Serializable</pre>
<div class="block">:: AlphaComponent ::
 The entry point for running relational queries using Spark.  Allows the creation of <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>
 objects and the execution of SQL queries.
 <p></div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SQLContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_org.apache.spark.sql.SQLConf">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a></h3>
<code><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql">SQLConf.Deprecated$</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchema</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;rowRDD,
           org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> from an <code>RDD</code> containing <code>Row</code>s by applying a schema to this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object[]&gt;&nbsp;rdd,
                      String&nbsp;schemaString)</code>
<div class="block">Apply a schema defined by the schemaString to an RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object[]&gt;&nbsp;rdd,
                      org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">Apply a schema defined by the schema to an RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#baseRelationToSchemaRDD(org.apache.spark.sql.sources.BaseRelation)">baseRelationToSchemaRDD</a></strong>(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">createParquetFile</a></strong>(String&nbsp;path,
                 boolean&nbsp;allowExisting,
                 org.apache.hadoop.conf.Configuration&nbsp;conf,
                 scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>A</code>, which can be registered as a table.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">createSchemaRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">Creates a SchemaRDD from an RDD of case classes.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)">dropTempTable</a></strong>(String&nbsp;tableName)</code>
<div class="block">Drops the temporary table with the given table name in the catalog.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.Seq&lt;org.apache.spark.sql.catalyst.planning.GenericStrategy&lt;<a href="../../../../org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#extraStrategies()">extraStrategies</a></strong>()</code>
<div class="block">:: DeveloperApi ::
 Allows extra strategies to be injected into the query planner at runtime.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a></strong>(String&nbsp;path)</code>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">jsonFile</a></strong>(String&nbsp;path,
        double&nbsp;samplingRatio)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">jsonFile</a></strong>(String&nbsp;path,
        org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json)</code>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
       double&nbsp;samplingRatio)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
       org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</code>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">logicalPlanToSparkQuery</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>
<div class="block">:: DeveloperApi ::
 Allows catalyst LogicalPlans to be executed as a SchemaRDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String)">parquetFile</a></strong>(String&nbsp;path)</code>
<div class="block">Loads a Parquet file, returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.types.DataType</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parseDataType(java.lang.String)">parseDataType</a></strong>(String&nbsp;dataTypeString)</code>
<div class="block">Parses the data type in our internal string representation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">registerRDDAsTable</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;rdd,
                  String&nbsp;tableName)</code>
<div class="block">Registers the given RDD as a temporary table in the catalog.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a></strong>(String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a></strong>(String&nbsp;tableName)</code>
<div class="block">Returns the specified table as a SchemaRDD</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SQLConf">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a></h3>
<code><a href="../../../../org/apache/spark/sql/SQLConf.html#autoBroadcastJoinThreshold()">autoBroadcastJoinThreshold</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#clear()">clear</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#codegenEnabled()">codegenEnabled</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#columnBatchSize()">columnBatchSize</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#columnNameOfCorruptRecord()">columnNameOfCorruptRecord</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#defaultSizeInBytes()">defaultSizeInBytes</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#dialect()">dialect</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#externalSortEnabled()">externalSortEnabled</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#getAllConfs()">getAllConfs</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String)">getConf</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String, java.lang.String)">getConf</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#inMemoryPartitionPruning()">inMemoryPartitionPruning</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#isParquetBinaryAsString()">isParquetBinaryAsString</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#numShufflePartitions()">numShufflePartitions</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#parquetCompressionCodec()">parquetCompressionCodec</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#parquetFilterPushDown()">parquetFilterPushDown</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#setConf(java.util.Properties)">setConf</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#setConf(java.lang.String, java.lang.String)">setConf</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#settings()">settings</a>, <a href="../../../../org/apache/spark/sql/SQLConf.html#useCompression()">useCompression</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.CacheManager">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql">CacheManager</a></h3>
<code><a href="../../../../org/apache/spark/sql/CacheManager.html#cachedData()">cachedData</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#cacheLock()">cacheLock</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#cacheQuery(org.apache.spark.sql.SchemaRDD, scala.Option, org.apache.spark.storage.StorageLevel)">cacheQuery</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#cacheTable(java.lang.String)">cacheTable</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#clearCache()">clearCache</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#invalidateCache(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">invalidateCache</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#isCached(java.lang.String)">isCached</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#lookupCachedData(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">lookupCachedData</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#lookupCachedData(org.apache.spark.sql.SchemaRDD)">lookupCachedData</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#readLock(scala.Function0)">readLock</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#tryUncacheQuery(org.apache.spark.sql.SchemaRDD, boolean)">tryUncacheQuery</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#uncacheQuery(org.apache.spark.sql.SchemaRDD, boolean)">uncacheQuery</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#uncacheTable(java.lang.String)">uncacheTable</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#useCachedData(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">useCachedData</a>, <a href="../../../../org/apache/spark/sql/CacheManager.html#writeLock(scala.Function0)">writeLock</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.UDFRegistration">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql">UDFRegistration</a></h3>
<code><a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../org/apache/spark/sql/UDFRegistration.html#registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, java.util.List, org.apache.spark.Accumulator, java.lang.String)">registerPython</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SQLContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logicalPlanToSparkQuery</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
<div class="block">:: DeveloperApi ::
 Allows catalyst LogicalPlans to be executed as a SchemaRDD.  Note that the LogicalPlan
 interface is considered internal, and thus not guaranteed to be stable.  As a result, using
 them directly is not recommended.</div>
</li>
</ul>
<a name="createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createSchemaRDD</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;createSchemaRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                  scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">Creates a SchemaRDD from an RDD of case classes.
 <p></div>
</li>
</ul>
<a name="baseRelationToSchemaRDD(org.apache.spark.sql.sources.BaseRelation)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseRelationToSchemaRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;baseRelationToSchemaRDD(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</pre>
</li>
</ul>
<a name="applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;rowRDD,
                    org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> from an <code>RDD</code> containing <code>Row</code>s by applying a schema to this RDD.
 It is important to make sure that the structure of every <code>Row</code> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 Example:
 <pre><code>
  import org.apache.spark.sql._
  val sqlContext = new org.apache.spark.sql.SQLContext(sc)

  val schema =
    StructType(
      StructField("name", StringType, false) ::
      StructField("age", IntegerType, true) :: Nil)

  val people =
    sc.textFile("examples/src/main/resources/people.txt").map(
      _.split(",")).map(p =&gt; Row(p(0), p(1).trim.toInt))
  val peopleSchemaRDD = sqlContext. applySchema(people, schema)
  peopleSchemaRDD.printSchema
  // root
  // |-- name: string (nullable = false)
  // |-- age: integer (nullable = true)

    peopleSchemaRDD.registerTempTable("people")
  sqlContext.sql("select name from people").collect.foreach(println)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="parquetFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;parquetFile(String&nbsp;path)</pre>
<div class="block">Loads a Parquet file, returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path)</pre>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path,
                 org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonFile(java.lang.String, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonFile(String&nbsp;path,
                 double&nbsp;samplingRatio)</pre>
<div class="block">:: Experimental ::</div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json)</pre>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
                org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.
 <p></div>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;json,
                double&nbsp;samplingRatio)</pre>
<div class="block">:: Experimental ::</div>
</li>
</ul>
<a name="createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createParquetFile</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;createParquetFile(String&nbsp;path,
                                                    boolean&nbsp;allowExisting,
                                                    org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>A</code>, which can be registered as a table.
 This registered table can be used as the target of future <code>insertInto</code> operations.
 <p>
 <pre><code>
   val sqlContext = new SQLContext(...)
   import sqlContext._

   case class Person(name: String, age: Int)
   createParquetFile[Person]("path/to/file.parquet").registerTempTable("people")
   sql("INSERT INTO people SELECT 'michael', 29")
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - The path where the directory containing parquet metadata should be created.
             Data inserted into this table will also be stored at this location.</dd><dd><code>allowExisting</code> - When false, an exception will be thrown if this directory already exists.</dd><dd><code>conf</code> - A Hadoop configuration object that can be used to specify options to the parquet
             output format.
 <p></dd></dl>
</li>
</ul>
<a name="registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerRDDAsTable</h4>
<pre>public&nbsp;void&nbsp;registerRDDAsTable(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;rdd,
                      String&nbsp;tableName)</pre>
<div class="block">Registers the given RDD as a temporary table in the catalog.  Temporary tables exist only
 during the lifetime of this instance of SQLContext.
 <p></div>
</li>
</ul>
<a name="dropTempTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dropTempTable</h4>
<pre>public&nbsp;void&nbsp;dropTempTable(String&nbsp;tableName)</pre>
<div class="block">Drops the temporary table with the given table name in the catalog. If the table has been
 cached/persisted before, it's also unpersisted.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - the name of the table to be unregistered.
 <p></dd></dl>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;sql(String&nbsp;sqlText)</pre>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.  The dialect that is
 used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
</li>
</ul>
<a name="table(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;table(String&nbsp;tableName)</pre>
<div class="block">Returns the specified table as a SchemaRDD</div>
</li>
</ul>
<a name="extraStrategies()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>extraStrategies</h4>
<pre>public&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.catalyst.planning.GenericStrategy&lt;<a href="../../../../org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a>&gt;&gt;&nbsp;extraStrategies()</pre>
<div class="block">:: DeveloperApi ::
 Allows extra strategies to be injected into the query planner at runtime.  Note this API
 should be consider experimental and is not intended to be stable across releases.</div>
</li>
</ul>
<a name="parseDataType(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseDataType</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.types.DataType&nbsp;parseDataType(String&nbsp;dataTypeString)</pre>
<div class="block">Parses the data type in our internal string representation. The data type string should
 have the same format as the one generated by <code>toString</code> in scala.
 It is only used by PySpark.</div>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object[]&gt;&nbsp;rdd,
                               String&nbsp;schemaString)</pre>
<div class="block">Apply a schema defined by the schemaString to an RDD. It is only used by PySpark.</div>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object[]&gt;&nbsp;rdd,
                               org.apache.spark.sql.catalyst.types.StructType&nbsp;schema)</pre>
<div class="block">Apply a schema defined by the schema to an RDD. It is only used by PySpark.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
