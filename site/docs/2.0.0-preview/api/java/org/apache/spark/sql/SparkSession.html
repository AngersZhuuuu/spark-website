<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_80) on Wed Jun 08 10:02:50 BST 2016 -->
<title>SparkSession</title>
<meta name="date" content="2016-06-08">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SparkSession";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SourceStatus.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SparkSession.html" target="_top">Frames</a></li>
<li><a href="SparkSession.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SparkSession" class="title">Class SparkSession</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SparkSession</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable</dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SparkSession</span>
extends java.lang.Object
implements scala.Serializable</pre>
<div class="block">The entry point to programming Spark with the Dataset and DataFrame API.
 <p>
 To create a SparkSession, use the following builder pattern:
 <p>
 <pre><code>
   SparkSession.builder()
     .master("local")
     .appName("Word Count")
     .config("spark.some.config.option", "some-value").
     .getOrCreate()
 </code></pre></div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SparkSession">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql">SparkSession.Builder</a></strong></code>
<div class="block">Builder for <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.implicits$.html" title="class in org.apache.spark.sql">SparkSession.implicits$</a></strong></code>
<div class="block">:: Experimental ::
 (Scala-specific) Implicit methods available in Scala for converting
 common Scala objects into <code>DataFrame</code>s.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20java.lang.String)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      java.lang.String&nbsp;schemaString)</code>
<div class="block">Apply a schema defined by the schemaString to an RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">Apply a schema defined by the schema to an RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">baseRelationToDataFrame</a></strong>(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</code>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql">SparkSession.Builder</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#builder()">builder</a></strong>()</code>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql"><code>SparkSession.Builder</code></a> for constructing a <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.CacheManager</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#cacheManager()">cacheManager</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/catalog/Catalog.html" title="class in org.apache.spark.sql.catalog">Catalog</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#catalog()">catalog</a></strong>()</code>
<div class="block">Interface through which the user may create, drop, alter or query underlying
 databases, tables, functions etc.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="class in org.apache.spark.sql">RuntimeConfig</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#conf()">conf</a></strong>()</code>
<div class="block">Runtime configuration interface for Spark.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(java.util.List,%20java.lang.Class)">createDataFrame</a></strong>(java.util.List&lt;?&gt;&nbsp;data,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an List of Java Beans.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(java.util.List,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.rdd.RDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.rdd.RDD,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">:: Experimental ::
 Creates a <code>DataFrame</code> from an RDD of Product (e.g.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType,%20boolean)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
               boolean&nbsp;needsConversion)</code>
<div class="block">Creates a <code>DataFrame</code> from an RDD[Row].</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataFrame(scala.collection.Seq,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(scala.collection.Seq&lt;A&gt;&nbsp;data,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>
<div class="block">:: Experimental ::
 Creates a <code>DataFrame</code> from a local Seq of Product.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataset(java.util.List,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(java.util.List&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataset(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createDataset(scala.collection.Seq,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(scala.collection.Seq&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#createTempView(java.lang.String,%20org.apache.spark.sql.Dataset,%20boolean)">createTempView</a></strong>(java.lang.String&nbsp;viewName,
              <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;df,
              boolean&nbsp;replaceIfExists)</code>
<div class="block">Creates a temporary view with a DataFrame.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#emptyDataFrame()">emptyDataFrame</a></strong>()</code>
<div class="block">:: Experimental ::
 Returns a <code>DataFrame</code> with no rows or columns.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#executeSql(java.lang.String)">executeSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#experimental()">experimental</a></strong>()</code>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.catalog.ExternalCatalog</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#externalCatalog()">externalCatalog</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SparkSession.implicits$.html" title="class in org.apache.spark.sql">SparkSession.implicits$</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#implicits()">implicits</a></strong>()</code>
<div class="block">Accessor for nested Scala object</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#initializeLogIfNecessary(boolean)">initializeLogIfNecessary</a></strong>(boolean&nbsp;isInterpreter)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#internalCreateDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">internalCreateDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&nbsp;catalystRows,
                       <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">Creates a <code>DataFrame</code> from an RDD[Row].</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#isTraceEnabled()">isTraceEnabled</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.ui.SQLListener</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#listener()">listener</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#listenerManager()">listenerManager</a></strong>()</code>
<div class="block">:: Experimental ::
 An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static org.slf4j.Logger</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#log()">log</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logDebug(scala.Function0)">logDebug</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logError(scala.Function0)">logError</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logInfo(scala.Function0)">logInfo</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
       java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logName()">logName</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logTrace(scala.Function0)">logTrace</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logWarning(scala.Function0)">logWarning</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
          java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#newSession()">newSession</a></strong>()</code>
<div class="block">Start a new session with isolated SQL configurations, temporary tables, registered
 functions are isolated, but sharing the underlying <code>SparkContext</code> and cached data.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#parseDataType(java.lang.String)">parseDataType</a></strong>(java.lang.String&nbsp;dataTypeString)</code>
<div class="block">Parses the data type in our internal string representation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.plans.logical.LogicalPlan</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#parseSql(java.lang.String)">parseSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#range(long)">range</a></strong>(long&nbsp;end)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from 0 to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#range(long,%20long)">range</a></strong>(long&nbsp;start,
     long&nbsp;end)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#range(long,%20long,%20long)">range</a></strong>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#range(long,%20long,%20long,%20int)">range</a></strong>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step,
     int&nbsp;numPartitions)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#read()">read</a></strong>()</code>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read data and streams in as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.internal.SessionState</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#sessionState()">sessionState</a></strong>()</code>
<div class="block">State isolated across sessions, including SQL configurations, temporary tables, registered
 functions, and everything else that accepts a <code>SQLConf</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#setWrappedContext(org.apache.spark.sql.SQLContext)">setWrappedContext</a></strong>(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.internal.SharedState</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#sharedState()">sharedState</a></strong>()</code>
<div class="block">State shared across sessions, including the <code>SparkContext</code>, cached data, listener,
 and a catalog that interacts with external systems.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#sql(java.lang.String)">sql</a></strong>(java.lang.String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#stop()">stop</a></strong>()</code>
<div class="block">Stop the underlying <code>SparkContext</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql">ContinuousQueryManager</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#streams()">streams</a></strong>()</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql"><code>ContinuousQueryManager</code></a> that allows managing all the
 <a href="../../../../org/apache/spark/sql/ContinuousQuery.html" title="interface in org.apache.spark.sql"><code>ContinuousQueries</code></a> active on <code>this</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#table(java.lang.String)">table</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Returns the specified table as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#table(org.apache.spark.sql.catalyst.TableIdentifier)">table</a></strong>(org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#udf()">udf</a></strong>()</code>
<div class="block">A collection of methods for registering user-defined functions (UDF).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SparkSession.html#wrapped()">wrapped</a></strong>()</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="builder()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>builder</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql">SparkSession.Builder</a>&nbsp;builder()</pre>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql"><code>SparkSession.Builder</code></a> for constructing a <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="logName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logName</h4>
<pre>protected static&nbsp;java.lang.String&nbsp;logName()</pre>
</li>
</ul>
<a name="log()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>log</h4>
<pre>protected static&nbsp;org.slf4j.Logger&nbsp;log()</pre>
</li>
</ul>
<a name="logInfo(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logInfo</h4>
<pre>protected static&nbsp;void&nbsp;logInfo(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logDebug(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logDebug</h4>
<pre>protected static&nbsp;void&nbsp;logDebug(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logTrace(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logTrace</h4>
<pre>protected static&nbsp;void&nbsp;logTrace(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logWarning(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logWarning</h4>
<pre>protected static&nbsp;void&nbsp;logWarning(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logError(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logError</h4>
<pre>protected static&nbsp;void&nbsp;logError(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logInfo(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logInfo</h4>
<pre>protected static&nbsp;void&nbsp;logInfo(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
           java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logDebug(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logDebug</h4>
<pre>protected static&nbsp;void&nbsp;logDebug(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logTrace(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logTrace</h4>
<pre>protected static&nbsp;void&nbsp;logTrace(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logWarning(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logWarning</h4>
<pre>protected static&nbsp;void&nbsp;logWarning(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
              java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logError(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logError</h4>
<pre>protected static&nbsp;void&nbsp;logError(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="isTraceEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isTraceEnabled</h4>
<pre>protected static&nbsp;boolean&nbsp;isTraceEnabled()</pre>
</li>
</ul>
<a name="initializeLogIfNecessary(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeLogIfNecessary</h4>
<pre>protected static&nbsp;void&nbsp;initializeLogIfNecessary(boolean&nbsp;isInterpreter)</pre>
</li>
</ul>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="sharedState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sharedState</h4>
<pre>protected&nbsp;org.apache.spark.sql.internal.SharedState&nbsp;sharedState()</pre>
<div class="block">State shared across sessions, including the <code>SparkContext</code>, cached data, listener,
 and a catalog that interacts with external systems.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="sessionState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sessionState</h4>
<pre>protected&nbsp;org.apache.spark.sql.internal.SessionState&nbsp;sessionState()</pre>
<div class="block">State isolated across sessions, including SQL configurations, temporary tables, registered
 functions, and everything else that accepts a <code>SQLConf</code>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="wrapped()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>wrapped</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;wrapped()</pre>
</li>
</ul>
<a name="setWrappedContext(org.apache.spark.sql.SQLContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setWrappedContext</h4>
<pre>protected&nbsp;void&nbsp;setWrappedContext(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</pre>
</li>
</ul>
<a name="cacheManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheManager</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.CacheManager&nbsp;cacheManager()</pre>
</li>
</ul>
<a name="listener()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listener</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.ui.SQLListener&nbsp;listener()</pre>
</li>
</ul>
<a name="externalCatalog()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>externalCatalog</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.catalog.ExternalCatalog&nbsp;externalCatalog()</pre>
</li>
</ul>
<a name="conf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="class in org.apache.spark.sql">RuntimeConfig</a>&nbsp;conf()</pre>
<div class="block">Runtime configuration interface for Spark.
 <p>
 This is the interface through which the user can get and set all Spark and Hadoop
 configurations that are relevant to Spark SQL. When getting the value of a config,
 this defaults to the value set in the underlying <code>SparkContext</code>, if any.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="listenerManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listenerManager</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a>&nbsp;listenerManager()</pre>
<div class="block">:: Experimental ::
 An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="experimental()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>experimental</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a>&nbsp;experimental()</pre>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="udf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>udf</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a>&nbsp;udf()</pre>
<div class="block">A collection of methods for registering user-defined functions (UDF).
 <p>
 The following example registers a Scala closure as UDF:
 <pre><code>
   sparkSession.udf.register("myUDF", (arg1: Int, arg2: String) =&gt; arg2 + arg1)
 </code></pre>
 <p>
 The following example registers a UDF in Java:
 <pre><code>
   sparkSession.udf().register("myUDF",
       new UDF2&lt;Integer, String, String&gt;() {
           &#64;Override
           public String call(Integer arg1, String arg2) {
               return arg2 + arg1;
           }
      }, DataTypes.StringType);
 </code></pre>
 <p>
 Or, to use Java 8 lambda syntax:
 <pre><code>
   sparkSession.udf().register("myUDF",
       (Integer arg1, String arg2) -&gt; arg2 + arg1,
       DataTypes.StringType);
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="streams()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>streams</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql">ContinuousQueryManager</a>&nbsp;streams()</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql"><code>ContinuousQueryManager</code></a> that allows managing all the
 <a href="../../../../org/apache/spark/sql/ContinuousQuery.html" title="interface in org.apache.spark.sql"><code>ContinuousQueries</code></a> active on <code>this</code>.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="newSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;newSession()</pre>
<div class="block">Start a new session with isolated SQL configurations, temporary tables, registered
 functions are isolated, but sharing the underlying <code>SparkContext</code> and cached data.
 <p>
 Note: Other than the <code>SparkContext</code>, all shared state is initialized lazily.
 This method will force the initialization of the shared state to ensure that parent
 and child sessions are set up with the same shared state. If the underlying catalog
 implementation is Hive, this will initialize the metastore, which may take some time.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="emptyDataFrame()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;emptyDataFrame()</pre>
<div class="block">:: Experimental ::
 Returns a <code>DataFrame</code> with no rows or columns.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                     scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">:: Experimental ::
 Creates a <code>DataFrame</code> from an RDD of Product (e.g. case classes, tuples).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(scala.collection.Seq, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(scala.collection.Seq&lt;A&gt;&nbsp;data,
                                                     scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
<div class="block">:: Experimental ::
 Creates a <code>DataFrame</code> from a local Seq of Product.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - (undocumented)</dd><dd><code>evidence$2</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 Example:
 <pre><code>
  import org.apache.spark.sql._
  import org.apache.spark.sql.types._
  val sparkSession = new org.apache.spark.sql.SparkSession(sc)

  val schema =
    StructType(
      StructField("name", StringType, false) ::
      StructField("age", IntegerType, true) :: Nil)

  val people =
    sc.textFile("examples/src/main/resources/people.txt").map(
      _.split(",")).map(p =&gt; Row(p(0), p(1).trim.toInt))
  val dataFrame = sparkSession.createDataFrame(people, schema)
  dataFrame.printSchema
  // root
  // |-- name: string (nullable = false)
  // |-- age: integer (nullable = true)

  dataFrame.createOrReplaceTempView("people")
  sparkSession.sql("select name from people").collect.foreach(println)
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rowRDD</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rowRDD</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(java.util.List, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided List matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rows</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
 SELECT * queries will return the columns in an undefined order.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
 SELECT * queries will return the columns in an undefined order.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(java.util.List, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;?&gt;&nbsp;data,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an List of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseRelationToDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;baseRelationToDataFrame(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</pre>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>baseRelation</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="createDataset(scala.collection.Seq, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(scala.collection.Seq&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="createDataset(org.apache.spark.rdd.RDD, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="createDataset(java.util.List, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(java.util.List&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="range(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;end)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from 0 to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>end</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end,
                            long&nbsp;step)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd><dd><code>step</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long, long, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end,
                            long&nbsp;step,
                            int&nbsp;numPartitions)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd><dd><code>step</code> - (undocumented)</dd><dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="internalCreateDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>internalCreateDataFrame</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;internalCreateDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&nbsp;catalystRows,
                                   <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">Creates a <code>DataFrame</code> from an RDD[Row].
 User can specify whether the input rows should be converted to Catalyst rows.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>catalystRows</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                           boolean&nbsp;needsConversion)</pre>
<div class="block">Creates a <code>DataFrame</code> from an RDD[Row].
 User can specify whether the input rows should be converted to Catalyst rows.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rowRDD</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd><dd><code>needsConversion</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="catalog()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>catalog</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/catalog/Catalog.html" title="class in org.apache.spark.sql.catalog">Catalog</a>&nbsp;catalog()</pre>
<div class="block">Interface through which the user may create, drop, alter or query underlying
 databases, tables, functions etc.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="table(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;table(java.lang.String&nbsp;tableName)</pre>
<div class="block">Returns the specified table as a <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="table(org.apache.spark.sql.catalyst.TableIdentifier)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;table(org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent)</pre>
</li>
</ul>
<a name="createTempView(java.lang.String, org.apache.spark.sql.Dataset, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createTempView</h4>
<pre>protected&nbsp;void&nbsp;createTempView(java.lang.String&nbsp;viewName,
                  <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;df,
                  boolean&nbsp;replaceIfExists)</pre>
<div class="block">Creates a temporary view with a DataFrame. The lifetime of this temporary view is tied to
 this <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>viewName</code> - (undocumented)</dd><dd><code>df</code> - (undocumented)</dd><dd><code>replaceIfExists</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sql(java.lang.String&nbsp;sqlText)</pre>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>.
 The dialect that is used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sqlText</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="read()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>read</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;read()</pre>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read data and streams in as a <code>DataFrame</code>.
 <pre><code>
   sparkSession.read.parquet("/path/to/file.parquet")
   sparkSession.read.schema(schema).json("/path/to/file.json")
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="implicits()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>implicits</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SparkSession.implicits$.html" title="class in org.apache.spark.sql">SparkSession.implicits$</a>&nbsp;implicits()</pre>
<div class="block">Accessor for nested Scala object</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="stop()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>stop</h4>
<pre>public&nbsp;void&nbsp;stop()</pre>
<div class="block">Stop the underlying <code>SparkContext</code>.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="parseSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;parseSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executeSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executeSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executeSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executePlan</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
</li>
</ul>
<a name="parseDataType(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseDataType</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&nbsp;parseDataType(java.lang.String&nbsp;dataTypeString)</pre>
<div class="block">Parses the data type in our internal string representation. The data type string should
 have the same format as the one generated by <code>toString</code> in scala.
 It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>dataTypeString</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                                  java.lang.String&nbsp;schemaString)</pre>
<div class="block">Apply a schema defined by the schemaString to an RDD. It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>schemaString</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                                  <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">Apply a schema defined by the schema to an RDD. It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SourceStatus.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SparkSession.Builder.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SparkSession.html" target="_top">Frames</a></li>
<li><a href="SparkSession.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
