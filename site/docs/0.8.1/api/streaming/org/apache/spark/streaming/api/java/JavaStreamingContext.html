<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>org.apache.spark.streaming.api.java.JavaStreamingContext</title>
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link type="text/css" media="screen" rel="stylesheet" href="../../../../../../lib/template.css" />
      <script type="text/javascript" src="../../../../../../lib/jquery.js"></script>
      <script type="text/javascript" src="../../../../../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../../../../../lib/template.js"></script>
      <script type="text/javascript" src="../../../../../../lib/tools.tooltip.js"></script>
    
        </head>
        <body onload="sh_highlightDocument('../lib/', '.min.js');" class="type">
      <div id="definition">
        <img src="../../../../../../lib/class_big.png" />
        <p id="owner"><a name="org" class="extype" href="../../../../../package.html">org</a>.<a name="org.apache" class="extype" href="../../../../package.html">apache</a>.<a name="org.apache.spark" class="extype" href="../../../package.html">spark</a>.<a name="org.apache.spark.streaming" class="extype" href="../../package.html">streaming</a>.<a name="org.apache.spark.streaming.api" class="extype" href="../package.html">api</a>.<a name="org.apache.spark.streaming.api.java" class="extype" href="package.html">java</a></p>
        <h1>JavaStreamingContext</h1>
      </div>

      <h4 class="signature" id="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="result"> extends AnyRef</span>
      </span>
      </h4>
      
      <div class="fullcommenttop" id="comment"><div class="comment cmt"><p>A StreamingContext is the main entry point for Spark Streaming functionality. Besides the basic
information (such as, cluster URL and job name) to internally create a SparkContext, it provides
methods used to create DStream from various input sources.
</p></div><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent">AnyRef, <span name="scala.Any" class="extype">Any</span></div>
        </div></div>
    

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input accesskey="/" type="text" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By inheritance</span></li></ol>
            </div>
        <div id="ancestors">
              <span class="filtertype">Inherited</span>
              <ol><li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li></ol>
              <ol id="linearization"><li name="org.apache.spark.streaming.api.java.JavaStreamingContext" class="in"><span>JavaStreamingContext</span></li><li name="scala.AnyRef" class="in"><span>AnyRef</span></li><li name="scala.Any" class="in"><span>Any</span></li></ol>
            </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div class="members" id="constructors">
              <h3>Instance Constructors</h3>
              <ol><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="path">path: String</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Re-creates a StreamingContext from a checkpoint file.</p><div class="fullcomment"><div class="comment cmt"><p>Re-creates a StreamingContext from a checkpoint file.</p></div><dl class="paramcmts block"><dt class="param">path</dt><dd class="cmt"><p>Path either to the directory that was specified as the checkpoint directory, or
            to the checkpoint file 'graph' or 'graph.bk'.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="sparkContext">sparkContext: <span name="org.apache.spark.api.java.JavaSparkContext" class="extype">JavaSparkContext</span></span>, <span name="batchDuration">batchDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a StreamingContext using an existing SparkContext.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a StreamingContext using an existing SparkContext.</p></div><dl class="paramcmts block"><dt class="param">sparkContext</dt><dd class="cmt"><p>The underlying JavaSparkContext to use</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: String</span>, <span name="appName">appName: String</span>, <span name="batchDuration">batchDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="sparkHome">sparkHome: String</span>, <span name="jars">jars: <span name="scala.Array" class="extype">Array</span>[String]</span>, <span name="environment">environment: <span name="java.util.Map" class="extype">Map</span>[String, String]</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jars</dt><dd class="cmt"><p>Collection of JARs to send to the cluster. These can be paths on the local file
            system or HDFS, HTTP, HTTPS, or FTP URLs.</p></dd><dt class="param">environment</dt><dd class="cmt"><p>Environment variables to set on worker nodes
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: String</span>, <span name="appName">appName: String</span>, <span name="batchDuration">batchDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="sparkHome">sparkHome: String</span>, <span name="jars">jars: <span name="scala.Array" class="extype">Array</span>[String]</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jars</dt><dd class="cmt"><p>Collection of JARs to send to the cluster. These can be paths on the local file
            system or HDFS, HTTP, HTTPS, or FTP URLs.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: String</span>, <span name="appName">appName: String</span>, <span name="batchDuration">batchDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="sparkHome">sparkHome: String</span>, <span name="jarFile">jarFile: String</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jarFile</dt><dd class="cmt"><p>JAR file containing job code, to ship to cluster. This can be a path on the local
               file system or an HDFS, HTTP, HTTPS, or FTP URL.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: String</span>, <span name="appName">appName: String</span>, <span name="batchDuration">batchDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#this" data-isabs="false">
      <a id="this:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="ssc">ssc: <a name="org.apache.spark.streaming.StreamingContext" class="extype" href="../../StreamingContext.html">StreamingContext</a></span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div class="values members" id="values">
              <h3>Value Members</h3>
              <ol><li visbl="pub" name="scala.AnyRef#!=" data-isabs="false">
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#!=" data-isabs="false">
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef###" data-isabs="false">
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $hash$hash">##</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#==" data-isabs="false">
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#==" data-isabs="false">
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" data-isabs="false">
      <a id="actorStream[T](Props,String):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span name="akka.actor.Props" class="extype">Props</span></span>, <span name="name">name: String</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" data-isabs="false">
      <a id="actorStream[T](Props,String,StorageLevel):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span name="akka.actor.Props" class="extype">Props</span></span>, <span name="name">name: String</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" data-isabs="false">
      <a id="actorStream[T](Props,String,StorageLevel,SupervisorStrategy):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span name="akka.actor.Props" class="extype">Props</span></span>, <span name="name">name: String</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>, <span name="supervisorStrategy">supervisorStrategy: <span name="akka.actor.SupervisorStrategy" class="extype">SupervisorStrategy</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li visbl="pub" name="scala.Any#asInstanceOf" data-isabs="false">
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#checkpoint" data-isabs="false">
      <a id="checkpoint(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">checkpoint</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sets the context to periodically checkpoint the DStream operations for master
fault-tolerance.</p><div class="fullcomment"><div class="comment cmt"><p>Sets the context to periodically checkpoint the DStream operations for master
fault-tolerance. The graph will be checkpointed every batch interval.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS-compatible directory where the checkpoint data will be reliably stored
</p></dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#clone" data-isabs="false">
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: AnyRef</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#eq" data-isabs="false">
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#equals" data-isabs="false">
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#fileStream" data-isabs="false">
      <a id="fileStream[K, V, F&lt;:InputFormat[K, V]](String):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.InputFormat" class="extype">InputFormat</span>[K, V]</span>]</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.
File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#finalize" data-isabs="false">
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#flumeStream" data-isabs="false">
      <a id="flumeStream(String,Int):JavaDStream[SparkFlumeEvent]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flumeStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<a name="org.apache.spark.streaming.dstream.SparkFlumeEvent" class="extype" href="../../dstream/SparkFlumeEvent.html">SparkFlumeEvent</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream from a Flume source.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream from a Flume source.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname of the slave machine to which the flume data will be sent</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port of the slave machine to which the flume data will be sent
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#flumeStream" data-isabs="false">
      <a id="flumeStream(String,Int,StorageLevel):JavaDStream[SparkFlumeEvent]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flumeStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<a name="org.apache.spark.streaming.dstream.SparkFlumeEvent" class="extype" href="../../dstream/SparkFlumeEvent.html">SparkFlumeEvent</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream from a Flume source.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream from a Flume source.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname of the slave machine to which the flume data will be sent</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port of the slave machine to which the flume data will be sent</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#getClass" data-isabs="false">
      <a id="getClass():java.lang.Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: java.lang.Class[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#hashCode" data-isabs="false">
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#isInstanceOf" data-isabs="false">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#kafkaStream" data-isabs="false">
      <a id="kafkaStream[T, D&lt;:kafka.serializer.Decoder[_]](Class[T],Class[D],Map[String, String],Map[String, Integer],StorageLevel):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">kafkaStream</span><span class="tparams">[<span name="T">T</span>, <span name="D">D &lt;: kafka.serializer.Decoder[_]</span>]</span><span class="params">(<span name="typeClass">typeClass: Class[T]</span>, <span name="decoderClass">decoderClass: Class[D]</span>, <span name="kafkaParams">kafkaParams: <span name="java.util.Map" class="extype">Map</span>[String, String]</span>, <span name="topics">topics: <span name="java.util.Map" class="extype">Map</span>[String, <span name="java.lang.Integer" class="extype">Integer</span>]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that pulls messages form a Kafka Broker.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that pulls messages form a Kafka Broker.</p></div><dl class="paramcmts block"><dt class="param">typeClass</dt><dd class="cmt"><p>Type of RDD</p></dd><dt class="param">decoderClass</dt><dd class="cmt"><p>Type of kafka decoder</p></dd><dt class="param">kafkaParams</dt><dd class="cmt"><p>Map of kafka configuration paramaters.
                   See: http://kafka.apache.org/configuration.html</p></dd><dt class="param">topics</dt><dd class="cmt"><p>Map of (topic_name -&gt; numPartitions) to consume. Each partition is consumed
in its own thread.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>RDD storage level. Defaults to memory-only
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#kafkaStream" data-isabs="false">
      <a id="kafkaStream(String,String,Map[String, Integer],StorageLevel):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">kafkaStream</span><span class="params">(<span name="zkQuorum">zkQuorum: String</span>, <span name="groupId">groupId: String</span>, <span name="topics">topics: <span name="java.util.Map" class="extype">Map</span>[String, <span name="java.lang.Integer" class="extype">Integer</span>]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that pulls messages form a Kafka Broker.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that pulls messages form a Kafka Broker.</p></div><dl class="paramcmts block"><dt class="param">zkQuorum</dt><dd class="cmt"><p>Zookeper quorum (hostname:port,hostname:port,..).</p></dd><dt class="param">groupId</dt><dd class="cmt"><p>The group id for this consumer.</p></dd><dt class="param">topics</dt><dd class="cmt"><p>Map of (topic_name -&gt; numPartitions) to consume. Each partition is consumed
              in its own thread.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>RDD storage level. Defaults to memory-only</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#kafkaStream" data-isabs="false">
      <a id="kafkaStream(String,String,Map[String, Integer]):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">kafkaStream</span><span class="params">(<span name="zkQuorum">zkQuorum: String</span>, <span name="groupId">groupId: String</span>, <span name="topics">topics: <span name="java.util.Map" class="extype">Map</span>[String, <span name="java.lang.Integer" class="extype">Integer</span>]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that pulls messages form a Kafka Broker.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that pulls messages form a Kafka Broker.</p></div><dl class="paramcmts block"><dt class="param">zkQuorum</dt><dd class="cmt"><p>Zookeper quorum (hostname:port,hostname:port,..).</p></dd><dt class="param">groupId</dt><dd class="cmt"><p>The group id for this consumer.</p></dd><dt class="param">topics</dt><dd class="cmt"><p>Map of (topic_name -&gt; numPartitions) to consume. Each partition is consumed
in its own thread.
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#ne" data-isabs="false">
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notify" data-isabs="false">
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notifyAll" data-isabs="false">
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" data-isabs="false">
      <a id="queueStream[T](Queue[JavaRDD[T]],Boolean,JavaRDD[T]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span name="java.util.Queue" class="extype">Queue</span>[<span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[T]]</span>, <span name="oneAtATime">oneAtATime: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="defaultRDD">defaultRDD: <span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[T]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd><dt class="param">defaultRDD</dt><dd class="cmt"><p>Default RDD is returned by the DStream when the queue is empty</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" data-isabs="false">
      <a id="queueStream[T](Queue[JavaRDD[T]],Boolean):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span name="java.util.Queue" class="extype">Queue</span>[<span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[T]]</span>, <span name="oneAtATime">oneAtATime: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" data-isabs="false">
      <a id="queueStream[T](Queue[JavaRDD[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span name="java.util.Queue" class="extype">Queue</span>[<span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[T]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#rawSocketStream" data-isabs="false">
      <a id="rawSocketStream[T](String,Int):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rawSocketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them. This is the most efficient
way to receive data.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects in the received blocks
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#rawSocketStream" data-isabs="false">
      <a id="rawSocketStream[T](String,Int,StorageLevel):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rawSocketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them. This is the most efficient
way to receive data.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects in the received blocks
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#registerOutputStream" data-isabs="false">
      <a id="registerOutputStream(org.apache.spark.streaming.api.java.JavaDStreamLike[_, _, _]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">registerOutputStream</span><span class="params">(<span name="outputStream">outputStream: org.apache.spark.streaming.api.java.JavaDStreamLike[_, _, _]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Registers an output stream that will be computed every interval
</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#remember" data-isabs="false">
      <a id="remember(Duration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">remember</span><span class="params">(<span name="duration">duration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sets each DStreams in this context to remember RDDs it generated in the last given duration.</p><div class="fullcomment"><div class="comment cmt"><p>Sets each DStreams in this context to remember RDDs it generated in the last given duration.
DStreams remember RDDs only for a limited duration of duration and releases them for garbage
collection. This method allows the developer to specify how to long to remember the RDDs (
if the developer wishes to query old data outside the DStream computation).</p></div><dl class="paramcmts block"><dt class="param">duration</dt><dd class="cmt"><p>Minimum duration that each DStream should remember its RDDs
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#sc" data-isabs="false">
      <a id="sc:JavaSparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sc</span><span class="result">: <span name="org.apache.spark.api.java.JavaSparkContext" class="extype">JavaSparkContext</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">The underlying SparkContext</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketStream" data-isabs="false">
      <a id="socketStream[T](String,Int,Function[InputStream, Iterable[T]],StorageLevel):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="converter">converter: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="java.io.InputStream" class="extype">InputStream</span>, <span name="java.lang.Iterable" class="extype">Iterable</span>[T]]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes it interepreted as object using the given
converter.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects received (after converting bytes to objects)
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">converter</dt><dd class="cmt"><p>Function to convert the byte stream to objects</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketTextStream" data-isabs="false">
      <a id="socketTextStream(String,Int):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketTextStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
lines.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketTextStream" data-isabs="false">
      <a id="socketTextStream(String,Int,StorageLevel):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketTextStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
lines.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
                     (default: StorageLevel.MEMORY_AND_DISK_SER_2)
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#ssc" data-isabs="false">
      <a id="ssc:StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">ssc</span><span class="result">: <a name="org.apache.spark.streaming.StreamingContext" class="extype" href="../../StreamingContext.html">StreamingContext</a></span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#start" data-isabs="false">
      <a id="start():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">start</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Starts the execution of the streams.</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#stop" data-isabs="false">
      <a id="stop():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stop</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sstops the execution of the streams.</p>
    </li><li visbl="pub" name="scala.AnyRef#synchronized" data-isabs="false">
      <a id="synchronized[T0](⇒ T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ T0</span>)</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#textFileStream" data-isabs="false">
      <a id="textFileStream(String):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">textFileStream</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat).</p><div class="fullcomment"><div class="comment cmt"><p>Creates a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat). File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#toString" data-isabs="false">
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span name="java.lang.String" class="extype">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#transform" data-isabs="false">
      <a id="transform[K, V](List[org.apache.spark.streaming.api.java.JavaDStream[_]],Function2[List[org.apache.spark.api.java.JavaRDD[_]], Time, JavaPairRDD[K, V]]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="dstreams">dstreams: <span name="java.util.List" class="extype">List</span>[org.apache.spark.streaming.api.java.JavaDStream[_]]</span>, <span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="java.util.List" class="extype">List</span>[org.apache.spark.api.java.JavaRDD[_]], <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a>, <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams. The order of the JavaRDDs in the transform function parameter will be the
same as the order of corresponding DStreams in the list. Note that for adding a
JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
<a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>.toJavaDStream().
In the transform function, convert the JavaRDD corresponding to that JavaDStream to
a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#transform" data-isabs="false">
      <a id="transform[T](List[org.apache.spark.streaming.api.java.JavaDStream[_]],Function2[List[org.apache.spark.api.java.JavaRDD[_]], Time, JavaRDD[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="dstreams">dstreams: <span name="java.util.List" class="extype">List</span>[org.apache.spark.streaming.api.java.JavaDStream[_]]</span>, <span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="java.util.List" class="extype">List</span>[org.apache.spark.api.java.JavaRDD[_]], <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a>, <span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[T]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams. The order of the JavaRDDs in the transform function parameter will be the
same as the order of corresponding DStreams in the list. Note that for adding a
JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
<a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>.toJavaDStream().
In the transform function, convert the JavaRDD corresponding to that JavaDStream to
a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream():JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
.consumerSecret, .accessToken and .accessTokenSecret to be set.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(Authorization):JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="twitterAuth">twitterAuth: <span name="twitter4j.auth.Authorization" class="extype">Authorization</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter.</p></div><dl class="paramcmts block"><dt class="param">twitterAuth</dt><dd class="cmt"><p>Twitter4J Authorization
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(Array[String]):JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="filters">filters: <span name="scala.Array" class="extype">Array</span>[String]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
.consumerSecret, .accessToken and .accessTokenSecret to be set.</p></div><dl class="paramcmts block"><dt class="param">filters</dt><dd class="cmt"><p>Set of filter strings to get only those tweets that match them
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(Authorization,Array[String]):JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="twitterAuth">twitterAuth: <span name="twitter4j.auth.Authorization" class="extype">Authorization</span></span>, <span name="filters">filters: <span name="scala.Array" class="extype">Array</span>[String]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter.</p></div><dl class="paramcmts block"><dt class="param">twitterAuth</dt><dd class="cmt"><p>Twitter4J Authorization</p></dd><dt class="param">filters</dt><dd class="cmt"><p>Set of filter strings to get only those tweets that match them
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(Array[String],StorageLevel):JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="filters">filters: <span name="scala.Array" class="extype">Array</span>[String]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter using Twitter4J's default
OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
.consumerSecret, .accessToken and .accessTokenSecret to be set.</p></div><dl class="paramcmts block"><dt class="param">filters</dt><dd class="cmt"><p>Set of filter strings to get only those tweets that match them</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(Authorization,Array[String],StorageLevel):JavaDStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="twitterAuth">twitterAuth: <span name="twitter4j.auth.Authorization" class="extype">Authorization</span></span>, <span name="filters">filters: <span name="scala.Array" class="extype">Array</span>[String]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter.</p></div><dl class="paramcmts block"><dt class="param">twitterAuth</dt><dd class="cmt"><p>Twitter4J Authorization object</p></dd><dt class="param">filters</dt><dd class="cmt"><p>Set of filter strings to get only those tweets that match them</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#union" data-isabs="false">
      <a id="union[K, V](JavaPairDStream[K, V],List[JavaPairDStream[K, V]]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="first">first: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>[K, V]</span>, <span name="rest">rest: <span name="java.util.List" class="extype">List</span>[<a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>[K, V]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="JavaPairDStream.html">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a unified DStream from multiple DStreams of the same type and same slide duration.</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#union" data-isabs="false">
      <a id="union[T](JavaDStream[T],List[JavaDStream[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="first">first: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>, <span name="rest">rest: <span name="java.util.List" class="extype">List</span>[<a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a unified DStream from multiple DStreams of the same type and same slide duration.</p>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#zeroMQStream" data-isabs="false">
      <a id="zeroMQStream[T](String,Subscribe,Function[Array[Array[Byte]], Iterable[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">zeroMQStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="publisherUrl">publisherUrl: String</span>, <span name="subscribe">subscribe: <span name="akka.zeromq.Subscribe" class="extype">Subscribe</span></span>, <span name="bytesToObjects">bytesToObjects: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Byte" class="extype">Byte</span>]], <span name="java.lang.Iterable" class="extype">Iterable</span>[T]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that receives messages pushed by a zeromq publisher.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that receives messages pushed by a zeromq publisher.</p></div><dl class="paramcmts block"><dt class="param">publisherUrl</dt><dd class="cmt"><p>Url of remote zeromq publisher</p></dd><dt class="param">subscribe</dt><dd class="cmt"><p>topic to subscribe to</p></dd><dt class="param">bytesToObjects</dt><dd class="cmt"><p>A zeroMQ stream publishes sequence of frames for each topic and each frame has sequence
                      of byte thus it needs the converter(which might be deserializer of bytes)
                      to translate from sequence of sequence of bytes, where sequence refer to a frame
                      and sub sequence refer to its payload.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#zeroMQStream" data-isabs="false">
      <a id="zeroMQStream[T](String,Subscribe,Function[Array[Array[Byte]], Iterable[T]],StorageLevel):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">zeroMQStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="publisherUrl">publisherUrl: String</span>, <span name="subscribe">subscribe: <span name="akka.zeromq.Subscribe" class="extype">Subscribe</span></span>, <span name="bytesToObjects">bytesToObjects: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Byte" class="extype">Byte</span>]], <span name="java.lang.Iterable" class="extype">Iterable</span>[T]]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that receives messages pushed by a zeromq publisher.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that receives messages pushed by a zeromq publisher.</p></div><dl class="paramcmts block"><dt class="param">publisherUrl</dt><dd class="cmt"><p>Url of remote zeromq publisher</p></dd><dt class="param">subscribe</dt><dd class="cmt"><p>topic to subscribe to</p></dd><dt class="param">bytesToObjects</dt><dd class="cmt"><p>A zeroMQ stream publishes sequence of frames for each topic and each frame has sequence
                      of byte thus it needs the converter(which might be deserializer of bytes)
                      to translate from sequence of sequence of bytes, where sequence refer to a frame
                      and sub sequence refer to its payload.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>RDD storage level. Defaults to memory-only.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaStreamingContext#zeroMQStream" data-isabs="false">
      <a id="zeroMQStream[T](String,Subscribe,(Seq[Seq[Byte]]) ⇒ Iterator[T],StorageLevel,SupervisorStrategy):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">zeroMQStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="publisherUrl">publisherUrl: String</span>, <span name="subscribe">subscribe: <span name="akka.zeromq.Subscribe" class="extype">Subscribe</span></span>, <span name="bytesToObjects">bytesToObjects: (Seq[Seq[<span name="scala.Byte" class="extype">Byte</span>]]) ⇒ Iterator[T]</span>, <span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>, <span name="supervisorStrategy">supervisorStrategy: <span name="akka.actor.SupervisorStrategy" class="extype">SupervisorStrategy</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that receives messages pushed by a zeromq publisher.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that receives messages pushed by a zeromq publisher.</p></div><dl class="paramcmts block"><dt class="param">publisherUrl</dt><dd class="cmt"><p>Url of remote zeromq publisher</p></dd><dt class="param">subscribe</dt><dd class="cmt"><p>topic to subscribe to</p></dd><dt class="param">bytesToObjects</dt><dd class="cmt"><p>A zeroMQ stream publishes sequence of frames for each topic and each frame has sequence
                      of byte thus it needs the converter(which might be deserializer of bytes)
                      to translate from sequence of sequence of bytes, where sequence refer to a frame
                      and sub sequence refer to its payload.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li></ol>
            </div>

        
        </div>

        <div id="inheritedMembers">
        <div name="scala.AnyRef" class="parent">
              <h3>Inherited from AnyRef</h3>
            </div><div name="scala.Any" class="parent">
              <h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3>
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>