<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Tue Feb 03 03:51:45 UTC 2015 -->
<title>SQLConf (Spark 1.2.1 JavaDoc)</title>
<meta name="date" content="2015-02-03">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SQLConf (Spark 1.2.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLConf.html" target="_top">Frames</a></li>
<li><a href="SQLConf.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Interface SQLConf" class="title">Interface SQLConf</h2>
</div>
<div class="contentContainer">
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Known Implementing Classes:</dt>
<dd><a href="../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>, <a href="../../../../org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive">LocalHiveContext</a>, <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>, <a href="../../../../org/apache/spark/sql/hive/test/TestHive.html" title="class in org.apache.spark.sql.hive.test">TestHive</a>, <a href="../../../../org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a>, <a href="../../../../org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test">TestSQLContext</a></dd>
</dl>
<hr>
<br>
<pre>public interface <span class="strong">SQLConf</span></pre>
<div class="block">A trait that enables the setting and getting of mutable config parameters/hints.
 <p>
 In the presence of a SQLContext, these can be set and queried by passing SET commands
 into Spark SQL's query functions (i.e. sql()). Otherwise, users of this trait can
 modify the hints by programmatically calling the setters and getters of this trait.
 <p>
 SQLConf is thread-safe (internally synchronized, so safe to be used in multiple threads).</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Interface and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql">SQLConf.Deprecated$</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#autoBroadcastJoinThreshold()">autoBroadcastJoinThreshold</a></strong>()</code>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#clear()">clear</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#codegenEnabled()">codegenEnabled</a></strong>()</code>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#columnBatchSize()">columnBatchSize</a></strong>()</code>
<div class="block">The number of rows that will be</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#columnNameOfCorruptRecord()">columnNameOfCorruptRecord</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#defaultSizeInBytes()">defaultSizeInBytes</a></strong>()</code>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#dialect()">dialect</a></strong>()</code>
<div class="block">The SQL dialect that is used when parsing queries.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#externalSortEnabled()">externalSortEnabled</a></strong>()</code>
<div class="block">When true the planner will use the external sort, which may spill to disk.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#getAllConfs()">getAllConfs</a></strong>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String)">getConf</a></strong>(String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String, java.lang.String)">getConf</a></strong>(String&nbsp;key,
       String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#inMemoryPartitionPruning()">inMemoryPartitionPruning</a></strong>()</code>
<div class="block">When set to true, partition pruning for in-memory columnar tables is enabled.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#isParquetBinaryAsString()">isParquetBinaryAsString</a></strong>()</code>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#numShufflePartitions()">numShufflePartitions</a></strong>()</code>
<div class="block">Number of partitions to use for shuffle operators.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#parquetCompressionCodec()">parquetCompressionCodec</a></strong>()</code>
<div class="block">The compression codec for writing to a Parquetfile</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#parquetFilterPushDown()">parquetFilterPushDown</a></strong>()</code>
<div class="block">When true predicates will be passed to the parquet record reader when possible.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#setConf(java.util.Properties)">setConf</a></strong>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#setConf(java.lang.String, java.lang.String)">setConf</a></strong>(String&nbsp;key,
       String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#settings()">settings</a></strong>()</code>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLConf.html#useCompression()">useCompression</a></strong>()</code>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</td>
</tr>
</table>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="settings()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>settings</h4>
<pre>java.util.Map&lt;String,String&gt;&nbsp;settings()</pre>
<div class="block">Only low degree of contention is expected for conf, thus NOT using ConcurrentHashMap.</div>
</li>
</ul>
<a name="dialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dialect</h4>
<pre>String&nbsp;dialect()</pre>
<div class="block">The SQL dialect that is used when parsing queries.  This defaults to 'sql' which uses
 a simple SQL parser provided by Spark SQL.  This is currently the only option for users of
 SQLContext.
 <p>
 When using a HiveContext, this value defaults to 'hiveql', which uses the Hive 0.12.0 HiveQL
 parser.  Users can change this to 'sql' if they want to run queries that aren't supported by
 HiveQL (e.g., SELECT 1).
 <p>
 Note that the choice of dialect does not affect things like what tables are available or
 how query execution is performed.</div>
</li>
</ul>
<a name="useCompression()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useCompression</h4>
<pre>boolean&nbsp;useCompression()</pre>
<div class="block">When true tables cached using the in-memory columnar caching will be compressed.</div>
</li>
</ul>
<a name="parquetCompressionCodec()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetCompressionCodec</h4>
<pre>String&nbsp;parquetCompressionCodec()</pre>
<div class="block">The compression codec for writing to a Parquetfile</div>
</li>
</ul>
<a name="columnBatchSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>columnBatchSize</h4>
<pre>int&nbsp;columnBatchSize()</pre>
<div class="block">The number of rows that will be</div>
</li>
</ul>
<a name="numShufflePartitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numShufflePartitions</h4>
<pre>int&nbsp;numShufflePartitions()</pre>
<div class="block">Number of partitions to use for shuffle operators.</div>
</li>
</ul>
<a name="parquetFilterPushDown()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetFilterPushDown</h4>
<pre>boolean&nbsp;parquetFilterPushDown()</pre>
<div class="block">When true predicates will be passed to the parquet record reader when possible.</div>
</li>
</ul>
<a name="externalSortEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>externalSortEnabled</h4>
<pre>boolean&nbsp;externalSortEnabled()</pre>
<div class="block">When true the planner will use the external sort, which may spill to disk.</div>
</li>
</ul>
<a name="codegenEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>codegenEnabled</h4>
<pre>boolean&nbsp;codegenEnabled()</pre>
<div class="block">When set to true, Spark SQL will use the Scala compiler at runtime to generate custom bytecode
 that evaluates expressions found in queries.  In general this custom code runs much faster
 than interpreted evaluation, but there are significant start-up costs due to compilation.
 As a result codegen is only beneficial when queries run for a long time, or when the same
 expressions are used multiple times.
 <p>
 Defaults to false as this feature is currently experimental.</div>
</li>
</ul>
<a name="autoBroadcastJoinThreshold()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>autoBroadcastJoinThreshold</h4>
<pre>int&nbsp;autoBroadcastJoinThreshold()</pre>
<div class="block">Upper bound on the sizes (in bytes) of the tables qualified for the auto conversion to
 a broadcast value during the physical executions of join operations.  Setting this to -1
 effectively disables auto conversion.
 <p>
 Hive setting: hive.auto.convert.join.noconditionaltask.size, whose default value is 10000.</div>
</li>
</ul>
<a name="defaultSizeInBytes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultSizeInBytes</h4>
<pre>long&nbsp;defaultSizeInBytes()</pre>
<div class="block">The default size in bytes to assign to a logical operator's estimation statistics.  By default,
 it is set to a larger value than <code>autoBroadcastJoinThreshold</code>, hence any logical operator
 without a properly implemented estimation of this statistic will not be incorrectly broadcasted
 in joins.</div>
</li>
</ul>
<a name="isParquetBinaryAsString()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isParquetBinaryAsString</h4>
<pre>boolean&nbsp;isParquetBinaryAsString()</pre>
<div class="block">When set to true, we always treat byte arrays in Parquet files as strings.</div>
</li>
</ul>
<a name="inMemoryPartitionPruning()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>inMemoryPartitionPruning</h4>
<pre>boolean&nbsp;inMemoryPartitionPruning()</pre>
<div class="block">When set to true, partition pruning for in-memory columnar tables is enabled.</div>
</li>
</ul>
<a name="columnNameOfCorruptRecord()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>columnNameOfCorruptRecord</h4>
<pre>String&nbsp;columnNameOfCorruptRecord()</pre>
</li>
</ul>
<a name="setConf(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.</div>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>void&nbsp;setConf(String&nbsp;key,
           String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.</div>
</li>
</ul>
<a name="getConf(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>String&nbsp;getConf(String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</li>
</ul>
<a name="getConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>String&nbsp;getConf(String&nbsp;key,
             String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.</div>
</li>
</ul>
<a name="getAllConfs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>scala.collection.immutable.Map&lt;String,String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.</div>
</li>
</ul>
<a name="clear()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>clear</h4>
<pre>void&nbsp;clear()</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLConf.html" target="_top">Frames</a></li>
<li><a href="SQLConf.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
