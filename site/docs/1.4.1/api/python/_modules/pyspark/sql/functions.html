<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pyspark.sql.functions &mdash; PySpark 1.4.1 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.4.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="PySpark 1.4.1 documentation" href="../../../index.html" />
    <link rel="up" title="pyspark.sql" href="../sql.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li><a href="../../../index.html">PySpark 1.4.1 documentation</a> &raquo;</li>
          <li><a href="../../index.html" >Module code</a> &raquo;</li>
          <li><a href="../../pyspark.html" >pyspark</a> &raquo;</li>
          <li><a href="../sql.html" accesskey="U">pyspark.sql</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pyspark.sql.functions</h1><div class="highlight"><pre>
<span class="c">#</span>
<span class="c"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c"># this work for additional information regarding copyright ownership.</span>
<span class="c"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c"># the License.  You may obtain a copy of the License at</span>
<span class="c">#</span>
<span class="c">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c">#</span>
<span class="c"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c"># See the License for the specific language governing permissions and</span>
<span class="c"># limitations under the License.</span>
<span class="c">#</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A collections of builtin functions</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">&lt;</span> <span class="s">&quot;3&quot;</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">imap</span> <span class="k">as</span> <span class="nb">map</span>

<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.rdd</span> <span class="kn">import</span> <span class="n">_prepare_for_python_RDD</span><span class="p">,</span> <span class="n">ignore_unicode_prefix</span>
<span class="kn">from</span> <span class="nn">pyspark.serializers</span> <span class="kn">import</span> <span class="n">PickleSerializer</span><span class="p">,</span> <span class="n">AutoBatchedSerializer</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">since</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.column</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">,</span> <span class="n">_to_seq</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&#39;array&#39;</span><span class="p">,</span>
    <span class="s">&#39;approxCountDistinct&#39;</span><span class="p">,</span>
    <span class="s">&#39;coalesce&#39;</span><span class="p">,</span>
    <span class="s">&#39;countDistinct&#39;</span><span class="p">,</span>
    <span class="s">&#39;explode&#39;</span><span class="p">,</span>
    <span class="s">&#39;monotonicallyIncreasingId&#39;</span><span class="p">,</span>
    <span class="s">&#39;rand&#39;</span><span class="p">,</span>
    <span class="s">&#39;randn&#39;</span><span class="p">,</span>
    <span class="s">&#39;sparkPartitionId&#39;</span><span class="p">,</span>
    <span class="s">&#39;struct&#39;</span><span class="p">,</span>
    <span class="s">&#39;udf&#39;</span><span class="p">,</span>
    <span class="s">&#39;when&#39;</span><span class="p">]</span>

<span class="n">__all__</span> <span class="o">+=</span> <span class="p">[</span><span class="s">&#39;lag&#39;</span><span class="p">,</span> <span class="s">&#39;lead&#39;</span><span class="p">,</span> <span class="s">&#39;ntile&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_create_function</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Create a function for aggregator by name&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span> <span class="n">name</span><span class="p">)(</span><span class="n">col</span><span class="o">.</span><span class="n">_jc</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">Column</span><span class="p">)</span> <span class="k">else</span> <span class="n">col</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">doc</span>
    <span class="k">return</span> <span class="n">_</span>


<span class="k">def</span> <span class="nf">_create_binary_mathfunction</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Create a binary mathfunction by name&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">):</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
        <span class="c"># users might write ints for simplicity. This would throw an error on the JVM side.</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span> <span class="n">name</span><span class="p">)(</span><span class="n">col1</span><span class="o">.</span><span class="n">_jc</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">Column</span><span class="p">)</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="n">col1</span><span class="p">),</span>
                                              <span class="n">col2</span><span class="o">.</span><span class="n">_jc</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col2</span><span class="p">,</span> <span class="n">Column</span><span class="p">)</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="n">col2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">doc</span>
    <span class="k">return</span> <span class="n">_</span>


<span class="k">def</span> <span class="nf">_create_window_function</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Create a window function by name &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span> <span class="n">name</span><span class="p">)()</span>
        <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">_</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="s">&#39;Window function: &#39;</span> <span class="o">+</span> <span class="n">doc</span>
    <span class="k">return</span> <span class="n">_</span>


<span class="n">_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;lit&#39;</span><span class="p">:</span> <span class="s">&#39;Creates a :class:`Column` of literal value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;col&#39;</span><span class="p">:</span> <span class="s">&#39;Returns a :class:`Column` based on the given column name.&#39;</span><span class="p">,</span>
    <span class="s">&#39;column&#39;</span><span class="p">:</span> <span class="s">&#39;Returns a :class:`Column` based on the given column name.&#39;</span><span class="p">,</span>
    <span class="s">&#39;asc&#39;</span><span class="p">:</span> <span class="s">&#39;Returns a sort expression based on the ascending order of the given column name.&#39;</span><span class="p">,</span>
    <span class="s">&#39;desc&#39;</span><span class="p">:</span> <span class="s">&#39;Returns a sort expression based on the descending order of the given column name.&#39;</span><span class="p">,</span>

    <span class="s">&#39;upper&#39;</span><span class="p">:</span> <span class="s">&#39;Converts a string expression to upper case.&#39;</span><span class="p">,</span>
    <span class="s">&#39;lower&#39;</span><span class="p">:</span> <span class="s">&#39;Converts a string expression to upper case.&#39;</span><span class="p">,</span>
    <span class="s">&#39;sqrt&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the square root of the specified float value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;abs&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the absolute value.&#39;</span><span class="p">,</span>

    <span class="s">&#39;max&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the maximum value of the expression in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;min&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the minimum value of the expression in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;first&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the first value in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;last&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the last value in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;count&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the number of items in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;sum&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the sum of all values in the expression.&#39;</span><span class="p">,</span>
    <span class="s">&#39;avg&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the average of the values in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;mean&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the average of the values in a group.&#39;</span><span class="p">,</span>
    <span class="s">&#39;sumDistinct&#39;</span><span class="p">:</span> <span class="s">&#39;Aggregate function: returns the sum of distinct values in the expression.&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_functions_1_4</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c"># unary math functions</span>
    <span class="s">&#39;acos&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the cosine inverse of the given value; the returned angle is in the range&#39;</span> <span class="o">+</span>
            <span class="s">&#39;0.0 through pi.&#39;</span><span class="p">,</span>
    <span class="s">&#39;asin&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the sine inverse of the given value; the returned angle is in the range&#39;</span> <span class="o">+</span>
            <span class="s">&#39;-pi/2 through pi/2.&#39;</span><span class="p">,</span>
    <span class="s">&#39;atan&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the tangent inverse of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;cbrt&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the cube-root of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;ceil&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the ceiling of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;cos&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the cosine of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;cosh&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the hyperbolic cosine of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;exp&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the exponential of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;expm1&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the exponential of the given value minus one.&#39;</span><span class="p">,</span>
    <span class="s">&#39;floor&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the floor of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;log&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the natural logarithm of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;log10&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the logarithm of the given value in Base 10.&#39;</span><span class="p">,</span>
    <span class="s">&#39;log1p&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the natural logarithm of the given value plus one.&#39;</span><span class="p">,</span>
    <span class="s">&#39;rint&#39;</span><span class="p">:</span> <span class="s">&#39;Returns the double value that is closest in value to the argument and&#39;</span> <span class="o">+</span>
            <span class="s">&#39; is equal to a mathematical integer.&#39;</span><span class="p">,</span>
    <span class="s">&#39;signum&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the signum of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;sin&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the sine of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;sinh&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the hyperbolic sine of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;tan&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the tangent of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;tanh&#39;</span><span class="p">:</span> <span class="s">&#39;Computes the hyperbolic tangent of the given value.&#39;</span><span class="p">,</span>
    <span class="s">&#39;toDegrees&#39;</span><span class="p">:</span> <span class="s">&#39;Converts an angle measured in radians to an approximately equivalent angle &#39;</span> <span class="o">+</span>
                 <span class="s">&#39;measured in degrees.&#39;</span><span class="p">,</span>
    <span class="s">&#39;toRadians&#39;</span><span class="p">:</span> <span class="s">&#39;Converts an angle measured in degrees to an approximately equivalent angle &#39;</span> <span class="o">+</span>
                 <span class="s">&#39;measured in radians.&#39;</span><span class="p">,</span>

    <span class="s">&#39;bitwiseNOT&#39;</span><span class="p">:</span> <span class="s">&#39;Computes bitwise not.&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># math functions that take two arguments as input</span>
<span class="n">_binary_mathfunctions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;atan2&#39;</span><span class="p">:</span> <span class="s">&#39;Returns the angle theta from the conversion of rectangular coordinates (x, y) to&#39;</span> <span class="o">+</span>
             <span class="s">&#39;polar coordinates (r, theta).&#39;</span><span class="p">,</span>
    <span class="s">&#39;hypot&#39;</span><span class="p">:</span> <span class="s">&#39;Computes `sqrt(a^2^ + b^2^)` without intermediate overflow or underflow.&#39;</span><span class="p">,</span>
    <span class="s">&#39;pow&#39;</span><span class="p">:</span> <span class="s">&#39;Returns the value of the first argument raised to the power of the second argument.&#39;</span>
<span class="p">}</span>

<span class="n">_window_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;rowNumber&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;returns a sequential number starting at 1 within a window partition.</span>

<span class="sd">        This is equivalent to the ROW_NUMBER function in SQL.&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s">&#39;denseRank&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;returns the rank of rows within a window partition, without any gaps.</span>

<span class="sd">        The difference between rank and denseRank is that denseRank leaves no gaps in ranking</span>
<span class="sd">        sequence when there are ties. That is, if you were ranking a competition using denseRank</span>
<span class="sd">        and had three people tie for second place, you would say that all three were in second</span>
<span class="sd">        place and that the next person came in third.</span>

<span class="sd">        This is equivalent to the DENSE_RANK function in SQL.&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s">&#39;rank&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;returns the rank of rows within a window partition.</span>

<span class="sd">        The difference between rank and denseRank is that denseRank leaves no gaps in ranking</span>
<span class="sd">        sequence when there are ties. That is, if you were ranking a competition using denseRank</span>
<span class="sd">        and had three people tie for second place, you would say that all three were in second</span>
<span class="sd">        place and that the next person came in third.</span>

<span class="sd">        This is equivalent to the RANK function in SQL.&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s">&#39;cumeDist&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;returns the cumulative distribution of values within a window partition,</span>
<span class="sd">        i.e. the fraction of rows that are below the current row.</span>

<span class="sd">        This is equivalent to the CUME_DIST function in SQL.&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s">&#39;percentRank&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;returns the relative rank (i.e. percentile) of rows within a window partition.</span>

<span class="sd">        This is equivalent to the PERCENT_RANK function in SQL.&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span> <span class="ow">in</span> <span class="n">_functions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">since</span><span class="p">(</span><span class="mf">1.3</span><span class="p">)(</span><span class="n">_create_function</span><span class="p">(</span><span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span> <span class="ow">in</span> <span class="n">_functions_1_4</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)(</span><span class="n">_create_function</span><span class="p">(</span><span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span> <span class="ow">in</span> <span class="n">_binary_mathfunctions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)(</span><span class="n">_create_binary_mathfunction</span><span class="p">(</span><span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span><span class="p">))</span>
<span class="k">for</span> <span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span> <span class="ow">in</span> <span class="n">_window_functions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">globals</span><span class="p">()[</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)(</span><span class="n">_create_window_function</span><span class="p">(</span><span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span><span class="p">))</span>
<span class="k">del</span> <span class="n">_name</span><span class="p">,</span> <span class="n">_doc</span>
<span class="n">__all__</span> <span class="o">+=</span> <span class="n">_functions</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">__all__</span> <span class="o">+=</span> <span class="n">_functions_1_4</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">__all__</span> <span class="o">+=</span> <span class="n">_binary_mathfunctions</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">__all__</span> <span class="o">+=</span> <span class="n">_window_functions</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">__all__</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>


<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="array"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.array">[docs]</a><span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="o">*</span><span class="n">cols</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new array column.</span>

<span class="sd">    :param cols: list of column names (string) or list of :class:`Column` expressions that have</span>
<span class="sd">        the same data type.</span>

<span class="sd">    &gt;&gt;&gt; df.select(array(&#39;age&#39;, &#39;age&#39;).alias(&quot;arr&quot;)).collect()</span>
<span class="sd">    [Row(arr=[2, 2]), Row(arr=[5, 5])]</span>
<span class="sd">    &gt;&gt;&gt; df.select(array([df.age, df.age]).alias(&quot;arr&quot;)).collect()</span>
<span class="sd">    [Row(arr=[2, 2]), Row(arr=[5, 5])]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cols</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">set</span><span class="p">)):</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">_to_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.3</span><span class="p">)</span>
<div class="viewcode-block" id="approxCountDistinct"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.approxCountDistinct">[docs]</a><span class="k">def</span> <span class="nf">approxCountDistinct</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">rsd</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a new :class:`Column` for approximate distinct count of ``col``.</span>

<span class="sd">    &gt;&gt;&gt; df.agg(approxCountDistinct(df.age).alias(&#39;c&#39;)).collect()</span>
<span class="sd">    [Row(c=2)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="n">rsd</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">approxCountDistinct</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">approxCountDistinct</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">),</span> <span class="n">rsd</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="coalesce"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.coalesce">[docs]</a><span class="k">def</span> <span class="nf">coalesce</span><span class="p">(</span><span class="o">*</span><span class="n">cols</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the first column that is not null.</span>

<span class="sd">    &gt;&gt;&gt; cDf = sqlContext.createDataFrame([(None, None), (1, None), (None, 2)], (&quot;a&quot;, &quot;b&quot;))</span>
<span class="sd">    &gt;&gt;&gt; cDf.show()</span>
<span class="sd">    +----+----+</span>
<span class="sd">    |   a|   b|</span>
<span class="sd">    +----+----+</span>
<span class="sd">    |null|null|</span>
<span class="sd">    |   1|null|</span>
<span class="sd">    |null|   2|</span>
<span class="sd">    +----+----+</span>

<span class="sd">    &gt;&gt;&gt; cDf.select(coalesce(cDf[&quot;a&quot;], cDf[&quot;b&quot;])).show()</span>
<span class="sd">    +-------------+</span>
<span class="sd">    |Coalesce(a,b)|</span>
<span class="sd">    +-------------+</span>
<span class="sd">    |         null|</span>
<span class="sd">    |            1|</span>
<span class="sd">    |            2|</span>
<span class="sd">    +-------------+</span>

<span class="sd">    &gt;&gt;&gt; cDf.select(&#39;*&#39;, coalesce(cDf[&quot;a&quot;], lit(0.0))).show()</span>
<span class="sd">    +----+----+---------------+</span>
<span class="sd">    |   a|   b|Coalesce(a,0.0)|</span>
<span class="sd">    +----+----+---------------+</span>
<span class="sd">    |null|null|            0.0|</span>
<span class="sd">    |   1|null|            1.0|</span>
<span class="sd">    |null|   2|            0.0|</span>
<span class="sd">    +----+----+---------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="n">_to_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.3</span><span class="p">)</span>
<div class="viewcode-block" id="countDistinct"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.countDistinct">[docs]</a><span class="k">def</span> <span class="nf">countDistinct</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="o">*</span><span class="n">cols</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a new :class:`Column` for distinct count of ``col`` or ``cols``.</span>

<span class="sd">    &gt;&gt;&gt; df.agg(countDistinct(df.age, df.name).alias(&#39;c&#39;)).collect()</span>
<span class="sd">    [Row(c=2)]</span>

<span class="sd">    &gt;&gt;&gt; df.agg(countDistinct(&quot;age&quot;, &quot;name&quot;).alias(&#39;c&#39;)).collect()</span>
<span class="sd">    [Row(c=2)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">countDistinct</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">),</span> <span class="n">_to_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="explode"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.explode">[docs]</a><span class="k">def</span> <span class="nf">explode</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a new row for each element in the given array or map.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.sql import Row</span>
<span class="sd">    &gt;&gt;&gt; eDF = sqlContext.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={&quot;a&quot;: &quot;b&quot;})])</span>
<span class="sd">    &gt;&gt;&gt; eDF.select(explode(eDF.intlist).alias(&quot;anInt&quot;)).collect()</span>
<span class="sd">    [Row(anInt=1), Row(anInt=2), Row(anInt=3)]</span>

<span class="sd">    &gt;&gt;&gt; eDF.select(explode(eDF.mapfield).alias(&quot;key&quot;, &quot;value&quot;)).show()</span>
<span class="sd">    +---+-----+</span>
<span class="sd">    |key|value|</span>
<span class="sd">    +---+-----+</span>
<span class="sd">    |  a|    b|</span>
<span class="sd">    +---+-----+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">explode</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="monotonicallyIncreasingId"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.monotonicallyIncreasingId">[docs]</a><span class="k">def</span> <span class="nf">monotonicallyIncreasingId</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;A column that generates monotonically increasing 64-bit integers.</span>

<span class="sd">    The generated ID is guaranteed to be monotonically increasing and unique, but not consecutive.</span>
<span class="sd">    The current implementation puts the partition ID in the upper 31 bits, and the record number</span>
<span class="sd">    within each partition in the lower 33 bits. The assumption is that the data frame has</span>
<span class="sd">    less than 1 billion partitions, and each partition has less than 8 billion records.</span>

<span class="sd">    As an example, consider a :class:`DataFrame` with two partitions, each with 3 records.</span>
<span class="sd">    This expression would return the following IDs:</span>
<span class="sd">    0, 1, 2, 8589934592 (1L &lt;&lt; 33), 8589934593, 8589934594.</span>

<span class="sd">    &gt;&gt;&gt; df0 = sc.parallelize(range(2), 2).mapPartitions(lambda x: [(1,), (2,), (3,)]).toDF([&#39;col1&#39;])</span>
<span class="sd">    &gt;&gt;&gt; df0.select(monotonicallyIncreasingId().alias(&#39;id&#39;)).collect()</span>
<span class="sd">    [Row(id=0), Row(id=1), Row(id=2), Row(id=8589934592), Row(id=8589934593), Row(id=8589934594)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">monotonicallyIncreasingId</span><span class="p">())</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="rand"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.rand">[docs]</a><span class="k">def</span> <span class="nf">rand</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates a random column with i.i.d. samples from U[0.0, 1.0].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="n">seed</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="randn"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.randn">[docs]</a><span class="k">def</span> <span class="nf">randn</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates a column with i.i.d. samples from the standard normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="n">seed</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="sparkPartitionId"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.sparkPartitionId">[docs]</a><span class="k">def</span> <span class="nf">sparkPartitionId</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;A column for partition ID of the Spark task.</span>

<span class="sd">    Note that this is indeterministic because it depends on data partitioning and task scheduling.</span>

<span class="sd">    &gt;&gt;&gt; df.repartition(1).select(sparkPartitionId().alias(&quot;pid&quot;)).collect()</span>
<span class="sd">    [Row(pid=0), Row(pid=0)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">sparkPartitionId</span><span class="p">())</span>

</div>
<span class="nd">@ignore_unicode_prefix</span>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="struct"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.struct">[docs]</a><span class="k">def</span> <span class="nf">struct</span><span class="p">(</span><span class="o">*</span><span class="n">cols</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new struct column.</span>

<span class="sd">    :param cols: list of column names (string) or list of :class:`Column` expressions</span>
<span class="sd">        that are named or aliased.</span>

<span class="sd">    &gt;&gt;&gt; df.select(struct(&#39;age&#39;, &#39;name&#39;).alias(&quot;struct&quot;)).collect()</span>
<span class="sd">    [Row(struct=Row(age=2, name=u&#39;Alice&#39;)), Row(struct=Row(age=5, name=u&#39;Bob&#39;))]</span>
<span class="sd">    &gt;&gt;&gt; df.select(struct([df.age, df.name]).alias(&quot;struct&quot;)).collect()</span>
<span class="sd">    [Row(struct=Row(age=2, name=u&#39;Alice&#39;)), Row(struct=Row(age=5, name=u&#39;Bob&#39;))]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cols</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">set</span><span class="p">)):</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">struct</span><span class="p">(</span><span class="n">_to_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="when"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.when">[docs]</a><span class="k">def</span> <span class="nf">when</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates a list of conditions and returns one of multiple possible result expressions.</span>
<span class="sd">    If :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.</span>

<span class="sd">    :param condition: a boolean :class:`Column` expression.</span>
<span class="sd">    :param value: a literal value, or a :class:`Column` expression.</span>

<span class="sd">    &gt;&gt;&gt; df.select(when(df[&#39;age&#39;] == 2, 3).otherwise(4).alias(&quot;age&quot;)).collect()</span>
<span class="sd">    [Row(age=3), Row(age=4)]</span>

<span class="sd">    &gt;&gt;&gt; df.select(when(df.age == 2, df.age + 1).alias(&quot;age&quot;)).collect()</span>
<span class="sd">    [Row(age=3), Row(age=None)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">Column</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s">&quot;condition should be a Column&quot;</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">_jc</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Column</span><span class="p">)</span> <span class="k">else</span> <span class="n">value</span>
    <span class="n">jc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">condition</span><span class="o">.</span><span class="n">_jc</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="lag"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.lag">[docs]</a><span class="k">def</span> <span class="nf">lag</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Window function: returns the value that is `offset` rows before the current row, and</span>
<span class="sd">    `defaultValue` if there is less than `offset` rows before the current row. For example,</span>
<span class="sd">    an `offset` of one will return the previous row at any given point in the window partition.</span>

<span class="sd">    This is equivalent to the LAG function in SQL.</span>

<span class="sd">    :param col: name of column or expression</span>
<span class="sd">    :param count: number of row to extend</span>
<span class="sd">    :param default: default value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">lag</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">default</span><span class="p">))</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="lead"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.lead">[docs]</a><span class="k">def</span> <span class="nf">lead</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Window function: returns the value that is `offset` rows after the current row, and</span>
<span class="sd">    `defaultValue` if there is less than `offset` rows after the current row. For example,</span>
<span class="sd">    an `offset` of one will return the next row at any given point in the window partition.</span>

<span class="sd">    This is equivalent to the LEAD function in SQL.</span>

<span class="sd">    :param col: name of column or expression</span>
<span class="sd">    :param count: number of row to extend</span>
<span class="sd">    :param default: default value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">lead</span><span class="p">(</span><span class="n">_to_java_column</span><span class="p">(</span><span class="n">col</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">default</span><span class="p">))</span>

</div>
<span class="nd">@since</span><span class="p">(</span><span class="mf">1.4</span><span class="p">)</span>
<div class="viewcode-block" id="ntile"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.ntile">[docs]</a><span class="k">def</span> <span class="nf">ntile</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Window function: returns a group id from 1 to `n` (inclusive) in a round-robin fashion in</span>
<span class="sd">    a window partition. Fow example, if `n` is 3, the first row will get 1, the second row will</span>
<span class="sd">    get 2, the third row will get 3, and the fourth row will get 1...</span>

<span class="sd">    This is equivalent to the NTILE function in SQL.</span>

<span class="sd">    :param n: an integer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">ntile</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>

</div>
<span class="k">class</span> <span class="nc">UserDefinedFunction</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    User defined function in Python</span>

<span class="sd">    .. versionadded:: 1.3</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">returnType</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returnType</span> <span class="o">=</span> <span class="n">returnType</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_judf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_judf</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_create_judf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span>  <span class="c"># put it in closure `func`</span>
        <span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="n">it</span><span class="p">:</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">),</span> <span class="n">it</span><span class="p">)</span>
        <span class="n">ser</span> <span class="o">=</span> <span class="n">AutoBatchedSerializer</span><span class="p">(</span><span class="n">PickleSerializer</span><span class="p">())</span>
        <span class="n">command</span> <span class="o">=</span> <span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">ser</span><span class="p">,</span> <span class="n">ser</span><span class="p">)</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
        <span class="n">pickled_command</span><span class="p">,</span> <span class="n">broadcast_vars</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">includes</span> <span class="o">=</span> <span class="n">_prepare_for_python_RDD</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">command</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="n">ssql_ctx</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">_jsc</span><span class="o">.</span><span class="n">sc</span><span class="p">())</span>
        <span class="n">jdt</span> <span class="o">=</span> <span class="n">ssql_ctx</span><span class="o">.</span><span class="n">parseDataType</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">returnType</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s">&#39;__name__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">f</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span>
        <span class="n">judf</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">UserDefinedPythonFunction</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="nb">bytearray</span><span class="p">(</span><span class="n">pickled_command</span><span class="p">),</span> <span class="n">env</span><span class="p">,</span> <span class="n">includes</span><span class="p">,</span>
                                                 <span class="n">sc</span><span class="o">.</span><span class="n">pythonExec</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">pythonVer</span><span class="p">,</span> <span class="n">broadcast_vars</span><span class="p">,</span>
                                                 <span class="n">sc</span><span class="o">.</span><span class="n">_javaAccumulator</span><span class="p">,</span> <span class="n">jdt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">judf</span>

    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">cols</span><span class="p">):</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span>
        <span class="n">jc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_judf</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">_to_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_to_java_column</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span>


<span class="nd">@since</span><span class="p">(</span><span class="mf">1.3</span><span class="p">)</span>
<div class="viewcode-block" id="udf"><a class="viewcode-back" href="../../../pyspark.sql.html#pyspark.sql.functions.udf">[docs]</a><span class="k">def</span> <span class="nf">udf</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">returnType</span><span class="o">=</span><span class="n">StringType</span><span class="p">()):</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`Column` expression representing a user defined function (UDF).</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.sql.types import IntegerType</span>
<span class="sd">    &gt;&gt;&gt; slen = udf(lambda s: len(s), IntegerType())</span>
<span class="sd">    &gt;&gt;&gt; df.select(slen(df.name).alias(&#39;slen&#39;)).collect()</span>
<span class="sd">    [Row(slen=5), Row(slen=3)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">UserDefinedFunction</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">returnType</span><span class="p">)</span>

</div>
<span class="k">def</span> <span class="nf">_test</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">from</span> <span class="nn">pyspark.context</span> <span class="kn">import</span> <span class="n">SparkContext</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span><span class="p">,</span> <span class="n">SQLContext</span>
    <span class="kn">import</span> <span class="nn">pyspark.sql.functions</span>
    <span class="n">globs</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s">&#39;local[4]&#39;</span><span class="p">,</span> <span class="s">&#39;PythonTest&#39;</span><span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s">&#39;sc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sc</span>
    <span class="n">globs</span><span class="p">[</span><span class="s">&#39;sqlContext&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&#39;Alice&#39;</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&#39;Bob&#39;</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">5</span><span class="p">)])</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
    <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span>
        <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span> <span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span>
        <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span> <span class="o">|</span> <span class="n">doctest</span><span class="o">.</span><span class="n">NORMALIZE_WHITESPACE</span><span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s">&#39;sc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="nb">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">_test</span><span class="p">()</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/spark-logo-hd.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li><a href="../../../index.html">PySpark 1.4.1 documentation</a> &raquo;</li>
          <li><a href="../../index.html" >Module code</a> &raquo;</li>
          <li><a href="../../pyspark.html" >pyspark</a> &raquo;</li>
          <li><a href="../sql.html" >pyspark.sql</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>