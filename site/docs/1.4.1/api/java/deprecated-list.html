<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:43 PDT 2015 -->
<TITLE>
Deprecated List (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Deprecated List (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Deprecated</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="index.html?deprecated-list.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="deprecated-list.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<CENTER>
<H2>
<B>Deprecated API</B></H2>
</CENTER>
<HR SIZE="4" NOSHADE>
<B>Contents</B><UL>
<LI><A HREF="#method">Deprecated Methods</A>
</UL>

<A NAME="method"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Deprecated Methods</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/StreamingContext.html#awaitTermination(long)">org.apache.spark.streaming.StreamingContext.awaitTermination(long)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination(long)">org.apache.spark.streaming.api.java.JavaStreamingContext.awaitTermination(long)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/api/java/StorageLevels.html#create(boolean, boolean, boolean, int)">org.apache.spark.api.java.StorageLevels.create(boolean, boolean, boolean, int)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#createJDBCTable(java.lang.String, java.lang.String, boolean)">org.apache.spark.sql.DataFrame.createJDBCTable(String, String, boolean)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.340, replaced by <code>write().jdbc()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/api/java/JavaSparkContext.html#defaultMinSplits()">org.apache.spark.api.java.JavaSparkContext.defaultMinSplits()</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of Spark 1.0.0, defaultMinSplits is deprecated, use
            <A HREF="org/apache/spark/api/java/JavaSparkContext.html#defaultMinPartitions()"><CODE>JavaSparkContext.defaultMinPartitions()</CODE></A> instead</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function)">org.apache.spark.streaming.api.java.JavaDStreamLike.foreach(Function<R, Void>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of release 0.9.0, replaced by foreachRDD</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function1)">org.apache.spark.streaming.dstream.DStream.foreach(Function1<RDD<T>, BoxedUnit>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 0.9.0, replaced by <code>foreachRDD</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function2)">org.apache.spark.streaming.dstream.DStream.foreach(Function2<RDD<T>, Time, BoxedUnit>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 0.9.0, replaced by <code>foreachRDD</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function2)">org.apache.spark.streaming.api.java.JavaDStreamLike.foreach(Function2<R, Time, Void>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of release 0.9.0, replaced by foreachRDD</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/types/DataType.html#fromCaseClassString(java.lang.String)">org.apache.spark.sql.types.DataType.fromCaseClassString(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.2.0, replaced by <code>DataType.fromJson()</code></I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">org.apache.spark.streaming.api.java.JavaStreamingContext.getOrCreate(String, Configuration, JavaStreamingContextFactory)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory, boolean)">org.apache.spark.streaming.api.java.JavaStreamingContext.getOrCreate(String, Configuration, JavaStreamingContextFactory, boolean)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">org.apache.spark.streaming.api.java.JavaStreamingContext.getOrCreate(String, JavaStreamingContextFactory)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#insertInto(java.lang.String)">org.apache.spark.sql.DataFrame.insertInto(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().mode(SaveMode.Append).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#insertInto(java.lang.String, boolean)">org.apache.spark.sql.DataFrame.insertInto(String, boolean)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().mode(SaveMode.Append|SaveMode.Overwrite).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#insertIntoJDBC(java.lang.String, java.lang.String, boolean)">org.apache.spark.sql.DataFrame.insertIntoJDBC(String, String, boolean)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().jdbc()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String)">org.apache.spark.sql.SQLContext.jdbc(String, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String, java.lang.String[])">org.apache.spark.sql.SQLContext.jdbc(String, String, String[])</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String, java.lang.String, long, long, int)">org.apache.spark.sql.SQLContext.jdbc(String, String, String, long, long, int)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">org.apache.spark.sql.SQLContext.jsonFile(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">org.apache.spark.sql.SQLContext.jsonFile(String, double)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.types.StructType)">org.apache.spark.sql.SQLContext.jsonFile(String, StructType)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD)">org.apache.spark.sql.SQLContext.jsonRDD(JavaRDD<String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD, double)">org.apache.spark.sql.SQLContext.jsonRDD(JavaRDD<String>, double)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">org.apache.spark.sql.SQLContext.jsonRDD(JavaRDD<String>, StructType)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">org.apache.spark.sql.SQLContext.jsonRDD(RDD<String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">org.apache.spark.sql.SQLContext.jsonRDD(RDD<String>, double)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">org.apache.spark.sql.SQLContext.jsonRDD(RDD<String>, StructType)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String)">org.apache.spark.sql.SQLContext.load(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().load(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String, java.util.Map)">org.apache.spark.sql.SQLContext.load(String, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String, scala.collection.immutable.Map)">org.apache.spark.sql.SQLContext.load(String, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String, java.lang.String)">org.apache.spark.sql.SQLContext.load(String, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).load(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)">org.apache.spark.sql.SQLContext.load(String, StructType, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#load(java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)">org.apache.spark.sql.SQLContext.load(String, StructType, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/mllib/util/MLUtils.html#loadLabeledData(org.apache.spark.SparkContext, java.lang.String)">org.apache.spark.mllib.util.MLUtils.loadLabeledData(SparkContext, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>Should use <A HREF="org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><CODE>RDD.saveAsTextFile(java.lang.String)</CODE></A> for saving and
            <A HREF="org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><CODE>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</CODE></A> for loading.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/StreamingContext.html#networkStream(org.apache.spark.streaming.receiver.Receiver, scala.reflect.ClassTag)">org.apache.spark.streaming.StreamingContext.networkStream(Receiver<T>, ClassTag<T>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.0.0", replaced by <code>receiverStream</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String...)">org.apache.spark.sql.SQLContext.parquetFile(String...)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>read().parquet()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">org.apache.spark.streaming.api.java.JavaDStreamLike.reduceByWindow(Function2<T, T, T>, Duration, Duration)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As this API is not Java compatible.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String)">org.apache.spark.sql.DataFrame.save(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode)">org.apache.spark.sql.DataFrame.save(String, SaveMode)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode, java.util.Map)">org.apache.spark.sql.DataFrame.save(String, SaveMode, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode, scala.collection.immutable.Map)">org.apache.spark.sql.DataFrame.save(String, SaveMode, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String, java.lang.String)">org.apache.spark.sql.DataFrame.save(String, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#save(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode)">org.apache.spark.sql.DataFrame.save(String, String, SaveMode)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).mode(mode).save(path)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsParquetFile(java.lang.String)">org.apache.spark.sql.DataFrame.saveAsParquetFile(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().parquet()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String)">org.apache.spark.sql.DataFrame.saveAsTable(String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, org.apache.spark.sql.SaveMode)">org.apache.spark.sql.DataFrame.saveAsTable(String, SaveMode)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String)">org.apache.spark.sql.DataFrame.saveAsTable(String, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode)">org.apache.spark.sql.DataFrame.saveAsTable(String, String, SaveMode)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode, java.util.Map)">org.apache.spark.sql.DataFrame.saveAsTable(String, String, SaveMode, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode, scala.collection.immutable.Map)">org.apache.spark.sql.DataFrame.saveAsTable(String, String, SaveMode, Map<String, String>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).saveAsTable(tableName)</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/mllib/util/MLUtils.html#saveLabeledData(org.apache.spark.rdd.RDD, java.lang.String)">org.apache.spark.mllib.util.MLUtils.saveLabeledData(RDD<LabeledPoint>, String)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>Should use <A HREF="org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><CODE>RDD.saveAsTextFile(java.lang.String)</CODE></A> for saving and
            <A HREF="org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><CODE>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</CODE></A> for loading.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/api/java/JavaStreamingContext.html#sc()">org.apache.spark.streaming.api.java.JavaStreamingContext.sc()</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 0.9.0, replaced by <code>sparkContext</code></I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/mllib/optimization/LBFGS.html#setMaxNumIterations(int)">org.apache.spark.mllib.optimization.LBFGS.setMaxNumIterations(int)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>use <A HREF="org/apache/spark/mllib/optimization/LBFGS.html#setNumIterations(int)"><CODE>LBFGS.setNumIterations(int)</CODE></A> instead</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/api/java/JavaRDDLike.html#toArray()">org.apache.spark.api.java.JavaRDDLike.toArray()</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of Spark 1.0.0, toArray() is deprecated, use <A HREF="org/apache/spark/api/java/JavaRDDLike.html#collect()"><CODE>JavaRDDLike.collect()</CODE></A> instead</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/streaming/StreamingContext.html#toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">org.apache.spark.streaming.StreamingContext.toPairDStreamFunctions(DStream<Tuple2<K, V>>, ClassTag<K>, ClassTag<V>, Ordering<K>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.3.0, replaced by implicit functions in the DStream companion object.
             This is kept here only for backward compatibility.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/sql/DataFrame.html#toSchemaRDD()">org.apache.spark.sql.DataFrame.toSchemaRDD()</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>As of 1.3.0, replaced by <code>toDF()</code>.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/mllib/rdd/RDDFunctions.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)">org.apache.spark.mllib.rdd.RDDFunctions.treeAggregate(U, Function2<U, T, U>, Function2<U, U, U>, int, ClassTag<U>)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>Use <A HREF="org/apache/spark/rdd/RDD.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)"><CODE>RDD.treeAggregate(U, scala.Function2<U, T, U>, scala.Function2<U, U, U>, int, scala.reflect.ClassTag<U>)</CODE></A> instead.</I>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><A HREF="org/apache/spark/mllib/rdd/RDDFunctions.html#treeReduce(scala.Function2, int)">org.apache.spark.mllib.rdd.RDDFunctions.treeReduce(Function2<T, T, T>, int)</A>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<I>Use <A HREF="org/apache/spark/rdd/RDD.html#treeReduce(scala.Function2, int)"><CODE>RDD.treeReduce(scala.Function2<T, T, T>, int)</CODE></A> instead.</I>&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<P>
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Deprecated</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="index.html?deprecated-list.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="deprecated-list.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
