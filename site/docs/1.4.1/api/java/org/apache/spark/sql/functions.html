<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:38 PDT 2015 -->
<TITLE>
functions (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="functions (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/sql/functions.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="functions.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.sql</FONT>
<BR>
Class functions</H2>
<PRE>
Object
  <IMG SRC="../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.sql.functions</B>
</PRE>
<HR>
<DL>
<DT><PRE>public class <B>functions</B><DT>extends Object</DL>
</PRE>

<P>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#functions()">functions</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#abs(org.apache.spark.sql.Column)">abs</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the absolute value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#acos(org.apache.spark.sql.Column)">acos</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cosine inverse of the given value; the returned angle is in the range
 0.0 through pi.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#acos(java.lang.String)">acos</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cosine inverse of the given column; the returned angle is in the range
 0.0 through pi.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#approxCountDistinct(org.apache.spark.sql.Column)">approxCountDistinct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the approximate number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#approxCountDistinct(org.apache.spark.sql.Column, double)">approxCountDistinct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                    double&nbsp;rsd)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the approximate number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#approxCountDistinct(java.lang.String)">approxCountDistinct</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the approximate number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#approxCountDistinct(java.lang.String, double)">approxCountDistinct</A></B>(String&nbsp;columnName,
                    double&nbsp;rsd)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the approximate number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#array(org.apache.spark.sql.Column...)">array</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;cols)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new array column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#array(scala.collection.Seq)">array</A></B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new array column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#array(java.lang.String, scala.collection.Seq)">array</A></B>(String&nbsp;colName,
      scala.collection.Seq&lt;String&gt;&nbsp;colNames)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new array column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#asc(java.lang.String)">asc</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a sort expression based on ascending order of the column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#asin(org.apache.spark.sql.Column)">asin</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the sine inverse of the given value; the returned angle is in the range
 -pi/2 through pi/2.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#asin(java.lang.String)">asin</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the sine inverse of the given column; the returned angle is in the range
 -pi/2 through pi/2.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan(org.apache.spark.sql.Column)">atan</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the tangent inverse of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan(java.lang.String)">atan</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the tangent inverse of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, org.apache.spark.sql.Column)">atan2</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, double)">atan2</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, java.lang.String)">atan2</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(double, org.apache.spark.sql.Column)">atan2</A></B>(double&nbsp;l,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(double, java.lang.String)">atan2</A></B>(double&nbsp;l,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(java.lang.String, org.apache.spark.sql.Column)">atan2</A></B>(String&nbsp;leftName,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(java.lang.String, double)">atan2</A></B>(String&nbsp;leftName,
      double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#atan2(java.lang.String, java.lang.String)">atan2</A></B>(String&nbsp;leftName,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#avg(org.apache.spark.sql.Column)">avg</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the average of the values in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#avg(java.lang.String)">avg</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the average of the values in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#bitwiseNOT(org.apache.spark.sql.Column)">bitwiseNOT</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes bitwise NOT.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function0, org.apache.spark.sql.types.DataType)">callUDF</A></B>(scala.Function0&lt;?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 0 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function1, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function1&lt;?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 1 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function10, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg9,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg10)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 10 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function2, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function2&lt;?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 2 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function3, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function3&lt;?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 3 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function4, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function4&lt;?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 4 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function5, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function5&lt;?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 5 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function6, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function6&lt;?,?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 6 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function7, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function7&lt;?,?,?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 7 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function8, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function8&lt;?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 8 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUDF(scala.Function9, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)">callUDF</A></B>(scala.Function9&lt;?,?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
        <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8,
        <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg9)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call a Scala function of 9 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#callUdf(java.lang.String, scala.collection.Seq)">callUdf</A></B>(String&nbsp;udfName,
        scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call an user-defined function.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cbrt(org.apache.spark.sql.Column)">cbrt</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cube-root of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cbrt(java.lang.String)">cbrt</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cube-root of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#ceil(org.apache.spark.sql.Column)">ceil</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the ceiling of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#ceil(java.lang.String)">ceil</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the ceiling of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#coalesce(org.apache.spark.sql.Column...)">coalesce</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the first column that is not null.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#coalesce(scala.collection.Seq)">coalesce</A></B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the first column that is not null.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#col(java.lang.String)">col</A></B>(String&nbsp;colName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#column(java.lang.String)">column</A></B>(String&nbsp;colName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cos(org.apache.spark.sql.Column)">cos</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cosine of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cos(java.lang.String)">cos</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the cosine of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cosh(org.apache.spark.sql.Column)">cosh</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic cosine of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cosh(java.lang.String)">cosh</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic cosine of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#count(org.apache.spark.sql.Column)">count</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#count(java.lang.String)">count</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#countDistinct(org.apache.spark.sql.Column, org.apache.spark.sql.Column...)">countDistinct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;expr,
              <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;exprs)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#countDistinct(org.apache.spark.sql.Column, scala.collection.Seq)">countDistinct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;expr,
              scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;exprs)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#countDistinct(java.lang.String, scala.collection.Seq)">countDistinct</A></B>(String&nbsp;columnName,
              scala.collection.Seq&lt;String&gt;&nbsp;columnNames)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#countDistinct(java.lang.String, java.lang.String...)">countDistinct</A></B>(String&nbsp;columnName,
              String...&nbsp;columnNames)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the number of distinct items in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#cumeDist()">cumeDist</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the cumulative distribution of values within a window partition,
 i.e.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#denseRank()">denseRank</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the rank of rows within a window partition, without any gaps.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#desc(java.lang.String)">desc</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a sort expression based on the descending order of the column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#exp(org.apache.spark.sql.Column)">exp</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the exponential of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#exp(java.lang.String)">exp</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the exponential of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#explode(org.apache.spark.sql.Column)">explode</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new row for each element in the given array or map column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#expm1(org.apache.spark.sql.Column)">expm1</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the exponential of the given value minus one.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#expm1(java.lang.String)">expm1</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the exponential of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#first(org.apache.spark.sql.Column)">first</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the first value in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#first(java.lang.String)">first</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the first value of a column in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#floor(org.apache.spark.sql.Column)">floor</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the floor of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#floor(java.lang.String)">floor</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the floor of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, org.apache.spark.sql.Column)">hypot</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, double)">hypot</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, java.lang.String)">hypot</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(double, org.apache.spark.sql.Column)">hypot</A></B>(double&nbsp;l,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(double, java.lang.String)">hypot</A></B>(double&nbsp;l,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(java.lang.String, org.apache.spark.sql.Column)">hypot</A></B>(String&nbsp;leftName,
      <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(java.lang.String, double)">hypot</A></B>(String&nbsp;leftName,
      double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#hypot(java.lang.String, java.lang.String)">hypot</A></B>(String&nbsp;leftName,
      String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lag(org.apache.spark.sql.Column, int)">lag</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
    int&nbsp;offset)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lag(org.apache.spark.sql.Column, int, java.lang.Object)">lag</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
    int&nbsp;offset,
    Object&nbsp;defaultValue)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lag(java.lang.String, int)">lag</A></B>(String&nbsp;columnName,
    int&nbsp;offset)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lag(java.lang.String, int, java.lang.Object)">lag</A></B>(String&nbsp;columnName,
    int&nbsp;offset,
    Object&nbsp;defaultValue)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#last(org.apache.spark.sql.Column)">last</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the last value in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#last(java.lang.String)">last</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the last value of the column in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lead(org.apache.spark.sql.Column, int)">lead</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
     int&nbsp;offset)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lead(org.apache.spark.sql.Column, int, java.lang.Object)">lead</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
     int&nbsp;offset,
     Object&nbsp;defaultValue)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lead(java.lang.String, int)">lead</A></B>(String&nbsp;columnName,
     int&nbsp;offset)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lead(java.lang.String, int, java.lang.Object)">lead</A></B>(String&nbsp;columnName,
     int&nbsp;offset,
     Object&nbsp;defaultValue)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lit(java.lang.Object)">lit</A></B>(Object&nbsp;literal)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> of literal value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log(org.apache.spark.sql.Column)">log</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the natural logarithm of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log(java.lang.String)">log</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the natural logarithm of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log10(org.apache.spark.sql.Column)">log10</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the logarithm of the given value in Base 10.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log10(java.lang.String)">log10</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the logarithm of the given value in Base 10.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log1p(org.apache.spark.sql.Column)">log1p</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the natural logarithm of the given value plus one.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#log1p(java.lang.String)">log1p</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the natural logarithm of the given column plus one.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#lower(org.apache.spark.sql.Column)">lower</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts a string exprsesion to lower case.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#max(org.apache.spark.sql.Column)">max</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the maximum value of the expression in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#max(java.lang.String)">max</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the maximum value of the column in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#mean(org.apache.spark.sql.Column)">mean</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the average of the values in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#mean(java.lang.String)">mean</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the average of the values in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#min(org.apache.spark.sql.Column)">min</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the minimum value of the expression in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#min(java.lang.String)">min</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the minimum value of the column in a group.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#monotonicallyIncreasingId()">monotonicallyIncreasingId</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A column expression that generates monotonically increasing 64-bit integers.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#negate(org.apache.spark.sql.Column)">negate</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unary minus, i.e.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#not(org.apache.spark.sql.Column)">not</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Inversion of boolean expression, i.e.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#ntile(int)">ntile</A></B>(int&nbsp;n)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the ntile group id (from 1 to <code>n</code> inclusive) in an ordered window
 partition.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#percentRank()">percentRank</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the relative rank (i.e.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, org.apache.spark.sql.Column)">pow</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
    <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, double)">pow</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
    double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, java.lang.String)">pow</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
    String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(double, org.apache.spark.sql.Column)">pow</A></B>(double&nbsp;l,
    <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(double, java.lang.String)">pow</A></B>(double&nbsp;l,
    String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(java.lang.String, org.apache.spark.sql.Column)">pow</A></B>(String&nbsp;leftName,
    <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(java.lang.String, double)">pow</A></B>(String&nbsp;leftName,
    double&nbsp;r)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#pow(java.lang.String, java.lang.String)">pow</A></B>(String&nbsp;leftName,
    String&nbsp;rightName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the first argument raised to the power of the second argument.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rand()">rand</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate a random column with i.i.d.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rand(long)">rand</A></B>(long&nbsp;seed)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate a random column with i.i.d.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#randn()">randn</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate a column with i.i.d.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#randn(long)">randn</A></B>(long&nbsp;seed)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate a column with i.i.d.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rank()">rank</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns the rank of rows within a window partition.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rint(org.apache.spark.sql.Column)">rint</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rint(java.lang.String)">rint</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#rowNumber()">rowNumber</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Window function: returns a sequential number starting at 1 within a window partition.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#signum(org.apache.spark.sql.Column)">signum</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the signum of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#signum(java.lang.String)">signum</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the signum of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sin(org.apache.spark.sql.Column)">sin</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the sine of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sin(java.lang.String)">sin</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the sine of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sinh(org.apache.spark.sql.Column)">sinh</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic sine of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sinh(java.lang.String)">sinh</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic sine of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sparkPartitionId()">sparkPartitionId</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Partition ID of the Spark task.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sqrt(org.apache.spark.sql.Column)">sqrt</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the square root of the specified float value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#struct(org.apache.spark.sql.Column...)">struct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;cols)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new struct column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#struct(scala.collection.Seq)">struct</A></B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new struct column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#struct(java.lang.String, scala.collection.Seq)">struct</A></B>(String&nbsp;colName,
       scala.collection.Seq&lt;String&gt;&nbsp;colNames)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a new struct column that composes multiple input columns.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sum(org.apache.spark.sql.Column)">sum</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the sum of all values in the expression.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sum(java.lang.String)">sum</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the sum of all values in the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sumDistinct(org.apache.spark.sql.Column)">sumDistinct</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the sum of distinct values in the expression.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#sumDistinct(java.lang.String)">sumDistinct</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate function: returns the sum of distinct values in the expression.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#tan(org.apache.spark.sql.Column)">tan</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the tangent of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#tan(java.lang.String)">tan</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the tangent of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#tanh(org.apache.spark.sql.Column)">tanh</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic tangent of the given value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#tanh(java.lang.String)">tanh</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computes the hyperbolic tangent of the given column.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#toDegrees(org.apache.spark.sql.Column)">toDegrees</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts an angle measured in radians to an approximately equivalent angle measured in degrees.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#toDegrees(java.lang.String)">toDegrees</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts an angle measured in radians to an approximately equivalent angle measured in degrees.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#toRadians(org.apache.spark.sql.Column)">toRadians</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts an angle measured in degrees to an approximately equivalent angle measured in radians.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#toRadians(java.lang.String)">toRadians</A></B>(String&nbsp;columnName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts an angle measured in degrees to an approximately equivalent angle measured in radians.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function0, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function0&lt;RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$1)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 0 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function1, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function1&lt;A1,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$2,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$3)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 1 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5,A6,A7,A8,A9,A10&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function10, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function10&lt;A1,A2,A3,A4,A5,A6,A7,A8,A9,A10,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$56,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$57,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$58,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$59,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$60,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$61,
    scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$62,
    scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$63,
    scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$64,
    scala.reflect.api.TypeTags.TypeTag&lt;A9&gt;&nbsp;evidence$65,
    scala.reflect.api.TypeTags.TypeTag&lt;A10&gt;&nbsp;evidence$66)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 10 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function2, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function2&lt;A1,A2,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$4,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$5,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$6)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 2 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function3, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function3&lt;A1,A2,A3,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$7,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$8,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$9,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$10)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 3 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function4, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function4&lt;A1,A2,A3,A4,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$11,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$12,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$13,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$14,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$15)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 4 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function5, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function5&lt;A1,A2,A3,A4,A5,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$16,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$17,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$18,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$19,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$20,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$21)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 5 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5,A6&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function6, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function6&lt;A1,A2,A3,A4,A5,A6,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$22,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$23,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$24,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$25,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$26,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$27,
    scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$28)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 6 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5,A6,A7&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function7, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function7&lt;A1,A2,A3,A4,A5,A6,A7,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$29,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$30,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$31,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$32,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$33,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$34,
    scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$35,
    scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$36)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 7 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5,A6,A7,A8&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function8, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function8&lt;A1,A2,A3,A4,A5,A6,A7,A8,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$37,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$38,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$39,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$40,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$41,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$42,
    scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$43,
    scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$44,
    scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$45)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 8 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;RT,A1,A2,A3,A4,A5,A6,A7,A8,A9&gt; 
<BR>
<A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#udf(scala.Function9, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)">udf</A></B>(scala.Function9&lt;A1,A2,A3,A4,A5,A6,A7,A8,A9,RT&gt;&nbsp;f,
    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$46,
    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$47,
    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$48,
    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$49,
    scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$50,
    scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$51,
    scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$52,
    scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$53,
    scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$54,
    scala.reflect.api.TypeTags.TypeTag&lt;A9&gt;&nbsp;evidence$55)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defines a user-defined function of 9 arguments as user-defined function (UDF).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#upper(org.apache.spark.sql.Column)">upper</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Converts a string expression to upper case.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/sql/functions.html#when(org.apache.spark.sql.Column, java.lang.Object)">when</A></B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;condition,
     Object&nbsp;value)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Evaluates a list of conditions and returns one of multiple possible result expressions.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="functions()"><!-- --></A><H3>
functions</H3>
<PRE>
public <B>functions</B>()</PRE>
<DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="countDistinct(org.apache.spark.sql.Column, org.apache.spark.sql.Column...)"><!-- --></A><H3>
countDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>countDistinct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;expr,
                                   <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;exprs)</PRE>
<DL>
<DD>Aggregate function: returns the number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>expr</CODE> - (undocumented)<DD><CODE>exprs</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="countDistinct(java.lang.String, java.lang.String...)"><!-- --></A><H3>
countDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>countDistinct</B>(String&nbsp;columnName,
                                   String...&nbsp;columnNames)</PRE>
<DL>
<DD>Aggregate function: returns the number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>columnNames</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="array(org.apache.spark.sql.Column...)"><!-- --></A><H3>
array</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>array</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;cols)</PRE>
<DL>
<DD>Creates a new array column. The input columns must all have the same data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>cols</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="coalesce(org.apache.spark.sql.Column...)"><!-- --></A><H3>
coalesce</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>coalesce</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;e)</PRE>
<DL>
<DD>Returns the first column that is not null.
 <pre><code>
   df.select(coalesce(df("a"), df("b")))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="struct(org.apache.spark.sql.Column...)"><!-- --></A><H3>
struct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>struct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>...&nbsp;cols)</PRE>
<DL>
<DD>Creates a new struct column. The input column must be a column in a <A HREF="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, or
 a derived column expression that is named (i.e. aliased).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>cols</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="col(java.lang.String)"><!-- --></A><H3>
col</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>col</B>(String&nbsp;colName)</PRE>
<DL>
<DD>Returns a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>colName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="column(java.lang.String)"><!-- --></A><H3>
column</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>column</B>(String&nbsp;colName)</PRE>
<DL>
<DD>Returns a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name. Alias of <CODE>col</CODE>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>colName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lit(java.lang.Object)"><!-- --></A><H3>
lit</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lit</B>(Object&nbsp;literal)</PRE>
<DL>
<DD>Creates a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> of literal value.
 <p>
 The passed in object is returned directly if it is already a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A>.
 If the object is a Scala Symbol, it is converted into a <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> also.
 Otherwise, a new <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> is created to represent the literal value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>literal</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="asc(java.lang.String)"><!-- --></A><H3>
asc</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>asc</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Returns a sort expression based on ascending order of the column.
 <pre><code>
   // Sort by dept in ascending order, and then age in descending order.
   df.sort(asc("dept"), desc("age"))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="desc(java.lang.String)"><!-- --></A><H3>
desc</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>desc</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Returns a sort expression based on the descending order of the column.
 <pre><code>
   // Sort by dept in ascending order, and then age in descending order.
   df.sort(asc("dept"), desc("age"))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sum(org.apache.spark.sql.Column)"><!-- --></A><H3>
sum</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sum</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the sum of all values in the expression.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sum(java.lang.String)"><!-- --></A><H3>
sum</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sum</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the sum of all values in the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sumDistinct(org.apache.spark.sql.Column)"><!-- --></A><H3>
sumDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sumDistinct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the sum of distinct values in the expression.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sumDistinct(java.lang.String)"><!-- --></A><H3>
sumDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sumDistinct</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the sum of distinct values in the expression.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="count(org.apache.spark.sql.Column)"><!-- --></A><H3>
count</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>count</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the number of items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="count(java.lang.String)"><!-- --></A><H3>
count</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>count</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the number of items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="countDistinct(org.apache.spark.sql.Column, scala.collection.Seq)"><!-- --></A><H3>
countDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>countDistinct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;expr,
                                   scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;exprs)</PRE>
<DL>
<DD>Aggregate function: returns the number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>expr</CODE> - (undocumented)<DD><CODE>exprs</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="countDistinct(java.lang.String, scala.collection.Seq)"><!-- --></A><H3>
countDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>countDistinct</B>(String&nbsp;columnName,
                                   scala.collection.Seq&lt;String&gt;&nbsp;columnNames)</PRE>
<DL>
<DD>Aggregate function: returns the number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>columnNames</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="approxCountDistinct(org.apache.spark.sql.Column)"><!-- --></A><H3>
approxCountDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>approxCountDistinct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="approxCountDistinct(java.lang.String)"><!-- --></A><H3>
approxCountDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>approxCountDistinct</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="approxCountDistinct(org.apache.spark.sql.Column, double)"><!-- --></A><H3>
approxCountDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>approxCountDistinct</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                                         double&nbsp;rsd)</PRE>
<DL>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)<DD><CODE>rsd</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="approxCountDistinct(java.lang.String, double)"><!-- --></A><H3>
approxCountDistinct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>approxCountDistinct</B>(String&nbsp;columnName,
                                         double&nbsp;rsd)</PRE>
<DL>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>rsd</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="avg(org.apache.spark.sql.Column)"><!-- --></A><H3>
avg</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>avg</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the average of the values in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="avg(java.lang.String)"><!-- --></A><H3>
avg</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>avg</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the average of the values in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="first(org.apache.spark.sql.Column)"><!-- --></A><H3>
first</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>first</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the first value in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="first(java.lang.String)"><!-- --></A><H3>
first</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>first</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the first value of a column in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="last(org.apache.spark.sql.Column)"><!-- --></A><H3>
last</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>last</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the last value in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="last(java.lang.String)"><!-- --></A><H3>
last</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>last</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the last value of the column in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="mean(org.apache.spark.sql.Column)"><!-- --></A><H3>
mean</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>mean</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the average of the values in a group.
 Alias for avg.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="mean(java.lang.String)"><!-- --></A><H3>
mean</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>mean</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the average of the values in a group.
 Alias for avg.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="min(org.apache.spark.sql.Column)"><!-- --></A><H3>
min</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>min</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the minimum value of the expression in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="min(java.lang.String)"><!-- --></A><H3>
min</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>min</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the minimum value of the column in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="max(org.apache.spark.sql.Column)"><!-- --></A><H3>
max</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>max</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Aggregate function: returns the maximum value of the expression in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="max(java.lang.String)"><!-- --></A><H3>
max</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>max</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Aggregate function: returns the maximum value of the column in a group.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lag(org.apache.spark.sql.Column, int)"><!-- --></A><H3>
lag</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lag</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                         int&nbsp;offset)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row. For example,
 an <code>offset</code> of one will return the previous row at any given point in the window partition.
 <p>
 This is equivalent to the LAG function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lag(java.lang.String, int)"><!-- --></A><H3>
lag</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lag</B>(String&nbsp;columnName,
                         int&nbsp;offset)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row. For example,
 an <code>offset</code> of one will return the previous row at any given point in the window partition.
 <p>
 This is equivalent to the LAG function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lag(java.lang.String, int, java.lang.Object)"><!-- --></A><H3>
lag</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lag</B>(String&nbsp;columnName,
                         int&nbsp;offset,
                         Object&nbsp;defaultValue)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row. For example,
 an <code>offset</code> of one will return the previous row at any given point in the window partition.
 <p>
 This is equivalent to the LAG function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)<DD><CODE>defaultValue</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lag(org.apache.spark.sql.Column, int, java.lang.Object)"><!-- --></A><H3>
lag</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lag</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                         int&nbsp;offset,
                         Object&nbsp;defaultValue)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row. For example,
 an <code>offset</code> of one will return the previous row at any given point in the window partition.
 <p>
 This is equivalent to the LAG function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)<DD><CODE>defaultValue</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lead(java.lang.String, int)"><!-- --></A><H3>
lead</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lead</B>(String&nbsp;columnName,
                          int&nbsp;offset)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row. For example,
 an <code>offset</code> of one will return the next row at any given point in the window partition.
 <p>
 This is equivalent to the LEAD function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lead(org.apache.spark.sql.Column, int)"><!-- --></A><H3>
lead</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lead</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                          int&nbsp;offset)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row. For example,
 an <code>offset</code> of one will return the next row at any given point in the window partition.
 <p>
 This is equivalent to the LEAD function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lead(java.lang.String, int, java.lang.Object)"><!-- --></A><H3>
lead</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lead</B>(String&nbsp;columnName,
                          int&nbsp;offset,
                          Object&nbsp;defaultValue)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row. For example,
 an <code>offset</code> of one will return the next row at any given point in the window partition.
 <p>
 This is equivalent to the LEAD function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)<DD><CODE>defaultValue</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="lead(org.apache.spark.sql.Column, int, java.lang.Object)"><!-- --></A><H3>
lead</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lead</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e,
                          int&nbsp;offset,
                          Object&nbsp;defaultValue)</PRE>
<DL>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row. For example,
 an <code>offset</code> of one will return the next row at any given point in the window partition.
 <p>
 This is equivalent to the LEAD function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)<DD><CODE>offset</CODE> - (undocumented)<DD><CODE>defaultValue</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="ntile(int)"><!-- --></A><H3>
ntile</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>ntile</B>(int&nbsp;n)</PRE>
<DL>
<DD>Window function: returns the ntile group id (from 1 to <code>n</code> inclusive) in an ordered window
 partition. Fow example, if <code>n</code> is 4, the first quarter of the rows will get value 1, the second
 quarter will get 2, the third quarter will get 3, and the last quarter will get 4.
 <p>
 This is equivalent to the NTILE function in SQL.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>n</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rowNumber()"><!-- --></A><H3>
rowNumber</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rowNumber</B>()</PRE>
<DL>
<DD>Window function: returns a sequential number starting at 1 within a window partition.
 <p>
 This is equivalent to the ROW_NUMBER function in SQL.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="denseRank()"><!-- --></A><H3>
denseRank</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>denseRank</B>()</PRE>
<DL>
<DD>Window function: returns the rank of rows within a window partition, without any gaps.
 <p>
 The difference between rank and denseRank is that denseRank leaves no gaps in ranking
 sequence when there are ties. That is, if you were ranking a competition using denseRank
 and had three people tie for second place, you would say that all three were in second
 place and that the next person came in third.
 <p>
 This is equivalent to the DENSE_RANK function in SQL.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rank()"><!-- --></A><H3>
rank</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rank</B>()</PRE>
<DL>
<DD>Window function: returns the rank of rows within a window partition.
 <p>
 The difference between rank and denseRank is that denseRank leaves no gaps in ranking
 sequence when there are ties. That is, if you were ranking a competition using denseRank
 and had three people tie for second place, you would say that all three were in second
 place and that the next person came in third.
 <p>
 This is equivalent to the RANK function in SQL.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cumeDist()"><!-- --></A><H3>
cumeDist</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cumeDist</B>()</PRE>
<DL>
<DD>Window function: returns the cumulative distribution of values within a window partition,
 i.e. the fraction of rows that are below the current row.
 <p>
 <pre><code>
   N = total number of rows in the partition
   cumeDist(x) = number of values before (and including) x / N
 </code></pre>
 <p>
 This is equivalent to the CUME_DIST function in SQL.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="percentRank()"><!-- --></A><H3>
percentRank</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>percentRank</B>()</PRE>
<DL>
<DD>Window function: returns the relative rank (i.e. percentile) of rows within a window partition.
 <p>
 This is computed by:
 <pre><code>
   (rank of row in its partition - 1) / (number of rows in the partition - 1)
 </code></pre>
 <p>
 This is equivalent to the PERCENT_RANK function in SQL.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="abs(org.apache.spark.sql.Column)"><!-- --></A><H3>
abs</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>abs</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the absolute value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="array(scala.collection.Seq)"><!-- --></A><H3>
array</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>array</B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</PRE>
<DL>
<DD>Creates a new array column. The input columns must all have the same data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>cols</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="array(java.lang.String, scala.collection.Seq)"><!-- --></A><H3>
array</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>array</B>(String&nbsp;colName,
                           scala.collection.Seq&lt;String&gt;&nbsp;colNames)</PRE>
<DL>
<DD>Creates a new array column. The input columns must all have the same data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>colName</CODE> - (undocumented)<DD><CODE>colNames</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="coalesce(scala.collection.Seq)"><!-- --></A><H3>
coalesce</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>coalesce</B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;e)</PRE>
<DL>
<DD>Returns the first column that is not null.
 <pre><code>
   df.select(coalesce(df("a"), df("b")))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="explode(org.apache.spark.sql.Column)"><!-- --></A><H3>
explode</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>explode</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Creates a new row for each element in the given array or map column.
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="lower(org.apache.spark.sql.Column)"><!-- --></A><H3>
lower</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>lower</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Converts a string exprsesion to lower case.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="monotonicallyIncreasingId()"><!-- --></A><H3>
monotonicallyIncreasingId</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>monotonicallyIncreasingId</B>()</PRE>
<DL>
<DD>A column expression that generates monotonically increasing 64-bit integers.
 <p>
 The generated ID is guaranteed to be monotonically increasing and unique, but not consecutive.
 The current implementation puts the partition ID in the upper 31 bits, and the record number
 within each partition in the lower 33 bits. The assumption is that the data frame has
 less than 1 billion partitions, and each partition has less than 8 billion records.
 <p>
 As an example, consider a <A HREF="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with two partitions, each with 3 records.
 This expression would return the following IDs:
 0, 1, 2, 8589934592 (1L << 33), 8589934593, 8589934594.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="negate(org.apache.spark.sql.Column)"><!-- --></A><H3>
negate</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>negate</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Unary minus, i.e. negate the expression.
 <pre><code>
   // Select the amount column and negates all values.
   // Scala:
   df.select( -df("amount") )

   // Java:
   df.select( negate(df.col("amount")) );
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="not(org.apache.spark.sql.Column)"><!-- --></A><H3>
not</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>not</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Inversion of boolean expression, i.e. NOT.
 <pre><code>
   // Scala: select rows that are not active (isActive === false)
   df.filter( !df("isActive") )

   // Java:
   df.filter( not(df.col("isActive")) );
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="when(org.apache.spark.sql.Column, java.lang.Object)"><!-- --></A><H3>
when</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>when</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;condition,
                          Object&nbsp;value)</PRE>
<DL>
<DD>Evaluates a list of conditions and returns one of multiple possible result expressions.
 If otherwise is not defined at the end, null is returned for unmatched conditions.
 <p>
 <pre><code>
   // Example: encoding gender string column into integer.

   // Scala:
   people.select(when(people("gender") === "male", 0)
     .when(people("gender") === "female", 1)
     .otherwise(2))

   // Java:
   people.select(when(col("gender").equalTo("male"), 0)
     .when(col("gender").equalTo("female"), 1)
     .otherwise(2))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>condition</CODE> - (undocumented)<DD><CODE>value</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rand(long)"><!-- --></A><H3>
rand</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rand</B>(long&nbsp;seed)</PRE>
<DL>
<DD>Generate a random column with i.i.d. samples from U[0.0, 1.0].
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>seed</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rand()"><!-- --></A><H3>
rand</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rand</B>()</PRE>
<DL>
<DD>Generate a random column with i.i.d. samples from U[0.0, 1.0].
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="randn(long)"><!-- --></A><H3>
randn</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>randn</B>(long&nbsp;seed)</PRE>
<DL>
<DD>Generate a column with i.i.d. samples from the standard normal distribution.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>seed</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="randn()"><!-- --></A><H3>
randn</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>randn</B>()</PRE>
<DL>
<DD>Generate a column with i.i.d. samples from the standard normal distribution.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sparkPartitionId()"><!-- --></A><H3>
sparkPartitionId</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sparkPartitionId</B>()</PRE>
<DL>
<DD>Partition ID of the Spark task.
 <p>
 Note that this is indeterministic because it depends on data partitioning and task scheduling.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sqrt(org.apache.spark.sql.Column)"><!-- --></A><H3>
sqrt</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sqrt</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the square root of the specified float value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="struct(scala.collection.Seq)"><!-- --></A><H3>
struct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>struct</B>(scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</PRE>
<DL>
<DD>Creates a new struct column. The input column must be a column in a <A HREF="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, or
 a derived column expression that is named (i.e. aliased).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>cols</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="struct(java.lang.String, scala.collection.Seq)"><!-- --></A><H3>
struct</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>struct</B>(String&nbsp;colName,
                            scala.collection.Seq&lt;String&gt;&nbsp;colNames)</PRE>
<DL>
<DD>Creates a new struct column that composes multiple input columns.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>colName</CODE> - (undocumented)<DD><CODE>colNames</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="upper(org.apache.spark.sql.Column)"><!-- --></A><H3>
upper</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>upper</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Converts a string expression to upper case.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="bitwiseNOT(org.apache.spark.sql.Column)"><!-- --></A><H3>
bitwiseNOT</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>bitwiseNOT</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes bitwise NOT.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="acos(org.apache.spark.sql.Column)"><!-- --></A><H3>
acos</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>acos</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the cosine inverse of the given value; the returned angle is in the range
 0.0 through pi.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="acos(java.lang.String)"><!-- --></A><H3>
acos</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>acos</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the cosine inverse of the given column; the returned angle is in the range
 0.0 through pi.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="asin(org.apache.spark.sql.Column)"><!-- --></A><H3>
asin</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>asin</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the sine inverse of the given value; the returned angle is in the range
 -pi/2 through pi/2.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="asin(java.lang.String)"><!-- --></A><H3>
asin</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>asin</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the sine inverse of the given column; the returned angle is in the range
 -pi/2 through pi/2.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan(org.apache.spark.sql.Column)"><!-- --></A><H3>
atan</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the tangent inverse of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan(java.lang.String)"><!-- --></A><H3>
atan</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the tangent inverse of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(org.apache.spark.sql.Column, java.lang.String)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(java.lang.String, org.apache.spark.sql.Column)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(String&nbsp;leftName,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(java.lang.String, java.lang.String)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(String&nbsp;leftName,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(org.apache.spark.sql.Column, double)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           double&nbsp;r)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(java.lang.String, double)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(String&nbsp;leftName,
                           double&nbsp;r)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(double, org.apache.spark.sql.Column)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(double&nbsp;l,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="atan2(double, java.lang.String)"><!-- --></A><H3>
atan2</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>atan2</B>(double&nbsp;l,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cbrt(org.apache.spark.sql.Column)"><!-- --></A><H3>
cbrt</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cbrt</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the cube-root of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cbrt(java.lang.String)"><!-- --></A><H3>
cbrt</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cbrt</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the cube-root of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="ceil(org.apache.spark.sql.Column)"><!-- --></A><H3>
ceil</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>ceil</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the ceiling of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="ceil(java.lang.String)"><!-- --></A><H3>
ceil</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>ceil</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the ceiling of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cos(org.apache.spark.sql.Column)"><!-- --></A><H3>
cos</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cos</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the cosine of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cos(java.lang.String)"><!-- --></A><H3>
cos</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cos</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the cosine of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cosh(org.apache.spark.sql.Column)"><!-- --></A><H3>
cosh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cosh</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the hyperbolic cosine of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="cosh(java.lang.String)"><!-- --></A><H3>
cosh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>cosh</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the hyperbolic cosine of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="exp(org.apache.spark.sql.Column)"><!-- --></A><H3>
exp</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>exp</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the exponential of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="exp(java.lang.String)"><!-- --></A><H3>
exp</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>exp</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the exponential of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="expm1(org.apache.spark.sql.Column)"><!-- --></A><H3>
expm1</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>expm1</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the exponential of the given value minus one.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="expm1(java.lang.String)"><!-- --></A><H3>
expm1</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>expm1</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the exponential of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="floor(org.apache.spark.sql.Column)"><!-- --></A><H3>
floor</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>floor</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the floor of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="floor(java.lang.String)"><!-- --></A><H3>
floor</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>floor</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the floor of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(org.apache.spark.sql.Column, java.lang.String)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(java.lang.String, org.apache.spark.sql.Column)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(String&nbsp;leftName,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(java.lang.String, java.lang.String)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(String&nbsp;leftName,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(org.apache.spark.sql.Column, double)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                           double&nbsp;r)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(java.lang.String, double)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(String&nbsp;leftName,
                           double&nbsp;r)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(double, org.apache.spark.sql.Column)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(double&nbsp;l,
                           <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="hypot(double, java.lang.String)"><!-- --></A><H3>
hypot</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>hypot</B>(double&nbsp;l,
                           String&nbsp;rightName)</PRE>
<DL>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log(org.apache.spark.sql.Column)"><!-- --></A><H3>
log</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the natural logarithm of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log(java.lang.String)"><!-- --></A><H3>
log</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the natural logarithm of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log10(org.apache.spark.sql.Column)"><!-- --></A><H3>
log10</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log10</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the logarithm of the given value in Base 10.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log10(java.lang.String)"><!-- --></A><H3>
log10</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log10</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the logarithm of the given value in Base 10.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log1p(org.apache.spark.sql.Column)"><!-- --></A><H3>
log1p</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log1p</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the natural logarithm of the given value plus one.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="log1p(java.lang.String)"><!-- --></A><H3>
log1p</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>log1p</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the natural logarithm of the given column plus one.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                         <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(org.apache.spark.sql.Column, java.lang.String)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                         String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(java.lang.String, org.apache.spark.sql.Column)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(String&nbsp;leftName,
                         <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(java.lang.String, java.lang.String)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(String&nbsp;leftName,
                         String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(org.apache.spark.sql.Column, double)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;l,
                         double&nbsp;r)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(java.lang.String, double)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(String&nbsp;leftName,
                         double&nbsp;r)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>leftName</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(double, org.apache.spark.sql.Column)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(double&nbsp;l,
                         <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;r)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>r</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="pow(double, java.lang.String)"><!-- --></A><H3>
pow</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>pow</B>(double&nbsp;l,
                         String&nbsp;rightName)</PRE>
<DL>
<DD>Returns the value of the first argument raised to the power of the second argument.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>l</CODE> - (undocumented)<DD><CODE>rightName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rint(org.apache.spark.sql.Column)"><!-- --></A><H3>
rint</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rint</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="rint(java.lang.String)"><!-- --></A><H3>
rint</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>rint</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="signum(org.apache.spark.sql.Column)"><!-- --></A><H3>
signum</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>signum</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the signum of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="signum(java.lang.String)"><!-- --></A><H3>
signum</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>signum</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the signum of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sin(org.apache.spark.sql.Column)"><!-- --></A><H3>
sin</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sin</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the sine of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sin(java.lang.String)"><!-- --></A><H3>
sin</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sin</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the sine of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sinh(org.apache.spark.sql.Column)"><!-- --></A><H3>
sinh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sinh</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the hyperbolic sine of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="sinh(java.lang.String)"><!-- --></A><H3>
sinh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>sinh</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the hyperbolic sine of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="tan(org.apache.spark.sql.Column)"><!-- --></A><H3>
tan</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>tan</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the tangent of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="tan(java.lang.String)"><!-- --></A><H3>
tan</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>tan</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the tangent of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="tanh(org.apache.spark.sql.Column)"><!-- --></A><H3>
tanh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>tanh</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Computes the hyperbolic tangent of the given value.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="tanh(java.lang.String)"><!-- --></A><H3>
tanh</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>tanh</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Computes the hyperbolic tangent of the given column.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="toDegrees(org.apache.spark.sql.Column)"><!-- --></A><H3>
toDegrees</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>toDegrees</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Converts an angle measured in radians to an approximately equivalent angle measured in degrees.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="toDegrees(java.lang.String)"><!-- --></A><H3>
toDegrees</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>toDegrees</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Converts an angle measured in radians to an approximately equivalent angle measured in degrees.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="toRadians(org.apache.spark.sql.Column)"><!-- --></A><H3>
toRadians</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>toRadians</B>(<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;e)</PRE>
<DL>
<DD>Converts an angle measured in degrees to an approximately equivalent angle measured in radians.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>e</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="toRadians(java.lang.String)"><!-- --></A><H3>
toRadians</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>toRadians</B>(String&nbsp;columnName)</PRE>
<DL>
<DD>Converts an angle measured in degrees to an approximately equivalent angle measured in radians.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>columnName</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function0, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function0&lt;RT&gt;&nbsp;f,
                                           scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$1)</PRE>
<DL>
<DD>Defines a user-defined function of 0 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$1</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function1, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function1&lt;A1,RT&gt;&nbsp;f,
                                              scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$2,
                                              scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$3)</PRE>
<DL>
<DD>Defines a user-defined function of 1 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$2</CODE> - (undocumented)<DD><CODE>evidence$3</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function2, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function2&lt;A1,A2,RT&gt;&nbsp;f,
                                                 scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$4,
                                                 scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$5,
                                                 scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$6)</PRE>
<DL>
<DD>Defines a user-defined function of 2 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$4</CODE> - (undocumented)<DD><CODE>evidence$5</CODE> - (undocumented)<DD><CODE>evidence$6</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function3, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function3&lt;A1,A2,A3,RT&gt;&nbsp;f,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$7,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$8,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$9,
                                                    scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$10)</PRE>
<DL>
<DD>Defines a user-defined function of 3 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$7</CODE> - (undocumented)<DD><CODE>evidence$8</CODE> - (undocumented)<DD><CODE>evidence$9</CODE> - (undocumented)<DD><CODE>evidence$10</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function4, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function4&lt;A1,A2,A3,A4,RT&gt;&nbsp;f,
                                                       scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$11,
                                                       scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$12,
                                                       scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$13,
                                                       scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$14,
                                                       scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$15)</PRE>
<DL>
<DD>Defines a user-defined function of 4 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$11</CODE> - (undocumented)<DD><CODE>evidence$12</CODE> - (undocumented)<DD><CODE>evidence$13</CODE> - (undocumented)<DD><CODE>evidence$14</CODE> - (undocumented)<DD><CODE>evidence$15</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function5, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function5&lt;A1,A2,A3,A4,A5,RT&gt;&nbsp;f,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$16,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$17,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$18,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$19,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$20,
                                                          scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$21)</PRE>
<DL>
<DD>Defines a user-defined function of 5 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$16</CODE> - (undocumented)<DD><CODE>evidence$17</CODE> - (undocumented)<DD><CODE>evidence$18</CODE> - (undocumented)<DD><CODE>evidence$19</CODE> - (undocumented)<DD><CODE>evidence$20</CODE> - (undocumented)<DD><CODE>evidence$21</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function6, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5,A6&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function6&lt;A1,A2,A3,A4,A5,A6,RT&gt;&nbsp;f,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$22,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$23,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$24,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$25,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$26,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$27,
                                                             scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$28)</PRE>
<DL>
<DD>Defines a user-defined function of 6 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$22</CODE> - (undocumented)<DD><CODE>evidence$23</CODE> - (undocumented)<DD><CODE>evidence$24</CODE> - (undocumented)<DD><CODE>evidence$25</CODE> - (undocumented)<DD><CODE>evidence$26</CODE> - (undocumented)<DD><CODE>evidence$27</CODE> - (undocumented)<DD><CODE>evidence$28</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function7, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5,A6,A7&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function7&lt;A1,A2,A3,A4,A5,A6,A7,RT&gt;&nbsp;f,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$29,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$30,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$31,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$32,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$33,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$34,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$35,
                                                                scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$36)</PRE>
<DL>
<DD>Defines a user-defined function of 7 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$29</CODE> - (undocumented)<DD><CODE>evidence$30</CODE> - (undocumented)<DD><CODE>evidence$31</CODE> - (undocumented)<DD><CODE>evidence$32</CODE> - (undocumented)<DD><CODE>evidence$33</CODE> - (undocumented)<DD><CODE>evidence$34</CODE> - (undocumented)<DD><CODE>evidence$35</CODE> - (undocumented)<DD><CODE>evidence$36</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function8, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5,A6,A7,A8&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function8&lt;A1,A2,A3,A4,A5,A6,A7,A8,RT&gt;&nbsp;f,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$37,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$38,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$39,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$40,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$41,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$42,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$43,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$44,
                                                                   scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$45)</PRE>
<DL>
<DD>Defines a user-defined function of 8 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$37</CODE> - (undocumented)<DD><CODE>evidence$38</CODE> - (undocumented)<DD><CODE>evidence$39</CODE> - (undocumented)<DD><CODE>evidence$40</CODE> - (undocumented)<DD><CODE>evidence$41</CODE> - (undocumented)<DD><CODE>evidence$42</CODE> - (undocumented)<DD><CODE>evidence$43</CODE> - (undocumented)<DD><CODE>evidence$44</CODE> - (undocumented)<DD><CODE>evidence$45</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function9, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5,A6,A7,A8,A9&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function9&lt;A1,A2,A3,A4,A5,A6,A7,A8,A9,RT&gt;&nbsp;f,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$46,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$47,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$48,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$49,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$50,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$51,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$52,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$53,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$54,
                                                                      scala.reflect.api.TypeTags.TypeTag&lt;A9&gt;&nbsp;evidence$55)</PRE>
<DL>
<DD>Defines a user-defined function of 9 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$46</CODE> - (undocumented)<DD><CODE>evidence$47</CODE> - (undocumented)<DD><CODE>evidence$48</CODE> - (undocumented)<DD><CODE>evidence$49</CODE> - (undocumented)<DD><CODE>evidence$50</CODE> - (undocumented)<DD><CODE>evidence$51</CODE> - (undocumented)<DD><CODE>evidence$52</CODE> - (undocumented)<DD><CODE>evidence$53</CODE> - (undocumented)<DD><CODE>evidence$54</CODE> - (undocumented)<DD><CODE>evidence$55</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="udf(scala.Function10, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><!-- --></A><H3>
udf</H3>
<PRE>
public static &lt;RT,A1,A2,A3,A4,A5,A6,A7,A8,A9,A10&gt; <A HREF="../../../../org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A> <B>udf</B>(scala.Function10&lt;A1,A2,A3,A4,A5,A6,A7,A8,A9,A10,RT&gt;&nbsp;f,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;RT&gt;&nbsp;evidence$56,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A1&gt;&nbsp;evidence$57,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A2&gt;&nbsp;evidence$58,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A3&gt;&nbsp;evidence$59,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A4&gt;&nbsp;evidence$60,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A5&gt;&nbsp;evidence$61,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A6&gt;&nbsp;evidence$62,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A7&gt;&nbsp;evidence$63,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A8&gt;&nbsp;evidence$64,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A9&gt;&nbsp;evidence$65,
                                                                          scala.reflect.api.TypeTags.TypeTag&lt;A10&gt;&nbsp;evidence$66)</PRE>
<DL>
<DD>Defines a user-defined function of 10 arguments as user-defined function (UDF).
 The data types are automatically inferred based on the function's signature.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$56</CODE> - (undocumented)<DD><CODE>evidence$57</CODE> - (undocumented)<DD><CODE>evidence$58</CODE> - (undocumented)<DD><CODE>evidence$59</CODE> - (undocumented)<DD><CODE>evidence$60</CODE> - (undocumented)<DD><CODE>evidence$61</CODE> - (undocumented)<DD><CODE>evidence$62</CODE> - (undocumented)<DD><CODE>evidence$63</CODE> - (undocumented)<DD><CODE>evidence$64</CODE> - (undocumented)<DD><CODE>evidence$65</CODE> - (undocumented)<DD><CODE>evidence$66</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function0, org.apache.spark.sql.types.DataType)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function0&lt;?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType)</PRE>
<DL>
<DD>Call a Scala function of 0 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function1, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function1&lt;?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1)</PRE>
<DL>
<DD>Call a Scala function of 1 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function2, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function2&lt;?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2)</PRE>
<DL>
<DD>Call a Scala function of 2 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function3, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function3&lt;?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3)</PRE>
<DL>
<DD>Call a Scala function of 3 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function4, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function4&lt;?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4)</PRE>
<DL>
<DD>Call a Scala function of 4 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function5, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function5&lt;?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5)</PRE>
<DL>
<DD>Call a Scala function of 5 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function6, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function6&lt;?,?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6)</PRE>
<DL>
<DD>Call a Scala function of 6 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)<DD><CODE>arg6</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function7, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function7&lt;?,?,?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7)</PRE>
<DL>
<DD>Call a Scala function of 7 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)<DD><CODE>arg6</CODE> - (undocumented)<DD><CODE>arg7</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function8, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function8&lt;?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8)</PRE>
<DL>
<DD>Call a Scala function of 8 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)<DD><CODE>arg6</CODE> - (undocumented)<DD><CODE>arg7</CODE> - (undocumented)<DD><CODE>arg8</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function9, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function9&lt;?,?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg9)</PRE>
<DL>
<DD>Call a Scala function of 9 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)<DD><CODE>arg6</CODE> - (undocumented)<DD><CODE>arg7</CODE> - (undocumented)<DD><CODE>arg8</CODE> - (undocumented)<DD><CODE>arg9</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUDF(scala.Function10, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><!-- --></A><H3>
callUDF</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUDF</B>(scala.Function10&lt;?,?,?,?,?,?,?,?,?,?,?&gt;&nbsp;f,
                             <A HREF="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>&nbsp;returnType,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg1,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg2,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg3,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg4,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg5,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg6,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg7,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg8,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg9,
                             <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&nbsp;arg10)</PRE>
<DL>
<DD>Call a Scala function of 10 arguments as user-defined function (UDF). This requires
 you to specify the return data type.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>returnType</CODE> - (undocumented)<DD><CODE>arg1</CODE> - (undocumented)<DD><CODE>arg2</CODE> - (undocumented)<DD><CODE>arg3</CODE> - (undocumented)<DD><CODE>arg4</CODE> - (undocumented)<DD><CODE>arg5</CODE> - (undocumented)<DD><CODE>arg6</CODE> - (undocumented)<DD><CODE>arg7</CODE> - (undocumented)<DD><CODE>arg8</CODE> - (undocumented)<DD><CODE>arg9</CODE> - (undocumented)<DD><CODE>arg10</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.3.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="callUdf(java.lang.String, scala.collection.Seq)"><!-- --></A><H3>
callUdf</H3>
<PRE>
public static <A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A> <B>callUdf</B>(String&nbsp;udfName,
                             scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>&gt;&nbsp;cols)</PRE>
<DL>
<DD>Call an user-defined function.
 Example:
 <pre><code>
  import org.apache.spark.sql._

  val df = Seq(("id1", 1), ("id2", 4), ("id3", 5)).toDF("id", "value")
  val sqlContext = df.sqlContext
  sqlContext.udf.register("simpleUdf", (v: Int) =&gt; v * v)
  df.select($"id", callUdf("simpleUdf", $"value"))
 </code></pre>
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>udfName</CODE> - (undocumented)<DD><CODE>cols</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/sql/functions.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="functions.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
