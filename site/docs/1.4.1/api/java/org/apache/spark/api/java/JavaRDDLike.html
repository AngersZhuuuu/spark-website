<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:40 PDT 2015 -->
<TITLE>
JavaRDDLike (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="JavaRDDLike (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/api/java/JavaRDDLike.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="JavaRDDLike.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.api.java</FONT>
<BR>
Interface JavaRDDLike&lt;T,This extends JavaRDDLike&lt;T,This&gt;&gt;</H2>
<DL>
<DT><B>All Superinterfaces:</B> <DD>java.io.Serializable</DD>
</DL>
<DL>
<DT><B>All Known Implementing Classes:</B> <DD><A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>, <A HREF="../../../../../org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</A>, <A HREF="../../../../../org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</A>, <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>, <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A></DD>
</DL>
<HR>
<DL>
<DT><PRE>public interface <B>JavaRDDLike&lt;T,This extends JavaRDDLike&lt;T,This&gt;&gt;</B><DT>extends scala.Serializable</DL>
</PRE>

<P>
Defines operations common to several Java RDD implementations.
 Note that this trait is not intended to be implemented by user code.
<P>

<P>
<HR>

<P>

<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; U</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#aggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">aggregate</A></B>(U&nbsp;zeroValue,
          <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
          <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value".</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#cartesian(org.apache.spark.api.java.JavaRDDLike)">cartesian</A></B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#checkpoint()">checkpoint</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mark this RDD for checkpointing.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#classTag()">classTag</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#collect()">collect</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an array that contains all of the elements in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#collectAsync()">collectAsync</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The asynchronous version of <code>collect</code>, which returns a future for
 retrieving an array containing all of the elements in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#collectPartitions(int[])">collectPartitions</A></B>(int[]&nbsp;partitionIds)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an array that contains all of the elements in a specific partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#context()">context</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The <A HREF="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark"><CODE>SparkContext</CODE></A> that this RDD was created on.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#count()">count</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the number of elements in the RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countApprox(long)">countApprox</A></B>(long&nbsp;timeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countApprox(long, double)">countApprox</A></B>(long&nbsp;timeout,
            double&nbsp;confidence)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countApproxDistinct(double)">countApproxDistinct</A></B>(double&nbsp;relativeSD)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return approximate number of distinct elements in the RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Long&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countAsync()">countAsync</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The asynchronous version of <code>count</code>, which returns a
 future for counting the number of elements in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countByValue()">countByValue</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the count of each unique value in this RDD as a map of (value, count) pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long)">countByValueApprox</A></B>(long&nbsp;timeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Experimental) Approximate version of countByValue().</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long, double)">countByValueApprox</A></B>(long&nbsp;timeout,
                   double&nbsp;confidence)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Experimental) Approximate version of countByValue().</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#first()">first</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the first element in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction)">flatMap</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#flatMapToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)">flatMapToDouble</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">flatMapToPair</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,K2,V2&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#fold(T, org.apache.spark.api.java.function.Function2)">fold</A></B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&nbsp;zeroValue,
     <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative and commutative function and a neutral "zero value".</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#foreach(org.apache.spark.api.java.function.VoidFunction)">foreach</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Applies a function f to all elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Void&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#foreachAsync(org.apache.spark.api.java.function.VoidFunction)">foreachAsync</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The asynchronous version of the <code>foreach</code> action, which
 applies a function f to all the elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#foreachPartition(org.apache.spark.api.java.function.VoidFunction)">foreachPartition</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Applies a function f to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Void&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#foreachPartitionAsync(org.apache.spark.api.java.function.VoidFunction)">foreachPartitionAsync</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The asynchronous version of the <code>foreachPartition</code> action, which
 applies a function f to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;com.google.common.base.Optional&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#getCheckpointFile()">getCheckpointFile</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the name of the file to which this RDD was checkpointed</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#getStorageLevel()">getStorageLevel</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the RDD's current storage level, or StorageLevel.NONE if none is set.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#glom()">glom</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD created by coalescing all elements within each partition into an array.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,Iterable&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function)">groupBy</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD of grouped elements.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,Iterable&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function, int)">groupBy</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f,
        int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD of grouped elements.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#id()">id</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A unique ID for this RDD (within its SparkContext).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#isCheckpointed()">isCheckpointed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return whether this RDD has been checkpointed or not</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#isEmpty()">isEmpty</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator</A></B>(<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&nbsp;split,
         <A HREF="../../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>&nbsp;taskContext)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Internal method to this RDD; will read from cache if applicable, or otherwise compute it.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#keyBy(org.apache.spark.api.java.function.Function)">keyBy</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates tuples of the elements in this RDD by applying <code>f</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;R&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#map(org.apache.spark.api.java.function.Function)">map</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,R&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to all elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)">mapPartitions</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,U&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction, boolean)">mapPartitions</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,U&gt;&nbsp;f,
              boolean&nbsp;preservesPartitioning)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)">mapPartitionsToDouble</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction, boolean)">mapPartitionsToDouble</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f,
                      boolean&nbsp;preservesPartitioning)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">mapPartitionsToPair</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,K2,V2&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction, boolean)">mapPartitionsToPair</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,K2,V2&gt;&nbsp;f,
                    boolean&nbsp;preservesPartitioning)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;R&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsWithIndex(org.apache.spark.api.java.function.Function2, boolean)">mapPartitionsWithIndex</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;Integer,java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,java.util.Iterator&lt;R&gt;&gt;&nbsp;f,
                       boolean&nbsp;preservesPartitioning)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A></CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapToDouble(org.apache.spark.api.java.function.DoubleFunction)">mapToDouble</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to all elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#mapToPair(org.apache.spark.api.java.function.PairFunction)">mapToPair</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function">PairFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,K2,V2&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new RDD by applying a function to all elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#max(java.util.Comparator)">max</A></B>(java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the maximum element from this RDD as defined by the specified
 Comparator[T].</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#min(java.util.Comparator)">min</A></B>(java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the minimum element from this RDD as defined by the specified
 Comparator[T].</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#name()">name</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#partitions()">partitions</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set of partitions in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List)">pipe</A></B>(java.util.List&lt;String&gt;&nbsp;command)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD created by piping elements to a forked external process.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List, java.util.Map)">pipe</A></B>(java.util.List&lt;String&gt;&nbsp;command,
     java.util.Map&lt;String,String&gt;&nbsp;env)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD created by piping elements to a forked external process.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#pipe(java.lang.String)">pipe</A></B>(String&nbsp;command)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an RDD created by piping elements to a forked external process.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#rdd()">rdd</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#reduce(org.apache.spark.api.java.function.Function2)">reduce</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduces the elements of this RDD using the specified commutative and associative binary
 operator.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile</A></B>(String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save this RDD as a SequenceFile of serialized objects.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String)">saveAsTextFile</A></B>(String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save this RDD as a text file, using string representations of elements.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile</A></B>(String&nbsp;path,
               Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save this RDD as a compressed text file, using string representations of elements.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#splits()">splits</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#take(int)">take</A></B>(int&nbsp;num)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Take the first num elements of the RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#takeAsync(int)">takeAsync</A></B>(int&nbsp;num)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The asynchronous version of the <code>take</code> action, which returns a
 future for retrieving the first <code>num</code> elements of this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int)">takeOrdered</A></B>(int&nbsp;num)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the first k (smallest) elements from this RDD using the
 natural ordering for T while maintain the order.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int, java.util.Comparator)">takeOrdered</A></B>(int&nbsp;num,
            java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the first k (smallest) elements from this RDD as defined by
 the specified Comparator[T] and maintains the order.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int)">takeSample</A></B>(boolean&nbsp;withReplacement,
           int&nbsp;num)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int, long)">takeSample</A></B>(boolean&nbsp;withReplacement,
           int&nbsp;num,
           long&nbsp;seed)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#toArray()">toArray</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of Spark 1.0.0, toArray() is deprecated, use <A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#collect()"><CODE>collect()</CODE></A> instead</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#toDebugString()">toDebugString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A description of this RDD and its recursive dependencies for debugging.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#toLocalIterator()">toLocalIterator</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return an iterator that contains all of the elements in this RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#top(int)">top</A></B>(int&nbsp;num)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the top k (largest) elements from this RDD using the
 natural ordering for T.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#top(int, java.util.Comparator)">top</A></B>(int&nbsp;num,
    java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the top k (largest) elements from this RDD as defined by
 the specified Comparator[T].</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; U</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">treeAggregate</A></B>(U&nbsp;zeroValue,
              <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
              <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><CODE>treeAggregate(U, org.apache.spark.api.java.function.Function2<U, T, U>, org.apache.spark.api.java.function.Function2<U, U, U>, int)</CODE></A> with suggested depth 2.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; U</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)">treeAggregate</A></B>(U&nbsp;zeroValue,
              <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
              <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp,
              int&nbsp;depth)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregates the elements of this RDD in a multi-level tree pattern.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2)">treeReduce</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2, int)"><CODE>treeReduce(org.apache.spark.api.java.function.Function2<T, T, T>, int)</CODE></A> with suggested depth 2.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2, int)">treeReduce</A></B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f,
           int&nbsp;depth)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduces the elements of this RDD in a multi-level tree pattern.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD</A></B>(<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;rdd)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#zip(org.apache.spark.api.java.JavaRDDLike)">zip</A></B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U,V&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#zipPartitions(org.apache.spark.api.java.JavaRDDLike, org.apache.spark.api.java.function.FlatMapFunction2)">zipPartitions</A></B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other,
              <A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction2</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,java.util.Iterator&lt;U&gt;,V&gt;&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#zipWithIndex()">zipWithIndex</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zips this RDD with its element indices.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#zipWithUniqueId()">zipWithUniqueId</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zips this RDD with generated unique Long ids.</TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="wrapRDD(org.apache.spark.rdd.RDD)"><!-- --></A><H3>
wrapRDD</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</A> <B>wrapRDD</B>(<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;rdd)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="classTag()"><!-- --></A><H3>
classTag</H3>
<PRE>
scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>classTag</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="rdd()"><!-- --></A><H3>
rdd</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>rdd</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="splits()"><!-- --></A><H3>
splits</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&gt; <B>splits</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="partitions()"><!-- --></A><H3>
partitions</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&gt; <B>partitions</B>()</PRE>
<DL>
<DD>Set of partitions in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="context()"><!-- --></A><H3>
context</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A> <B>context</B>()</PRE>
<DL>
<DD>The <A HREF="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark"><CODE>SparkContext</CODE></A> that this RDD was created on.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="id()"><!-- --></A><H3>
id</H3>
<PRE>
int <B>id</B>()</PRE>
<DL>
<DD>A unique ID for this RDD (within its SparkContext).
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStorageLevel()"><!-- --></A><H3>
getStorageLevel</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A> <B>getStorageLevel</B>()</PRE>
<DL>
<DD>Get the RDD's current storage level, or StorageLevel.NONE if none is set.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)"><!-- --></A><H3>
iterator</H3>
<PRE>
java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>iterator</B>(<A HREF="../../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&nbsp;split,
                               <A HREF="../../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>&nbsp;taskContext)</PRE>
<DL>
<DD>Internal method to this RDD; will read from cache if applicable, or otherwise compute it.
 This should ''not'' be called by users directly, but is available for implementors of custom
 subclasses of RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>split</CODE> - (undocumented)<DD><CODE>taskContext</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="map(org.apache.spark.api.java.function.Function)"><!-- --></A><H3>
map</H3>
<PRE>
&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;R&gt; <B>map</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,R&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitionsWithIndex(org.apache.spark.api.java.function.Function2, boolean)"><!-- --></A><H3>
mapPartitionsWithIndex</H3>
<PRE>
&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;R&gt; <B>mapPartitionsWithIndex</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;Integer,java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,java.util.Iterator&lt;R&gt;&gt;&nbsp;f,
                                      boolean&nbsp;preservesPartitioning)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>preservesPartitioning</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapToDouble(org.apache.spark.api.java.function.DoubleFunction)"><!-- --></A><H3>
mapToDouble</H3>
<PRE>
&lt;R&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A> <B>mapToDouble</B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapToPair(org.apache.spark.api.java.function.PairFunction)"><!-- --></A><H3>
mapToPair</H3>
<PRE>
&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt; <B>mapToPair</B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function">PairFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,K2,V2&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="flatMap(org.apache.spark.api.java.function.FlatMapFunction)"><!-- --></A><H3>
flatMap</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt; <B>flatMap</B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="flatMapToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)"><!-- --></A><H3>
flatMapToDouble</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A> <B>flatMapToDouble</B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><!-- --></A><H3>
flatMapToPair</H3>
<PRE>
&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt; <B>flatMapToPair</B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,K2,V2&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)"><!-- --></A><H3>
mapPartitions</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt; <B>mapPartitions</B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,U&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitions(org.apache.spark.api.java.function.FlatMapFunction, boolean)"><!-- --></A><H3>
mapPartitions</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;U&gt; <B>mapPartitions</B>(<A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,U&gt;&nbsp;f,
                             boolean&nbsp;preservesPartitioning)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>preservesPartitioning</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)"><!-- --></A><H3>
mapPartitionsToDouble</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A> <B>mapPartitionsToDouble</B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><!-- --></A><H3>
mapPartitionsToPair</H3>
<PRE>
&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt; <B>mapPartitionsToPair</B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,K2,V2&gt;&nbsp;f)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction, boolean)"><!-- --></A><H3>
mapPartitionsToDouble</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A> <B>mapPartitionsToDouble</B>(<A HREF="../../../../../org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f,
                                    boolean&nbsp;preservesPartitioning)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>preservesPartitioning</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction, boolean)"><!-- --></A><H3>
mapPartitionsToPair</H3>
<PRE>
&lt;K2,V2&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K2,V2&gt; <B>mapPartitionsToPair</B>(<A HREF="../../../../../org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,K2,V2&gt;&nbsp;f,
                                               boolean&nbsp;preservesPartitioning)</PRE>
<DL>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>preservesPartitioning</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="foreachPartition(org.apache.spark.api.java.function.VoidFunction)"><!-- --></A><H3>
foreachPartition</H3>
<PRE>
void <B>foreachPartition</B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</PRE>
<DL>
<DD>Applies a function f to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="glom()"><!-- --></A><H3>
glom</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt; <B>glom</B>()</PRE>
<DL>
<DD>Return an RDD created by coalescing all elements within each partition into an array.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="cartesian(org.apache.spark.api.java.JavaRDDLike)"><!-- --></A><H3>
cartesian</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt; <B>cartesian</B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other)</PRE>
<DL>
<DD>Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupBy(org.apache.spark.api.java.function.Function)"><!-- --></A><H3>
groupBy</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,Iterable&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt; <B>groupBy</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</PRE>
<DL>
<DD>Return an RDD of grouped elements. Each group consists of a key and a sequence of elements
 mapping to that key.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupBy(org.apache.spark.api.java.function.Function, int)"><!-- --></A><H3>
groupBy</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,Iterable&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt; <B>groupBy</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f,
                                       int&nbsp;numPartitions)</PRE>
<DL>
<DD>Return an RDD of grouped elements. Each group consists of a key and a sequence of elements
 mapping to that key.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="pipe(java.lang.String)"><!-- --></A><H3>
pipe</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt; <B>pipe</B>(String&nbsp;command)</PRE>
<DL>
<DD>Return an RDD created by piping elements to a forked external process.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>command</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="pipe(java.util.List)"><!-- --></A><H3>
pipe</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt; <B>pipe</B>(java.util.List&lt;String&gt;&nbsp;command)</PRE>
<DL>
<DD>Return an RDD created by piping elements to a forked external process.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>command</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="pipe(java.util.List, java.util.Map)"><!-- --></A><H3>
pipe</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;String&gt; <B>pipe</B>(java.util.List&lt;String&gt;&nbsp;command,
                     java.util.Map&lt;String,String&gt;&nbsp;env)</PRE>
<DL>
<DD>Return an RDD created by piping elements to a forked external process.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>command</CODE> - (undocumented)<DD><CODE>env</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="zip(org.apache.spark.api.java.JavaRDDLike)"><!-- --></A><H3>
zip</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt; <B>zip</B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other)</PRE>
<DL>
<DD>Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc. Assumes that the two RDDs have the *same number of
 partitions* and the *same number of elements in each partition* (e.g. one was made through
 a map on the other).
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="zipPartitions(org.apache.spark.api.java.JavaRDDLike, org.apache.spark.api.java.function.FlatMapFunction2)"><!-- --></A><H3>
zipPartitions</H3>
<PRE>
&lt;U,V&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;V&gt; <B>zipPartitions</B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;U,?&gt;&nbsp;other,
                               <A HREF="../../../../../org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction2</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;,java.util.Iterator&lt;U&gt;,V&gt;&nbsp;f)</PRE>
<DL>
<DD>Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions. Assumes that all the RDDs have the
 *same number of partitions*, but does *not* require them to have the same number
 of elements in each partition.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="zipWithUniqueId()"><!-- --></A><H3>
zipWithUniqueId</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt; <B>zipWithUniqueId</B>()</PRE>
<DL>
<DD>Zips this RDD with generated unique Long ids. Items in the kth partition will get ids k, n+k,
 2*n+k, ..., where n is the number of partitions. So there may exist gaps, but this method
 won't trigger a spark job, which is different from <A HREF="../../../../../org/apache/spark/rdd/RDD.html#zipWithIndex()"><CODE>RDD.zipWithIndex()</CODE></A>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="zipWithIndex()"><!-- --></A><H3>
zipWithIndex</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt; <B>zipWithIndex</B>()</PRE>
<DL>
<DD>Zips this RDD with its element indices. The ordering is first based on the partition index
 and then the ordering of items within each partition. So the first item in the first
 partition gets index 0, and the last item in the last partition receives the largest index.
 This is similar to Scala's zipWithIndex but it uses Long instead of Int as the index type.
 This method needs to trigger a spark job when this RDD contains more than one partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="foreach(org.apache.spark.api.java.function.VoidFunction)"><!-- --></A><H3>
foreach</H3>
<PRE>
void <B>foreach</B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>Applies a function f to all elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="collect()"><!-- --></A><H3>
collect</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>collect</B>()</PRE>
<DL>
<DD>Return an array that contains all of the elements in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="toLocalIterator()"><!-- --></A><H3>
toLocalIterator</H3>
<PRE>
java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>toLocalIterator</B>()</PRE>
<DL>
<DD>Return an iterator that contains all of the elements in this RDD.
 <p>
 The iterator will consume as much memory as the largest partition in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="toArray()"><!-- --></A><H3>
toArray</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>toArray</B>()</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of Spark 1.0.0, toArray() is deprecated, use <A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#collect()"><CODE>collect()</CODE></A> instead</I>
<P>
<DD>Return an array that contains all of the elements in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="collectPartitions(int[])"><!-- --></A><H3>
collectPartitions</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;[] <B>collectPartitions</B>(int[]&nbsp;partitionIds)</PRE>
<DL>
<DD>Return an array that contains all of the elements in a specific partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>partitionIds</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduce(org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
reduce</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>reduce</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>Reduces the elements of this RDD using the specified commutative and associative binary
 operator.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="treeReduce(org.apache.spark.api.java.function.Function2, int)"><!-- --></A><H3>
treeReduce</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>treeReduce</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f,
             int&nbsp;depth)</PRE>
<DL>
<DD>Reduces the elements of this RDD in a multi-level tree pattern.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>depth</CODE> - suggested depth of the tree<DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>See Also:</B><DD><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#reduce(org.apache.spark.api.java.function.Function2)"><CODE>reduce(org.apache.spark.api.java.function.Function2<T, T, T>)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="treeReduce(org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
treeReduce</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>treeReduce</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2, int)"><CODE>treeReduce(org.apache.spark.api.java.function.Function2<T, T, T>, int)</CODE></A> with suggested depth 2.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fold(java.lang.Object,org.apache.spark.api.java.function.Function2)"><!-- --></A><A NAME="fold(T, org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
fold</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>fold</B>(<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&nbsp;zeroValue,
       <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative and commutative function and a neutral "zero value". The function
 op(t1, t2) is allowed to modify t1 and return it as its result value to avoid object
 allocation; however, it should not modify t2.
 <p>
 This behaves somewhat differently from fold operations implemented for non-distributed
 collections in functional languages like Scala. This fold operation may be applied to
 partitions individually, and then fold those results into the final result, rather than
 apply the fold to each element sequentially in some defined ordering. For functions
 that are not commutative, the result may differ from that of a fold applied to a
 non-distributed collection.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>zeroValue</CODE> - (undocumented)<DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="aggregate(java.lang.Object,org.apache.spark.api.java.function.Function2,org.apache.spark.api.java.function.Function2)"><!-- --></A><A NAME="aggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
aggregate</H3>
<PRE>
&lt;U&gt; U <B>aggregate</B>(U&nbsp;zeroValue,
                <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
                <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp)</PRE>
<DL>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value". This function can return a different result
 type, U, than the type of this RDD, T. Thus, we need one operation for merging a T into an U
 and one operation for merging two U's, as in scala.TraversableOnce. Both of these functions are
 allowed to modify and return their first argument instead of creating a new U to avoid memory
 allocation.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>zeroValue</CODE> - (undocumented)<DD><CODE>seqOp</CODE> - (undocumented)<DD><CODE>combOp</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="treeAggregate(java.lang.Object,org.apache.spark.api.java.function.Function2,org.apache.spark.api.java.function.Function2,int)"><!-- --></A><A NAME="treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><!-- --></A><H3>
treeAggregate</H3>
<PRE>
&lt;U&gt; U <B>treeAggregate</B>(U&nbsp;zeroValue,
                    <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
                    <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp,
                    int&nbsp;depth)</PRE>
<DL>
<DD>Aggregates the elements of this RDD in a multi-level tree pattern.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>depth</CODE> - suggested depth of the tree<DD><CODE>zeroValue</CODE> - (undocumented)<DD><CODE>seqOp</CODE> - (undocumented)<DD><CODE>combOp</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>See Also:</B><DD><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#aggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><CODE>aggregate(U, org.apache.spark.api.java.function.Function2<U, T, U>, org.apache.spark.api.java.function.Function2<U, U, U>)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="treeAggregate(java.lang.Object,org.apache.spark.api.java.function.Function2,org.apache.spark.api.java.function.Function2)"><!-- --></A><A NAME="treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
treeAggregate</H3>
<PRE>
&lt;U&gt; U <B>treeAggregate</B>(U&nbsp;zeroValue,
                    <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;seqOp,
                    <A HREF="../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;U,U,U&gt;&nbsp;combOp)</PRE>
<DL>
<DD><A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><CODE>treeAggregate(U, org.apache.spark.api.java.function.Function2<U, T, U>, org.apache.spark.api.java.function.Function2<U, U, U>, int)</CODE></A> with suggested depth 2.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>zeroValue</CODE> - (undocumented)<DD><CODE>seqOp</CODE> - (undocumented)<DD><CODE>combOp</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="count()"><!-- --></A><H3>
count</H3>
<PRE>
long <B>count</B>()</PRE>
<DL>
<DD>Return the number of elements in the RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="countApprox(long, double)"><!-- --></A><H3>
countApprox</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt; <B>countApprox</B>(long&nbsp;timeout,
                                         double&nbsp;confidence)</PRE>
<DL>
<DD>:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - (undocumented)<DD><CODE>confidence</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="countApprox(long)"><!-- --></A><H3>
countApprox</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt; <B>countApprox</B>(long&nbsp;timeout)</PRE>
<DL>
<DD>:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="countByValue()"><!-- --></A><H3>
countByValue</H3>
<PRE>
java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,Long&gt; <B>countByValue</B>()</PRE>
<DL>
<DD>Return the count of each unique value in this RDD as a map of (value, count) pairs. The final
 combine step happens locally on the master, equivalent to running a single reduce task.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="countByValueApprox(long, double)"><!-- --></A><H3>
countByValueApprox</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;&gt; <B>countByValueApprox</B>(long&nbsp;timeout,
                                                                 double&nbsp;confidence)</PRE>
<DL>
<DD>(Experimental) Approximate version of countByValue().
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - (undocumented)<DD><CODE>confidence</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="countByValueApprox(long)"><!-- --></A><H3>
countByValueApprox</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>&lt;java.util.Map&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="../../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>&gt;&gt; <B>countByValueApprox</B>(long&nbsp;timeout)</PRE>
<DL>
<DD>(Experimental) Approximate version of countByValue().
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="take(int)"><!-- --></A><H3>
take</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>take</B>(int&nbsp;num)</PRE>
<DL>
<DD>Take the first num elements of the RDD. This currently scans the partitions *one by one*, so
 it will be slow if a lot of partitions are required. In that case, use collect() to get the
 whole RDD instead.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="takeSample(boolean, int)"><!-- --></A><H3>
takeSample</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>takeSample</B>(boolean&nbsp;withReplacement,
                             int&nbsp;num)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="takeSample(boolean, int, long)"><!-- --></A><H3>
takeSample</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>takeSample</B>(boolean&nbsp;withReplacement,
                             int&nbsp;num,
                             long&nbsp;seed)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="first()"><!-- --></A><H3>
first</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>first</B>()</PRE>
<DL>
<DD>Return the first element in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="isEmpty()"><!-- --></A><H3>
isEmpty</H3>
<PRE>
boolean <B>isEmpty</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>true if and only if the RDD contains no elements at all. Note that an RDD
         may be empty even when it has at least 1 partition.</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsTextFile(java.lang.String)"><!-- --></A><H3>
saveAsTextFile</H3>
<PRE>
void <B>saveAsTextFile</B>(String&nbsp;path)</PRE>
<DL>
<DD>Save this RDD as a text file, using string representations of elements.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>path</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsTextFile(java.lang.String, java.lang.Class)"><!-- --></A><H3>
saveAsTextFile</H3>
<PRE>
void <B>saveAsTextFile</B>(String&nbsp;path,
                    Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</PRE>
<DL>
<DD>Save this RDD as a compressed text file, using string representations of elements.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>path</CODE> - (undocumented)<DD><CODE>codec</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsObjectFile(java.lang.String)"><!-- --></A><H3>
saveAsObjectFile</H3>
<PRE>
void <B>saveAsObjectFile</B>(String&nbsp;path)</PRE>
<DL>
<DD>Save this RDD as a SequenceFile of serialized objects.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>path</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="keyBy(org.apache.spark.api.java.function.Function)"><!-- --></A><H3>
keyBy</H3>
<PRE>
&lt;U&gt; <A HREF="../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;U,<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>keyBy</B>(<A HREF="../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,U&gt;&nbsp;f)</PRE>
<DL>
<DD>Creates tuples of the elements in this RDD by applying <code>f</code>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="checkpoint()"><!-- --></A><H3>
checkpoint</H3>
<PRE>
void <B>checkpoint</B>()</PRE>
<DL>
<DD>Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 directory set with SparkContext.setCheckpointDir() and all references to its parent
 RDDs will be removed. This function must be called before any job has been
 executed on this RDD. It is strongly recommended that this RDD is persisted in
 memory, otherwise saving it on a file will require recomputation.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="isCheckpointed()"><!-- --></A><H3>
isCheckpointed</H3>
<PRE>
boolean <B>isCheckpointed</B>()</PRE>
<DL>
<DD>Return whether this RDD has been checkpointed or not
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getCheckpointFile()"><!-- --></A><H3>
getCheckpointFile</H3>
<PRE>
com.google.common.base.Optional&lt;String&gt; <B>getCheckpointFile</B>()</PRE>
<DL>
<DD>Gets the name of the file to which this RDD was checkpointed
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="toDebugString()"><!-- --></A><H3>
toDebugString</H3>
<PRE>
String <B>toDebugString</B>()</PRE>
<DL>
<DD>A description of this RDD and its recursive dependencies for debugging.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="top(int, java.util.Comparator)"><!-- --></A><H3>
top</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>top</B>(int&nbsp;num,
                      java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</PRE>
<DL>
<DD>Returns the top k (largest) elements from this RDD as defined by
 the specified Comparator[T].
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - k, the number of top elements to return<DD><CODE>comp</CODE> - the comparator that defines the order
<DT><B>Returns:</B><DD>an array of top elements</DL>
</DD>
</DL>
<HR>

<A NAME="top(int)"><!-- --></A><H3>
top</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>top</B>(int&nbsp;num)</PRE>
<DL>
<DD>Returns the top k (largest) elements from this RDD using the
 natural ordering for T.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - k, the number of top elements to return
<DT><B>Returns:</B><DD>an array of top elements</DL>
</DD>
</DL>
<HR>

<A NAME="takeOrdered(int, java.util.Comparator)"><!-- --></A><H3>
takeOrdered</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>takeOrdered</B>(int&nbsp;num,
                              java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</PRE>
<DL>
<DD>Returns the first k (smallest) elements from this RDD as defined by
 the specified Comparator[T] and maintains the order.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - k, the number of elements to return<DD><CODE>comp</CODE> - the comparator that defines the order
<DT><B>Returns:</B><DD>an array of top elements</DL>
</DD>
</DL>
<HR>

<A NAME="max(java.util.Comparator)"><!-- --></A><H3>
max</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>max</B>(java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</PRE>
<DL>
<DD>Returns the maximum element from this RDD as defined by the specified
 Comparator[T].
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>comp</CODE> - the comparator that defines ordering
<DT><B>Returns:</B><DD>the maximum of the RDD</DL>
</DD>
</DL>
<HR>

<A NAME="min(java.util.Comparator)"><!-- --></A><H3>
min</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A> <B>min</B>(java.util.Comparator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;comp)</PRE>
<DL>
<DD>Returns the minimum element from this RDD as defined by the specified
 Comparator[T].
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>comp</CODE> - the comparator that defines ordering
<DT><B>Returns:</B><DD>the minimum of the RDD</DL>
</DD>
</DL>
<HR>

<A NAME="takeOrdered(int)"><!-- --></A><H3>
takeOrdered</H3>
<PRE>
java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt; <B>takeOrdered</B>(int&nbsp;num)</PRE>
<DL>
<DD>Returns the first k (smallest) elements from this RDD using the
 natural ordering for T while maintain the order.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - k, the number of top elements to return
<DT><B>Returns:</B><DD>an array of top elements</DL>
</DD>
</DL>
<HR>

<A NAME="countApproxDistinct(double)"><!-- --></A><H3>
countApproxDistinct</H3>
<PRE>
long <B>countApproxDistinct</B>(double&nbsp;relativeSD)</PRE>
<DL>
<DD>Return approximate number of distinct elements in the RDD.
 <p>
 The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 <a href="http://dx.doi.org/10.1145/2452376.2452456">here</a>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>relativeSD</CODE> - Relative accuracy. Smaller values create counters that require more space.
                   It must be greater than 0.000017.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="name()"><!-- --></A><H3>
name</H3>
<PRE>
String <B>name</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="countAsync()"><!-- --></A><H3>
countAsync</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Long&gt; <B>countAsync</B>()</PRE>
<DL>
<DD>The asynchronous version of <code>count</code>, which returns a
 future for counting the number of elements in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="collectAsync()"><!-- --></A><H3>
collectAsync</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt; <B>collectAsync</B>()</PRE>
<DL>
<DD>The asynchronous version of <code>collect</code>, which returns a future for
 retrieving an array containing all of the elements in this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="takeAsync(int)"><!-- --></A><H3>
takeAsync</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;java.util.List&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt; <B>takeAsync</B>(int&nbsp;num)</PRE>
<DL>
<DD>The asynchronous version of the <code>take</code> action, which returns a
 future for retrieving the first <code>num</code> elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>num</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="foreachAsync(org.apache.spark.api.java.function.VoidFunction)"><!-- --></A><H3>
foreachAsync</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Void&gt; <B>foreachAsync</B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&nbsp;f)</PRE>
<DL>
<DD>The asynchronous version of the <code>foreach</code> action, which
 applies a function f to all the elements of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="foreachPartitionAsync(org.apache.spark.api.java.function.VoidFunction)"><!-- --></A><H3>
foreachPartitionAsync</H3>
<PRE>
<A HREF="../../../../../org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>&lt;Void&gt; <B>foreachPartitionAsync</B>(<A HREF="../../../../../org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>&lt;java.util.Iterator&lt;<A HREF="../../../../../org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>&gt;&gt;&nbsp;f)</PRE>
<DL>
<DD>The asynchronous version of the <code>foreachPartition</code> action, which
 applies a function f to each partition of this RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/api/java/JavaRDDLike.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="JavaRDDLike.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
