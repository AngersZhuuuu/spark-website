<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:41 PDT 2015 -->
<TITLE>
PairDStreamFunctions (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="PairDStreamFunctions (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/streaming/dstream/PairDStreamFunctions.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="PairDStreamFunctions.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.streaming.dstream</FONT>
<BR>
Class PairDStreamFunctions&lt;K,V&gt;</H2>
<PRE>
Object
  <IMG SRC="../../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.streaming.dstream.PairDStreamFunctions&lt;K,V&gt;</B>
</PRE>
<DL>
<DT><B>All Implemented Interfaces:</B> <DD>java.io.Serializable</DD>
</DL>
<HR>
<DL>
<DT><PRE>public class <B>PairDStreamFunctions&lt;K,V&gt;</B><DT>extends Object<DT>implements scala.Serializable</DL>
</PRE>

<P>
Extra functions available on DStream of (key, value) pairs through an implicit conversion.
<P>

<P>
<DL>
<DT><B>See Also:</B><DD><A HREF="../../../../../serialized-form.html#org.apache.spark.streaming.dstream.PairDStreamFunctions">Serialized Form</A></DL>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#PairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">PairDStreamFunctions</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&nbsp;self,
                     scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>&gt;&nbsp;kt,
                     scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;vt,
                     scala.math.Ordering&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>&gt;&nbsp;ord)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">cogroup</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
        scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$10)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">cogroup</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
        int&nbsp;numPartitions,
        scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$11)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">cogroup</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
        <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
        scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$12)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;C&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,C&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)">combineByKey</A></B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,C&gt;&nbsp;createCombiner,
             scala.Function2&lt;C,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,C&gt;&nbsp;mergeValue,
             scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiner,
             <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
             boolean&nbsp;mapSideCombine,
             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Combine elements of each key in DStream's RDDs using custom functions.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,U&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#flatMapValues(scala.Function1, scala.reflect.ClassTag)">flatMapValues</A></B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$9)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">fullOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">fullOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              int&nbsp;numPartitions,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">fullOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey()">groupByKey</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> to each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(int)">groupByKey</A></B>(int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> to each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(org.apache.spark.Partitioner)">groupByKey</A></B>(<A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> on each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration)">groupByKeyAndWindow</A></B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">groupByKeyAndWindow</A></B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                    <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">groupByKeyAndWindow</A></B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                    <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                    int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">groupByKeyAndWindow</A></B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                    <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                    <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">join</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
     scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">join</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
     int&nbsp;numPartitions,
     scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">join</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
     <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
     scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">leftOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">leftOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              int&nbsp;numPartitions,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">leftOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
              <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,U&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapValues(scala.Function1, scala.reflect.ClassTag)">mapValues</A></B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,U&gt;&nbsp;mapValuesFunc,
          scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$8)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2)">reduceByKey</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> to each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, int)">reduceByKey</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
            int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> to each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, org.apache.spark.Partitioner)">reduceByKey</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
            <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> to each RDD.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                     int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                     <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.Function1)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;invReduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                     int&nbsp;numPartitions,
                     scala.Function1&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,Object&gt;&nbsp;filterFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, scala.Function1)">reduceByKeyAndWindow</A></B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                     scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;invReduceFunc,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                     <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                     <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                     scala.Function1&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,Object&gt;&nbsp;filterFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">rightOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
               scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">rightOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
               int&nbsp;numPartitions,
               scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">rightOuterJoin</A></B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
               <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
               scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)">saveAsHadoopFiles</A></B>(String&nbsp;prefix,
                  String&nbsp;suffix,
                  Class&lt;?&gt;&nbsp;keyClass,
                  Class&lt;?&gt;&nbsp;valueClass,
                  Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                  org.apache.hadoop.mapred.JobConf&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save each RDD in <code>this</code> DStream as a Hadoop file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; 
<BR>
void</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)">saveAsHadoopFiles</A></B>(String&nbsp;prefix,
                  String&nbsp;suffix,
                  scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save each RDD in <code>this</code> DStream as a Hadoop file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFiles</A></B>(String&nbsp;prefix,
                        String&nbsp;suffix,
                        Class&lt;?&gt;&nbsp;keyClass,
                        Class&lt;?&gt;&nbsp;valueClass,
                        Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                        org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save each RDD in <code>this</code> DStream as a Hadoop file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; 
<BR>
void</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)">saveAsNewAPIHadoopFiles</A></B>(String&nbsp;prefix,
                        String&nbsp;suffix,
                        scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save each RDD in <code>this</code> DStream as a Hadoop file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&gt;&nbsp;updateFunc,
                 <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                 boolean&nbsp;rememberPartitioner,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&gt;&nbsp;updateFunc,
                 <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                 boolean&nbsp;rememberPartitioner,
                 <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&nbsp;initialRDD,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$2)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, int, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                 int&nbsp;numPartitions,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$3)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, org.apache.spark.Partitioner, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                 <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, org.apache.spark.Partitioner, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">updateStateByKey</A></B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                 <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                 <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&nbsp;initialRDD,
                 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="PairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><!-- --></A><H3>
PairDStreamFunctions</H3>
<PRE>
public <B>PairDStreamFunctions</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&nbsp;self,
                            scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>&gt;&nbsp;kt,
                            scala.reflect.ClassTag&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;vt,
                            scala.math.Ordering&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>&gt;&nbsp;ord)</PRE>
<DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="groupByKey()"><!-- --></A><H3>
groupByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKey</B>()</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKey(int)"><!-- --></A><H3>
groupByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKey</B>(int&nbsp;numPartitions)</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>numPartitions</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKey(org.apache.spark.Partitioner)"><!-- --></A><H3>
groupByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKey</B>(<A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>partitioner</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKey(scala.Function2)"><!-- --></A><H3>
reduceByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKey</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the associative reduce function. Hash partitioning is used to generate the RDDs
 with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKey(scala.Function2, int)"><!-- --></A><H3>
reduceByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKey</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                              int&nbsp;numPartitions)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
 with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKey(scala.Function2, org.apache.spark.Partitioner)"><!-- --></A><H3>
reduceByKey</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKey</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                              <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)"><!-- --></A><H3>
combineByKey</H3>
<PRE>
public &lt;C&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,C&gt;&gt; <B>combineByKey</B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,C&gt;&nbsp;createCombiner,
                                                   scala.Function2&lt;C,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,C&gt;&nbsp;mergeValue,
                                                   scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiner,
                                                   <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                   boolean&nbsp;mapSideCombine,
                                                   scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</PRE>
<DL>
<DD>Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
 combineByKey for RDDs. Please refer to combineByKey in
 org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>createCombiner</CODE> - (undocumented)<DD><CODE>mergeValue</CODE> - (undocumented)<DD><CODE>mergeCombiner</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>mapSideCombine</CODE> - (undocumented)<DD><CODE>evidence$1</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKeyAndWindow(org.apache.spark.streaming.Duration)"><!-- --></A><H3>
groupByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKeyAndWindow</B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration)</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
 <code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
 with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
 Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
groupByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKeyAndWindow</B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                                                 <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration)</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
 <code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><!-- --></A><H3>
groupByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKeyAndWindow</B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                                                 <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                                                 int&nbsp;numPartitions)</PRE>
<DL>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>numPartitions</CODE> - number of partitions of each RDD in the new DStream; if not specified
                       then Spark's default number of partitions will be used
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><!-- --></A><H3>
groupByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt;&gt; <B>groupByKeyAndWindow</B>(<A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                                                 <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                                                 <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</PRE>
<DL>
<DD>Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>partitioner</CODE> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
 generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
 the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                       int&nbsp;numPartitions)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>numPartitions</CODE> - number of partitions of each RDD in the new DStream.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner)</PRE>
<DL>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
 <code>DStream.reduceByKey()</code>, but applies it over a sliding window.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>partitioner</CODE> - partitioner for controlling the partitioning of each RDD
                       in the new DStream.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.Function1)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;invReduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                       int&nbsp;numPartitions,
                                                       scala.Function1&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,Object&gt;&nbsp;filterFunc)</PRE>
<DL>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
 <p>
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 <p>
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>invReduceFunc</CODE> - inverse reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>filterFunc</CODE> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained<DD><CODE>numPartitions</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, scala.Function1)"><!-- --></A><H3>
reduceByKeyAndWindow</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; <B>reduceByKeyAndWindow</B>(scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;reduceFunc,
                                                       scala.Function2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&nbsp;invReduceFunc,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;windowDuration,
                                                       <A HREF="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;slideDuration,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                       scala.Function1&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,Object&gt;&nbsp;filterFunc)</PRE>
<DL>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reduceFunc</CODE> - associative reduce function<DD><CODE>invReduceFunc</CODE> - inverse reduce function<DD><CODE>windowDuration</CODE> - width of the window; must be a multiple of this DStream's
                       batching interval<DD><CODE>slideDuration</CODE> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval<DD><CODE>partitioner</CODE> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.<DD><CODE>filterFunc</CODE> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function2, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$2)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.<DD><CODE>evidence$2</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function2, int, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       int&nbsp;numPartitions,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$3)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.<DD><CODE>numPartitions</CODE> - Number of partitions of each RDD in the new DStream.<DD><CODE>evidence$3</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function2, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.<DD><CODE>partitioner</CODE> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.<DD><CODE>evidence$4</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&gt;&nbsp;updateFunc,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                       boolean&nbsp;rememberPartitioner,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the partitioner despite the key being changed.<DD><CODE>partitioner</CODE> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream<DD><CODE>rememberPartitioner</CODE> - Whether to remember the paritioner object in the generated RDDs.<DD><CODE>evidence$5</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function2, org.apache.spark.Partitioner, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function2&lt;scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                       <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&nbsp;initialRDD,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.<DD><CODE>partitioner</CODE> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.<DD><CODE>initialRDD</CODE> - initial state value of each key.<DD><CODE>evidence$6</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><!-- --></A><H3>
updateStateByKey</H3>
<PRE>
public &lt;S&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt; <B>updateStateByKey</B>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.collection.Seq&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&gt;&nbsp;updateFunc,
                                                       <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                       boolean&nbsp;rememberPartitioner,
                                                       <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,S&gt;&gt;&nbsp;initialRDD,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</PRE>
<DL>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>updateFunc</CODE> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the  partitioner despite the key being changed.<DD><CODE>partitioner</CODE> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream<DD><CODE>rememberPartitioner</CODE> - Whether to remember the paritioner object in the generated RDDs.<DD><CODE>initialRDD</CODE> - initial state value of each key.<DD><CODE>evidence$7</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapValues(scala.Function1, scala.reflect.ClassTag)"><!-- --></A><H3>
mapValues</H3>
<PRE>
public &lt;U&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,U&gt;&gt; <B>mapValues</B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,U&gt;&nbsp;mapValuesFunc,
                                                scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$8)</PRE>
<DL>
<DD>Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>mapValuesFunc</CODE> - (undocumented)<DD><CODE>evidence$8</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="flatMapValues(scala.Function1, scala.reflect.ClassTag)"><!-- --></A><H3>
flatMapValues</H3>
<PRE>
public &lt;U&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,U&gt;&gt; <B>flatMapValues</B>(scala.Function1&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
                                                    scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$9)</PRE>
<DL>
<DD>Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>flatMapValuesFunc</CODE> - (undocumented)<DD><CODE>evidence$9</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="cogroup(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><!-- --></A><H3>
cogroup</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt; <B>cogroup</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$10)</PRE>
<DL>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number
 of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>evidence$10</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="cogroup(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><!-- --></A><H3>
cogroup</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt; <B>cogroup</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                                    int&nbsp;numPartitions,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$11)</PRE>
<DL>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)<DD><CODE>evidence$11</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="cogroup(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
cogroup</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.collection.Iterable&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt; <B>cogroup</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                                    <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$12)</PRE>
<DL>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>evidence$12</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="join(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><!-- --></A><H3>
join</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt; <B>join</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</PRE>
<DL>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>evidence$13</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="join(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><!-- --></A><H3>
join</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt; <B>join</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                           int&nbsp;numPartitions,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</PRE>
<DL>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)<DD><CODE>evidence$14</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="join(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
join</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,W&gt;&gt;&gt; <B>join</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                           <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</PRE>
<DL>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>evidence$15</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="leftOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><!-- --></A><H3>
leftOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>leftOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</PRE>
<DL>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>evidence$16</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="leftOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><!-- --></A><H3>
leftOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>leftOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                  int&nbsp;numPartitions,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</PRE>
<DL>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)<DD><CODE>evidence$17</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="leftOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
leftOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>leftOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                  <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</PRE>
<DL>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>evidence$18</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="rightOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><!-- --></A><H3>
rightOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt; <B>rightOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</PRE>
<DL>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>evidence$19</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="rightOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><!-- --></A><H3>
rightOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt; <B>rightOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                   int&nbsp;numPartitions,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</PRE>
<DL>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)<DD><CODE>evidence$20</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="rightOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
rightOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,W&gt;&gt;&gt; <B>rightOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                   <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</PRE>
<DL>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>evidence$21</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fullOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><!-- --></A><H3>
fullOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>fullOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</PRE>
<DL>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>evidence$22</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fullOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><!-- --></A><H3>
fullOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>fullOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                int&nbsp;numPartitions,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</PRE>
<DL>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>numPartitions</CODE> - (undocumented)<DD><CODE>evidence$23</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fullOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><!-- --></A><H3>
fullOuterJoin</H3>
<PRE>
public &lt;W&gt; <A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,scala.Tuple2&lt;scala.Option&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt; <B>fullOuterJoin</B>(<A HREF="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>&lt;scala.Tuple2&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,W&gt;&gt;&nbsp;other,
                                                                                                <A HREF="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>&nbsp;partitioner,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</PRE>
<DL>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>partitioner</CODE> - (undocumented)<DD><CODE>evidence$24</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)"><!-- --></A><H3>
saveAsHadoopFiles</H3>
<PRE>
public &lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; void <B>saveAsHadoopFiles</B>(String&nbsp;prefix,
                                                                                     String&nbsp;suffix,
                                                                                     scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</PRE>
<DL>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>prefix</CODE> - (undocumented)<DD><CODE>suffix</CODE> - (undocumented)<DD><CODE>fm</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)"><!-- --></A><H3>
saveAsHadoopFiles</H3>
<PRE>
public void <B>saveAsHadoopFiles</B>(String&nbsp;prefix,
                              String&nbsp;suffix,
                              Class&lt;?&gt;&nbsp;keyClass,
                              Class&lt;?&gt;&nbsp;valueClass,
                              Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                              org.apache.hadoop.mapred.JobConf&nbsp;conf)</PRE>
<DL>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>prefix</CODE> - (undocumented)<DD><CODE>suffix</CODE> - (undocumented)<DD><CODE>keyClass</CODE> - (undocumented)<DD><CODE>valueClass</CODE> - (undocumented)<DD><CODE>outputFormatClass</CODE> - (undocumented)<DD><CODE>conf</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)"><!-- --></A><H3>
saveAsNewAPIHadoopFiles</H3>
<PRE>
public &lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt;&gt; void <B>saveAsNewAPIHadoopFiles</B>(String&nbsp;prefix,
                                                                                              String&nbsp;suffix,
                                                                                              scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</PRE>
<DL>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>prefix</CODE> - (undocumented)<DD><CODE>suffix</CODE> - (undocumented)<DD><CODE>fm</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
saveAsNewAPIHadoopFiles</H3>
<PRE>
public void <B>saveAsNewAPIHadoopFiles</B>(String&nbsp;prefix,
                                    String&nbsp;suffix,
                                    Class&lt;?&gt;&nbsp;keyClass,
                                    Class&lt;?&gt;&nbsp;valueClass,
                                    Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                                    org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>prefix</CODE> - (undocumented)<DD><CODE>suffix</CODE> - (undocumented)<DD><CODE>keyClass</CODE> - (undocumented)<DD><CODE>valueClass</CODE> - (undocumented)<DD><CODE>outputFormatClass</CODE> - (undocumented)<DD><CODE>conf</CODE> - (undocumented)</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/streaming/dstream/PairDStreamFunctions.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="PairDStreamFunctions.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
