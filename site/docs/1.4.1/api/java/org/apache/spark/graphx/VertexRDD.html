<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:37 PDT 2015 -->
<TITLE>
VertexRDD (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="VertexRDD (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx"><B>PREV CLASS</B></A>&nbsp;
&nbsp;NEXT CLASS</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/graphx/VertexRDD.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="VertexRDD.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.graphx</FONT>
<BR>
Class VertexRDD&lt;VD&gt;</H2>
<PRE>
Object
  <IMG SRC="../../../../resources/inherit.gif" ALT="extended by "><A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;
      <IMG SRC="../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.graphx.VertexRDD&lt;VD&gt;</B>
</PRE>
<DL>
<DT><B>All Implemented Interfaces:</B> <DD>java.io.Serializable, <A HREF="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A></DD>
</DL>
<DL>
<DT><B>Direct Known Subclasses:</B> <DD><A HREF="../../../../org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A></DD>
</DL>
<HR>
<DL>
<DT><PRE>public abstract class <B>VertexRDD&lt;VD&gt;</B><DT>extends <A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;</DL>
</PRE>

<P>
Extends <code>RDD[(VertexId, VD)]</code> by ensuring that there is only one entry for each vertex and by
 pre-indexing the entries for fast, efficient joins. Two VertexRDDs with the same index can be
 joined efficiently. All operations except <CODE>reindex</CODE> preserve the index. To construct a
 <code>VertexRDD</code>, use the <CODE>VertexRDD object</CODE>.
 <p>
 Additionally, stores routing information to enable joining the vertex attributes with an
 <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>.
 <p>
<P>

<P>
<DL>
<DT><B>See Also:</B><DD><A HREF="../../../../serialized-form.html#org.apache.spark.graphx.VertexRDD">Serialized Form</A></DL>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#VertexRDD(org.apache.spark.SparkContext, scala.collection.Seq)">VertexRDD</A></B>(<A HREF="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>&nbsp;sc,
          scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</A>&lt;?&gt;&gt;&nbsp;deps)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#aggregateUsingIndex(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)">aggregateUsingIndex</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD2&gt;&gt;&nbsp;messages,
                    scala.Function2&lt;VD2,VD2,VD2&gt;&nbsp;reduceFunc,
                    scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$12)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregates vertices in <code>messages</code> that have the same ids using <code>reduceFunc</code>, returning a
 VertexRDD co-indexed with <code>this</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">apply</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
      scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$14)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Constructs a standalone <code>VertexRDD</code> (one that is not set up for efficient joins with an
 <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>) from an RDD of vertex-attribute pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.reflect.ClassTag)">apply</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
      <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
      VD&nbsp;defaultVal,
      scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$15)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.Function2, scala.reflect.ClassTag)">apply</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
      <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
      VD&nbsp;defaultVal,
      scala.Function2&lt;VD,VD,VD&gt;&nbsp;mergeFunc,
      scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$16)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;scala.collection.Iterator&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute</A></B>(<A HREF="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&nbsp;part,
        <A HREF="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>&nbsp;context)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Provides the <code>RDD[(VertexId, VD)]</code> equivalent output.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#diff(org.apache.spark.rdd.RDD)">diff</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#diff(org.apache.spark.graphx.VertexRDD)">diff</A></B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#filter(scala.Function1)">filter</A></B>(scala.Function1&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;,Object&gt;&nbsp;pred)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Restricts the vertex set to the set of vertices satisfying the given predicate.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#fromEdges(org.apache.spark.graphx.EdgeRDD, int, VD, scala.reflect.ClassTag)">fromEdges</A></B>(<A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
          int&nbsp;numPartitions,
          VD&nbsp;defaultVal,
          scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$17)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Constructs a <code>VertexRDD</code> containing all vertices referred to in <code>edges</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#innerJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)">innerJoin</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,U&gt;&gt;&nbsp;other,
          scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,U,VD2&gt;&nbsp;f,
          scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$10,
          scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$11)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Inner joins this VertexRDD with an RDD containing vertex attribute pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#innerZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)">innerZipJoin</A></B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;U&gt;&nbsp;other,
             scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,U,VD2&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$8,
             scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$9)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Efficiently inner joins this VertexRDD with another VertexRDD sharing the same index.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2,VD3&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD3&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#leftJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)">leftJoin</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD2&gt;&gt;&nbsp;other,
         scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,scala.Option&lt;VD2&gt;,VD3&gt;&nbsp;f,
         scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$6,
         scala.reflect.ClassTag&lt;VD3&gt;&nbsp;evidence$7)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left joins this VertexRDD with an RDD containing vertex attribute pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2,VD3&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD3&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#leftZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)">leftZipJoin</A></B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;&nbsp;other,
            scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,scala.Option&lt;VD2&gt;,VD3&gt;&nbsp;f,
            scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$4,
            scala.reflect.ClassTag&lt;VD3&gt;&nbsp;evidence$5)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left joins this RDD with another VertexRDD with the same index.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#mapValues(scala.Function1, scala.reflect.ClassTag)">mapValues</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,VD2&gt;&nbsp;f,
          scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$2)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maps each vertex attribute, preserving the index.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#mapValues(scala.Function2, scala.reflect.ClassTag)">mapValues</A></B>(scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,VD2&gt;&nbsp;f,
          scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$3)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maps each vertex attribute, additionally supplying the vertex ID.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#minus(org.apache.spark.rdd.RDD)">minus</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#minus(org.apache.spark.graphx.VertexRDD)">minus</A></B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&nbsp;other)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#reindex()">reindex</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construct a new VertexRDD that is indexed by only the visible vertices.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#reverseRoutingTables()">reverseRoutingTables</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a new <code>VertexRDD</code> reflecting a reversal of all edge directions in the corresponding
 <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/VertexRDD.html#withEdges(org.apache.spark.graphx.EdgeRDD)">withEdges</A></B>(<A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Prepares this VertexRDD for efficient joins with the given EdgeRDD.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.spark.rdd.RDD"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class org.apache.spark.rdd.<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A></B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../org/apache/spark/rdd/RDD.html#aggregate(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregate</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#cache()">cache</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">cartesian</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#checkpoint()">checkpoint</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#checkpointData()">checkpointData</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#collect()">collect</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction, scala.reflect.ClassTag)">collect</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#context()">context</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#count()">count</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#countApprox(long, double)">countApprox</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(double)">countApproxDistinct</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(int, int)">countApproxDistinct</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)">countByValue</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#countByValueApprox(long, double, scala.math.Ordering)">countByValueApprox</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#creationSite()">creationSite</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#dependencies()">dependencies</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#distinct()">distinct</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#distinct(int, scala.math.Ordering)">distinct</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#doubleRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD)">doubleRDDToDoubleRDDFunctions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#filterWith(scala.Function1, scala.Function2)">filterWith</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#first()">first</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#flatMap(scala.Function1, scala.reflect.ClassTag)">flatMap</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">flatMapWith</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#fold(T, scala.Function2)">fold</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#foreach(scala.Function1)">foreach</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)">foreachPartition</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1, scala.Function2)">foreachWith</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile()">getCheckpointFile</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#getStorageLevel()">getStorageLevel</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#glom()">glom</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, scala.reflect.ClassTag)">groupBy</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, int, scala.reflect.ClassTag)">groupBy</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, org.apache.spark.Partitioner, scala.reflect.ClassTag, scala.math.Ordering)">groupBy</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#id()">id</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)">intersection</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#isCheckpointed()">isCheckpointed</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#isEmpty()">isEmpty</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)">keyBy</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#map(scala.Function1, scala.reflect.ClassTag)">map</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)">mapPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithContext</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithIndex</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithSplit</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#mapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">mapWith</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)">max</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)">min</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#name()">name</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#numericRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Numeric)">numericRDDToDoubleRDDFunctions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#partitioner()">partitioner</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#partitions()">partitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#persist()">persist</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">persist</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq, scala.collection.Map, scala.Function1, scala.Function2, boolean)">pipe</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String)">pipe</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String, scala.collection.Map)">pipe</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)">preferredLocations</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#randomSplit(double[], long)">randomSplit</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#rddToAsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">rddToAsyncRDDActions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#rddToOrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag)">rddToOrderedRDDFunctions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#rddToPairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">rddToPairRDDFunctions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, , )">rddToSequenceFileRDDFunctions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#reduce(scala.Function2)">reduce</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#repartition(int, scala.math.Ordering)">repartition</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#sample(boolean, double, long)">sample</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)">saveAsTextFile</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#scope()">scope</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#setName(java.lang.String)">setName</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#sortBy(scala.Function1, boolean, int, scala.math.Ordering, scala.reflect.ClassTag)">sortBy</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#sparkContext()">sparkContext</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)">subtract</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#take(int)">take</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#takeOrdered(int, scala.math.Ordering)">takeOrdered</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#takeSample(boolean, int, long)">takeSample</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#toArray()">toArray</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#toDebugString()">toDebugString</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#toJavaRDD()">toJavaRDD</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#toLocalIterator()">toLocalIterator</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#top(int, scala.math.Ordering)">top</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#toString()">toString</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)">treeAggregate</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#treeReduce(scala.Function2, int)">treeReduce</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)">union</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#unpersist(boolean)">unpersist</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">zip</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, boolean, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipWithIndex()">zipWithIndex</A>, <A HREF="../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId()">zipWithUniqueId</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.spark.Logging"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from interface org.apache.spark.<A HREF="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A></B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</A>, <A HREF="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</A>, <A HREF="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</A>, <A HREF="../../../../org/apache/spark/Logging.html#log_()">log_</A>, <A HREF="../../../../org/apache/spark/Logging.html#log()">log</A>, <A HREF="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</A>, <A HREF="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</A>, <A HREF="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</A>, <A HREF="../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</A>, <A HREF="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</A>, <A HREF="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</A>, <A HREF="../../../../org/apache/spark/Logging.html#logName()">logName</A>, <A HREF="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</A>, <A HREF="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</A>, <A HREF="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</A>, <A HREF="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="VertexRDD(org.apache.spark.SparkContext, scala.collection.Seq)"><!-- --></A><H3>
VertexRDD</H3>
<PRE>
public <B>VertexRDD</B>(<A HREF="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>&nbsp;sc,
                 scala.collection.Seq&lt;<A HREF="../../../../org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</A>&lt;?&gt;&gt;&nbsp;deps)</PRE>
<DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="apply(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><!-- --></A><H3>
apply</H3>
<PRE>
public static &lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt; <B>apply</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
                                       scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$14)</PRE>
<DL>
<DD>Constructs a standalone <code>VertexRDD</code> (one that is not set up for efficient joins with an
 <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>) from an RDD of vertex-attribute pairs. Duplicate entries are removed arbitrarily.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>vertices</CODE> - the collection of vertex-attribute pairs<DD><CODE>evidence$14</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="apply(org.apache.spark.rdd.RDD,org.apache.spark.graphx.EdgeRDD,java.lang.Object,scala.reflect.ClassTag)"><!-- --></A><A NAME="apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.reflect.ClassTag)"><!-- --></A><H3>
apply</H3>
<PRE>
public static &lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt; <B>apply</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
                                       <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
                                       VD&nbsp;defaultVal,
                                       scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$15)</PRE>
<DL>
<DD>Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs. Duplicate vertex entries are
 removed arbitrarily. The resulting <code>VertexRDD</code> will be joinable with <code>edges</code>, and any missing
 vertices referred to by <code>edges</code> will be created with the attribute <code>defaultVal</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>vertices</CODE> - the collection of vertex-attribute pairs<DD><CODE>edges</CODE> - the <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A> that these vertices may be joined with<DD><CODE>defaultVal</CODE> - the vertex attribute to use when creating missing vertices<DD><CODE>evidence$15</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="apply(org.apache.spark.rdd.RDD,org.apache.spark.graphx.EdgeRDD,java.lang.Object,scala.Function2,scala.reflect.ClassTag)"><!-- --></A><A NAME="apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.Function2, scala.reflect.ClassTag)"><!-- --></A><H3>
apply</H3>
<PRE>
public static &lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt; <B>apply</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
                                       <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
                                       VD&nbsp;defaultVal,
                                       scala.Function2&lt;VD,VD,VD&gt;&nbsp;mergeFunc,
                                       scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$16)</PRE>
<DL>
<DD>Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs. Duplicate vertex entries are
 merged using <code>mergeFunc</code>. The resulting <code>VertexRDD</code> will be joinable with <code>edges</code>, and any
 missing vertices referred to by <code>edges</code> will be created with the attribute <code>defaultVal</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>vertices</CODE> - the collection of vertex-attribute pairs<DD><CODE>edges</CODE> - the <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A> that these vertices may be joined with<DD><CODE>defaultVal</CODE> - the vertex attribute to use when creating missing vertices<DD><CODE>mergeFunc</CODE> - the commutative, associative duplicate vertex attribute merge function<DD><CODE>evidence$16</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fromEdges(org.apache.spark.graphx.EdgeRDD,int,java.lang.Object,scala.reflect.ClassTag)"><!-- --></A><A NAME="fromEdges(org.apache.spark.graphx.EdgeRDD, int, VD, scala.reflect.ClassTag)"><!-- --></A><H3>
fromEdges</H3>
<PRE>
public static &lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD&gt; <B>fromEdges</B>(<A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges,
                                           int&nbsp;numPartitions,
                                           VD&nbsp;defaultVal,
                                           scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$17)</PRE>
<DL>
<DD>Constructs a <code>VertexRDD</code> containing all vertices referred to in <code>edges</code>. The vertices will be
 created with the attribute <code>defaultVal</code>. The resulting <code>VertexRDD</code> will be joinable with
 <code>edges</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>edges</CODE> - the <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A> referring to the vertices to create<DD><CODE>numPartitions</CODE> - the desired number of partitions for the resulting <code>VertexRDD</code><DD><CODE>defaultVal</CODE> - the vertex attribute to use when creating missing vertices<DD><CODE>evidence$17</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><!-- --></A><H3>
compute</H3>
<PRE>
public scala.collection.Iterator&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt; <B>compute</B>(<A HREF="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>&nbsp;part,
                                                                  <A HREF="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>&nbsp;context)</PRE>
<DL>
<DD>Provides the <code>RDD[(VertexId, VD)]</code> equivalent output.
<P>
<DD><DL>
<DT><B>Specified by:</B><DD><CODE><A HREF="../../../../org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute</A></CODE> in class <CODE><A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;</CODE></DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>part</CODE> - (undocumented)<DD><CODE>context</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reindex()"><!-- --></A><H3>
reindex</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>reindex</B>()</PRE>
<DL>
<DD>Construct a new VertexRDD that is indexed by only the visible vertices. The resulting
 VertexRDD will be based on a different index and can no longer be quickly joined with this
 RDD.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="filter(scala.Function1)"><!-- --></A><H3>
filter</H3>
<PRE>
public <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>filter</B>(scala.Function1&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;,Object&gt;&nbsp;pred)</PRE>
<DL>
<DD>Restricts the vertex set to the set of vertices satisfying the given predicate. This operation
 preserves the index for efficient joins with the original RDD, and it sets bits in the bitmask
 rather than allocating new memory.
 <p>
 It is declared and defined here to allow refining the return type from <code>RDD[(VertexId, VD)]</code> to
 <code>VertexRDD[VD]</code>.
 <p>
<P>
<DD><DL>
<DT><B>Overrides:</B><DD><CODE><A HREF="../../../../org/apache/spark/rdd/RDD.html#filter(scala.Function1)">filter</A></CODE> in class <CODE><A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;</CODE></DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>pred</CODE> - the user defined predicate, which takes a tuple to conform to the
 <code>RDD[(VertexId, VD)]</code> interface
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapValues(scala.Function1, scala.reflect.ClassTag)"><!-- --></A><H3>
mapValues</H3>
<PRE>
public abstract &lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt; <B>mapValues</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,VD2&gt;&nbsp;f,
                                               scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$2)</PRE>
<DL>
<DD>Maps each vertex attribute, preserving the index.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - the function applied to each value in the RDD<DD><CODE>evidence$2</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a new VertexRDD with values obtained by applying <code>f</code> to each of the entries in the
 original VertexRDD</DL>
</DD>
</DL>
<HR>

<A NAME="mapValues(scala.Function2, scala.reflect.ClassTag)"><!-- --></A><H3>
mapValues</H3>
<PRE>
public abstract &lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt; <B>mapValues</B>(scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,VD2&gt;&nbsp;f,
                                               scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$3)</PRE>
<DL>
<DD>Maps each vertex attribute, additionally supplying the vertex ID.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>f</CODE> - the function applied to each ID-value pair in the RDD<DD><CODE>evidence$3</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a new VertexRDD with values obtained by applying <code>f</code> to each of the entries in the
 original VertexRDD.  The resulting VertexRDD retains the same index.</DL>
</DD>
</DL>
<HR>

<A NAME="minus(org.apache.spark.rdd.RDD)"><!-- --></A><H3>
minus</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>minus</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;&nbsp;other)</PRE>
<DL>
<DD>For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - an RDD to run the set operation against
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="minus(org.apache.spark.graphx.VertexRDD)"><!-- --></A><H3>
minus</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>minus</B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&nbsp;other)</PRE>
<DL>
<DD>For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - a VertexRDD to run the set operation against
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="diff(org.apache.spark.rdd.RDD)"><!-- --></A><H3>
diff</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>diff</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&gt;&nbsp;other)</PRE>
<DL>
<DD>For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>. This is
 only guaranteed to work if the VertexRDDs share a common ancestor.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the other RDD[(VertexId, VD)] with which to diff against.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="diff(org.apache.spark.graphx.VertexRDD)"><!-- --></A><H3>
diff</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>diff</B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt;&nbsp;other)</PRE>
<DL>
<DD>For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>. This is
 only guaranteed to work if the VertexRDDs share a common ancestor.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the other VertexRDD with which to diff against.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="leftZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
leftZipJoin</H3>
<PRE>
public abstract &lt;VD2,VD3&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD3&gt; <B>leftZipJoin</B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt;&nbsp;other,
                                                     scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,scala.Option&lt;VD2&gt;,VD3&gt;&nbsp;f,
                                                     scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$4,
                                                     scala.reflect.ClassTag&lt;VD3&gt;&nbsp;evidence$5)</PRE>
<DL>
<DD>Left joins this RDD with another VertexRDD with the same index. This function will fail if
 both VertexRDDs do not share the same index. The resulting vertex set contains an entry for
 each vertex in <code>this</code>.
 If <code>other</code> is missing any vertex in this VertexRDD, <code>f</code> is passed <code>None</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the other VertexRDD with which to join.<DD><CODE>f</CODE> - the function mapping a vertex id and its attributes in this and the other vertex set
 to a new vertex attribute.<DD><CODE>evidence$4</CODE> - (undocumented)<DD><CODE>evidence$5</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a VertexRDD containing the results of <code>f</code></DL>
</DD>
</DL>
<HR>

<A NAME="leftJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
leftJoin</H3>
<PRE>
public abstract &lt;VD2,VD3&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD3&gt; <B>leftJoin</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD2&gt;&gt;&nbsp;other,
                                                  scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,scala.Option&lt;VD2&gt;,VD3&gt;&nbsp;f,
                                                  scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$6,
                                                  scala.reflect.ClassTag&lt;VD3&gt;&nbsp;evidence$7)</PRE>
<DL>
<DD>Left joins this VertexRDD with an RDD containing vertex attribute pairs. If the other RDD is
 backed by a VertexRDD with the same index then the efficient <CODE>leftZipJoin</CODE> implementation is
 used. The resulting VertexRDD contains an entry for each vertex in <code>this</code>. If <code>other</code> is
 missing any vertex in this VertexRDD, <code>f</code> is passed <code>None</code>. If there are duplicates,
 the vertex is picked arbitrarily.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the other VertexRDD with which to join<DD><CODE>f</CODE> - the function mapping a vertex id and its attributes in this and the other vertex set
 to a new vertex attribute.<DD><CODE>evidence$6</CODE> - (undocumented)<DD><CODE>evidence$7</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a VertexRDD containing all the vertices in this VertexRDD with the attributes emitted
 by <code>f</code>.</DL>
</DD>
</DL>
<HR>

<A NAME="innerZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
innerZipJoin</H3>
<PRE>
public abstract &lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt; <B>innerZipJoin</B>(<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;U&gt;&nbsp;other,
                                                    scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,U,VD2&gt;&nbsp;f,
                                                    scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$8,
                                                    scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$9)</PRE>
<DL>
<DD>Efficiently inner joins this VertexRDD with another VertexRDD sharing the same index. See
 <CODE>innerJoin</CODE> for the behavior of the join.
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - (undocumented)<DD><CODE>f</CODE> - (undocumented)<DD><CODE>evidence$8</CODE> - (undocumented)<DD><CODE>evidence$9</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="innerJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
innerJoin</H3>
<PRE>
public abstract &lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt; <B>innerJoin</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,U&gt;&gt;&nbsp;other,
                                                 scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>,U,VD2&gt;&nbsp;f,
                                                 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$10,
                                                 scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$11)</PRE>
<DL>
<DD>Inner joins this VertexRDD with an RDD containing vertex attribute pairs. If the other RDD is
 backed by a VertexRDD with the same index then the efficient <CODE>innerZipJoin</CODE> implementation
 is used.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - an RDD containing vertices to join. If there are multiple entries for the same
 vertex, one is picked arbitrarily. Use <CODE>aggregateUsingIndex</CODE> to merge multiple entries.<DD><CODE>f</CODE> - the join function applied to corresponding values of <code>this</code> and <code>other</code><DD><CODE>evidence$10</CODE> - (undocumented)<DD><CODE>evidence$11</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a VertexRDD co-indexed with <code>this</code>, containing only vertices that appear in both
         <code>this</code> and <code>other</code>, with values supplied by <code>f</code></DL>
</DD>
</DL>
<HR>

<A NAME="aggregateUsingIndex(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)"><!-- --></A><H3>
aggregateUsingIndex</H3>
<PRE>
public abstract &lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;VD2&gt; <B>aggregateUsingIndex</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD2&gt;&gt;&nbsp;messages,
                                                         scala.Function2&lt;VD2,VD2,VD2&gt;&nbsp;reduceFunc,
                                                         scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$12)</PRE>
<DL>
<DD>Aggregates vertices in <code>messages</code> that have the same ids using <code>reduceFunc</code>, returning a
 VertexRDD co-indexed with <code>this</code>.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>messages</CODE> - an RDD containing messages to aggregate, where each message is a pair of its
 target vertex ID and the message data<DD><CODE>reduceFunc</CODE> - the associative aggregation function for merging messages to the same vertex<DD><CODE>evidence$12</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a VertexRDD co-indexed with <code>this</code>, containing only vertices that received messages.
 For those vertices, their values are the result of applying <code>reduceFunc</code> to all received
 messages.</DL>
</DD>
</DL>
<HR>

<A NAME="reverseRoutingTables()"><!-- --></A><H3>
reverseRoutingTables</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>reverseRoutingTables</B>()</PRE>
<DL>
<DD>Returns a new <code>VertexRDD</code> reflecting a reversal of all edge directions in the corresponding
 <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="withEdges(org.apache.spark.graphx.EdgeRDD)"><!-- --></A><H3>
withEdges</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; <B>withEdges</B>(<A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;?&gt;&nbsp;edges)</PRE>
<DL>
<DD>Prepares this VertexRDD for efficient joins with the given EdgeRDD.
<P>
<DD><DL>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx"><B>PREV CLASS</B></A>&nbsp;
&nbsp;NEXT CLASS</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/graphx/VertexRDD.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="VertexRDD.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
