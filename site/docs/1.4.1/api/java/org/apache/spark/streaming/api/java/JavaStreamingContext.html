<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:41 PDT 2015 -->
<TITLE>
JavaStreamingContext (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="JavaStreamingContext (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/spark/streaming/api/java/JavaStreamingContext.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="JavaStreamingContext.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.streaming.api.java</FONT>
<BR>
Class JavaStreamingContext</H2>
<PRE>
Object
  <IMG SRC="../../../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.streaming.api.java.JavaStreamingContext</B>
</PRE>
<DL>
<DT><B>All Implemented Interfaces:</B> <DD>java.io.Closeable</DD>
</DL>
<HR>
<DL>
<DT><PRE>public class <B>JavaStreamingContext</B><DT>extends Object<DT>implements java.io.Closeable</DL>
</PRE>

<P>
A Java-friendly version of <A HREF="../../../../../../org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><CODE>StreamingContext</CODE></A> which is the main
 entry point for Spark Streaming functionality. It provides methods to create
 <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaDStream</CODE></A> and
 <CODE>JavaPairDStream$</CODE> from input sources. The internal
 org.apache.spark.api.java.JavaSparkContext (see core Spark documentation) can be accessed
 using <code>context.sparkContext</code>. After creating and transforming DStreams, the streaming
 computation can be started and stopped using <code>context.start()</code> and <code>context.stop()</code>,
 respectively. <code>context.awaitTermination()</code> allows the current thread to wait for the
 termination of a context by <code>stop()</code> or by an exception.
<P>

<P>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.streaming.Duration)">JavaStreamingContext</A></B>(<A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>&nbsp;sparkContext,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a JavaStreamingContext using an existing JavaSparkContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)">JavaStreamingContext</A></B>(<A HREF="../../../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>&nbsp;conf,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a JavaStreamingContext using a SparkConf configuration.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.streaming.StreamingContext)">JavaStreamingContext</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>&nbsp;ssc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String)">JavaStreamingContext</A></B>(String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recreate a JavaStreamingContext from a checkpoint file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)">JavaStreamingContext</A></B>(String&nbsp;path,
                     org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Re-creates a JavaStreamingContext from a checkpoint file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration)">JavaStreamingContext</A></B>(String&nbsp;master,
                     String&nbsp;appName,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String)">JavaStreamingContext</A></B>(String&nbsp;master,
                     String&nbsp;appName,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                     String&nbsp;sparkHome,
                     String&nbsp;jarFile)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[])">JavaStreamingContext</A></B>(String&nbsp;master,
                     String&nbsp;appName,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                     String&nbsp;sparkHome,
                     String[]&nbsp;jars)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[], java.util.Map)">JavaStreamingContext</A></B>(String&nbsp;master,
                     String&nbsp;appName,
                     <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                     String&nbsp;sparkHome,
                     String[]&nbsp;jars,
                     java.util.Map&lt;String,String&gt;&nbsp;environment)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a StreamingContext.</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String)">actorStream</A></B>(akka.actor.Props&nbsp;props,
            String&nbsp;name)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream with any arbitrary user implemented actor receiver.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel)">actorStream</A></B>(akka.actor.Props&nbsp;props,
            String&nbsp;name,
            <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream with any arbitrary user implemented actor receiver.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)">actorStream</A></B>(akka.actor.Props&nbsp;props,
            String&nbsp;name,
            <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel,
            akka.actor.SupervisorStrategy&nbsp;supervisorStrategy)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream with any arbitrary user implemented actor receiver.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)">addStreamingListener</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>&nbsp;streamingListener)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add a <A HREF="../../../../../../org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><CODE>StreamingListener</CODE></A> object for
 receiving system events related to streaming.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination()">awaitTermination</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Wait for the execution to stop.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination(long)">awaitTermination</A></B>(long&nbsp;timeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTerminationOrTimeout(long)">awaitTerminationOrTimeout</A></B>(long&nbsp;timeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Wait for the execution to stop.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;byte[]&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#binaryRecordsStream(java.lang.String, int)">binaryRecordsStream</A></B>(String&nbsp;directory,
                    int&nbsp;recordLength)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: Experimental ::</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#checkpoint(java.lang.String)">checkpoint</A></B>(String&nbsp;directory)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets the context to periodically checkpoint the DStream operations for master
 fault-tolerance.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#close()">close</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; 
<BR>
<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">fileStream</A></B>(String&nbsp;directory,
           Class&lt;K&gt;&nbsp;kClass,
           Class&lt;V&gt;&nbsp;vClass,
           Class&lt;F&gt;&nbsp;fClass)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; 
<BR>
<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean)">fileStream</A></B>(String&nbsp;directory,
           Class&lt;K&gt;&nbsp;kClass,
           Class&lt;V&gt;&nbsp;vClass,
           Class&lt;F&gt;&nbsp;fClass,
           <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;org.apache.hadoop.fs.Path,Boolean&gt;&nbsp;filter,
           boolean&nbsp;newFilesOnly)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; 
<BR>
<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean, org.apache.hadoop.conf.Configuration)">fileStream</A></B>(String&nbsp;directory,
           Class&lt;K&gt;&nbsp;kClass,
           Class&lt;V&gt;&nbsp;vClass,
           Class&lt;F&gt;&nbsp;fClass,
           <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;org.apache.hadoop.fs.Path,Boolean&gt;&nbsp;filter,
           boolean&nbsp;newFilesOnly,
           org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
            <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory, boolean)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
            <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory,
            boolean&nbsp;createOnError)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc,
            org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration, boolean)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc,
            org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
            boolean&nbsp;createOnError)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">getOrCreate</A></B>(String&nbsp;checkpointPath,
            <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/StreamingContextState.html" title="enum in org.apache.spark.streaming">StreamingContextState</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#getState()">getState</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:: DeveloperApi ::</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;String[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#jarOfClass(java.lang.Class)">jarOfClass</A></B>(Class&lt;?&gt;&nbsp;cls)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue)">queueStream</A></B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from an queue of RDDs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean)">queueStream</A></B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue,
            boolean&nbsp;oneAtATime)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from an queue of RDDs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean, org.apache.spark.api.java.JavaRDD)">queueStream</A></B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue,
            boolean&nbsp;oneAtATime,
            <A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&nbsp;defaultRDD)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from an queue of RDDs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int)">rawSocketStream</A></B>(String&nbsp;hostname,
                int&nbsp;port)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)">rawSocketStream</A></B>(String&nbsp;hostname,
                int&nbsp;port,
                <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#receiverStream(org.apache.spark.streaming.receiver.Receiver)">receiverStream</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>&lt;T&gt;&nbsp;receiver)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream with any arbitrary user implemented receiver.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#remember(org.apache.spark.streaming.Duration)">remember</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;duration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets each DStreams in this context to remember RDDs it generated in the last given duration.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#sc()">sc</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>Deprecated.</B>&nbsp;<I>As of 0.9.0, replaced by <code>sparkContext</code></I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketStream(java.lang.String, int, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)">socketStream</A></B>(String&nbsp;hostname,
             int&nbsp;port,
             <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;java.io.InputStream,Iterable&lt;T&gt;&gt;&nbsp;converter,
             <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from network source hostname:port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int)">socketTextStream</A></B>(String&nbsp;hostname,
                 int&nbsp;port)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from network source hostname:port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)">socketTextStream</A></B>(String&nbsp;hostname,
                 int&nbsp;port,
                 <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream from network source hostname:port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#sparkContext()">sparkContext</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The underlying SparkContext</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#ssc()">ssc</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#start()">start</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start the execution of the streams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop()">stop</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stop the execution of the streams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean)">stop</A></B>(boolean&nbsp;stopSparkContext)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stop the execution of the streams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean, boolean)">stop</A></B>(boolean&nbsp;stopSparkContext,
     boolean&nbsp;stopGracefully)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stop the execution of the streams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#textFileStream(java.lang.String)">textFileStream</A></B>(String&nbsp;directory)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#transform(java.util.List, org.apache.spark.api.java.function.Function2)">transform</A></B>(java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;?&gt;&gt;&nbsp;dstreams,
          <A HREF="../../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;java.util.List&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;?&gt;&gt;,<A HREF="../../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>,<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;transformFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K,V&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#transformToPair(java.util.List, org.apache.spark.api.java.function.Function2)">transformToPair</A></B>(java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;?&gt;&gt;&nbsp;dstreams,
                <A HREF="../../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;java.util.List&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;?&gt;&gt;,<A HREF="../../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>,<A HREF="../../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K,V&gt;&gt;&nbsp;transformFunc)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaDStream, java.util.List)">union</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;&nbsp;first,
      java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;&gt;&nbsp;rest)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a unified DStream from multiple DStreams of the same type and same slide duration.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;K,V&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaPairDStream, java.util.List)">union</A></B>(<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;&nbsp;first,
      java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;&gt;&nbsp;rest)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a unified DStream from multiple DStreams of the same type and same slide duration.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="JavaStreamingContext(org.apache.spark.streaming.StreamingContext)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(<A HREF="../../../../../../org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>&nbsp;ssc)</PRE>
<DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;master,
                            String&nbsp;appName,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</PRE>
<DL>
<DD>Create a StreamingContext.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>master</CODE> - Name of the Spark Master<DD><CODE>appName</CODE> - Name to be used when registering with the scheduler<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;master,
                            String&nbsp;appName,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                            String&nbsp;sparkHome,
                            String&nbsp;jarFile)</PRE>
<DL>
<DD>Create a StreamingContext.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>master</CODE> - Name of the Spark Master<DD><CODE>appName</CODE> - Name to be used when registering with the scheduler<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches<DD><CODE>sparkHome</CODE> - The SPARK_HOME directory on the slave nodes<DD><CODE>jarFile</CODE> - JAR file containing job code, to ship to cluster. This can be a path on the
                local file system or an HDFS, HTTP, HTTPS, or FTP URL.</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[])"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;master,
                            String&nbsp;appName,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                            String&nbsp;sparkHome,
                            String[]&nbsp;jars)</PRE>
<DL>
<DD>Create a StreamingContext.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>master</CODE> - Name of the Spark Master<DD><CODE>appName</CODE> - Name to be used when registering with the scheduler<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches<DD><CODE>sparkHome</CODE> - The SPARK_HOME directory on the slave nodes<DD><CODE>jars</CODE> - Collection of JARs to send to the cluster. These can be paths on the local file
             system or HDFS, HTTP, HTTPS, or FTP URLs.</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[], java.util.Map)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;master,
                            String&nbsp;appName,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration,
                            String&nbsp;sparkHome,
                            String[]&nbsp;jars,
                            java.util.Map&lt;String,String&gt;&nbsp;environment)</PRE>
<DL>
<DD>Create a StreamingContext.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>master</CODE> - Name of the Spark Master<DD><CODE>appName</CODE> - Name to be used when registering with the scheduler<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches<DD><CODE>sparkHome</CODE> - The SPARK_HOME directory on the slave nodes<DD><CODE>jars</CODE> - Collection of JARs to send to the cluster. These can be paths on the local file
             system or HDFS, HTTP, HTTPS, or FTP URLs.<DD><CODE>environment</CODE> - Environment variables to set on worker nodes</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(<A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>&nbsp;sparkContext,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</PRE>
<DL>
<DD>Create a JavaStreamingContext using an existing JavaSparkContext.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>sparkContext</CODE> - The underlying JavaSparkContext to use<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(<A HREF="../../../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>&nbsp;conf,
                            <A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;batchDuration)</PRE>
<DL>
<DD>Create a JavaStreamingContext using a SparkConf configuration.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>conf</CODE> - A Spark application configuration<DD><CODE>batchDuration</CODE> - The time interval at which streaming data will be divided into batches</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;path)</PRE>
<DL>
<DD>Recreate a JavaStreamingContext from a checkpoint file.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>path</CODE> - Path to the directory that was specified as the checkpoint directory</DL>
</DL>
<HR>

<A NAME="JavaStreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
JavaStreamingContext</H3>
<PRE>
public <B>JavaStreamingContext</B>(String&nbsp;path,
                            org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</PRE>
<DL>
<DD>Re-creates a JavaStreamingContext from a checkpoint file.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>path</CODE> - Path to the directory that was specified as the checkpoint directory
 <p><DD><CODE>hadoopConf</CODE> - (undocumented)</DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="getOrCreate(java.lang.String, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory)</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<P>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier JavaStreamingContext program<DD><CODE>factory</CODE> - JavaStreamingContextFactory object to create a new JavaStreamingContext
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                               <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory)</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<P>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier StreamingContext program<DD><CODE>factory</CODE> - JavaStreamingContextFactory object to create a new JavaStreamingContext<DD><CODE>hadoopConf</CODE> - Hadoop configuration if necessary for reading from any HDFS compatible
                       file system
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory, boolean)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                               <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>&nbsp;factory,
                                               boolean&nbsp;createOnError)</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<P>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier StreamingContext program<DD><CODE>factory</CODE> - JavaStreamingContextFactory object to create a new JavaStreamingContext<DD><CODE>hadoopConf</CODE> - Hadoop configuration if necessary for reading from any HDFS compatible
                       file system<DD><CODE>createOnError</CODE> - Whether to create a new JavaStreamingContext if there is an
                       error in reading checkpoint data.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc)</PRE>
<DL>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier JavaStreamingContext program<DD><CODE>creatingFunc</CODE> - Function to create a new JavaStreamingContext
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc,
                                               org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</PRE>
<DL>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier StreamingContext program<DD><CODE>creatingFunc</CODE> - Function to create a new JavaStreamingContext<DD><CODE>hadoopConf</CODE> - Hadoop configuration if necessary for reading from any HDFS compatible
                       file system
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration, boolean)"><!-- --></A><H3>
getOrCreate</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A> <B>getOrCreate</B>(String&nbsp;checkpointPath,
                                               <A HREF="../../../../../../org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>&gt;&nbsp;creatingFunc,
                                               org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                               boolean&nbsp;createOnError)</PRE>
<DL>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
 If checkpoint data exists in the provided <code>checkpointPath</code>, then StreamingContext will be
 recreated from the checkpoint data. If the data does not exist, then the provided factory
 will be used to create a JavaStreamingContext.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>checkpointPath</CODE> - Checkpoint directory used in an earlier StreamingContext program<DD><CODE>creatingFunc</CODE> - Function to create a new JavaStreamingContext<DD><CODE>hadoopConf</CODE> - Hadoop configuration if necessary for reading from any HDFS compatible
                       file system<DD><CODE>createOnError</CODE> - Whether to create a new JavaStreamingContext if there is an
                       error in reading checkpoint data.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="jarOfClass(java.lang.Class)"><!-- --></A><H3>
jarOfClass</H3>
<PRE>
public static String[] <B>jarOfClass</B>(Class&lt;?&gt;&nbsp;cls)</PRE>
<DL>
<DD>Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>cls</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="ssc()"><!-- --></A><H3>
ssc</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A> <B>ssc</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="sparkContext()"><!-- --></A><H3>
sparkContext</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A> <B>sparkContext</B>()</PRE>
<DL>
<DD>The underlying SparkContext
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="sc()"><!-- --></A><H3>
sc</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A> <B>sc</B>()</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of 0.9.0, replaced by <code>sparkContext</code></I>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)"><!-- --></A><H3>
socketTextStream</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;String&gt; <B>socketTextStream</B>(String&nbsp;hostname,
                                                         int&nbsp;port,
                                                         <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</PRE>
<DL>
<DD>Create an input stream from network source hostname:port. Data is received using
 a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
 lines.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>hostname</CODE> - Hostname to connect to for receiving data<DD><CODE>port</CODE> - Port to connect to for receiving data<DD><CODE>storageLevel</CODE> - Storage level to use for storing the received objects
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="socketTextStream(java.lang.String, int)"><!-- --></A><H3>
socketTextStream</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;String&gt; <B>socketTextStream</B>(String&nbsp;hostname,
                                                         int&nbsp;port)</PRE>
<DL>
<DD>Create an input stream from network source hostname:port. Data is received using
 a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
 lines. Storage level of the data will be the default StorageLevel.MEMORY_AND_DISK_SER_2.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>hostname</CODE> - Hostname to connect to for receiving data<DD><CODE>port</CODE> - Port to connect to for receiving data
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="socketStream(java.lang.String, int, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)"><!-- --></A><H3>
socketStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>socketStream</B>(String&nbsp;hostname,
                                                    int&nbsp;port,
                                                    <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;java.io.InputStream,Iterable&lt;T&gt;&gt;&nbsp;converter,
                                                    <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</PRE>
<DL>
<DD>Create an input stream from network source hostname:port. Data is received using
 a TCP socket and the receive bytes it interpreted as object using the given
 converter.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>hostname</CODE> - Hostname to connect to for receiving data<DD><CODE>port</CODE> - Port to connect to for receiving data<DD><CODE>converter</CODE> - Function to convert the byte stream to objects<DD><CODE>storageLevel</CODE> - Storage level to use for storing the received objects
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="textFileStream(java.lang.String)"><!-- --></A><H3>
textFileStream</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;String&gt; <B>textFileStream</B>(String&nbsp;directory)</PRE>
<DL>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat). Files must be written to the
 monitored directory by "moving" them from another location within the same
 file system. File names starting with . are ignored.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS directory to monitor for new file
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="binaryRecordsStream(java.lang.String, int)"><!-- --></A><H3>
binaryRecordsStream</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;byte[]&gt; <B>binaryRecordsStream</B>(String&nbsp;directory,
                                               int&nbsp;recordLength)</PRE>
<DL>
<DD>:: Experimental ::
 <p>
 Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as flat binary files with fixed record lengths,
 yielding byte arrays
 <p>
 '''Note:''' We ensure that the byte array for each record in the
 resulting RDDs of the DStream has the provided record length.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS directory to monitor for new files<DD><CODE>recordLength</CODE> - The length at which to split the records
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)"><!-- --></A><H3>
rawSocketStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>rawSocketStream</B>(String&nbsp;hostname,
                                                       int&nbsp;port,
                                                       <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</PRE>
<DL>
<DD>Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them. This is the most efficient
 way to receive data.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>hostname</CODE> - Hostname to connect to for receiving data<DD><CODE>port</CODE> - Port to connect to for receiving data<DD><CODE>storageLevel</CODE> - Storage level to use for storing the received objects
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="rawSocketStream(java.lang.String, int)"><!-- --></A><H3>
rawSocketStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>rawSocketStream</B>(String&nbsp;hostname,
                                                       int&nbsp;port)</PRE>
<DL>
<DD>Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them. This is the most efficient
 way to receive data.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>hostname</CODE> - Hostname to connect to for receiving data<DD><CODE>port</CODE> - Port to connect to for receiving data
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><!-- --></A><H3>
fileStream</H3>
<PRE>
public &lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt; <B>fileStream</B>(String&nbsp;directory,
                                                                                                         Class&lt;K&gt;&nbsp;kClass,
                                                                                                         Class&lt;V&gt;&nbsp;vClass,
                                                                                                         Class&lt;F&gt;&nbsp;fClass)</PRE>
<DL>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
 Files must be written to the monitored directory by "moving" them from another
 location within the same file system. File names starting with . are ignored.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS directory to monitor for new file<DD><CODE>kClass</CODE> - class of key for reading HDFS file<DD><CODE>vClass</CODE> - class of value for reading HDFS file<DD><CODE>fClass</CODE> - class of input format for reading HDFS file
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean)"><!-- --></A><H3>
fileStream</H3>
<PRE>
public &lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt; <B>fileStream</B>(String&nbsp;directory,
                                                                                                         Class&lt;K&gt;&nbsp;kClass,
                                                                                                         Class&lt;V&gt;&nbsp;vClass,
                                                                                                         Class&lt;F&gt;&nbsp;fClass,
                                                                                                         <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;org.apache.hadoop.fs.Path,Boolean&gt;&nbsp;filter,
                                                                                                         boolean&nbsp;newFilesOnly)</PRE>
<DL>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
 Files must be written to the monitored directory by "moving" them from another
 location within the same file system. File names starting with . are ignored.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS directory to monitor for new file<DD><CODE>kClass</CODE> - class of key for reading HDFS file<DD><CODE>vClass</CODE> - class of value for reading HDFS file<DD><CODE>fClass</CODE> - class of input format for reading HDFS file<DD><CODE>filter</CODE> - Function to filter paths to process<DD><CODE>newFilesOnly</CODE> - Should process only new files and ignore existing files in the directory
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
fileStream</H3>
<PRE>
public &lt;K,V,F extends org.apache.hadoop.mapreduce.InputFormat&lt;K,V&gt;&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>&lt;K,V&gt; <B>fileStream</B>(String&nbsp;directory,
                                                                                                         Class&lt;K&gt;&nbsp;kClass,
                                                                                                         Class&lt;V&gt;&nbsp;vClass,
                                                                                                         Class&lt;F&gt;&nbsp;fClass,
                                                                                                         <A HREF="../../../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>&lt;org.apache.hadoop.fs.Path,Boolean&gt;&nbsp;filter,
                                                                                                         boolean&nbsp;newFilesOnly,
                                                                                                         org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
 Files must be written to the monitored directory by "moving" them from another
 location within the same file system. File names starting with . are ignored.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS directory to monitor for new file<DD><CODE>kClass</CODE> - class of key for reading HDFS file<DD><CODE>vClass</CODE> - class of value for reading HDFS file<DD><CODE>fClass</CODE> - class of input format for reading HDFS file<DD><CODE>filter</CODE> - Function to filter paths to process<DD><CODE>newFilesOnly</CODE> - Should process only new files and ignore existing files in the directory<DD><CODE>conf</CODE> - Hadoop configuration
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)"><!-- --></A><H3>
actorStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>actorStream</B>(akka.actor.Props&nbsp;props,
                                                   String&nbsp;name,
                                                   <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel,
                                                   akka.actor.SupervisorStrategy&nbsp;supervisorStrategy)</PRE>
<DL>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>props</CODE> - Props object defining creation of the actor<DD><CODE>name</CODE> - Name of the actor<DD><CODE>storageLevel</CODE> - Storage level to use for storing the received objects
 <p><DD><CODE>supervisorStrategy</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel)"><!-- --></A><H3>
actorStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>actorStream</B>(akka.actor.Props&nbsp;props,
                                                   String&nbsp;name,
                                                   <A HREF="../../../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;storageLevel)</PRE>
<DL>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>props</CODE> - Props object defining creation of the actor<DD><CODE>name</CODE> - Name of the actor<DD><CODE>storageLevel</CODE> - Storage level to use for storing the received objects
 <p>
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="actorStream(akka.actor.Props, java.lang.String)"><!-- --></A><H3>
actorStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>actorStream</B>(akka.actor.Props&nbsp;props,
                                                   String&nbsp;name)</PRE>
<DL>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
 Storage level of the data will be the default StorageLevel.MEMORY_AND_DISK_SER_2.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>props</CODE> - Props object defining creation of the actor<DD><CODE>name</CODE> - Name of the actor
 <p>
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="queueStream(java.util.Queue)"><!-- --></A><H3>
queueStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt; <B>queueStream</B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue)</PRE>
<DL>
<DD>Create an input stream from an queue of RDDs. In each batch,
 it will process either one or all of the RDDs returned by the queue.
 <p>
 NOTE:
 1. Changes to the queue after the stream is created will not be recognized.
 2. Arbitrary RDDs can be added to <code>queueStream</code>, there is no way to recover data of
 those RDDs, so <code>queueStream</code> doesn't support checkpointing.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>queue</CODE> - Queue of RDDs
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="queueStream(java.util.Queue, boolean)"><!-- --></A><H3>
queueStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>&lt;T&gt; <B>queueStream</B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue,
                                           boolean&nbsp;oneAtATime)</PRE>
<DL>
<DD>Create an input stream from an queue of RDDs. In each batch,
 it will process either one or all of the RDDs returned by the queue.
 <p>
 NOTE:
 1. Changes to the queue after the stream is created will not be recognized.
 2. Arbitrary RDDs can be added to <code>queueStream</code>, there is no way to recover data of
 those RDDs, so <code>queueStream</code> doesn't support checkpointing.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>queue</CODE> - Queue of RDDs<DD><CODE>oneAtATime</CODE> - Whether only one RDD should be consumed from the queue in every interval
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="queueStream(java.util.Queue, boolean, org.apache.spark.api.java.JavaRDD)"><!-- --></A><H3>
queueStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>&lt;T&gt; <B>queueStream</B>(java.util.Queue&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;queue,
                                           boolean&nbsp;oneAtATime,
                                           <A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&nbsp;defaultRDD)</PRE>
<DL>
<DD>Create an input stream from an queue of RDDs. In each batch,
 it will process either one or all of the RDDs returned by the queue.
 <p>
 NOTE:
 1. Changes to the queue after the stream is created will not be recognized.
 2. Arbitrary RDDs can be added to <code>queueStream</code>, there is no way to recover data of
 those RDDs, so <code>queueStream</code> doesn't support checkpointing.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>queue</CODE> - Queue of RDDs<DD><CODE>oneAtATime</CODE> - Whether only one RDD should be consumed from the queue in every interval<DD><CODE>defaultRDD</CODE> - Default RDD is returned by the DStream when the queue is empty
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="receiverStream(org.apache.spark.streaming.receiver.Receiver)"><!-- --></A><H3>
receiverStream</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>&lt;T&gt; <B>receiverStream</B>(<A HREF="../../../../../../org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>&lt;T&gt;&nbsp;receiver)</PRE>
<DL>
<DD>Create an input stream with any arbitrary user implemented receiver.
 Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>receiver</CODE> - Custom implementation of Receiver
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="union(org.apache.spark.streaming.api.java.JavaDStream, java.util.List)"><!-- --></A><H3>
union</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt; <B>union</B>(<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;&nbsp;first,
                                java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt;&gt;&nbsp;rest)</PRE>
<DL>
<DD>Create a unified DStream from multiple DStreams of the same type and same slide duration.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>first</CODE> - (undocumented)<DD><CODE>rest</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="union(org.apache.spark.streaming.api.java.JavaPairDStream, java.util.List)"><!-- --></A><H3>
union</H3>
<PRE>
public &lt;K,V&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt; <B>union</B>(<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;&nbsp;first,
                                        java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt;&gt;&nbsp;rest)</PRE>
<DL>
<DD>Create a unified DStream from multiple DStreams of the same type and same slide duration.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>first</CODE> - (undocumented)<DD><CODE>rest</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="transform(java.util.List, org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
transform</H3>
<PRE>
public &lt;T&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;T&gt; <B>transform</B>(java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;?&gt;&gt;&nbsp;dstreams,
                                    <A HREF="../../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;java.util.List&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;?&gt;&gt;,<A HREF="../../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>,<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;T&gt;&gt;&nbsp;transformFunc)</PRE>
<DL>
<DD>Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams. The order of the JavaRDDs in the transform function parameter will be the
 same as the order of corresponding DStreams in the list. Note that for adding a
 JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
 <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaPairDStream</CODE></A>.toJavaDStream().
 In the transform function, convert the JavaRDD corresponding to that JavaDStream to
 a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>dstreams</CODE> - (undocumented)<DD><CODE>transformFunc</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="transformToPair(java.util.List, org.apache.spark.api.java.function.Function2)"><!-- --></A><H3>
transformToPair</H3>
<PRE>
public &lt;K,V&gt; <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>&lt;K,V&gt; <B>transformToPair</B>(java.util.List&lt;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>&lt;?&gt;&gt;&nbsp;dstreams,
                                                  <A HREF="../../../../../../org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>&lt;java.util.List&lt;<A HREF="../../../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>&lt;?&gt;&gt;,<A HREF="../../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>,<A HREF="../../../../../../org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>&lt;K,V&gt;&gt;&nbsp;transformFunc)</PRE>
<DL>
<DD>Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams. The order of the JavaRDDs in the transform function parameter will be the
 same as the order of corresponding DStreams in the list. Note that for adding a
 JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
 <A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaPairDStream</CODE></A>.toJavaDStream().
 In the transform function, convert the JavaRDD corresponding to that JavaDStream to
 a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>dstreams</CODE> - (undocumented)<DD><CODE>transformFunc</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="checkpoint(java.lang.String)"><!-- --></A><H3>
checkpoint</H3>
<PRE>
public void <B>checkpoint</B>(String&nbsp;directory)</PRE>
<DL>
<DD>Sets the context to periodically checkpoint the DStream operations for master
 fault-tolerance. The graph will be checkpointed every batch interval.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>directory</CODE> - HDFS-compatible directory where the checkpoint data will be reliably stored</DL>
</DD>
</DL>
<HR>

<A NAME="remember(org.apache.spark.streaming.Duration)"><!-- --></A><H3>
remember</H3>
<PRE>
public void <B>remember</B>(<A HREF="../../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>&nbsp;duration)</PRE>
<DL>
<DD>Sets each DStreams in this context to remember RDDs it generated in the last given duration.
 DStreams remember RDDs only for a limited duration of duration and releases them for garbage
 collection. This method allows the developer to specify how long to remember the RDDs (
 if the developer wishes to query old data outside the DStream computation).
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>duration</CODE> - Minimum duration that each DStream should remember its RDDs</DL>
</DD>
</DL>
<HR>

<A NAME="addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)"><!-- --></A><H3>
addStreamingListener</H3>
<PRE>
public void <B>addStreamingListener</B>(<A HREF="../../../../../../org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>&nbsp;streamingListener)</PRE>
<DL>
<DD>Add a <A HREF="../../../../../../org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><CODE>StreamingListener</CODE></A> object for
 receiving system events related to streaming.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>streamingListener</CODE> - (undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getState()"><!-- --></A><H3>
getState</H3>
<PRE>
public <A HREF="../../../../../../org/apache/spark/streaming/StreamingContextState.html" title="enum in org.apache.spark.streaming">StreamingContextState</A> <B>getState</B>()</PRE>
<DL>
<DD>:: DeveloperApi ::
 <p>
 Return the current state of the context. The context can be in three possible states -
 <ul>
   <li>
   StreamingContextState.INTIALIZED - The context has been created, but not been started yet.
   Input DStreams, transformations and output operations can be created on the context.
   </li>
   <li>
   StreamingContextState.ACTIVE - The context has been started, and been not stopped.
   Input DStreams, transformations and output operations cannot be created on the context.
   </li>
   <li>
   StreamingContextState.STOPPED - The context has been stopped and cannot be used any more.
   </li>
 </ul>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="start()"><!-- --></A><H3>
start</H3>
<PRE>
public void <B>start</B>()</PRE>
<DL>
<DD>Start the execution of the streams.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="awaitTermination()"><!-- --></A><H3>
awaitTermination</H3>
<PRE>
public void <B>awaitTermination</B>()</PRE>
<DL>
<DD>Wait for the execution to stop. Any exceptions that occurs during the execution
 will be thrown in this thread.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="awaitTermination(long)"><!-- --></A><H3>
awaitTermination</H3>
<PRE>
public void <B>awaitTermination</B>(long&nbsp;timeout)</PRE>
<DL>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I>
<P>
<DD>Wait for the execution to stop. Any exceptions that occurs during the execution
 will be thrown in this thread.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - time to wait in milliseconds</DL>
</DD>
</DL>
<HR>

<A NAME="awaitTerminationOrTimeout(long)"><!-- --></A><H3>
awaitTerminationOrTimeout</H3>
<PRE>
public boolean <B>awaitTerminationOrTimeout</B>(long&nbsp;timeout)</PRE>
<DL>
<DD>Wait for the execution to stop. Any exceptions that occurs during the execution
 will be thrown in this thread.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>timeout</CODE> - time to wait in milliseconds
<DT><B>Returns:</B><DD><code>true</code> if it's stopped; or throw the reported error during the execution; or <code>false</code>
         if the waiting time elapsed before returning from the method.</DL>
</DD>
</DL>
<HR>

<A NAME="stop()"><!-- --></A><H3>
stop</H3>
<PRE>
public void <B>stop</B>()</PRE>
<DL>
<DD>Stop the execution of the streams. Will stop the associated JavaSparkContext as well.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="stop(boolean)"><!-- --></A><H3>
stop</H3>
<PRE>
public void <B>stop</B>(boolean&nbsp;stopSparkContext)</PRE>
<DL>
<DD>Stop the execution of the streams.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>stopSparkContext</CODE> - Stop the associated SparkContext or not</DL>
</DD>
</DL>
<HR>

<A NAME="stop(boolean, boolean)"><!-- --></A><H3>
stop</H3>
<PRE>
public void <B>stop</B>(boolean&nbsp;stopSparkContext,
                 boolean&nbsp;stopGracefully)</PRE>
<DL>
<DD>Stop the execution of the streams.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>stopSparkContext</CODE> - Stop the associated SparkContext or not<DD><CODE>stopGracefully</CODE> - Stop gracefully by waiting for the processing of all
                       received data to be completed</DL>
</DD>
</DL>
<HR>

<A NAME="close()"><!-- --></A><H3>
close</H3>
<PRE>
public void <B>close</B>()</PRE>
<DL>
<DD><DL>
<DT><B>Specified by:</B><DD><CODE>close</CODE> in interface <CODE>java.io.Closeable</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/spark/streaming/api/java/JavaStreamingContext.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="JavaStreamingContext.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
