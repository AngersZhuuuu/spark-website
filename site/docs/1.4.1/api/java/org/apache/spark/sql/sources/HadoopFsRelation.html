<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:40 PDT 2015 -->
<TITLE>
HadoopFsRelation (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="HadoopFsRelation (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/sql/sources/HadoopFsRelation.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="HadoopFsRelation.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.sql.sources</FONT>
<BR>
Class HadoopFsRelation</H2>
<PRE>
Object
  <IMG SRC="../../../../../resources/inherit.gif" ALT="extended by "><A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">org.apache.spark.sql.sources.BaseRelation</A>
      <IMG SRC="../../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.sql.sources.HadoopFsRelation</B>
</PRE>
<HR>
<DL>
<DT><PRE>public abstract class <B>HadoopFsRelation</B><DT>extends <A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A></DL>
</PRE>

<P>
::Experimental::
 A <A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><CODE>BaseRelation</CODE></A> that provides much of the common code required for formats that store their
 data to an HDFS compatible filesystem.
 <p>
 For the read path, similar to <A HREF="../../../../../org/apache/spark/sql/sources/PrunedFilteredScan.html" title="interface in org.apache.spark.sql.sources"><CODE>PrunedFilteredScan</CODE></A>, it can eliminate unneeded columns and
 filter using selected predicates before producing an RDD containing all matching tuples as
 <CODE>Row</CODE> objects. In addition, when reading from Hive style partitioned tables stored in file
 systems, it's able to discover partitioning information from the paths of input directories, and
 perform partition pruning before start reading the data. Subclasses of <A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation()"><CODE>HadoopFsRelation()</CODE></A>
 must override one of the three <code>buildScan</code> methods to implement the read path.
 <p>
 For the write path, it provides the ability to write to both non-partitioned and partitioned
 tables.  Directory layout of the partitioned tables is compatible with Hive.
 <p>
<P>

<P>
<DL>
<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation()">HadoopFsRelation</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(org.apache.hadoop.fs.FileStatus[])">buildScan</A></B>(org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[], org.apache.hadoop.fs.FileStatus[])">buildScan</A></B>(String[]&nbsp;requiredColumns,
          org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[], org.apache.spark.sql.sources.Filter[], org.apache.hadoop.fs.FileStatus[])">buildScan</A></B>(String[]&nbsp;requiredColumns,
          <A HREF="../../../../../org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources">Filter</A>[]&nbsp;filters,
          org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#dataSchema()">dataSchema</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Specifies schema of actual data files.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#partitionColumns()">partitionColumns</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Partition columns.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;String[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#paths()">paths</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Base paths of this relation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#prepareJobForWrite(org.apache.hadoop.mapreduce.Job)">prepareJobForWrite</A></B>(org.apache.hadoop.mapreduce.Job&nbsp;job)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Prepares a write job and returns an <A HREF="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriterFactory</CODE></A>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#schema()">schema</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Schema of this relation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;scala.Option&lt;<A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#userDefinedPartitionColumns()">userDefinedPartitionColumns</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Optional user defined partition columns.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.spark.sql.sources.BaseRelation"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class org.apache.spark.sql.sources.<A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A></B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html#needConversion()">needConversion</A>, <A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()">sizeInBytes</A>, <A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sqlContext()">sqlContext</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="HadoopFsRelation()"><!-- --></A><H3>
HadoopFsRelation</H3>
<PRE>
public <B>HadoopFsRelation</B>()</PRE>
<DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="paths()"><!-- --></A><H3>
paths</H3>
<PRE>
public abstract String[] <B>paths</B>()</PRE>
<DL>
<DD>Base paths of this relation.  For partitioned relations, it should be either root directories
 of all partition directories.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="partitionColumns()"><!-- --></A><H3>
partitionColumns</H3>
<PRE>
public final <A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A> <B>partitionColumns</B>()</PRE>
<DL>
<DD>Partition columns.  Can be either defined by <CODE>userDefinedPartitionColumns</CODE> or automatically
 discovered.  Note that they should always be nullable.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="userDefinedPartitionColumns()"><!-- --></A><H3>
userDefinedPartitionColumns</H3>
<PRE>
public scala.Option&lt;<A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>&gt; <B>userDefinedPartitionColumns</B>()</PRE>
<DL>
<DD>Optional user defined partition columns.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="schema()"><!-- --></A><H3>
schema</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A> <B>schema</B>()</PRE>
<DL>
<DD>Schema of this relation.  It consists of columns appearing in <CODE>dataSchema</CODE> and all partition
 columns not appearing in <CODE>dataSchema</CODE>.
 <p>
<P>
<DD><DL>
<DT><B>Specified by:</B><DD><CODE><A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html#schema()">schema</A></CODE> in class <CODE><A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="dataSchema()"><!-- --></A><H3>
dataSchema</H3>
<PRE>
public abstract <A HREF="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A> <B>dataSchema</B>()</PRE>
<DL>
<DD>Specifies schema of actual data files.  For partitioned relations, if one or more partitioned
 columns are contained in the data files, they should also appear in <code>dataSchema</code>.
 <p>
<P>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="buildScan(org.apache.hadoop.fs.FileStatus[])"><!-- --></A><H3>
buildScan</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt; <B>buildScan</B>(org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</PRE>
<DL>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>inputFiles</CODE> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p>
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="buildScan(java.lang.String[], org.apache.hadoop.fs.FileStatus[])"><!-- --></A><H3>
buildScan</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt; <B>buildScan</B>(String[]&nbsp;requiredColumns,
                          org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</PRE>
<DL>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>requiredColumns</CODE> - Required columns.<DD><CODE>inputFiles</CODE> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p>
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="buildScan(java.lang.String[], org.apache.spark.sql.sources.Filter[], org.apache.hadoop.fs.FileStatus[])"><!-- --></A><H3>
buildScan</H3>
<PRE>
public <A HREF="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>&gt; <B>buildScan</B>(String[]&nbsp;requiredColumns,
                          <A HREF="../../../../../org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources">Filter</A>[]&nbsp;filters,
                          org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</PRE>
<DL>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>requiredColumns</CODE> - Required columns.<DD><CODE>filters</CODE> - Candidate filters to be pushed down. The actual filter should be the conjunction
        of all <code>filters</code>.  The pushed down filters are currently purely an optimization as they
        will all be evaluated again. This means it is safe to use them with methods that produce
        false positives such as filtering partitions based on a bloom filter.<DD><CODE>inputFiles</CODE> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p>
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<HR>

<A NAME="prepareJobForWrite(org.apache.hadoop.mapreduce.Job)"><!-- --></A><H3>
prepareJobForWrite</H3>
<PRE>
public abstract <A HREF="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</A> <B>prepareJobForWrite</B>(org.apache.hadoop.mapreduce.Job&nbsp;job)</PRE>
<DL>
<DD>Prepares a write job and returns an <A HREF="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriterFactory</CODE></A>.  Client side job preparation can
 be put here.  For example, user defined output committer can be configured here
 by setting the output committer class in the conf of spark.sql.sources.outputCommitterClass.
 <p>
 Note that the only side effect expected here is mutating <code>job</code> via its setters.  Especially,
 Spark SQL caches <A HREF="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><CODE>BaseRelation</CODE></A> instances for performance, mutating relation internal states
 may cause unexpected behaviors.
 <p>
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>job</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)<DT><B>Since:</B></DT>
  <DD>1.4.0</DD>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/spark/sql/sources/HadoopFsRelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/spark/sql/sources/HadoopFsRelation.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="HadoopFsRelation.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
