<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:37 PDT 2015 -->
<TITLE>
Graph (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Graph (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/spark/graphx/GraphKryoRegistrator.html" title="class in org.apache.spark.graphx"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/graphx/Graph.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="Graph.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.spark.graphx</FONT>
<BR>
Class Graph&lt;VD,ED&gt;</H2>
<PRE>
Object
  <IMG SRC="../../../../resources/inherit.gif" ALT="extended by "><B>org.apache.spark.graphx.Graph&lt;VD,ED&gt;</B>
</PRE>
<DL>
<DT><B>All Implemented Interfaces:</B> <DD>java.io.Serializable</DD>
</DL>
<DL>
<DT><B>Direct Known Subclasses:</B> <DD><A HREF="../../../../org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A></DD>
</DL>
<HR>
<DL>
<DT><PRE>public abstract class <B>Graph&lt;VD,ED&gt;</B><DT>extends Object<DT>implements scala.Serializable</DL>
</PRE>

<P>
The Graph abstractly represents a graph with arbitrary objects
 associated with vertices and edges.  The graph provides basic
 operations to access and manipulate the data associated with
 vertices and edges as well as the underlying structure.  Like Spark
 RDDs, the graph is a functional data-structure in which mutating
 operations return new graphs.
 <p>
<P>

<P>
<DL>
<DT><B>See Also:</B><DD><A HREF="../../../../serialized-form.html#org.apache.spark.graphx.Graph">Serialized Form</A></DL>
<HR>

<P>

<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;A&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;A&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#aggregateMessages(scala.Function1, scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)">aggregateMessages</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,A&gt;,scala.runtime.BoxedUnit&gt;&nbsp;sendMsg,
                  scala.Function2&lt;A,A,A&gt;&nbsp;mergeMsg,
                  <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
                  scala.reflect.ClassTag&lt;A&gt;&nbsp;evidence$12)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregates values from the neighboring edges and vertices of each vertex.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)">apply</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
      <A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;ED&gt;&gt;&nbsp;edges,
      VD&nbsp;defaultVertexAttr,
      <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
      <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
      scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$19,
      scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$20)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construct a graph from a collection of vertices and
 edges with attributes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#cache()">cache</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Caches the vertices and edges associated with this graph at the previously-specified target
 storage levels, which default to <code>MEMORY_ONLY</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#checkpoint()">checkpoint</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mark this Graph for checkpointing.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#edges()">edges</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An RDD containing the edges and their associated attributes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#fromEdges(org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)">fromEdges</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;ED&gt;&gt;&nbsp;edges,
          VD&nbsp;defaultValue,
          <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
          <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
          scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$17,
          scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$18)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construct a graph from a collection of edges.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,Object&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#fromEdgeTuples(org.apache.spark.rdd.RDD, VD, scala.Option, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)">fromEdgeTuples</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,Object&gt;&gt;&nbsp;rawEdges,
               VD&nbsp;defaultValue,
               scala.Option&lt;<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&gt;&nbsp;uniqueEdges,
               <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
               <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
               scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$16)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construct a graph from a collection of edges encoded as vertex id pairs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;scala.collection.Seq&lt;String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#getCheckpointFiles()">getCheckpointFiles</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the name of the files to which this Graph was checkpointed.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>&lt;VD,ED&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#graphToGraphOps(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)">graphToGraphOps</A></B>(<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt;&nbsp;g,
                scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$21,
                scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$22)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Implicitly extracts the <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> member from a graph.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#groupEdges(scala.Function2)">groupEdges</A></B>(scala.Function2&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&nbsp;merge)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Merges multiple edges between two vertices into a single edge.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#isCheckpointed()">isCheckpointed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return whether this Graph has been checkpointed or not.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapEdges(scala.Function1, scala.reflect.ClassTag)">mapEdges</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
         scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$4)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each edge attribute in the graph using the map function.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapEdges(scala.Function2, scala.reflect.ClassTag)">mapEdges</A></B>(scala.Function2&lt;Object,scala.collection.Iterator&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt;,scala.collection.Iterator&lt;ED2&gt;&gt;&nbsp;map,
         scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$5)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each edge attribute using the map function, passing it a whole partition at a
 time.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;A&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;A&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapReduceTriplets(scala.Function1, scala.Function2, scala.Option, scala.reflect.ClassTag)">mapReduceTriplets</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;Object,A&gt;&gt;&gt;&nbsp;mapFunc,
                  scala.Function2&lt;A,A,A&gt;&nbsp;reduceFunc,
                  scala.Option&lt;scala.Tuple2&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;?&gt;,<A HREF="../../../../org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>&gt;&gt;&nbsp;activeSetOpt,
                  scala.reflect.ClassTag&lt;A&gt;&nbsp;evidence$11)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aggregates values from the neighboring edges and vertices of each vertex.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function1, scala.reflect.ClassTag)">mapTriplets</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
            scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$6)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function1, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)">mapTriplets</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
            <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
            scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$7)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)">mapTriplets</A></B>(scala.Function2&lt;Object,scala.collection.Iterator&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt;,scala.collection.Iterator&lt;ED2&gt;&gt;&nbsp;map,
            <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
            scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$8)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each edge attribute a partition at a time using the map function, passing it the
 adjacent vertex attributes as well.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mapVertices(scala.Function2, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)">mapVertices</A></B>(scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;map,
            scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$3,
            scala.Predef.$eq$colon$eq&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;eq)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms each vertex attribute in the graph using the map function.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;VD2,ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#mask(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)">mask</A></B>(<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,ED2&gt;&nbsp;other,
     scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$9,
     scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$10)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Restricts the graph to only the vertices and edges that are also in <code>other</code>, but keeps the
 attributes from this graph.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#ops()">ops</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The associated <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> object.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract 
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" SUMMARY="">
<TR ALIGN="right" VALIGN="">
<TD NOWRAP><FONT SIZE="-1">
<CODE>&lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
</TR>
</TABLE>
</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#outerJoinVertices(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)">outerJoinVertices</A></B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,U&gt;&gt;&nbsp;other,
                  scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,scala.Option&lt;U&gt;,VD2&gt;&nbsp;mapFunc,
                  scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$14,
                  scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$15,
                  scala.Predef.$eq$colon$eq&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;eq)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Joins the vertices with entries in the <code>table</code> RDD and merges the results using <code>mapFunc</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#partitionBy(org.apache.spark.graphx.PartitionStrategy)">partitionBy</A></B>(<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&nbsp;partitionStrategy)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Repartitions the edges in the graph according to <code>partitionStrategy</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#partitionBy(org.apache.spark.graphx.PartitionStrategy, int)">partitionBy</A></B>(<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&nbsp;partitionStrategy,
            int&nbsp;numPartitions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Repartitions the edges in the graph according to <code>partitionStrategy</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#persist(org.apache.spark.storage.StorageLevel)">persist</A></B>(<A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;newLevel)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Caches the vertices and edges associated with this graph at the specified storage level,
 ignoring any target storage levels previously set.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#reverse()">reverse</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reverses all edges in the graph.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#subgraph(scala.Function1, scala.Function2)">subgraph</A></B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,Object&gt;&nbsp;epred,
         scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,Object&gt;&nbsp;vpred)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Restricts the graph to only the vertices and edges satisfying the predicates.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#triplets()">triplets</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An RDD containing the edge triplets, which are edges along with the vertex data associated with
 the adjacent vertices.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#unpersist(boolean)">unpersist</A></B>(boolean&nbsp;blocking)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uncaches both vertices and edges of this graph.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#unpersistVertices(boolean)">unpersistVertices</A></B>(boolean&nbsp;blocking)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uncaches only the vertices of this graph, leaving the edges alone.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>abstract &nbsp;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/spark/graphx/Graph.html#vertices()">vertices</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An RDD containing the vertices and their associated attributes.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class Object</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="fromEdgeTuples(org.apache.spark.rdd.RDD,java.lang.Object,scala.Option,org.apache.spark.storage.StorageLevel,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag)"><!-- --></A><A NAME="fromEdgeTuples(org.apache.spark.rdd.RDD, VD, scala.Option, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)"><!-- --></A><H3>
fromEdgeTuples</H3>
<PRE>
public static &lt;VD&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,Object&gt; <B>fromEdgeTuples</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,Object&gt;&gt;&nbsp;rawEdges,
                                                   VD&nbsp;defaultValue,
                                                   scala.Option&lt;<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&gt;&nbsp;uniqueEdges,
                                                   <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
                                                   <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
                                                   scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$16)</PRE>
<DL>
<DD>Construct a graph from a collection of edges encoded as vertex id pairs.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>rawEdges</CODE> - a collection of edges in (src, dst) form<DD><CODE>defaultValue</CODE> - the vertex attributes with which to create vertices referenced by the edges<DD><CODE>uniqueEdges</CODE> - if multiple identical edges are found they are combined and the edge
 attribute is set to the sum.  Otherwise duplicate edges are treated as separate. To enable
 <code>uniqueEdges</code>, a <A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx"><CODE>PartitionStrategy</CODE></A> must be provided.<DD><CODE>edgeStorageLevel</CODE> - the desired storage level at which to cache the edges if necessary<DD><CODE>vertexStorageLevel</CODE> - the desired storage level at which to cache the vertices if necessary
 <p><DD><CODE>evidence$16</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a graph with edge attributes containing either the count of duplicate edges or 1
 (if <code>uniqueEdges</code> is <code>None</code>) and vertex attributes containing the total degree of each vertex.</DL>
</DD>
</DL>
<HR>

<A NAME="fromEdges(org.apache.spark.rdd.RDD,java.lang.Object,org.apache.spark.storage.StorageLevel,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag)"><!-- --></A><A NAME="fromEdges(org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
fromEdges</H3>
<PRE>
public static &lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt; <B>fromEdges</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;ED&gt;&gt;&nbsp;edges,
                                             VD&nbsp;defaultValue,
                                             <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
                                             <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
                                             scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$17,
                                             scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$18)</PRE>
<DL>
<DD>Construct a graph from a collection of edges.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>edges</CODE> - the RDD containing the set of edges in the graph<DD><CODE>defaultValue</CODE> - the default vertex attribute to use for each vertex<DD><CODE>edgeStorageLevel</CODE> - the desired storage level at which to cache the edges if necessary<DD><CODE>vertexStorageLevel</CODE> - the desired storage level at which to cache the vertices if necessary
 <p><DD><CODE>evidence$17</CODE> - (undocumented)<DD><CODE>evidence$18</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a graph with edge attributes described by <code>edges</code> and vertices
         given by all vertices in <code>edges</code> with value <code>defaultValue</code></DL>
</DD>
</DL>
<HR>

<A NAME="apply(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,java.lang.Object,org.apache.spark.storage.StorageLevel,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag)"><!-- --></A><A NAME="apply(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
apply</H3>
<PRE>
public static &lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt; <B>apply</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,VD&gt;&gt;&nbsp;vertices,
                                         <A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;ED&gt;&gt;&nbsp;edges,
                                         VD&nbsp;defaultVertexAttr,
                                         <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;edgeStorageLevel,
                                         <A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;vertexStorageLevel,
                                         scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$19,
                                         scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$20)</PRE>
<DL>
<DD>Construct a graph from a collection of vertices and
 edges with attributes.  Duplicate vertices are picked arbitrarily and
 vertices found in the edge collection but not in the input
 vertices are assigned the default attribute.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>vertices</CODE> - the "set" of vertices and their attributes<DD><CODE>edges</CODE> - the collection of edges in the graph<DD><CODE>defaultVertexAttr</CODE> - the default vertex attribute to use for vertices that are
                          mentioned in edges but not in vertices<DD><CODE>edgeStorageLevel</CODE> - the desired storage level at which to cache the edges if necessary<DD><CODE>vertexStorageLevel</CODE> - the desired storage level at which to cache the vertices if necessary<DD><CODE>evidence$19</CODE> - (undocumented)<DD><CODE>evidence$20</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="graphToGraphOps(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
graphToGraphOps</H3>
<PRE>
public static &lt;VD,ED&gt; <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>&lt;VD,ED&gt; <B>graphToGraphOps</B>(<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD,ED&gt;&nbsp;g,
                                                      scala.reflect.ClassTag&lt;VD&gt;&nbsp;evidence$21,
                                                      scala.reflect.ClassTag&lt;ED&gt;&nbsp;evidence$22)</PRE>
<DL>
<DD>Implicitly extracts the <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> member from a graph.
 <p>
 To improve modularity the Graph type only contains a small set of basic operations.
 All the convenience operations are defined in the <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> class which may be
 shared across multiple graph implementations.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>g</CODE> - (undocumented)<DD><CODE>evidence$21</CODE> - (undocumented)<DD><CODE>evidence$22</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="vertices()"><!-- --></A><H3>
vertices</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>&gt; <B>vertices</B>()</PRE>
<DL>
<DD>An RDD containing the vertices and their associated attributes.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>an RDD containing the vertices in this graph</DL>
</DD>
</DL>
<HR>

<A NAME="edges()"><!-- --></A><H3>
edges</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>edges</B>()</PRE>
<DL>
<DD>An RDD containing the edges and their associated attributes.  The entries in the RDD contain
 just the source id and target id along with the edge data.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>an RDD containing the edges in this graph
 <p><DT><B>See Also:</B><DD><CODE>Edge} for the edge type.</CODE>, 
<CODE>Graph#triplets} to get an RDD which contains all the edges
 along with their vertex data.
 <p></CODE></DL>
</DD>
</DL>
<HR>

<A NAME="triplets()"><!-- --></A><H3>
triplets</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt; <B>triplets</B>()</PRE>
<DL>
<DD>An RDD containing the edge triplets, which are edges along with the vertex data associated with
 the adjacent vertices. The caller should use <CODE>edges</CODE> if the vertex data are not needed, i.e.
 if only the edge data and adjacent vertex ids are needed.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>an RDD containing edge triplets
 <p></DL>
</DD>
</DL>
<HR>

<A NAME="persist(org.apache.spark.storage.StorageLevel)"><!-- --></A><H3>
persist</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>persist</B>(<A HREF="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>&nbsp;newLevel)</PRE>
<DL>
<DD>Caches the vertices and edges associated with this graph at the specified storage level,
 ignoring any target storage levels previously set.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>newLevel</CODE> - the level at which to cache the graph.
 <p>
<DT><B>Returns:</B><DD>A reference to this graph for convenience.</DL>
</DD>
</DL>
<HR>

<A NAME="cache()"><!-- --></A><H3>
cache</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>cache</B>()</PRE>
<DL>
<DD>Caches the vertices and edges associated with this graph at the previously-specified target
 storage levels, which default to <code>MEMORY_ONLY</code>. This is used to pin a graph in memory enabling
 multiple queries to reuse the same construction process.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="checkpoint()"><!-- --></A><H3>
checkpoint</H3>
<PRE>
public abstract void <B>checkpoint</B>()</PRE>
<DL>
<DD>Mark this Graph for checkpointing. It will be saved to a file inside the checkpoint
 directory set with SparkContext.setCheckpointDir() and all references to its parent
 RDDs will be removed. It is strongly recommended that this Graph is persisted in
 memory, otherwise saving it on a file will require recomputation.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="isCheckpointed()"><!-- --></A><H3>
isCheckpointed</H3>
<PRE>
public abstract boolean <B>isCheckpointed</B>()</PRE>
<DL>
<DD>Return whether this Graph has been checkpointed or not.
 This returns true iff both the vertices RDD and edges RDD have been checkpointed.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="getCheckpointFiles()"><!-- --></A><H3>
getCheckpointFiles</H3>
<PRE>
public abstract scala.collection.Seq&lt;String&gt; <B>getCheckpointFiles</B>()</PRE>
<DL>
<DD>Gets the name of the files to which this Graph was checkpointed.
 (The vertices RDD and edges RDD are checkpointed separately.)
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="unpersist(boolean)"><!-- --></A><H3>
unpersist</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>unpersist</B>(boolean&nbsp;blocking)</PRE>
<DL>
<DD>Uncaches both vertices and edges of this graph. This is useful in iterative algorithms that
 build a new graph in each iteration.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>blocking</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="unpersistVertices(boolean)"><!-- --></A><H3>
unpersistVertices</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>unpersistVertices</B>(boolean&nbsp;blocking)</PRE>
<DL>
<DD>Uncaches only the vertices of this graph, leaving the edges alone. This is useful in iterative
 algorithms that modify the vertex attributes but reuse the edges. This method can be used to
 uncache the vertex attributes of previous iterations once they are no longer needed, improving
 GC performance.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>blocking</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="partitionBy(org.apache.spark.graphx.PartitionStrategy)"><!-- --></A><H3>
partitionBy</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>partitionBy</B>(<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&nbsp;partitionStrategy)</PRE>
<DL>
<DD>Repartitions the edges in the graph according to <code>partitionStrategy</code>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>partitionStrategy</CODE> - the partitioning strategy to use when partitioning the edges
 in the graph.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="partitionBy(org.apache.spark.graphx.PartitionStrategy, int)"><!-- --></A><H3>
partitionBy</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>partitionBy</B>(<A HREF="../../../../org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>&nbsp;partitionStrategy,
                                         int&nbsp;numPartitions)</PRE>
<DL>
<DD>Repartitions the edges in the graph according to <code>partitionStrategy</code>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>partitionStrategy</CODE> - the partitioning strategy to use when partitioning the edges
 in the graph.<DD><CODE>numPartitions</CODE> - the number of edge partitions in the new graph.
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapVertices(scala.Function2, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><!-- --></A><H3>
mapVertices</H3>
<PRE>
public abstract &lt;VD2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>mapVertices</B>(scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;map,
                                                scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$3,
                                                scala.Predef.$eq$colon$eq&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;eq)</PRE>
<DL>
<DD>Transforms each vertex attribute in the graph using the map function.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - the function from a vertex object to a new vertex value
 <p><DD><CODE>evidence$3</CODE> - (undocumented)<DD><CODE>eq</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapEdges(scala.Function1, scala.reflect.ClassTag)"><!-- --></A><H3>
mapEdges</H3>
<PRE>
public &lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt; <B>mapEdges</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
                                    scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$4)</PRE>
<DL>
<DD>Transforms each edge attribute in the graph using the map function.  The map function is not
 passed the vertex value for the vertices adjacent to the edge.  If vertex values are desired,
 use <code>mapTriplets</code>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - the function from an edge object to a new edge value.
 <p><DD><CODE>evidence$4</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapEdges(scala.Function2, scala.reflect.ClassTag)"><!-- --></A><H3>
mapEdges</H3>
<PRE>
public abstract &lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt; <B>mapEdges</B>(scala.Function2&lt;Object,scala.collection.Iterator&lt;<A HREF="../../../../org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt;,scala.collection.Iterator&lt;ED2&gt;&gt;&nbsp;map,
                                             scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$5)</PRE>
<DL>
<DD>Transforms each edge attribute using the map function, passing it a whole partition at a
 time. The map function is given an iterator over edges within a logical partition as well as
 the partition's ID, and it should return a new iterator over the new values of each edge. The
 new iterator's elements must correspond one-to-one with the old iterator's elements. If
 adjacent vertex values are desired, use <code>mapTriplets</code>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - a function that takes a partition id and an iterator
 over all the edges in the partition, and must return an iterator over
 the new values for each edge in the order of the input iterator
 <p><DD><CODE>evidence$5</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapTriplets(scala.Function1, scala.reflect.ClassTag)"><!-- --></A><H3>
mapTriplets</H3>
<PRE>
public &lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt; <B>mapTriplets</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
                                       scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$6)</PRE>
<DL>
<DD>Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well. If adjacent vertex values are not required,
 consider using <code>mapEdges</code> instead.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - the function from an edge object to a new edge value.
 <p><DD><CODE>evidence$6</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapTriplets(scala.Function1, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><!-- --></A><H3>
mapTriplets</H3>
<PRE>
public &lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt; <B>mapTriplets</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,ED2&gt;&nbsp;map,
                                       <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
                                       scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$7)</PRE>
<DL>
<DD>Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well. If adjacent vertex values are not required,
 consider using <code>mapEdges</code> instead.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - the function from an edge object to a new edge value.<DD><CODE>tripletFields</CODE> - which fields should be included in the edge triplet passed to the map
   function. If not all fields are needed, specifying this can improve performance.
 <p><DD><CODE>evidence$7</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="mapTriplets(scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><!-- --></A><H3>
mapTriplets</H3>
<PRE>
public abstract &lt;ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,ED2&gt; <B>mapTriplets</B>(scala.Function2&lt;Object,scala.collection.Iterator&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&gt;,scala.collection.Iterator&lt;ED2&gt;&gt;&nbsp;map,
                                                <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
                                                scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$8)</PRE>
<DL>
<DD>Transforms each edge attribute a partition at a time using the map function, passing it the
 adjacent vertex attributes as well. The map function is given an iterator over edge triplets
 within a logical partition and should yield a new iterator over the new values of each edge in
 the order in which they are provided.  If adjacent vertex values are not required, consider
 using <code>mapEdges</code> instead.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>map</CODE> - the iterator transform<DD><CODE>tripletFields</CODE> - which fields should be included in the edge triplet passed to the map
   function. If not all fields are needed, specifying this can improve performance.
 <p><DD><CODE>evidence$8</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="reverse()"><!-- --></A><H3>
reverse</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>reverse</B>()</PRE>
<DL>
<DD>Reverses all edges in the graph.  If this graph contains an edge from a to b then the returned
 graph contains an edge from b to a.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="subgraph(scala.Function1, scala.Function2)"><!-- --></A><H3>
subgraph</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>subgraph</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,Object&gt;&nbsp;epred,
                                      scala.Function2&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,Object&gt;&nbsp;vpred)</PRE>
<DL>
<DD>Restricts the graph to only the vertices and edges satisfying the predicates. The resulting
 subgraph satisifies
 <p>
 <pre><code>
 V' = {v : for all v in V where vpred(v)}
 E' = {(u,v): for all (u,v) in E where epred((u,v)) &amp;&amp; vpred(u) &amp;&amp; vpred(v)}
 </code></pre>
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>epred</CODE> - the edge predicate, which takes a triplet and
 evaluates to true if the edge is to remain in the subgraph.  Note
 that only edges where both vertices satisfy the vertex
 predicate are considered.
 <p><DD><CODE>vpred</CODE> - the vertex predicate, which takes a vertex object and
 evaluates to true if the vertex is to be included in the subgraph
 <p>
<DT><B>Returns:</B><DD>the subgraph containing only the vertices and edges that
 satisfy the predicates</DL>
</DD>
</DL>
<HR>

<A NAME="mask(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><!-- --></A><H3>
mask</H3>
<PRE>
public abstract &lt;VD2,ED2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>mask</B>(<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,ED2&gt;&nbsp;other,
                                            scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$9,
                                            scala.reflect.ClassTag&lt;ED2&gt;&nbsp;evidence$10)</PRE>
<DL>
<DD>Restricts the graph to only the vertices and edges that are also in <code>other</code>, but keeps the
 attributes from this graph.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the graph to project this graph onto<DD><CODE>evidence$9</CODE> - (undocumented)<DD><CODE>evidence$10</CODE> - (undocumented)
<DT><B>Returns:</B><DD>a graph with vertices and edges that exist in both the current graph and <code>other</code>,
 with vertex and edge data from the current graph</DL>
</DD>
</DL>
<HR>

<A NAME="groupEdges(scala.Function2)"><!-- --></A><H3>
groupEdges</H3>
<PRE>
public abstract <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>groupEdges</B>(scala.Function2&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;&nbsp;merge)</PRE>
<DL>
<DD>Merges multiple edges between two vertices into a single edge. For correct results, the graph
 must have been partitioned using <CODE>partitionBy</CODE>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>merge</CODE> - the user-supplied commutative associative function to merge edge attributes
              for duplicate edges.
 <p>
<DT><B>Returns:</B><DD>The resulting graph with a single edge for each (source, dest) vertex pair.</DL>
</DD>
</DL>
<HR>

<A NAME="mapReduceTriplets(scala.Function1, scala.Function2, scala.Option, scala.reflect.ClassTag)"><!-- --></A><H3>
mapReduceTriplets</H3>
<PRE>
public abstract &lt;A&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;A&gt; <B>mapReduceTriplets</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;Object,A&gt;&gt;&gt;&nbsp;mapFunc,
                                                   scala.Function2&lt;A,A,A&gt;&nbsp;reduceFunc,
                                                   scala.Option&lt;scala.Tuple2&lt;<A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;?&gt;,<A HREF="../../../../org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>&gt;&gt;&nbsp;activeSetOpt,
                                                   scala.reflect.ClassTag&lt;A&gt;&nbsp;evidence$11)</PRE>
<DL>
<DD>Aggregates values from the neighboring edges and vertices of each vertex.  The user supplied
 <code>mapFunc</code> function is invoked on each edge of the graph, generating 0 or more "messages" to be
 "sent" to either vertex in the edge.  The <code>reduceFunc</code> is then used to combine the output of
 the map phase destined to each vertex.
 <p>
 This function is deprecated in 1.2.0 because of SPARK-3936. Use aggregateMessages instead.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>mapFunc</CODE> - the user defined map function which returns 0 or
 more messages to neighboring vertices
 <p><DD><CODE>reduceFunc</CODE> - the user defined reduce function which should
 be commutative and associative and is used to combine the output
 of the map phase
 <p><DD><CODE>activeSetOpt</CODE> - an efficient way to run the aggregation on a subset of the edges if
 desired. This is done by specifying a set of "active" vertices and an edge direction. The
 <code>sendMsg</code> function will then run only on edges connected to active vertices by edges in the
 specified direction. If the direction is <code>In</code>, <code>sendMsg</code> will only be run on edges with
 destination in the active set. If the direction is <code>Out</code>, <code>sendMsg</code> will only be run on edges
 originating from vertices in the active set. If the direction is <code>Either</code>, <code>sendMsg</code> will be
 run on edges with *either* vertex in the active set. If the direction is <code>Both</code>, <code>sendMsg</code>
 will be run on edges with *both* vertices in the active set. The active set must have the
 same index as the graph's vertices.
 <p><DD><CODE>evidence$11</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="aggregateMessages(scala.Function1, scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><!-- --></A><H3>
aggregateMessages</H3>
<PRE>
public &lt;A&gt; <A HREF="../../../../org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>&lt;A&gt; <B>aggregateMessages</B>(scala.Function1&lt;<A HREF="../../../../org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>,A&gt;,scala.runtime.BoxedUnit&gt;&nbsp;sendMsg,
                                          scala.Function2&lt;A,A,A&gt;&nbsp;mergeMsg,
                                          <A HREF="../../../../org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>&nbsp;tripletFields,
                                          scala.reflect.ClassTag&lt;A&gt;&nbsp;evidence$12)</PRE>
<DL>
<DD>Aggregates values from the neighboring edges and vertices of each vertex. The user-supplied
 <code>sendMsg</code> function is invoked on each edge of the graph, generating 0 or more messages to be
 sent to either vertex in the edge. The <code>mergeMsg</code> function is then used to combine all messages
 destined to the same vertex.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>sendMsg</CODE> - runs on each edge, sending messages to neighboring vertices using the
   <A HREF="../../../../org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx"><CODE>EdgeContext</CODE></A>.<DD><CODE>mergeMsg</CODE> - used to combine messages from <code>sendMsg</code> destined to the same vertex. This
   combiner should be commutative and associative.<DD><CODE>tripletFields</CODE> - which fields should be included in the <A HREF="../../../../org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx"><CODE>EdgeContext</CODE></A> passed to the
   <code>sendMsg</code> function. If not all fields are needed, specifying this can improve performance.
 <p><DD><CODE>evidence$12</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="outerJoinVertices(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><!-- --></A><H3>
outerJoinVertices</H3>
<PRE>
public abstract &lt;U,VD2&gt; <A HREF="../../../../org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>&lt;VD2,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>outerJoinVertices</B>(<A HREF="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>&lt;scala.Tuple2&lt;Object,U&gt;&gt;&nbsp;other,
                                                        scala.Function3&lt;Object,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,scala.Option&lt;U&gt;,VD2&gt;&nbsp;mapFunc,
                                                        scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$14,
                                                        scala.reflect.ClassTag&lt;VD2&gt;&nbsp;evidence$15,
                                                        scala.Predef.$eq$colon$eq&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,VD2&gt;&nbsp;eq)</PRE>
<DL>
<DD>Joins the vertices with entries in the <code>table</code> RDD and merges the results using <code>mapFunc</code>.
 The input table should contain at most one entry for each vertex.  If no entry in <code>other</code> is
 provided for a particular vertex in the graph, the map function receives <code>None</code>.
 <p>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>other</CODE> - the table to join with the vertices in the graph.
              The table should contain at most one entry for each vertex.<DD><CODE>mapFunc</CODE> - the function used to compute the new vertex values.
                The map function is invoked for all vertices, even those
                that do not have a corresponding entry in the table.
 <p><DD><CODE>evidence$14</CODE> - (undocumented)<DD><CODE>evidence$15</CODE> - (undocumented)<DD><CODE>eq</CODE> - (undocumented)
<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<HR>

<A NAME="ops()"><!-- --></A><H3>
ops</H3>
<PRE>
public <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>&lt;<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="../../../../org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; <B>ops</B>()</PRE>
<DL>
<DD>The associated <A HREF="../../../../org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> object.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>(undocumented)</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/spark/graphx/GraphKryoRegistrator.html" title="class in org.apache.spark.graphx"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/spark/graphx/Graph.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="Graph.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;CONSTR&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
