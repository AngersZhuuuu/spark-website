<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_45) on Wed Jul 08 16:13:43 PDT 2015 -->
<TITLE>
Index (Spark 1.4.1 JavaDoc)
</TITLE>

<META NAME="date" CONTENT="2015-07-08">

<LINK REL ="stylesheet" TYPE="text/css" HREF="./stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Index (Spark 1.4.1 JavaDoc)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Index</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="./index.html?index-all.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="index-all.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="./allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="./allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<A HREF="#_A_">A</A> <A HREF="#_B_">B</A> <A HREF="#_C_">C</A> <A HREF="#_D_">D</A> <A HREF="#_E_">E</A> <A HREF="#_F_">F</A> <A HREF="#_G_">G</A> <A HREF="#_H_">H</A> <A HREF="#_I_">I</A> <A HREF="#_J_">J</A> <A HREF="#_K_">K</A> <A HREF="#_L_">L</A> <A HREF="#_M_">M</A> <A HREF="#_N_">N</A> <A HREF="#_O_">O</A> <A HREF="#_P_">P</A> <A HREF="#_Q_">Q</A> <A HREF="#_R_">R</A> <A HREF="#_S_">S</A> <A HREF="#_T_">T</A> <A HREF="#_U_">U</A> <A HREF="#_V_">V</A> <A HREF="#_W_">W</A> <A HREF="#_Z_">Z</A> <A HREF="#___">_</A> <HR>
<A NAME="_A_"><!-- --></A><H2>
<B>A</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/sql/functions.html#abs(org.apache.spark.sql.Column)"><B>abs(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the absolute value.
<DT><A HREF="./org/apache/spark/mllib/tree/loss/AbsoluteError.html" title="class in org.apache.spark.mllib.tree.loss"><B>AbsoluteError</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html">org.apache.spark.mllib.tree.loss</A><DD>:: DeveloperApi ::
 Class for absolute error loss calculation (for regression).<DT><A HREF="./org/apache/spark/mllib/tree/loss/AbsoluteError.html#AbsoluteError()"><B>AbsoluteError()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/AbsoluteError.html" title="class in org.apache.spark.mllib.tree.loss">AbsoluteError</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanAccum.html#accId()"><B>accId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanAccum.html" title="class in org.apache.spark">CleanAccum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><B>Accumulable</B></A>&lt;<A HREF="./org/apache/spark/Accumulable.html" title="type parameter in Accumulable">R</A>,<A HREF="./org/apache/spark/Accumulable.html" title="type parameter in Accumulable">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A data type that can be accumulated, ie has an commutative and associative "add" operation,
 but where the result type, <code>R</code>, may be different from the element type being added, <code>T</code>.<DT><A HREF="./org/apache/spark/Accumulable.html#Accumulable(R, org.apache.spark.AccumulableParam, scala.Option)"><B>Accumulable(R, AccumulableParam&lt;R, T&gt;, Option&lt;String&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#Accumulable(R, org.apache.spark.AccumulableParam)"><B>Accumulable(R, AccumulableParam&lt;R, T&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulable(T, org.apache.spark.AccumulableParam)"><B>accumulable(T, AccumulableParam&lt;T, R&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> shared variable of the given type, to which tasks
 can "add" values with <code>add</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulable(T, java.lang.String, org.apache.spark.AccumulableParam)"><B>accumulable(T, String, AccumulableParam&lt;T, R&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> shared variable of the given type, to which tasks
 can "add" values with <code>add</code>.
<DT><A HREF="./org/apache/spark/SparkContext.html#accumulable(R, org.apache.spark.AccumulableParam)"><B>accumulable(R, AccumulableParam&lt;R, T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> shared variable, to which tasks can add values
 with <code>+=</code>.
<DT><A HREF="./org/apache/spark/SparkContext.html#accumulable(R, java.lang.String, org.apache.spark.AccumulableParam)"><B>accumulable(R, String, AccumulableParam&lt;R, T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> shared variable, with a name for display in the
 Spark UI.
<DT><A HREF="./org/apache/spark/SparkContext.html#accumulableCollection(R, scala.Function1, scala.reflect.ClassTag)"><B>accumulableCollection(R, Function1&lt;R, Growable&lt;T&gt;&gt;, ClassTag&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create an accumulator from a "mutable collection" type.
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler"><B>AccumulableInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Information about an <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> modified during a task or stage.<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#AccumulableInfo(long, java.lang.String, scala.Option, java.lang.String)"><B>AccumulableInfo(long, String, Option&lt;String&gt;, String)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html" title="class in org.apache.spark.status.api.v1"><B>AccumulableInfo</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark"><B>AccumulableParam</B></A>&lt;<A HREF="./org/apache/spark/AccumulableParam.html" title="type parameter in AccumulableParam">R</A>,<A HREF="./org/apache/spark/AccumulableParam.html" title="type parameter in AccumulableParam">T</A>&gt; - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Helper object defining how to accumulate values of a particular type.<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#accumulables()"><B>accumulables()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>Terminal values of accumulables updated during this stage.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#accumulables()"><B>accumulables()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>Intermediate updates to accumulables during this task.
<DT><A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><B>Accumulator</B></A>&lt;<A HREF="./org/apache/spark/Accumulator.html" title="type parameter in Accumulator">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A simpler value of <A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><CODE>Accumulable</CODE></A> where the result type being accumulated is the same
 as the types of elements being merged, i.e.<DT><A HREF="./org/apache/spark/Accumulator.html#Accumulator(T, org.apache.spark.AccumulatorParam, scala.Option)"><B>Accumulator(T, AccumulatorParam&lt;T&gt;, Option&lt;String&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulator.html#Accumulator(T, org.apache.spark.AccumulatorParam)"><B>Accumulator(T, AccumulatorParam&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(int)"><B>accumulator(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> integer variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(int, java.lang.String)"><B>accumulator(int, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> integer variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(double)"><B>accumulator(double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> double variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(double, java.lang.String)"><B>accumulator(double, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> double variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(T, org.apache.spark.AccumulatorParam)"><B>accumulator(T, AccumulatorParam&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> variable of a given type, which tasks can "add"
 values to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(T, java.lang.String, org.apache.spark.AccumulatorParam)"><B>accumulator(T, String, AccumulatorParam&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> variable of a given type, which tasks can "add"
 values to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/SparkContext.html#accumulator(T, org.apache.spark.AccumulatorParam)"><B>accumulator(T, AccumulatorParam&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> variable of a given type, which tasks can "add"
 values to using the <code>+=</code> method.
<DT><A HREF="./org/apache/spark/SparkContext.html#accumulator(T, java.lang.String, org.apache.spark.AccumulatorParam)"><B>accumulator(T, String, AccumulatorParam&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> variable of a given type, with a name for display
 in the Spark UI.
<DT><A HREF="./org/apache/spark/AccumulatorParam.html" title="interface in org.apache.spark"><B>AccumulatorParam</B></A>&lt;<A HREF="./org/apache/spark/AccumulatorParam.html" title="type parameter in AccumulatorParam">T</A>&gt; - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A simpler version of <A HREF="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark"><CODE>AccumulableParam</CODE></A> where the only data type you can add
 in is the same type as the accumulated value.<DT><A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html" title="class in org.apache.spark"><B>AccumulatorParam.DoubleAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html#AccumulatorParam.DoubleAccumulatorParam$()"><B>AccumulatorParam.DoubleAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html" title="class in org.apache.spark"><B>AccumulatorParam.FloatAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html#AccumulatorParam.FloatAccumulatorParam$()"><B>AccumulatorParam.FloatAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html" title="class in org.apache.spark"><B>AccumulatorParam.IntAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html#AccumulatorParam.IntAccumulatorParam$()"><B>AccumulatorParam.IntAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html" title="class in org.apache.spark"><B>AccumulatorParam.LongAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html#AccumulatorParam.LongAccumulatorParam$()"><B>AccumulatorParam.LongAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#accumulatorUpdates()"><B>accumulatorUpdates()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#accumulatorUpdates()"><B>accumulatorUpdates()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#accuracy()"><B>accuracy()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns accuracy
<DT><A HREF="./org/apache/spark/sql/functions.html#acos(org.apache.spark.sql.Column)"><B>acos(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cosine inverse of the given value; the returned angle is in the range
 0.0 through pi.
<DT><A HREF="./org/apache/spark/sql/functions.html#acos(java.lang.String)"><B>acos(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cosine inverse of the given column; the returned angle is in the range
 0.0 through pi.
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#active()"><B>active()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#activeJobs()"><B>activeJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#activeStages()"><B>activeStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#activeTasks()"><B>activeTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver"><B>ActorHelper</B></A> - Interface in <A HREF="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</A><DD>:: DeveloperApi ::
 A receiver trait to be mixed in with your Actor to gain access to
 the API for pushing received data into Spark Streaming for being processed.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)"><B>actorStream(Props, String, StorageLevel, SupervisorStrategy)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel)"><B>actorStream(Props, String, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String)"><B>actorStream(Props, String)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy, scala.reflect.ClassTag)"><B>actorStream(Props, String, StorageLevel, SupervisorStrategy, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented actor receiver.
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver"><B>ActorSupervisorStrategy</B></A> - Class in <A HREF="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</A><DD>:: DeveloperApi ::
 A helper with set of defaults for supervisor strategy<DT><A HREF="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html#ActorSupervisorStrategy()"><B>ActorSupervisorStrategy()</B></A> - 
Constructor for class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver">ActorSupervisorStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#actorSystem()"><B>actorSystem()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#add(T)"><B>add(T)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>Add more data to this accumulator / accumulable
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#add(double, org.apache.spark.mllib.linalg.Vector)"><B>add(double, Vector)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>Add a new training data to this LogisticAggregator, and update the loss and gradient
 of the objective function.
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#add(double, org.apache.spark.mllib.linalg.Vector)"><B>add(double, Vector)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>Add a new training data to this LeastSquaresAggregator, and update the loss and gradient
 of the objective function.
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#add(double[], org.apache.spark.mllib.stat.distribution.MultivariateGaussian[], org.apache.spark.mllib.clustering.ExpectationSum, breeze.linalg.Vector)"><B>add(double[], MultivariateGaussian[], ExpectationSum, Vector&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#add(org.apache.spark.mllib.linalg.Vector)"><B>add(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>Adds a new document.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#add(org.apache.spark.mllib.linalg.distributed.BlockMatrix)"><B>add(BlockMatrix)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Adds two block matrices together.
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#add(org.apache.spark.mllib.linalg.Vector)"><B>add(Vector)</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>Add a new sample to this summarizer, and update the statistical summary.
<DT><A HREF="./org/apache/spark/util/Vector.html#add(org.apache.spark.util.Vector)"><B>add(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulableParam.html#addAccumulator(R, T)"><B>addAccumulator(R, T)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</A>
<DD>Add additional data to the accumulator value.
<DT><A HREF="./org/apache/spark/AccumulatorParam.html#addAccumulator(T, T)"><B>addAccumulator(T, T)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.html" title="interface in org.apache.spark">AccumulatorParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#addAppArgs(java.lang.String...)"><B>addAppArgs(String...)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Adds command line arguments for the application.
<DT><A HREF="./org/apache/spark/SparkContext.html#addedFiles()"><B>addedFiles()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#addedJars()"><B>addedJars()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#addFile(java.lang.String)"><B>addFile(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Add a file to be downloaded with this Spark job on every node.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#addFile(java.lang.String)"><B>addFile(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Adds a file to be submitted with the application.
<DT><A HREF="./org/apache/spark/SparkContext.html#addFile(java.lang.String)"><B>addFile(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Add a file to be downloaded with this Spark job on every node.
<DT><A HREF="./org/apache/spark/SparkContext.html#addFile(java.lang.String, boolean)"><B>addFile(String, boolean)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Add a file to be downloaded with this Spark job on every node.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.Param, scala.collection.Iterable)"><B>addGrid(Param&lt;T&gt;, Iterable&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a param with multiple values (overwrites if the input param exists).
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.DoubleParam, double[])"><B>addGrid(DoubleParam, double[])</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a double param with multiple values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.IntParam, int[])"><B>addGrid(IntParam, int[])</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a int param with multiple values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.FloatParam, float[])"><B>addGrid(FloatParam, float[])</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a float param with multiple values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.LongParam, long[])"><B>addGrid(LongParam, long[])</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a long param with multiple values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#addGrid(org.apache.spark.ml.param.BooleanParam)"><B>addGrid(BooleanParam)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Adds a boolean param with true and false.
<DT><A HREF="./org/apache/spark/AccumulableParam.html#addInPlace(R, R)"><B>addInPlace(R, R)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</A>
<DD>Merge two accumulated values together.
<DT><A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html#addInPlace(double, double)"><B>addInPlace(double, double)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html#addInPlace(float, float)"><B>addInPlace(float, float)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html#addInPlace(int, int)"><B>addInPlace(int, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html#addInPlace(long, long)"><B>addInPlace(long, long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#addInPlace(double, double)"><B>addInPlace(double, double)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#addInPlace(float, float)"><B>addInPlace(float, float)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#addInPlace(int, int)"><B>addInPlace(int, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#addInPlace(long, long)"><B>addInPlace(long, long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#addInPlace(org.apache.spark.util.Vector)"><B>addInPlace(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html#addInPlace(org.apache.spark.util.Vector, org.apache.spark.util.Vector)"><B>addInPlace(Vector, Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#addJar(java.lang.String)"><B>addJar(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Adds a JAR dependency for all tasks to be executed on this SparkContext in the future.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#addJar(java.lang.String)"><B>addJar(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Adds a jar file to be submitted with the application.
<DT><A HREF="./org/apache/spark/SparkContext.html#addJar(java.lang.String)"><B>addJar(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Adds a JAR dependency for all tasks to be executed on this SparkContext in the future.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#addLocalConfiguration(java.lang.String, int, int, int, org.apache.hadoop.mapred.JobConf)"><B>addLocalConfiguration(String, int, int, int, JobConf)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>Add Hadoop configuration specific to a single partition and attempt.
<DT><A HREF="./org/apache/spark/TaskContext.html#addOnCompleteCallback(scala.Function0)"><B>addOnCompleteCallback(Function0&lt;BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Adds a callback function to be executed on task completion.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#addPartToPGroup(org.apache.spark.Partition, org.apache.spark.rdd.PartitionGroup)"><B>addPartToPGroup(Partition, PartitionGroup)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#addPyFile(java.lang.String)"><B>addPyFile(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Adds a python file / zip / egg to be submitted with the application.
<DT><A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html#address()"><B>address()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html" title="class in org.apache.spark.status.api.v1">RDDDataDistribution</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#addSparkListener(org.apache.spark.scheduler.SparkListener)"><B>addSparkListener(SparkListener)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Register a listener to receive up-calls from events that happen during execution.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)"><B>addStreamingListener(StreamingListener)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Add a <A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><CODE>StreamingListener</CODE></A> object for
 receiving system events related to streaming.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)"><B>addStreamingListener(StreamingListener)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Add a <A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><CODE>StreamingListener</CODE></A> object for
 receiving system events related to streaming.
<DT><A HREF="./org/apache/spark/TaskContext.html#addTaskCompletionListener(org.apache.spark.util.TaskCompletionListener)"><B>addTaskCompletionListener(TaskCompletionListener)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Adds a (Java friendly) listener to be executed on task completion.
<DT><A HREF="./org/apache/spark/TaskContext.html#addTaskCompletionListener(scala.Function1)"><B>addTaskCompletionListener(Function1&lt;TaskContext, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Adds a listener in the form of a Scala closure to be executed on task completion.
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html#addVector(org.apache.spark.mllib.linalg.Vector)"><B>addVector(Vector)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html" title="class in org.apache.spark.ml.feature">VectorIndexer.CategoryStats</A>
<DD>Add a new vector to this index, updating sets of unique feature values
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#agg(org.apache.spark.sql.Column, org.apache.spark.sql.Column...)"><B>agg(Column, Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Aggregates on the entire <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> without groups.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#agg(scala.Tuple2, scala.collection.Seq)"><B>agg(Tuple2&lt;String, String&gt;, Seq&lt;Tuple2&lt;String, String&gt;&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Aggregates on the entire <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> without groups.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#agg(scala.collection.immutable.Map)"><B>agg(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Aggregates on the entire <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> without groups.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#agg(java.util.Map)"><B>agg(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Java-specific) Aggregates on the entire <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> without groups.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#agg(org.apache.spark.sql.Column, scala.collection.Seq)"><B>agg(Column, Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Aggregates on the entire <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> without groups.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#agg(org.apache.spark.sql.Column, org.apache.spark.sql.Column...)"><B>agg(Column, Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute aggregates by specifying a series of aggregate columns.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#agg(scala.Tuple2, scala.collection.Seq)"><B>agg(Tuple2&lt;String, String&gt;, Seq&lt;Tuple2&lt;String, String&gt;&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>(Scala-specific) Compute aggregates by specifying a map from column name to
 aggregate methods.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#agg(scala.collection.immutable.Map)"><B>agg(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>(Scala-specific) Compute aggregates by specifying a map from column name to
 aggregate methods.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#agg(java.util.Map)"><B>agg(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>(Java-specific) Compute aggregates by specifying a map from column name to
 aggregate methods.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#agg(org.apache.spark.sql.Column, scala.collection.Seq)"><B>agg(Column, Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute aggregates by specifying a series of aggregate columns.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#aggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>aggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/rdd/RDD.html#aggregate(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)"><B>aggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>aggregateByKey(U, Partitioner, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, int, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>aggregateByKey(U, int, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>aggregateByKey(U, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, org.apache.spark.Partitioner, scala.Function2, scala.Function2, scala.reflect.ClassTag)"><B>aggregateByKey(U, Partitioner, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, int, scala.Function2, scala.Function2, scala.reflect.ClassTag)"><B>aggregateByKey(U, int, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)"><B>aggregateByKey(U, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Aggregate the values of each key, using given combine functions and a neutral "zero value".
<DT><A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html" title="class in org.apache.spark.sql.jdbc"><B>AggregatedDialect</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 AggregatedDialect can unify multiple dialects into one virtual Dialect.<DT><A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html#AggregatedDialect(scala.collection.immutable.List)"><B>AggregatedDialect(List&lt;JdbcDialect&gt;)</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html" title="class in org.apache.spark.sql.jdbc">AggregatedDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#aggregateMessages(scala.Function1, scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><B>aggregateMessages(Function1&lt;EdgeContext&lt;VD, ED, A&gt;, BoxedUnit&gt;, Function2&lt;A, A, A&gt;, TripletFields, ClassTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Aggregates values from the neighboring edges and vertices of each vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#aggregateMessagesWithActiveSet(scala.Function1, scala.Function2, org.apache.spark.graphx.TripletFields, scala.Option, scala.reflect.ClassTag)"><B>aggregateMessagesWithActiveSet(Function1&lt;EdgeContext&lt;VD, ED, A&gt;, BoxedUnit&gt;, Function2&lt;A, A, A&gt;, TripletFields, Option&lt;Tuple2&lt;VertexRDD&lt;?&gt;, EdgeDirection&gt;&gt;, ClassTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#aggregateUsingIndex(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)"><B>aggregateUsingIndex(RDD&lt;Tuple2&lt;Object, VD2&gt;&gt;, Function2&lt;VD2, VD2, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#aggregateUsingIndex(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)"><B>aggregateUsingIndex(RDD&lt;Tuple2&lt;Object, VD2&gt;&gt;, Function2&lt;VD2, VD2, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Aggregates vertices in <code>messages</code> that have the same ids using <code>reduceFunc</code>, returning a
 VertexRDD co-indexed with <code>this</code>.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl"><B>AggregatingEdgeContext</B></A>&lt;<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="type parameter in AggregatingEdgeContext">VD</A>,<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="type parameter in AggregatingEdgeContext">ED</A>,<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="type parameter in AggregatingEdgeContext">A</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/impl/package-summary.html">org.apache.spark.graphx.impl</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#AggregatingEdgeContext(scala.Function2, java.lang.Object, org.apache.spark.util.collection.BitSet)"><B>AggregatingEdgeContext(Function2&lt;A, A, A&gt;, Object, BitSet)</B></A> - 
Constructor for class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark"><B>Aggregator</B></A>&lt;<A HREF="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">K</A>,<A HREF="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">V</A>,<A HREF="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">C</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 A set of functions used to aggregate data.<DT><A HREF="./org/apache/spark/Aggregator.html#Aggregator(scala.Function1, scala.Function2, scala.Function2)"><B>Aggregator(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#aggregator()"><B>aggregator()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration"><B>Algo</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</A><DD>:: Experimental ::
 Enum to select the algorithm for the decision tree<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html#Algo()"><B>Algo()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#algo()"><B>algo()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#algo()"><B>algo()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#algo()"><B>algo()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html#algo()"><B>algo()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model">RandomForestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#algorithm()"><B>algorithm()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#alias(java.lang.String)"><B>alias(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Gives the column an alias.
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#All"><B>All</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Expose all the fields (source, edge, and destination).
<DT><A HREF="./org/apache/spark/annotation/AlphaComponent.html" title="annotation in org.apache.spark.annotation"><B>AlphaComponent</B></A> - Annotation Type in <A HREF="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</A><DD>A new component of Spark which may have unstable API's.<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation"><B>ALS</B></A> - Class in <A HREF="./org/apache/spark/ml/recommendation/package-summary.html">org.apache.spark.ml.recommendation</A><DD>:: Experimental ::
 Alternating Least Squares (ALS) matrix factorization.<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#ALS(java.lang.String)"><B>ALS(String)</B></A> - 
Constructor for class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#ALS()"><B>ALS()</B></A> - 
Constructor for class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation"><B>ALS</B></A> - Class in <A HREF="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#ALS()"><B>ALS()</B></A> - 
Constructor for class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="class in org.apache.spark.ml.recommendation"><B>ALS.Rating</B></A>&lt;<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="type parameter in ALS.Rating">ID</A>&gt; - Class in <A HREF="./org/apache/spark/ml/recommendation/package-summary.html">org.apache.spark.ml.recommendation</A><DD>:: DeveloperApi ::
 Rating class for better code readability.<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html#ALS.Rating(ID, ID, float)"><B>ALS.Rating(ID, ID, float)</B></A> - 
Constructor for class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating$.html" title="class in org.apache.spark.ml.recommendation"><B>ALS.Rating$</B></A> - Class in <A HREF="./org/apache/spark/ml/recommendation/package-summary.html">org.apache.spark.ml.recommendation</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating$.html#ALS.Rating$()"><B>ALS.Rating$()</B></A> - 
Constructor for class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating$.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation"><B>ALSModel</B></A> - Class in <A HREF="./org/apache/spark/ml/recommendation/package-summary.html">org.apache.spark.ml.recommendation</A><DD>:: Experimental ::
 Model fitted by ALS.<DT><A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql"><B>AnalysisException</B></A> - Exception in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: DeveloperApi ::
 Thrown when a query fails to analyze, usually because the query itself is invalid.<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#analyze(java.lang.String)"><B>analyze(String)</B></A> - 
Method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.
<DT><A HREF="./org/apache/spark/sql/Column.html#and(org.apache.spark.sql.Column)"><B>and(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Boolean AND.
<DT><A HREF="./org/apache/spark/sql/sources/And.html" title="class in org.apache.spark.sql.sources"><B>And</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff both <code>left</code> or <code>right</code> evaluate to <code>true</code>.<DT><A HREF="./org/apache/spark/sql/sources/And.html#And(org.apache.spark.sql.sources.Filter, org.apache.spark.sql.sources.Filter)"><B>And(Filter, Filter)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/And.html" title="class in org.apache.spark.sql.sources">And</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#ANY()"><B>ANY()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#anyNull()"><B>anyNull()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns true if there are any NULL values in this row.
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#appAttemptId()"><B>appAttemptId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#appendBias(org.apache.spark.mllib.linalg.Vector)"><B>appendBias(Vector)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Returns a new vector with <code>1.0</code> (bias) appended to the input vector.
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#appId()"><B>appId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#applicationAttemptId()"><B>applicationAttemptId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1"><B>ApplicationAttemptInfo</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkContext.html#applicationId()"><B>applicationId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html" title="class in org.apache.spark.status.api.v1"><B>ApplicationInfo</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html" title="enum in org.apache.spark.status.api.v1"><B>ApplicationStatus</B></A> - Enum in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/Graph.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>apply(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;, RDD&lt;Edge&lt;ED&gt;&gt;, VD, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Construct a graph from a collection of vertices and
 edges with attributes.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#apply(org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>apply(RDD&lt;Edge&lt;ED&gt;&gt;, VD, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Create a graph from edges, setting referenced vertices to `defaultVertexAttr`.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>apply(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;, RDD&lt;Edge&lt;ED&gt;&gt;, VD, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Create a graph from vertices and edges, setting missing vertices to `defaultVertexAttr`.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#apply(org.apache.spark.graphx.VertexRDD, org.apache.spark.graphx.EdgeRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>apply(VertexRDD&lt;VD&gt;, EdgeRDD&lt;ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Create a graph from a VertexRDD and an EdgeRDD with arbitrary replicated vertices.
<DT><A HREF="./org/apache/spark/graphx/Pregel.html#apply(org.apache.spark.graphx.Graph, A, int, org.apache.spark.graphx.EdgeDirection, scala.Function3, scala.Function1, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>apply(Graph&lt;VD, ED&gt;, A, int, EdgeDirection, Function3&lt;Object, VD, A, VD&gt;, Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Iterator&lt;Tuple2&lt;Object, A&gt;&gt;&gt;, Function2&lt;A, A, A&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;, ClassTag&lt;A&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Pregel.html" title="class in org.apache.spark.graphx">Pregel</A>
<DD>Execute a Pregel-like iterative vertex-parallel abstraction.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>apply(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Constructs a standalone <code>VertexRDD</code> (one that is not set up for efficient joins with an
 <A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>) from an RDD of vertex-attribute pairs.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.reflect.ClassTag)"><B>apply(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;, EdgeRDD&lt;?&gt;, VD, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#apply(org.apache.spark.rdd.RDD, org.apache.spark.graphx.EdgeRDD, VD, scala.Function2, scala.reflect.ClassTag)"><B>apply(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;, EdgeRDD&lt;?&gt;, VD, Function2&lt;VD, VD, VD&gt;, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Constructs a <code>VertexRDD</code> from an RDD of vertex-attribute pairs.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Gets an attribute by its name.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#apply(int)"><B>apply(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Gets an attribute by its index.
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#apply(org.apache.spark.ml.param.Param)"><B>apply(Param&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Gets the value of the input param or its default value if it does not exist.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#apply(int, int)"><B>apply(int, int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#apply(int)"><B>apply(int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#apply(int, int)"><B>apply(int, int)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Gets the (i, j)-th element.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#apply(int, int)"><B>apply(int, int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#apply(int)"><B>apply(int)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Gets the value of the ith element.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#apply(int, org.apache.spark.mllib.tree.model.Predict, double, boolean)"><B>apply(int, Predict, double, boolean)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Construct a node with nodeIndex, predict, impurity and isLeaf parameters.
<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd">PartitionGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#apply(long, java.lang.String, scala.Option, java.lang.String)"><B>apply(long, String, Option&lt;String&gt;, String)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#apply(long, java.lang.String, java.lang.String)"><B>apply(long, String, String)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html#apply(long, org.apache.spark.executor.TaskMetrics)"><B>apply(long, TaskMetrics)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler">RuntimePercentage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#apply(java.lang.Object)"><B>apply(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Extracts a value or values from a complex type.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects column based on the column name and return it as a <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#apply(org.apache.spark.sql.DataFrame, scala.collection.Seq, org.apache.spark.sql.GroupedData.GroupType)"><B>apply(DataFrame, Seq&lt;Expression&gt;, GroupedData.GroupType)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#apply(int)"><B>apply(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i.
<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#apply(org.apache.spark.sql.types.DataType)"><B>apply(DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>Construct a <A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types"><CODE>ArrayType</CODE></A> object with the given element type.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(double)"><B>apply(double)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(long)"><B>apply(long)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(int)"><B>apply(int)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(scala.math.BigDecimal)"><B>apply(BigDecimal)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(java.math.BigDecimal)"><B>apply(BigDecimal)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(scala.math.BigDecimal, int, int)"><B>apply(BigDecimal, int, int)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(long, int, int)"><B>apply(long, int, int)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#apply()"><B>apply()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#apply(int, int)"><B>apply(int, int)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#apply(org.apache.spark.sql.types.DataType, org.apache.spark.sql.types.DataType)"><B>apply(DataType, DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>Construct a <A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types"><CODE>MapType</CODE></A> object with the given key type and value type.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>Extracts a <A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types"><CODE>StructField</CODE></A> of the given name.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#apply(scala.collection.immutable.Set)"><B>apply(Set&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>Returns a <A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types"><CODE>StructType</CODE></A> containing <A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types"><CODE>StructField</CODE></A>s of the given names, preserving the
 original order of fields.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#apply(int)"><B>apply(int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Create a UTF-8 String from String
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#apply(byte[])"><B>apply(byte[])</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Create a UTF-8 String from Array[Byte], which should be encoded in UTF-8
<DT><A HREF="./org/apache/spark/sql/UserDefinedFunction.html#apply(scala.collection.Seq)"><B>apply(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#apply(java.lang.String)"><B>apply(String)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>Converts a BlockId "name" String back into a BlockId.
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#apply(java.lang.String, java.lang.String, int)"><B>apply(String, String, int)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>Returns a <A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage"><CODE>BlockManagerId</CODE></A> for the given configuration.
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#apply(java.io.ObjectInput)"><B>apply(ObjectInput)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#apply(boolean, boolean, boolean, boolean, int)"><B>apply(boolean, boolean, boolean, boolean, int)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Create a new StorageLevel object without setting useOffHeap.
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#apply(boolean, boolean, boolean, int)"><B>apply(boolean, boolean, boolean, int)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Create a new StorageLevel object.
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#apply(int, int)"><B>apply(int, int)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Create a new StorageLevel object from its integer representation.
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#apply(java.io.ObjectInput)"><B>apply(ObjectInput)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Read StorageLevel object from ObjectInput stream.
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#apply(java.lang.String, int)"><B>apply(String, int)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#apply(java.lang.String, int, long, long)"><B>apply(String, int, long, long)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#apply(kafka.common.TopicAndPartition, long, long)"><B>apply(TopicAndPartition, long, long)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Milliseconds.html#apply(long)"><B>apply(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming">Milliseconds</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Minutes.html#apply(long)"><B>apply(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming">Minutes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Seconds.html#apply(long)"><B>apply(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming">Seconds</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#apply(scala.collection.TraversableOnce)"><B>apply(TraversableOnce&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Build a StatCounter from a list of values.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#apply(scala.collection.Seq)"><B>apply(Seq&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Build a StatCounter from a list of values passed as variable-length arguments.
<DT><A HREF="./org/apache/spark/util/Vector.html#apply(int)"><B>apply(int)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)"><B>applySchema(RDD&lt;Row&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)"><B>applySchema(JavaRDD&lt;Row&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, java.lang.Class)"><B>applySchema(RDD&lt;?&gt;, Class&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD, java.lang.Class)"><B>applySchema(JavaRDD&lt;?&gt;, Class&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#appName()"><B>appName()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#appName()"><B>appName()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#appName()"><B>appName()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#approxCountDistinct(org.apache.spark.sql.Column)"><B>approxCountDistinct(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#approxCountDistinct(java.lang.String)"><B>approxCountDistinct(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#approxCountDistinct(org.apache.spark.sql.Column, double)"><B>approxCountDistinct(Column, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#approxCountDistinct(java.lang.String, double)"><B>approxCountDistinct(String, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the approximate number of distinct items in a group.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#ApproxHist()"><B>ApproxHist()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#areaUnderPR()"><B>areaUnderPR()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Computes the area under the precision-recall curve.
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#areaUnderROC()"><B>areaUnderROC()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Computes the area under the receiver operating characteristic (ROC) curve.
<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html#arr()"><B>arr()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd">PartitionGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#array(org.apache.spark.sql.types.DataType)"><B>array(DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type array.
<DT><A HREF="./org/apache/spark/sql/functions.html#array(org.apache.spark.sql.Column...)"><B>array(Column...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new array column.
<DT><A HREF="./org/apache/spark/sql/functions.html#array(scala.collection.Seq)"><B>array(Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new array column.
<DT><A HREF="./org/apache/spark/sql/functions.html#array(java.lang.String, scala.collection.Seq)"><B>array(String, Seq&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new array column.
<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types"><B>ArrayType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#ArrayType(org.apache.spark.sql.types.DataType, boolean)"><B>ArrayType(DataType, boolean)</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#as(java.lang.String)"><B>as(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Gives the column an alias.
<DT><A HREF="./org/apache/spark/sql/Column.html#as(scala.collection.Seq)"><B>as(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>(Scala-specific) Assigns the given aliases to the results of a table generating function.
<DT><A HREF="./org/apache/spark/sql/Column.html#as(java.lang.String[])"><B>as(String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Assigns the given aliases to the results of a table generating function.
<DT><A HREF="./org/apache/spark/sql/Column.html#as(scala.Symbol)"><B>as(Symbol)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Gives the column an alias.
<DT><A HREF="./org/apache/spark/sql/Column.html#as(java.lang.String, org.apache.spark.sql.types.Metadata)"><B>as(String, Metadata)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Gives the column an alias with metadata.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#as(java.lang.String)"><B>as(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with an alias set.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#as(scala.Symbol)"><B>as(Symbol)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with an alias set.
<DT><A HREF="./org/apache/spark/sql/Column.html#asc()"><B>asc()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Returns an ordering used in sorting.
<DT><A HREF="./org/apache/spark/sql/functions.html#asc(java.lang.String)"><B>asc(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns a sort expression based on ascending order of the column.
<DT><A HREF="./org/apache/spark/sql/functions.html#asin(org.apache.spark.sql.Column)"><B>asin(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the sine inverse of the given value; the returned angle is in the range
 -pi/2 through pi/2.
<DT><A HREF="./org/apache/spark/sql/functions.html#asin(java.lang.String)"><B>asin(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the sine inverse of the given column; the returned angle is in the range
 -pi/2 through pi/2.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#asIntegral()"><B>asIntegral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#asIntegral()"><B>asIntegral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#asIntegral()"><B>asIntegral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#asIterator()"><B>asIterator()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>Read the elements of this stream through an iterator.
<DT><A HREF="./org/apache/spark/api/r/PairwiseRRDD.html#asJavaPairRDD()"><B>asJavaPairRDD()</B></A> - 
Method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/PairwiseRRDD.html" title="class in org.apache.spark.api.r">PairwiseRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/RRDD.html#asJavaRDD()"><B>asJavaRDD()</B></A> - 
Method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r">RRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/StringRRDD.html#asJavaRDD()"><B>asJavaRDD()</B></A> - 
Method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/StringRRDD.html" title="class in org.apache.spark.api.r">StringRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#asKeyValueIterator()"><B>asKeyValueIterator()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>Read the elements of this stream through an iterator over key-value pairs.
<DT><A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html" title="class in org.apache.spark.scheduler"><B>AskPermissionToCommitOutput</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html#AskPermissionToCommitOutput(int, long, long)"><B>AskPermissionToCommitOutput(int, long, long)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html" title="class in org.apache.spark.scheduler">AskPermissionToCommitOutput</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/RpcUtils.html#askTimeout(org.apache.spark.SparkConf)"><B>askTimeout(SparkConf)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>Returns the default Spark timeout to use for RPC ask operations.
<DT><A HREF="./org/apache/spark/storage/BlockId.html#asRDDId()"><B>asRDDId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html#assignments()"><B>assignments()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClusteringModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd"><B>AsyncRDDActions</B></A>&lt;<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="type parameter in AsyncRDDActions">T</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>A set of asynchronous RDD actions available through an implicit conversion.<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#AsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>AsyncRDDActions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#atan(org.apache.spark.sql.Column)"><B>atan(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the tangent inverse of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#atan(java.lang.String)"><B>atan(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the tangent inverse of the given column.
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>atan2(Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, java.lang.String)"><B>atan2(Column, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(java.lang.String, org.apache.spark.sql.Column)"><B>atan2(String, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(java.lang.String, java.lang.String)"><B>atan2(String, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(org.apache.spark.sql.Column, double)"><B>atan2(Column, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(java.lang.String, double)"><B>atan2(String, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(double, org.apache.spark.sql.Column)"><B>atan2(double, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/sql/functions.html#atan2(double, java.lang.String)"><B>atan2(double, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the angle theta from the conversion of rectangular coordinates (x, y) to
 polar coordinates (r, theta).
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#attempt()"><B>attempt()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#attempt()"><B>attempt()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#attemptId()"><B>attemptId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html#attemptId()"><B>attemptId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationAttemptInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#attemptId()"><B>attemptId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskCommitDenied.html#attemptID()"><B>attemptID()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark">TaskCommitDenied</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#attemptId()"><B>attemptId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#attemptNumber()"><B>attemptNumber()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>How many times this task has been attempted.
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html#attempts()"><B>attempts()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Edge.html#attr()"><B>attr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#attr()"><B>attr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>The attribute associated with the edge.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#attr()"><B>attr()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute"><B>Attribute</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 Abstract class for ML attributes.<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#Attribute()"><B>Attribute()</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/EqualTo.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/EqualTo.html" title="class in org.apache.spark.sql.sources">EqualTo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThan.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThan.html" title="class in org.apache.spark.sql.sources">GreaterThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources">GreaterThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/In.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/In.html" title="class in org.apache.spark.sql.sources">In</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/IsNotNull.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/IsNotNull.html" title="class in org.apache.spark.sql.sources">IsNotNull</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/IsNull.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/IsNull.html" title="class in org.apache.spark.sql.sources">IsNull</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThan.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThan.html" title="class in org.apache.spark.sql.sources">LessThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html" title="class in org.apache.spark.sql.sources">LessThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringContains.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringContains.html" title="class in org.apache.spark.sql.sources">StringContains</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringEndsWith.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringEndsWith.html" title="class in org.apache.spark.sql.sources">StringEndsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringStartsWith.html#attribute()"><B>attribute()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringStartsWith.html" title="class in org.apache.spark.sql.sources">StringStartsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute"><B>AttributeGroup</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 Attributes that describe a vector ML column.<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#AttributeGroup(java.lang.String)"><B>AttributeGroup(String)</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Creates an attribute group without attribute info.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#AttributeGroup(java.lang.String, int)"><B>AttributeGroup(String, int)</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Creates an attribute group knowing only the number of attributes.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#AttributeGroup(java.lang.String, org.apache.spark.ml.attribute.Attribute[])"><B>AttributeGroup(String, Attribute[])</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Creates an attribute group with attributes.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#attributes()"><B>attributes()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Optional array of attributes.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute"><B>AttributeType</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 An enum-like type for attribute types: <CODE>AttributeType$.Numeric</CODE>, <CODE>AttributeType$.Nominal</CODE>,
 and <CODE>AttributeType$.Binary</CODE>.<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#AttributeType(java.lang.String)"><B>AttributeType(String)</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#attrType()"><B>attrType()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Attribute type.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#attrType()"><B>attrType()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#attrType()"><B>attrType()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#attrType()"><B>attrType()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#attrType()"><B>attrType()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#avg(org.apache.spark.sql.Column)"><B>avg(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the average of the values in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#avg(java.lang.String)"><B>avg(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the average of the values in a group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#avg(java.lang.String...)"><B>avg(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the mean value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#avg(scala.collection.Seq)"><B>avg(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the mean value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination()"><B>awaitTermination()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Wait for the execution to stop.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination(long)"><B>awaitTermination(long)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I>
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#awaitTermination()"><B>awaitTermination()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Wait for the execution to stop.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#awaitTermination(long)"><B>awaitTermination(long)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by <code>awaitTerminationOrTimeout(Long)</code>.</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTerminationOrTimeout(long)"><B>awaitTerminationOrTimeout(long)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Wait for the execution to stop.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#awaitTerminationOrTimeout(long)"><B>awaitTerminationOrTimeout(long)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Wait for the execution to stop.
</DL>
<HR>
<A NAME="_B_"><!-- --></A><H2>
<B>B</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#baseOn(org.apache.spark.ml.param.ParamPair...)"><B>baseOn(ParamPair&lt;?&gt;...)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Sets the given parameters in this grid to fixed values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#baseOn(org.apache.spark.ml.param.ParamMap)"><B>baseOn(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Sets the given parameters in this grid to fixed values.
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#baseOn(scala.collection.Seq)"><B>baseOn(Seq&lt;ParamPair&lt;?&gt;&gt;)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Sets the given parameters in this grid to fixed values.
<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><B>BaseRelation</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 Represents a collection of tuples with a known schema.<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html#BaseRelation()"><B>BaseRelation()</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)"><B>baseRelationToDataFrame(BaseRelation)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="class in org.apache.spark.api.r"><B>BaseRRDD</B></A>&lt;<A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="type parameter in BaseRRDD">T</A>,<A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="type parameter in BaseRRDD">U</A>&gt; - Class in <A HREF="./org/apache/spark/api/r/package-summary.html">org.apache.spark.api.r</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/r/BaseRRDD.html#BaseRRDD(org.apache.spark.rdd.RDD, int, byte[], java.lang.String, java.lang.String, byte[], java.lang.String, org.apache.spark.broadcast.Broadcast[], scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>BaseRRDD(RDD&lt;T&gt;, int, byte[], String, String, byte[], String, Broadcast&lt;Object&gt;[], ClassTag&lt;T&gt;, ClassTag&lt;U&gt;)</B></A> - 
Constructor for class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="class in org.apache.spark.api.r">BaseRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#BATCHES()"><B>BATCHES()</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler"><B>BatchInfo</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>:: DeveloperApi ::
 Class having information on completed batches.<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#BatchInfo(org.apache.spark.streaming.Time, scala.collection.immutable.Map, long, scala.Option, scala.Option)"><B>BatchInfo(Time, Map&lt;Object, Object&gt;, long, Option&lt;Object&gt;, Option&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html#batchInfo()"><B>batchInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchCompleted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html#batchInfo()"><B>batchInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchStarted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html#batchInfo()"><B>batchInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchSubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#batchInfos()"><B>batchInfos()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#batchTime()"><B>batchTime()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#Bernoulli()"><B>Bernoulli()</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>String name for Bernoulli model type.
<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random"><B>BernoulliCellSampler</B></A>&lt;<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="type parameter in BernoulliCellSampler">T</A>&gt; - Class in <A HREF="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</A><DD>:: DeveloperApi ::
 A sampler based on Bernoulli trials for partitioning a data sequence.<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html#BernoulliCellSampler(double, double, boolean)"><B>BernoulliCellSampler(double, double, boolean)</B></A> - 
Constructor for class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random">BernoulliCellSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random"><B>BernoulliSampler</B></A>&lt;<A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="type parameter in BernoulliSampler">T</A>&gt; - Class in <A HREF="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</A><DD>:: DeveloperApi ::
 A sampler based on Bernoulli trials.<DT><A HREF="./org/apache/spark/util/random/BernoulliSampler.html#BernoulliSampler(double, scala.reflect.ClassTag)"><B>BernoulliSampler(double, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#bestModel()"><B>bestModel()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#between(java.lang.Object, java.lang.Object)"><B>between(Object, Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>True if the current column is between the lower bound and upper bound, inclusive.
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature"><B>Binarizer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Binarize a column of continuous features given a threshold.<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#Binarizer(java.lang.String)"><B>Binarizer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#Binarizer()"><B>Binarizer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#Binary()"><B>Binary()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>Binary type.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#binary()"><B>binary()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type binary.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute"><B>BinaryAttribute</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 A binary attribute.<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation"><B>BinaryClassificationEvaluator</B></A> - Class in <A HREF="./org/apache/spark/ml/evaluation/package-summary.html">org.apache.spark.ml.evaluation</A><DD>:: Experimental ::
 Evaluator for binary classification, which expects two input columns: score and label.<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#BinaryClassificationEvaluator(java.lang.String)"><B>BinaryClassificationEvaluator(String)</B></A> - 
Constructor for class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#BinaryClassificationEvaluator()"><B>BinaryClassificationEvaluator()</B></A> - 
Constructor for class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation"><B>BinaryClassificationMetrics</B></A> - Class in <A HREF="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</A><DD>:: Experimental ::
 Evaluator for binary classification.<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#BinaryClassificationMetrics(org.apache.spark.rdd.RDD, int)"><B>BinaryClassificationMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;, int)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#BinaryClassificationMetrics(org.apache.spark.rdd.RDD)"><B>BinaryClassificationMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Defaults <code>numBins</code> to 0.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#binaryFiles(java.lang.String, int)"><B>binaryFiles(String, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Read a directory of binary files from HDFS, a local file system (available on all nodes),
 or any Hadoop-supported file system URI as a byte array.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#binaryFiles(java.lang.String)"><B>binaryFiles(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/SparkContext.html#binaryFiles(java.lang.String, int)"><B>binaryFiles(String, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/mllib/util/DataValidators.html#binaryLabelValidator()"><B>binaryLabelValidator()</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util">DataValidators</A>
<DD>Function to check if labels used for classification are either zero or one.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#binaryRecords(java.lang.String, int)"><B>binaryRecords(String, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/SparkContext.html#binaryRecords(java.lang.String, int, org.apache.hadoop.conf.Configuration)"><B>binaryRecords(String, int, Configuration)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#binaryRecordsStream(java.lang.String, int)"><B>binaryRecordsStream(String, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#binaryRecordsStream(java.lang.String, int)"><B>binaryRecordsStream(String, int)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#binarySearchForBuckets(double[], double)"><B>binarySearchForBuckets(double[], double)</B></A> - 
Static method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>Binary searching in several buckets to place each data point.
<DT><A HREF="./org/apache/spark/sql/types/BinaryType.html" title="class in org.apache.spark.sql.types"><B>BinaryType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Array[Byte]</code> values.<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#BinaryType"><B>BinaryType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the BinaryType object.
<DT><A HREF="./org/apache/spark/sql/Column.html#bitwiseAND(java.lang.Object)"><B>bitwiseAND(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Compute bitwise AND of this expression with another expression.
<DT><A HREF="./org/apache/spark/sql/functions.html#bitwiseNOT(org.apache.spark.sql.Column)"><B>bitwiseNOT(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes bitwise NOT.
<DT><A HREF="./org/apache/spark/sql/Column.html#bitwiseOR(java.lang.Object)"><B>bitwiseOR(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Compute bitwise OR of this expression with another expression.
<DT><A HREF="./org/apache/spark/sql/Column.html#bitwiseXOR(java.lang.Object)"><B>bitwiseXOR(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Compute bitwise XOR of this expression with another expression.
<DT><A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage"><B>BlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>:: DeveloperApi ::
 Identifies a particular Block of data, usually associated with a single file.<DT><A HREF="./org/apache/spark/storage/BlockId.html#BlockId()"><B>BlockId()</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#blockManager()"><B>blockManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#blockManagerId()"><B>blockManagerId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html#blockManagerId()"><B>blockManagerId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage"><B>BlockManagerId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>:: DeveloperApi ::
 This class represent an unique identifier for a BlockManager.<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#blockManagerId()"><B>blockManagerId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#blockManagerIdCache()"><B>blockManagerIdCache()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#blockManagerIds()"><B>blockManagerIds()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>BlockMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#BlockMatrix(org.apache.spark.rdd.RDD, int, int, long, long)"><B>BlockMatrix(RDD&lt;Tuple2&lt;Tuple2&lt;Object, Object&gt;, Matrix&gt;&gt;, int, int, long, long)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#BlockMatrix(org.apache.spark.rdd.RDD, int, int)"><B>BlockMatrix(RDD&lt;Tuple2&lt;Tuple2&lt;Object, Object&gt;, Matrix&gt;&gt;, int, int)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Alternate constructor for BlockMatrix without the input of the number of rows and columns.
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html#blockName()"><B>blockName()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1">RDDPartitionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockNotFoundException.html" title="class in org.apache.spark.storage"><B>BlockNotFoundException</B></A> - Exception in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/BlockNotFoundException.html#BlockNotFoundException(java.lang.String)"><B>BlockNotFoundException(String)</B></A> - 
Constructor for exception org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockNotFoundException.html" title="class in org.apache.spark.storage">BlockNotFoundException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#blocks()"><B>blocks()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#blocks()"><B>blocks()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the blocks stored in this block manager.
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage"><B>BlockStatus</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#BlockStatus(org.apache.spark.storage.StorageLevel, long, long, long)"><B>BlockStatus(StorageLevel, long, long, long)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#blockTransferService()"><B>blockTransferService()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html#bmAddress()"><B>bmAddress()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/BooleanParam.html" title="class in org.apache.spark.ml.param"><B>BooleanParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Boolean</CODE>] for Java.<DT><A HREF="./org/apache/spark/ml/param/BooleanParam.html#BooleanParam(java.lang.String, java.lang.String, java.lang.String)"><B>BooleanParam(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/BooleanParam.html" title="class in org.apache.spark.ml.param">BooleanParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/BooleanParam.html#BooleanParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>BooleanParam(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/BooleanParam.html" title="class in org.apache.spark.ml.param">BooleanParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/BooleanType.html" title="class in org.apache.spark.sql.types"><B>BooleanType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Boolean</code> values.<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#BooleanType"><B>BooleanType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the BooleanType object.
<DT><A HREF="./org/apache/spark/SparkContext.html#booleanWritableConverter()"><B>booleanWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#boolToBoolWritable(boolean)"><B>boolToBoolWritable(boolean)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration"><B>BoostingStrategy</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</A><DD>:: Experimental ::
 Configuration options for <A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree"><CODE>GradientBoostedTrees</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#BoostingStrategy(org.apache.spark.mllib.tree.configuration.Strategy, org.apache.spark.mllib.tree.loss.Loss, int, double, double)"><B>BoostingStrategy(Strategy, Loss, int, double, double)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#Both()"><B>Both()</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>Edges originating from *and* arriving at a vertex of interest.
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#boundaries()"><B>boundaries()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial"><B>BoundedDouble</B></A> - Class in <A HREF="./org/apache/spark/partial/package-summary.html">org.apache.spark.partial</A><DD>:: Experimental ::
 A Double value with error bars and associated confidence.<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#BoundedDouble(double, double, double, double)"><B>BoundedDouble(double, double, double, double)</B></A> - 
Constructor for class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#broadcast(T)"><B>broadcast(T)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Broadcast a read-only variable to the cluster, returning a
 <A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><CODE>Broadcast</CODE></A> object for reading it in distributed functions.
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><B>Broadcast</B></A>&lt;<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="type parameter in Broadcast">T</A>&gt; - Class in <A HREF="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</A><DD>A broadcast variable.<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#Broadcast(long, scala.reflect.ClassTag)"><B>Broadcast(long, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#broadcast(T, scala.reflect.ClassTag)"><B>broadcast(T, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Broadcast a read-only variable to the cluster, returning a
 <A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><CODE>Broadcast</CODE></A> object for reading it in distributed functions.
<DT><A HREF="./org/apache/spark/storage/BlockId.html#BROADCAST()"><B>BROADCAST()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage"><B>BroadcastBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/BroadcastBlockId.html#BroadcastBlockId(long, java.lang.String)"><B>BroadcastBlockId(long, String)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast"><B>BroadcastFactory</B></A> - Interface in <A HREF="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</A><DD>:: DeveloperApi ::
 An interface for all the broadcast implementations in Spark (to allow
 multiple broadcast implementations).<DT><A HREF="./org/apache/spark/CleanBroadcast.html#broadcastId()"><B>broadcastId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanBroadcast.html" title="class in org.apache.spark">CleanBroadcast</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BroadcastBlockId.html#broadcastId()"><B>broadcastId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#broadcastManager()"><B>broadcastManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka"><B>Broker</B></A> - Class in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>:: Experimental ::
 Represent the host and port info for a Kafka broker.<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#brokerAddress()"><B>brokerAddress()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature"><B>Bucketizer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 <code>Bucketizer</code> maps a column of continuous features to a column of feature buckets.<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#Bucketizer(java.lang.String)"><B>Bucketizer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#Bucketizer()"><B>Bucketizer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#build()"><B>build()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>Builds and returns all combinations of parameters specified by the param grid.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#build(org.apache.spark.mllib.tree.model.Node[])"><B>build(Node[])</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>build the left node and right nodes if not leaf
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#build()"><B>build()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Builds the <A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types"><CODE>Metadata</CODE></A> instance.
<DT><A HREF="./org/apache/spark/sql/sources/CatalystScan.html#buildScan(scala.collection.Seq, scala.collection.Seq)"><B>buildScan(Seq&lt;Attribute&gt;, Seq&lt;Expression&gt;)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/CatalystScan.html" title="interface in org.apache.spark.sql.sources">CatalystScan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(org.apache.hadoop.fs.FileStatus[])"><B>buildScan(FileStatus[])</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[], org.apache.hadoop.fs.FileStatus[])"><B>buildScan(String[], FileStatus[])</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[], org.apache.spark.sql.sources.Filter[], org.apache.hadoop.fs.FileStatus[])"><B>buildScan(String[], Filter[], FileStatus[])</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.
<DT><A HREF="./org/apache/spark/sql/sources/PrunedFilteredScan.html#buildScan(java.lang.String[], org.apache.spark.sql.sources.Filter[])"><B>buildScan(String[], Filter[])</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/PrunedFilteredScan.html" title="interface in org.apache.spark.sql.sources">PrunedFilteredScan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/PrunedScan.html#buildScan(java.lang.String[])"><B>buildScan(String[])</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/PrunedScan.html" title="interface in org.apache.spark.sql.sources">PrunedScan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/TableScan.html#buildScan()"><B>buildScan()</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/TableScan.html" title="interface in org.apache.spark.sql.sources">TableScan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#bytesOfCodePointInUTF8()"><B>bytesOfCodePointInUTF8()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/InputMetricDistributions.html#bytesRead()"><B>bytesRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/InputMetricDistributions.html" title="class in org.apache.spark.status.api.v1">InputMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/InputMetrics.html#bytesRead()"><B>bytesRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/InputMetrics.html" title="class in org.apache.spark.status.api.v1">InputMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#bytesToBytesWritable(byte[])"><B>bytesToBytesWritable(byte[])</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#bytesWritableConverter()"><B>bytesWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetricDistributions.html#bytesWritten()"><B>bytesWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/OutputMetricDistributions.html" title="class in org.apache.spark.status.api.v1">OutputMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetrics.html#bytesWritten()"><B>bytesWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/OutputMetrics.html" title="class in org.apache.spark.status.api.v1">OutputMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html#bytesWritten()"><B>bytesWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types"><B>ByteType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Byte</code> values.<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#ByteType"><B>ByteType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the ByteType object.
</DL>
<HR>
<A NAME="_C_"><!-- --></A><H2>
<B>C</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Persist this RDD with the default storage level (`MEMORY_ONLY`).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Persist this RDD with the default storage level (`MEMORY_ONLY`).
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Persist this RDD with the default storage level (`MEMORY_ONLY`).
<DT><A HREF="./org/apache/spark/graphx/Graph.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Caches the vertices and edges associated with this graph at the previously-specified target
 storage levels, which default to <code>MEMORY_ONLY</code>.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>Persists the edge partitions using `targetStorageLevel`, which defaults to MEMORY_ONLY.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>Persists the vertex partitions at `targetStorageLevel`, which defaults to MEMORY_ONLY.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Caches the underlying RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Persist this RDD with the default storage level (`MEMORY_ONLY`).
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#cache()"><B>cache()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/SparkEnv.html#cacheManager()"><B>cacheManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)"><B>cacheTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Caches the specified table in-memory.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticCostFun.html#calculate(breeze.linalg.DenseVector)"><B>calculate(DenseVector&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticCostFun.html" title="class in org.apache.spark.ml.classification">LogisticCostFun</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresCostFun.html#calculate(breeze.linalg.DenseVector)"><B>calculate(DenseVector&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresCostFun.html" title="class in org.apache.spark.ml.regression">LeastSquaresCostFun</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html#calculate(double[], double)"><B>calculate(double[], double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</A>
<DD>:: DeveloperApi ::
 information calculation for multiclass classification
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html#calculate(double, double, double)"><B>calculate(double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</A>
<DD>:: DeveloperApi ::
 variance calculation
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html#calculate(double[], double)"><B>calculate(double[], double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</A>
<DD>:: DeveloperApi ::
 information calculation for multiclass classification
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html#calculate(double, double, double)"><B>calculate(double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</A>
<DD>:: DeveloperApi ::
 variance calculation
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Impurity.html#calculate(double[], double)"><B>calculate(double[], double)</B></A> - 
Method in interface org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity">Impurity</A>
<DD>:: DeveloperApi ::
 information calculation for multiclass classification
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Impurity.html#calculate(double, double, double)"><B>calculate(double, double, double)</B></A> - 
Method in interface org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity">Impurity</A>
<DD>:: DeveloperApi ::
 information calculation for regression
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html#calculate(double[], double)"><B>calculate(double[], double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</A>
<DD>:: DeveloperApi ::
 information calculation for multiclass classification
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html#calculate(double, double, double)"><B>calculate(double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</A>
<DD>:: DeveloperApi ::
 variance calculation
<DT><A HREF="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/DoubleFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/FlatMapFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html#call(T1, T2)"><B>call(T1, T2)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction2</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/Function.html#call(T1)"><B>call(T1)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/Function0.html#call()"><B>call()</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function">Function0</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/Function2.html#call(T1, T2)"><B>call(T1, T2)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/Function3.html#call(T1, T2, T3)"><B>call(T1, T2, T3)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/Function3.html" title="interface in org.apache.spark.api.java.function">Function3</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/PairFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function">PairFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/VoidFunction.html#call(T)"><B>call(T)</B></A> - 
Method in interface org.apache.spark.api.java.function.<A HREF="./org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF1.html#call(T1)"><B>call(T1)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF1.html" title="interface in org.apache.spark.sql.api.java">UDF1</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF10.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="interface in org.apache.spark.sql.api.java">UDF10</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF11.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="interface in org.apache.spark.sql.api.java">UDF11</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF12.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="interface in org.apache.spark.sql.api.java">UDF12</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF13.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="interface in org.apache.spark.sql.api.java">UDF13</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF14.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="interface in org.apache.spark.sql.api.java">UDF14</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF15.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="interface in org.apache.spark.sql.api.java">UDF15</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF16.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="interface in org.apache.spark.sql.api.java">UDF16</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF17.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="interface in org.apache.spark.sql.api.java">UDF17</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF18.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="interface in org.apache.spark.sql.api.java">UDF18</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF19.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="interface in org.apache.spark.sql.api.java">UDF19</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF2.html#call(T1, T2)"><B>call(T1, T2)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF2.html" title="interface in org.apache.spark.sql.api.java">UDF2</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF20.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="interface in org.apache.spark.sql.api.java">UDF20</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF21.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="interface in org.apache.spark.sql.api.java">UDF21</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF22.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21, T22)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21, T22)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="interface in org.apache.spark.sql.api.java">UDF22</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF3.html#call(T1, T2, T3)"><B>call(T1, T2, T3)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="interface in org.apache.spark.sql.api.java">UDF3</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF4.html#call(T1, T2, T3, T4)"><B>call(T1, T2, T3, T4)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="interface in org.apache.spark.sql.api.java">UDF4</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF5.html#call(T1, T2, T3, T4, T5)"><B>call(T1, T2, T3, T4, T5)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="interface in org.apache.spark.sql.api.java">UDF5</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF6.html#call(T1, T2, T3, T4, T5, T6)"><B>call(T1, T2, T3, T4, T5, T6)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="interface in org.apache.spark.sql.api.java">UDF6</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF7.html#call(T1, T2, T3, T4, T5, T6, T7)"><B>call(T1, T2, T3, T4, T5, T6, T7)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="interface in org.apache.spark.sql.api.java">UDF7</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF8.html#call(T1, T2, T3, T4, T5, T6, T7, T8)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="interface in org.apache.spark.sql.api.java">UDF8</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/api/java/UDF9.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9)"><B>call(T1, T2, T3, T4, T5, T6, T7, T8, T9)</B></A> - 
Method in interface org.apache.spark.sql.api.java.<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="interface in org.apache.spark.sql.api.java">UDF9</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function0, org.apache.spark.sql.types.DataType)"><B>callUDF(Function0&lt;?&gt;, DataType)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 0 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function1, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column)"><B>callUDF(Function1&lt;?, ?&gt;, DataType, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 1 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function2, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function2&lt;?, ?, ?&gt;, DataType, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 2 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function3, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function3&lt;?, ?, ?, ?&gt;, DataType, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 3 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function4, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function4&lt;?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 4 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function5, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function5&lt;?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 5 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function6, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function6&lt;?, ?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 6 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function7, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function7&lt;?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 7 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function8, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function8&lt;?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 8 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function9, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function9&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 9 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUDF(scala.Function10, org.apache.spark.sql.types.DataType, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>callUDF(Function10&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType, Column, Column, Column, Column, Column, Column, Column, Column, Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call a Scala function of 10 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#callUdf(java.lang.String, scala.collection.Seq)"><B>callUdf(String, Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Call an user-defined function.
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#cancel()"><B>cancel()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#cancel()"><B>cancel()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Cancels the execution of this action.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#cancel()"><B>cancel()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#cancelAllJobs()"><B>cancelAllJobs()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Cancel all jobs that have been scheduled or are running.
<DT><A HREF="./org/apache/spark/SparkContext.html#cancelAllJobs()"><B>cancelAllJobs()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Cancel all jobs that have been scheduled or are running.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#cancelJobGroup(java.lang.String)"><B>cancelJobGroup(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Cancel active jobs for the specified group.
<DT><A HREF="./org/apache/spark/SparkContext.html#cancelJobGroup(java.lang.String)"><B>cancelJobGroup(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Cancel active jobs for the specified group.
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#canEqual(java.lang.Object)"><B>canEqual(Object)</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html#canEqual(java.lang.Object)"><B>canEqual(Object)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html#canHandle(java.lang.String)"><B>canHandle(String)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html" title="class in org.apache.spark.sql.jdbc">AggregatedDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html#canHandle(java.lang.String)"><B>canHandle(String)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc">JdbcDialect</A>
<DD>Check if this dialect instance can handle a certain jdbc url.
<DT><A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html#canHandle(java.lang.String)"><B>canHandle(String)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html" title="class in org.apache.spark.sql.jdbc">MySQLDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/NoopDialect.html#canHandle(java.lang.String)"><B>canHandle(String)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/NoopDialect.html" title="class in org.apache.spark.sql.jdbc">NoopDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html#canHandle(java.lang.String)"><B>canHandle(String)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html" title="class in org.apache.spark.sql.jdbc">PostgresDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#cartesian(org.apache.spark.api.java.JavaRDDLike)"><B>cartesian(JavaRDDLike&lt;U, ?&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>cartesian(RDD&lt;U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.
<DT><A HREF="./org/apache/spark/sql/Column.html#cast(org.apache.spark.sql.types.DataType)"><B>cast(DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Casts the column to a different data type.
<DT><A HREF="./org/apache/spark/sql/Column.html#cast(java.lang.String)"><B>cast(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Casts the column to a different data type, using the canonical string representation
 of the type.
<DT><A HREF="./org/apache/spark/sql/sources/CatalystScan.html" title="interface in org.apache.spark.sql.sources"><B>CatalystScan</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::Experimental::
 An interface for experimenting with a more direct connection to the query planner.<DT><A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html#Categorical()"><B>Categorical()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#categoricalFeaturesInfo()"><B>categoricalFeaturesInfo()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html" title="class in org.apache.spark.ml.tree"><B>CategoricalSplit</B></A> - Class in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Split which tests a categorical feature.<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#categories()"><B>categories()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#categoryMaps()"><B>categoryMaps()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#cbrt(org.apache.spark.sql.Column)"><B>cbrt(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cube-root of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#cbrt(java.lang.String)"><B>cbrt(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cube-root of the given column.
<DT><A HREF="./org/apache/spark/sql/functions.html#ceil(org.apache.spark.sql.Column)"><B>ceil(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the ceiling of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#ceil(java.lang.String)"><B>ceil(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the ceiling of the given column.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#changePrecision(int, int)"><B>changePrecision(int, int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Update precision and scale while keeping our value the same, and return true if successful.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Mark this RDD for checkpointing.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Mark this Graph for checkpointing.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#checkpoint()"><B>checkpoint()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Mark this RDD for checkpointing.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#checkpoint(org.apache.spark.streaming.Duration)"><B>checkpoint(Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Enable periodic checkpointing of RDDs of this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#checkpoint(java.lang.String)"><B>checkpoint(String)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Sets the context to periodically checkpoint the DStream operations for master
 fault-tolerance.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#checkpoint(org.apache.spark.streaming.Duration)"><B>checkpoint(Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Enable periodic checkpointing of RDDs of this DStream
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#checkpoint(java.lang.String)"><B>checkpoint(String)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Set the context to periodically checkpoint the DStream operations for driver
 fault-tolerance.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#checkpointData()"><B>checkpointData()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#checkpointData()"><B>checkpointData()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#checkpointDir()"><B>checkpointDir()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#checkpointDir()"><B>checkpointDir()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#checkpointDuration()"><B>checkpointDuration()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#checkpointDuration()"><B>checkpointDuration()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#checkpointInterval()"><B>checkpointInterval()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#checkpointInterval()"><B>checkpointInterval()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#checkSplits(double[])"><B>checkSplits(double[])</B></A> - 
Static method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>We require splits to be of length >= 3 and to be in strictly increasing order.
<DT><A HREF="./org/apache/spark/sql/sources/Not.html#child()"><B>child()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Not.html" title="class in org.apache.spark.sql.sources">Not</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html" title="class in org.apache.spark.mllib.feature"><B>ChiSqSelector</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Creates a ChiSquared feature selector.<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html#ChiSqSelector(int)"><B>ChiSqSelector(int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html" title="class in org.apache.spark.mllib.feature">ChiSqSelector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html" title="class in org.apache.spark.mllib.feature"><B>ChiSqSelectorModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Chi Squared selector model.<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html#ChiSqSelectorModel(int[])"><B>ChiSqSelectorModel(int[])</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html" title="class in org.apache.spark.mllib.feature">ChiSqSelectorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>chiSqTest(Vector, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Conduct Pearson's chi-squared goodness of fit test of the observed data against the
 expected distribution.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Vector)"><B>chiSqTest(Vector)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Conduct Pearson's chi-squared goodness of fit test of the observed data against the uniform
 distribution, with each category having an expected frequency of <code>1 / observed.size</code>.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Matrix)"><B>chiSqTest(Matrix)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Conduct Pearson's independence test on the input contingency matrix, which cannot contain
 negative entries or columns or rows that sum up to 0.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.rdd.RDD)"><B>chiSqTest(RDD&lt;LabeledPoint&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Conduct Pearson's independence test for every feature against the label across the input RDD.
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test"><B>ChiSqTestResult</B></A> - Class in <A HREF="./org/apache/spark/mllib/stat/test/package-summary.html">org.apache.spark.mllib.stat.test</A><DD>:: Experimental ::
 Object containing the test results for the chi-squared hypothesis test.<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html#Classification()"><B>Classification()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification"><B>ClassificationModel</B></A>&lt;<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="type parameter in ClassificationModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="type parameter in ClassificationModel">M</A> extends <A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>&lt;<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="type parameter in ClassificationModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="type parameter in ClassificationModel">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/ml/classification/ClassificationModel.html#ClassificationModel()"><B>ClassificationModel()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification"><B>ClassificationModel</B></A> - Interface in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>:: Experimental ::
 Represents a classification model that predicts to which of a set of categories an example
 belongs.<DT><A HREF="./org/apache/spark/ml/classification/Classifier.html" title="class in org.apache.spark.ml.classification"><B>Classifier</B></A>&lt;<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">FeaturesType</A>,<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">E</A> extends <A HREF="./org/apache/spark/ml/classification/Classifier.html" title="class in org.apache.spark.ml.classification">Classifier</A>&lt;<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">FeaturesType</A>,<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">E</A>,<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">M</A>&gt;,<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">M</A> extends <A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>&lt;<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">FeaturesType</A>,<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="type parameter in Classifier">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/ml/classification/Classifier.html#Classifier()"><B>Classifier()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="class in org.apache.spark.ml.classification">Classifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#className()"><B>className()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#classpathEntries()"><B>classpathEntries()</B></A> - 
Method in class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#classTag()"><B>classTag()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#classTag()"><B>classTag()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#classTag()"><B>classTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#clean(long, boolean)"><B>clean(long, boolean)</B></A> - 
Method in class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>Clean all the records that are older than the threshold time.
<DT><A HREF="./org/apache/spark/CleanAccum.html" title="class in org.apache.spark"><B>CleanAccum</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/CleanAccum.html#CleanAccum(long)"><B>CleanAccum(long)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanAccum.html" title="class in org.apache.spark">CleanAccum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanBroadcast.html" title="class in org.apache.spark"><B>CleanBroadcast</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/CleanBroadcast.html#CleanBroadcast(long)"><B>CleanBroadcast(long)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanBroadcast.html" title="class in org.apache.spark">CleanBroadcast</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanCheckpoint.html" title="class in org.apache.spark"><B>CleanCheckpoint</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/CleanCheckpoint.html#CleanCheckpoint(int)"><B>CleanCheckpoint(int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanCheckpoint.html" title="class in org.apache.spark">CleanCheckpoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanRDD.html" title="class in org.apache.spark"><B>CleanRDD</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/CleanRDD.html#CleanRDD(int)"><B>CleanRDD(int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanRDD.html" title="class in org.apache.spark">CleanRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanShuffle.html" title="class in org.apache.spark"><B>CleanShuffle</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/CleanShuffle.html#CleanShuffle(int)"><B>CleanShuffle(int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanShuffle.html" title="class in org.apache.spark">CleanShuffle</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanupTask.html" title="interface in org.apache.spark"><B>CleanupTask</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Classes that represent cleaning tasks.<DT><A HREF="./org/apache/spark/CleanupTaskWeakReference.html" title="class in org.apache.spark"><B>CleanupTaskWeakReference</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A WeakReference associated with a CleanupTask.<DT><A HREF="./org/apache/spark/CleanupTaskWeakReference.html#CleanupTaskWeakReference(org.apache.spark.CleanupTask, java.lang.Object, java.lang.ref.ReferenceQueue)"><B>CleanupTaskWeakReference(CleanupTask, Object, ReferenceQueue&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/CleanupTaskWeakReference.html" title="class in org.apache.spark">CleanupTaskWeakReference</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Params.html#clear(org.apache.spark.ml.param.Param)"><B>clear(Param&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Clears the user-supplied value for the input param.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#clearCache()"><B>clearCache()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Removes all cached tables from the in-memory cache.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#clearCallSite()"><B>clearCallSite()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Pass-through to SparkContext.setCallSite.
<DT><A HREF="./org/apache/spark/SparkContext.html#clearCallSite()"><B>clearCallSite()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Clear the thread-local property for overriding the call sites
 of actions and RDDs.
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#clearDependencies()"><B>clearDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#clearDependencies()"><B>clearDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#clearDependencies()"><B>clearDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#clearFiles()"><B>clearFiles()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Clear the job's list of files added by <code>addFile</code> so that they do not get downloaded to
 any new nodes.
<DT><A HREF="./org/apache/spark/SparkContext.html#clearFiles()"><B>clearFiles()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Clear the job's list of files added by <code>addFile</code> so that they do not get downloaded to
 any new nodes.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#clearJars()"><B>clearJars()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Clear the job's list of JARs added by <code>addJar</code> so that they do not get downloaded to
 any new nodes.
<DT><A HREF="./org/apache/spark/SparkContext.html#clearJars()"><B>clearJars()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Clear the job's list of JARs added by <code>addJar</code> so that they do not get downloaded to
 any new nodes.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#clearJobGroup()"><B>clearJobGroup()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Clear the current thread's job group ID and its description.
<DT><A HREF="./org/apache/spark/SparkContext.html#clearJobGroup()"><B>clearJobGroup()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Clear the current thread's job group ID and its description.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#clearThreshold()"><B>clearThreshold()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>:: Experimental ::
 Clears the threshold so that <code>predict</code> will output raw prediction scores.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#clearThreshold()"><B>clearThreshold()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>:: Experimental ::
 Clears the threshold so that <code>predict</code> will output raw prediction scores.
<DT><A HREF="./org/apache/spark/SparkConf.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Copy this object
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random">BernoulliCellSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliSampler.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/PoissonSampler.html#clone()"><B>clone()</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/RandomSampler.html#clone()"><B>clone()</B></A> - 
Method in interface org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random">RandomSampler</A>
<DD>return a copy of the RandomSampler object
<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html#cloneComplement()"><B>cloneComplement()</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random">BernoulliCellSampler</A>
<DD>Return a sampler that is the complement of the range specified of the current sampler.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/input/PortableDataStream.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.input.<A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input">PortableDataStream</A>
<DD>Close the file (if it is currently open)
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/OutputWriter.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources">OutputWriter</A>
<DD>Closes the <A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriter</CODE></A>.
<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#close()"><B>close()</B></A> - 
Method in class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>Close this log and release any resources.
<DT><A HREF="./org/apache/spark/SparkEnv.html#closureSerializer()"><B>closureSerializer()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MethodIdentifier.html#cls()"><B>cls()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MethodIdentifier.html" title="class in org.apache.spark.util">MethodIdentifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html#cluster()"><B>cluster()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering.Assignment</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#clusterCenters()"><B>clusterCenters()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html#clusterCenters()"><B>clusterCenters()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html#clusterWeights()"><B>clusterWeights()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#cn()"><B>cn()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#coalesce(int)"><B>coalesce(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#coalesce(int, boolean)"><B>coalesce(int, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#coalesce(int)"><B>coalesce(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#coalesce(int, boolean)"><B>coalesce(int, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#coalesce(int)"><B>coalesce(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#coalesce(int, boolean)"><B>coalesce(int, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#coalesce(int, boolean, scala.math.Ordering)"><B>coalesce(int, boolean, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD that is reduced into <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#coalesce(int)"><B>coalesce(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that has exactly <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/sql/functions.html#coalesce(org.apache.spark.sql.Column...)"><B>coalesce(Column...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the first column that is not null.
<DT><A HREF="./org/apache/spark/sql/functions.html#coalesce(scala.collection.Seq)"><B>coalesce(Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the first column that is not null.
<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#code()"><B>code()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#codeLen()"><B>codeLen()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>cogroup(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD)"><B>cogroup(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, int)"><B>cogroup(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, int)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, int)"><B>cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD)"><B>cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, int)"><B>cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)"><B>cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>cogroup(JavaPairDStream&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream, int)"><B>cogroup(JavaPairDStream&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)"><B>cogroup(JavaPairDStream&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><B>cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd"><B>CoGroupedRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="type parameter in CoGroupedRDD">K</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>:: DeveloperApi ::
 A RDD that cogroups its parents.<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#CoGroupedRDD(scala.collection.Seq, org.apache.spark.Partitioner)"><B>CoGroupedRDD(Seq&lt;RDD&lt;? extends Product2&lt;K, ?&gt;&gt;&gt;, Partitioner)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#col(java.lang.String)"><B>col(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects column based on the column name and return it as a <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/functions.html#col(java.lang.String)"><B>col(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns a <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#collect()"><B>collect()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an array that contains all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#collect()"><B>collect()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#collect()"><B>collect()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an array that contains all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction, scala.reflect.ClassTag)"><B>collect(PartialFunction&lt;T, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD that contains all matching values by applying <code>f</code>.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#collect()"><B>collect()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns an array that contains all of <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A>s in this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#collectAsList()"><B>collectAsList()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a Java list that contains all of <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A>s in this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#collectAsMap()"><B>collectAsMap()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return the key-value pairs in this RDD to the master as a Map.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#collectAsMap()"><B>collectAsMap()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return the key-value pairs in this RDD to the master as a Map.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#collectAsync()"><B>collectAsync()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The asynchronous version of <code>collect</code>, which returns a future for
 retrieving an array containing all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#collectAsync()"><B>collectAsync()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>Returns a future for retrieving all elements of this RDD.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#collectEdges(org.apache.spark.graphx.EdgeDirection)"><B>collectEdges(EdgeDirection)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Returns an RDD that contains for each vertex v its local edges,
 i.e., the edges that are incident on v, in the user-specified direction.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#collectNeighborIds(org.apache.spark.graphx.EdgeDirection)"><B>collectNeighborIds(EdgeDirection)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Collect the neighbor vertex ids for each vertex.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#collectNeighbors(org.apache.spark.graphx.EdgeDirection)"><B>collectNeighbors(EdgeDirection)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Collect the neighbor vertex attributes for each vertex.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#collectPartitions(int[])"><B>collectPartitions(int[])</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an array that contains all of the elements in a specific partition of this RDD.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#colPtrs()"><B>colPtrs()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#colsPerBlock()"><B>colsPerBlock()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#colStats(org.apache.spark.rdd.RDD)"><B>colStats(RDD&lt;Vector&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Computes column-wise summary statistics for the input RDD[Vector].
<DT><A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><B>Column</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 A column in a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.<DT><A HREF="./org/apache/spark/sql/Column.html#Column(org.apache.spark.sql.catalyst.expressions.Expression)"><B>Column(Expression)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#Column(java.lang.String)"><B>Column(String)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#column(java.lang.String)"><B>column(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns a <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> based on the given column name.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql"><B>ColumnName</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 A convenient class used for constructing schema.<DT><A HREF="./org/apache/spark/sql/ColumnName.html#ColumnName(java.lang.String)"><B>ColumnName(String)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#columns()"><B>columns()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns all column names as an array.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#columnSimilarities()"><B>columnSimilarities()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Compute all cosine similarities between columns of this matrix using the brute-force
 approach of computing normalized dot products.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#columnSimilarities(double)"><B>columnSimilarities(double)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Compute similarities between columns of this matrix using a sampling approach.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner, boolean, org.apache.spark.serializer.Serializer)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean, Serializer)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Generic function to combine the elements for each key using a custom set of aggregation
 functions.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Generic function to combine the elements for each key using a custom set of aggregation
 functions.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Simplified version of combineByKey that hash-partitions the output RDD and uses map-side
 aggregation.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Simplified version of combineByKey that hash-partitions the resulting RDD using the existing
 partitioner/parallelism level and using map-side aggregation.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, org.apache.spark.serializer.Serializer)"><B>combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean, Serializer)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Generic function to combine the elements for each key using a custom set of aggregation
 functions.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, int)"><B>combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Simplified version of combineByKey that hash-partitions the output RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2)"><B>combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Combine elements of each key in DStream's RDDs using custom function.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner, boolean)"><B>combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Combine elements of each key in DStream's RDDs using custom function.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)"><B>combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean, ClassTag&lt;C&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Combine elements of each key in DStream's RDDs using custom functions.
<DT><A HREF="./org/apache/spark/Aggregator.html#combineCombinersByKey(scala.collection.Iterator)"><B>combineCombinersByKey(Iterator&lt;Product2&lt;K, C&gt;&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html#combineCombinersByKey(scala.collection.Iterator, org.apache.spark.TaskContext)"><B>combineCombinersByKey(Iterator&lt;Product2&lt;K, C&gt;&gt;, TaskContext)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html#combineValuesByKey(scala.collection.Iterator)"><B>combineValuesByKey(Iterator&lt;Product2&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html#combineValuesByKey(scala.collection.Iterator, org.apache.spark.TaskContext)"><B>combineValuesByKey(Iterator&lt;Product2&lt;K, V&gt;&gt;, TaskContext)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#compare(org.apache.spark.rdd.PartitionGroup, org.apache.spark.rdd.PartitionGroup)"><B>compare(PartitionGroup, PartitionGroup)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#compare(scala.Option, scala.Option)"><B>compare(Option&lt;PartitionGroup&gt;, Option&lt;PartitionGroup&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#compare(org.apache.spark.sql.types.Decimal)"><B>compare(Decimal)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#compare(org.apache.spark.sql.types.UTF8String)"><B>compare(UTF8String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#compare(org.apache.spark.storage.RDDInfo)"><B>compare(RDDInfo)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#compareTo(org.apache.spark.sql.types.UTF8String)"><B>compareTo(UTF8String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/SparkShutdownHook.html#compareTo(org.apache.spark.util.SparkShutdownHook)"><B>compareTo(SparkShutdownHook)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/SparkShutdownHook.html" title="class in org.apache.spark.util">SparkShutdownHook</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html#completed()"><B>completed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationAttemptInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#completedJobs()"><B>completedJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#completedStages()"><B>completedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#completedTasks()"><B>completedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#completionTime()"><B>completionTime()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>Time when all tasks in the stage completed or when the stage was cancelled.
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#completionTime()"><B>completionTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark"><B>ComplexFutureAction</B></A>&lt;<A HREF="./org/apache/spark/ComplexFutureAction.html" title="type parameter in ComplexFutureAction">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A <A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><CODE>FutureAction</CODE></A> for actions that could trigger multiple Spark jobs.<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#ComplexFutureAction()"><B>ComplexFutureAction()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#compressed()"><B>compressed()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Returns a vector in either dense or sparse format, whichever uses less storage.
<DT><A HREF="./org/apache/spark/io/CompressionCodec.html#compressedInputStream(java.io.InputStream)"><B>compressedInputStream(InputStream)</B></A> - 
Method in interface org.apache.spark.io.<A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/LZ4CompressionCodec.html#compressedInputStream(java.io.InputStream)"><B>compressedInputStream(InputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/LZFCompressionCodec.html#compressedInputStream(java.io.InputStream)"><B>compressedInputStream(InputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyCompressionCodec.html#compressedInputStream(java.io.InputStream)"><B>compressedInputStream(InputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/CompressionCodec.html#compressedOutputStream(java.io.OutputStream)"><B>compressedOutputStream(OutputStream)</B></A> - 
Method in interface org.apache.spark.io.<A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/LZ4CompressionCodec.html#compressedOutputStream(java.io.OutputStream)"><B>compressedOutputStream(OutputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/LZFCompressionCodec.html#compressedOutputStream(java.io.OutputStream)"><B>compressedOutputStream(OutputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyCompressionCodec.html#compressedOutputStream(java.io.OutputStream)"><B>compressedOutputStream(OutputStream)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><B>CompressionCodec</B></A> - Interface in <A HREF="./org/apache/spark/io/package-summary.html">org.apache.spark.io</A><DD>:: DeveloperApi ::
 CompressionCodec allows the customization of choosing different compression implementations
 to be used in block storage.<DT><A HREF="./org/apache/spark/api/r/BaseRRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="class in org.apache.spark.api.r">BaseRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Provides the <code>RDD[(VertexId, VD)]</code> equivalent output.
<DT><A HREF="./org/apache/spark/mllib/optimization/Gradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</A>
<DD>Compute the gradient and loss given the features of a single data point.
<DT><A HREF="./org/apache/spark/mllib/optimization/Gradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</A>
<DD>Compute the gradient and loss given the features of a single data point,
 add the gradient to a provided vector to avoid creating new objects, and return loss.
<DT><A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/L1Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)"><B>compute(Vector, Vector, double, int, double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization">L1Updater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>compute(Vector, double, Vector, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/SimpleUpdater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)"><B>compute(Vector, Vector, double, int, double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization">SimpleUpdater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/SquaredL2Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)"><B>compute(Vector, Vector, double, int, double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization">SquaredL2Updater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)"><B>compute(Vector, Vector, double, int, double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization">Updater</A>
<DD>Compute an updated value for weights given the gradient, stepSize, iteration number and
 regularization parameter.
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>compute(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#compute(org.apache.spark.streaming.Time)"><B>compute(Time)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Generate an RDD for the given duration
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#compute(org.apache.spark.streaming.Time)"><B>compute(Time)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Method that generates a RDD for the given Duration
<DT><A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#compute(org.apache.spark.streaming.Time)"><B>compute(Time)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#compute(org.apache.spark.streaming.Time)"><B>compute(Time)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Method that generates a RDD for the given time
<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#compute(org.apache.spark.streaming.Time)"><B>compute(Time)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeColumnSummaryStatistics()"><B>computeColumnSummaryStatistics()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Computes column-wise summary statistics.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#computeCost(org.apache.spark.rdd.RDD)"><B>computeCost(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>Return the K-means cost (sum of squared distances of points to their nearest center) for this
 model on the given data.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeCovariance()"><B>computeCovariance()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Computes the covariance matrix, treating each row as an observation.
<DT><A HREF="./org/apache/spark/mllib/tree/loss/Loss.html#computeError(org.apache.spark.mllib.tree.model.TreeEnsembleModel, org.apache.spark.rdd.RDD)"><B>computeError(org.apache.spark.mllib.tree.model.TreeEnsembleModel, RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/Loss.html" title="interface in org.apache.spark.mllib.tree.loss">Loss</A>
<DD>Method to calculate error of the base learner for the gradient boosting calculation.
<DT><A HREF="./org/apache/spark/mllib/tree/loss/Loss.html#computeError(double, double)"><B>computeError(double, double)</B></A> - 
Method in interface org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/Loss.html" title="interface in org.apache.spark.mllib.tree.loss">Loss</A>
<DD>Method to calculate loss when the predictions are already known.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#computeGramianMatrix()"><B>computeGramianMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeGramianMatrix()"><B>computeGramianMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Computes the Gramian matrix <code>A^T A</code>.
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#computeInitialPredictionAndError(org.apache.spark.rdd.RDD, double, org.apache.spark.mllib.tree.model.DecisionTreeModel, org.apache.spark.mllib.tree.loss.Loss)"><B>computeInitialPredictionAndError(RDD&lt;LabeledPoint&gt;, double, DecisionTreeModel, Loss)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>Compute the initial predictions and errors for a dataset for the first
 iteration of gradient boosting.
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#computePreferredLocations(scala.collection.Seq)"><B>computePreferredLocations(Seq&lt;InputFormatInfo&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>Computes the preferred locations based on input(s) and returned a location to block map.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computePrincipalComponents(int)"><B>computePrincipalComponents(int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Computes the top k principal components.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#computeSVD(int, boolean, double)"><B>computeSVD(int, boolean, double)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeSVD(int, boolean, double)"><B>computeSVD(int, boolean, double)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Computes singular value decomposition of this matrix.
<DT><A HREF="./org/apache/spark/SparkEnv.html#conf()"><B>conf()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#conf()"><B>conf()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#confidence()"><B>confidence()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#configuration()"><B>configuration()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#CONFIGURATION_INSTANTIATION_LOCK()"><B>CONFIGURATION_INSTANTIATION_LOCK()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#confusionMatrix()"><B>confusionMatrix()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns confusion matrix:
 predicted classes are in columns,
 they are ordered by class label ascending,
 as in "labels"
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#connectedComponents()"><B>connectedComponents()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Compute the connected component membership of each vertex and return a graph with the vertex
 value containing the lowest vertex id in the connected component containing that vertex.
<DT><A HREF="./org/apache/spark/graphx/lib/ConnectedComponents.html" title="class in org.apache.spark.graphx.lib"><B>ConnectedComponents</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Connected components algorithm.<DT><A HREF="./org/apache/spark/graphx/lib/ConnectedComponents.html#ConnectedComponents()"><B>ConnectedComponents()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/ConnectedComponents.html" title="class in org.apache.spark.graphx.lib">ConnectedComponents</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>ConstantInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="type parameter in ConstantInputDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</A><DD>An input stream that always returns the same RDD on each timestep.<DT><A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#ConstantInputDStream(org.apache.spark.streaming.StreamingContext, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>ConstantInputDStream(StreamingContext, RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#contains(org.apache.spark.ml.param.Param)"><B>contains(Param&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Checks whether a parameter is explicitly specified.
<DT><A HREF="./org/apache/spark/SparkConf.html#contains(java.lang.String)"><B>contains(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Does the configuration contain a given parameter?
<DT><A HREF="./org/apache/spark/sql/Column.html#contains(java.lang.Object)"><B>contains(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Contains the other element.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#contains(java.lang.String)"><B>contains(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Tests whether this Metadata contains a binding for a key.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#contains(org.apache.spark.sql.types.UTF8String)"><B>contains(UTF8String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#containsBlock(org.apache.spark.storage.BlockId)"><B>containsBlock(BlockId)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return whether the given block is stored in this block manager in O(1) time.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#containsCachedMetadata(java.lang.String)"><B>containsCachedMetadata(String)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#containsNull()"><B>containsNull()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#context()"><B>context()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The <A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><CODE>SparkContext</CODE></A> that this RDD was created on.
<DT><A HREF="./org/apache/spark/InterruptibleIterator.html#context()"><B>context()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#context()"><B>context()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>The <A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><CODE>SparkContext</CODE></A> that this RDD was created on.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#context()"><B>context()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return the <A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><CODE>StreamingContext</CODE></A> associated with this DStream
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#context()"><B>context()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return the StreamingContext associated with this DStream
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html#Continuous()"><B>Continuous()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html" title="class in org.apache.spark.ml.tree"><B>ContinuousSplit</B></A> - Class in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Split which tests a continuous feature.<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#convertToCanonicalEdges(scala.Function2)"><B>convertToCanonicalEdges(Function2&lt;ED, ED, ED&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Convert bi-directional edges into uni-directional ones.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>CoordinateMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#CoordinateMatrix(org.apache.spark.rdd.RDD, long, long)"><B>CoordinateMatrix(RDD&lt;MatrixEntry&gt;, long, long)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#CoordinateMatrix(org.apache.spark.rdd.RDD)"><B>CoordinateMatrix(RDD&lt;MatrixEntry&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification">OneVsRestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Estimator.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/Evaluator.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/Evaluator.html" title="class in org.apache.spark.ml.evaluation">Evaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Tokenizer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Tokenizer.html" title="class in org.apache.spark.ml.feature">Tokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Model.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Creates a copy of this param map.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Creates a copy of this instance with the same UID and some extra params.
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineStage.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineStage.html" title="class in org.apache.spark.ml">PipelineStage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Predictor.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html" title="class in org.apache.spark.ml.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Transformer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#copy(org.apache.spark.ml.param.ParamMap)"><B>copy(ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#copy()"><B>copy()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Get a deep copy of the matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#copy()"><B>copy()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Makes a deep copy of this vector.
<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random">ExponentialGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html#copy()"><B>copy()</B></A> - 
Method in interface org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random">RandomDataGenerator</A>
<DD>Returns a copy of the RandomDataGenerator with a new instance of the rng object used in the
 class when applicable for non-locking concurrent usage.
<DT><A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/UniformGenerator.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Returns a shallow copy of this instance.
<DT><A HREF="./org/apache/spark/sql/Row.html#copy()"><B>copy()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Make a copy of the current <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A> object.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#copy()"><B>copy()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Clone this StatCounter
<DT><A HREF="./org/apache/spark/ml/param/Params.html#copyValues(T, org.apache.spark.ml.param.ParamMap)"><B>copyValues(T, ParamMap)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Copies param values from this instance to another instance for params shared by them.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD)"><B>corr(RDD&lt;Vector&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Compute the Pearson correlation matrix for the input RDD of Vectors.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, java.lang.String)"><B>corr(RDD&lt;Vector&gt;, String)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Compute the correlation matrix for the input RDD of Vectors using the specified method.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>corr(RDD&lt;Object&gt;, RDD&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Compute the Pearson correlation for the input RDDs.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.api.java.JavaRDD, org.apache.spark.api.java.JavaRDD)"><B>corr(JavaRDD&lt;Double&gt;, JavaRDD&lt;Double&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Java-friendly version of <CODE>corr()</CODE>
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, java.lang.String)"><B>corr(RDD&lt;Object&gt;, RDD&lt;Object&gt;, String)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Compute the correlation for the input RDDs using the specified method.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.api.java.JavaRDD, org.apache.spark.api.java.JavaRDD, java.lang.String)"><B>corr(JavaRDD&lt;Double&gt;, JavaRDD&lt;Double&gt;, String)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>Java-friendly version of <CODE>corr()</CODE>
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#corr(java.lang.String, java.lang.String, java.lang.String)"><B>corr(String, String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Calculates the correlation of two columns of a DataFrame.
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#corr(java.lang.String, java.lang.String)"><B>corr(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.
<DT><A HREF="./org/apache/spark/sql/functions.html#cos(org.apache.spark.sql.Column)"><B>cos(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cosine of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#cos(java.lang.String)"><B>cos(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the cosine of the given column.
<DT><A HREF="./org/apache/spark/sql/functions.html#cosh(org.apache.spark.sql.Column)"><B>cosh(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic cosine of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#cosh(java.lang.String)"><B>cosh(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic cosine of the given column.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#count()"><B>count()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return the number of elements in the RDD.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>The number of edges in the RDD.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>The number of vertices in the RDD.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#count()"><B>count()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Sample size.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the number of elements in the RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the number of rows in the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/functions.html#count(org.apache.spark.sql.Column)"><B>count(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#count(java.lang.String)"><B>count(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of items in a group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Count the number of rows for each group.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#count()"><B>count()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD has a single element generated by counting each RDD
 of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD has a single element generated by counting each RDD
 of this DStream.
<DT><A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="class in org.apache.spark.streaming.receiver">CountingIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#count()"><B>count()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countApprox(long, double)"><B>countApprox(long, double)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countApprox(long)"><B>countApprox(long)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#countApprox(long, double)"><B>countApprox(long, double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countApproxDistinct(double)"><B>countApproxDistinct(double)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return approximate number of distinct elements in the RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#countApproxDistinct(int, int)"><B>countApproxDistinct(int, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>:: Experimental ::
 Return approximate number of distinct elements in the RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#countApproxDistinct(double)"><B>countApproxDistinct(double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return approximate number of distinct elements in the RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double, org.apache.spark.Partitioner)"><B>countApproxDistinctByKey(double, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double, int)"><B>countApproxDistinctByKey(double, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double)"><B>countApproxDistinctByKey(double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(int, int, org.apache.spark.Partitioner)"><B>countApproxDistinctByKey(int, int, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, org.apache.spark.Partitioner)"><B>countApproxDistinctByKey(double, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, int)"><B>countApproxDistinctByKey(double, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double)"><B>countApproxDistinctByKey(double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return approximate number of distinct values for each key in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countAsync()"><B>countAsync()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The asynchronous version of <code>count</code>, which returns a
 future for counting the number of elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#countAsync()"><B>countAsync()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>Returns a future for counting the number of elements in the RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countByKey()"><B>countByKey()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Count the number of elements for each key, and return the result to the master as a Map.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countByKey()"><B>countByKey()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Count the number of elements for each key, collecting the results to a local Map.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countByKeyApprox(long)"><B>countByKeyApprox(long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#countByKeyApprox(long, double)"><B>countByKeyApprox(long, double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#countByKeyApprox(long, double)"><B>countByKeyApprox(long, double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countByValue()"><B>countByValue()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return the count of each unique value in this RDD as a map of (value, count) pairs.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)"><B>countByValue(Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the count of each unique value in this RDD as a local map of (value, count) pairs.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValue()"><B>countByValue()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValue(int)"><B>countByValue(int)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#countByValue(int, scala.math.Ordering)"><B>countByValue(int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>countByValueAndWindow(Duration, Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><B>countByValueAndWindow(Duration, Duration, int)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.math.Ordering)"><B>countByValueAndWindow(Duration, Duration, int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long, double)"><B>countByValueApprox(long, double)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>(Experimental) Approximate version of countByValue().
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long)"><B>countByValueApprox(long)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>(Experimental) Approximate version of countByValue().
<DT><A HREF="./org/apache/spark/rdd/RDD.html#countByValueApprox(long, double, scala.math.Ordering)"><B>countByValueApprox(long, double, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>:: Experimental ::
 Approximate version of countByValue().
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>countByWindow(Duration, Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD has a single element generated by counting the number
 of elements in a window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#countByWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>countByWindow(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD has a single element generated by counting the number
 of elements in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/sql/functions.html#countDistinct(org.apache.spark.sql.Column, org.apache.spark.sql.Column...)"><B>countDistinct(Column, Column...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#countDistinct(java.lang.String, java.lang.String...)"><B>countDistinct(String, String...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#countDistinct(org.apache.spark.sql.Column, scala.collection.Seq)"><B>countDistinct(Column, Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of distinct items in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#countDistinct(java.lang.String, scala.collection.Seq)"><B>countDistinct(String, Seq&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the number of distinct items in a group.
<DT><A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="class in org.apache.spark.streaming.receiver"><B>CountingIterator</B></A>&lt;<A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="type parameter in CountingIterator">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</A><DD>A utility that will wrap the Iterator to get the count<DT><A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html#CountingIterator(scala.collection.Iterator)"><B>CountingIterator(Iterator&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="class in org.apache.spark.streaming.receiver">CountingIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#cov(java.lang.String, java.lang.String)"><B>cov(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Calculate the sample covariance of two numerical columns of a DataFrame.
<DT><A HREF="./org/apache/spark/sql/sources/CreatableRelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>CreatableRelationProvider</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#create(boolean, boolean, boolean, int)"><B>create(boolean, boolean, boolean, int)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD><B>Deprecated.</B>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#create(boolean, boolean, boolean, boolean, int)"><B>create(boolean, boolean, boolean, boolean, int)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>Create a new StorageLevel object.
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#create(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.rdd.JdbcRDD.ConnectionFactory, java.lang.String, long, long, int, org.apache.spark.api.java.function.Function)"><B>create(JavaSparkContext, JdbcRDD.ConnectionFactory, String, long, long, int, Function&lt;ResultSet, T&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>Create an RDD that executes an SQL query on a JDBC connection and reads results.
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#create(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.rdd.JdbcRDD.ConnectionFactory, java.lang.String, long, long, int)"><B>create(JavaSparkContext, JdbcRDD.ConnectionFactory, String, long, long, int)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>Create an RDD that executes an SQL query on a JDBC connection and reads results.
<DT><A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html#create(org.apache.spark.rdd.RDD, scala.Function1)"><B>create(RDD&lt;T&gt;, Function1&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</A>
<DD>Create a PartitionPruningRDD.
<DT><A HREF="./org/apache/spark/sql/RowFactory.html#create(java.lang.Object...)"><B>create(Object...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/RowFactory.html" title="class in org.apache.spark.sql">RowFactory</A>
<DD>Create a <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A> from the given arguments.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html#create()"><B>create()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#create(java.lang.String, int)"><B>create(String, int)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#create(java.lang.String, int, long, long)"><B>create(String, int, long, long)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#create(kafka.common.TopicAndPartition, long, long)"><B>create(TopicAndPartition, long, long)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createArrayType(org.apache.spark.sql.types.DataType)"><B>createArrayType(DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates an ArrayType by specifying the data type of elements (<code>elementType</code>).
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createArrayType(org.apache.spark.sql.types.DataType, boolean)"><B>createArrayType(DataType, boolean)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates an ArrayType by specifying the data type of elements (<code>elementType</code>) and
 whether the array contains null values (<code>containsNull</code>).
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createBroker(java.lang.String, java.lang.Integer)"><B>createBroker(String, Integer)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html#createCombiner()"><B>createCombiner()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)"><B>createDataFrame(RDD&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(scala.collection.Seq, scala.reflect.api.TypeTags.TypeTag)"><B>createDataFrame(Seq&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)"><B>createDataFrame(RDD&lt;Row&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)"><B>createDataFrame(JavaRDD&lt;Row&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD, java.lang.Class)"><B>createDataFrame(RDD&lt;?&gt;, Class&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD, java.lang.Class)"><B>createDataFrame(JavaRDD&lt;?&gt;, Class&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createDecimalType(int, int)"><B>createDecimalType(int, int)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createDecimalType()"><B>createDecimalType()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createDirectStream(org.apache.spark.streaming.StreamingContext, scala.collection.immutable.Map, scala.collection.immutable.Map, scala.Function1, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>createDirectStream(StreamingContext, Map&lt;String, String&gt;, Map&lt;TopicAndPartition, Object&gt;, Function1&lt;MessageAndMetadata&lt;K, V&gt;, R&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;KD&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;R&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create an input stream that directly pulls messages from Kafka Brokers
 without using any receiver.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createDirectStream(org.apache.spark.streaming.StreamingContext, scala.collection.immutable.Map, scala.collection.immutable.Set, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>createDirectStream(StreamingContext, Map&lt;String, String&gt;, Set&lt;String&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;KD&gt;, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create an input stream that directly pulls messages from Kafka Brokers
 without using any receiver.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createDirectStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, java.util.Map, org.apache.spark.api.java.function.Function)"><B>createDirectStream(JavaStreamingContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;KD&gt;, Class&lt;VD&gt;, Class&lt;R&gt;, Map&lt;String, String&gt;, Map&lt;TopicAndPartition, Long&gt;, Function&lt;MessageAndMetadata&lt;K, V&gt;, R&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create an input stream that directly pulls messages from Kafka Brokers
 without using any receiver.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createDirectStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, java.util.Set)"><B>createDirectStream(JavaStreamingContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;KD&gt;, Class&lt;VD&gt;, Map&lt;String, String&gt;, Set&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create an input stream that directly pulls messages from Kafka Brokers
 without using any receiver.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createDirectStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.util.Map, java.util.Set, java.util.Map)"><B>createDirectStream(JavaStreamingContext, Map&lt;String, String&gt;, Set&lt;String&gt;, Map&lt;TopicAndPartition, Long&gt;)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String)"><B>createExternalTable(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String, java.lang.String)"><B>createExternalTable(String, String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String, java.util.Map)"><B>createExternalTable(String, String, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String, scala.collection.immutable.Map)"><B>createExternalTable(String, String, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)"><B>createExternalTable(String, String, StructType, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)"><B>createExternalTable(String, String, StructType, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#createJDBCTable(java.lang.String, java.lang.String, boolean)"><B>createJDBCTable(String, String, boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.340, replaced by <code>write().jdbc()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createMapType(org.apache.spark.sql.types.DataType, org.apache.spark.sql.types.DataType)"><B>createMapType(DataType, DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a MapType by specifying the data type of keys (<code>keyType</code>) and values
 (<code>keyType</code>).
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createMapType(org.apache.spark.sql.types.DataType, org.apache.spark.sql.types.DataType, boolean)"><B>createMapType(DataType, DataType, boolean)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a MapType by specifying the data type of keys (<code>keyType</code>), the data type of
 values (<code>keyType</code>), and whether values contain any null value
 (<code>valueContainsNull</code>).
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createOffsetRange(java.lang.String, java.lang.Integer, java.lang.Long, java.lang.Long)"><B>createOffsetRange(String, Integer, Long, Long)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>createPollingStream(StreamingContext, String, int, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, scala.collection.Seq, org.apache.spark.storage.StorageLevel)"><B>createPollingStream(StreamingContext, Seq&lt;InetSocketAddress&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, scala.collection.Seq, org.apache.spark.storage.StorageLevel, int, int)"><B>createPollingStream(StreamingContext, Seq&lt;InetSocketAddress&gt;, StorageLevel, int, int)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int)"><B>createPollingStream(JavaStreamingContext, String, int)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>createPollingStream(JavaStreamingContext, String, int, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.net.InetSocketAddress[], org.apache.spark.storage.StorageLevel)"><B>createPollingStream(JavaStreamingContext, InetSocketAddress[], StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.net.InetSocketAddress[], org.apache.spark.storage.StorageLevel, int, int)"><B>createPollingStream(JavaStreamingContext, InetSocketAddress[], StorageLevel, int, int)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createRDD(org.apache.spark.SparkContext, scala.collection.immutable.Map, org.apache.spark.streaming.kafka.OffsetRange[], scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>createRDD(SparkContext, Map&lt;String, String&gt;, OffsetRange[], ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;KD&gt;, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create a RDD from Kafka using offset ranges for each topic and partition.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createRDD(org.apache.spark.SparkContext, scala.collection.immutable.Map, org.apache.spark.streaming.kafka.OffsetRange[], scala.collection.immutable.Map, scala.Function1, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>createRDD(SparkContext, Map&lt;String, String&gt;, OffsetRange[], Map&lt;TopicAndPartition, Broker&gt;, Function1&lt;MessageAndMetadata&lt;K, V&gt;, R&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;KD&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;R&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create a RDD from Kafka using offset ranges for each topic and partition.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createRDD(org.apache.spark.api.java.JavaSparkContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, org.apache.spark.streaming.kafka.OffsetRange[])"><B>createRDD(JavaSparkContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;KD&gt;, Class&lt;VD&gt;, Map&lt;String, String&gt;, OffsetRange[])</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create a RDD from Kafka using offset ranges for each topic and partition.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createRDD(org.apache.spark.api.java.JavaSparkContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, org.apache.spark.streaming.kafka.OffsetRange[], java.util.Map, org.apache.spark.api.java.function.Function)"><B>createRDD(JavaSparkContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;KD&gt;, Class&lt;VD&gt;, Class&lt;R&gt;, Map&lt;String, String&gt;, OffsetRange[], Map&lt;TopicAndPartition, Broker&gt;, Function&lt;MessageAndMetadata&lt;K, V&gt;, R&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>:: Experimental ::
 Create a RDD from Kafka using offset ranges for each topic and partition.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createRDD(org.apache.spark.api.java.JavaSparkContext, java.util.Map, java.util.List, java.util.Map)"><B>createRDD(JavaSparkContext, Map&lt;String, String&gt;, List&lt;OffsetRange&gt;, Map&lt;TopicAndPartition, Broker&gt;)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/RRDD.html#createRDDFromArray(org.apache.spark.api.java.JavaSparkContext, byte[][])"><B>createRDDFromArray(JavaSparkContext, byte[][])</B></A> - 
Static method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r">RRDD</A>
<DD>Create an RRDD given a sequence of byte arrays.
<DT><A HREF="./org/apache/spark/sql/sources/CreatableRelationProvider.html#createRelation(org.apache.spark.sql.SQLContext, org.apache.spark.sql.SaveMode, scala.collection.immutable.Map, org.apache.spark.sql.DataFrame)"><B>createRelation(SQLContext, SaveMode, Map&lt;String, String&gt;, DataFrame)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/CreatableRelationProvider.html" title="interface in org.apache.spark.sql.sources">CreatableRelationProvider</A>
<DD>Creates a relation with the given parameters based on the contents of the given
 DataFrame.
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelationProvider.html#createRelation(org.apache.spark.sql.SQLContext, java.lang.String[], scala.Option, scala.Option, scala.collection.immutable.Map)"><B>createRelation(SQLContext, String[], Option&lt;StructType&gt;, Option&lt;StructType&gt;, Map&lt;String, String&gt;)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelationProvider.html" title="interface in org.apache.spark.sql.sources">HadoopFsRelationProvider</A>
<DD>Returns a new base relation with the given parameters, a user defined schema, and a list of
 partition columns.
<DT><A HREF="./org/apache/spark/sql/sources/RelationProvider.html#createRelation(org.apache.spark.sql.SQLContext, scala.collection.immutable.Map)"><B>createRelation(SQLContext, Map&lt;String, String&gt;)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/RelationProvider.html" title="interface in org.apache.spark.sql.sources">RelationProvider</A>
<DD>Returns a new base relation with the given parameters.
<DT><A HREF="./org/apache/spark/sql/sources/SchemaRelationProvider.html#createRelation(org.apache.spark.sql.SQLContext, scala.collection.immutable.Map, org.apache.spark.sql.types.StructType)"><B>createRelation(SQLContext, Map&lt;String, String&gt;, StructType)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/SchemaRelationProvider.html" title="interface in org.apache.spark.sql.sources">SchemaRelationProvider</A>
<DD>Returns a new base relation with the given parameters and user defined schema.
<DT><A HREF="./org/apache/spark/api/r/RRDD.html#createRWorker(java.lang.String, int)"><B>createRWorker(String, int)</B></A> - 
Static method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r">RRDD</A>
<DD>ProcessBuilder used to launch worker R processes.
<DT><A HREF="./org/apache/spark/api/r/RRDD.html#createSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String[], java.util.Map, java.util.Map)"><B>createSparkContext(String, String, String, String[], Map&lt;Object, Object&gt;, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r">RRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, String, int, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Create a input stream from a Flume source.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel, boolean)"><B>createStream(StreamingContext, String, int, StorageLevel, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Create a input stream from a Flume source.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int)"><B>createStream(JavaStreamingContext, String, int)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates a input stream from a Flume source.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, int, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates a input stream from a Flume source.
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel, boolean)"><B>createStream(JavaStreamingContext, String, int, StorageLevel, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>Creates a input stream from a Flume source.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, scala.collection.immutable.Map, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, String, String, Map&lt;String, Object&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create an input stream that pulls messages from Kafka Brokers.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.StreamingContext, scala.collection.immutable.Map, scala.collection.immutable.Map, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>createStream(StreamingContext, Map&lt;String, String&gt;, Map&lt;String, Object&gt;, StorageLevel, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;U&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create an input stream that pulls messages from Kafka Brokers.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.util.Map)"><B>createStream(JavaStreamingContext, String, String, Map&lt;String, Integer&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create an input stream that pulls messages from Kafka Brokers.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.util.Map, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, String, Map&lt;String, Integer&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create an input stream that pulls messages from Kafka Brokers.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, java.util.Map, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;U&gt;, Class&lt;T&gt;, Map&lt;String, String&gt;, Map&lt;String, Integer&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>Create an input stream that pulls messages from Kafka Brokers.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.util.Map, java.util.Map, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, Map&lt;String, String&gt;, Map&lt;String, Integer&gt;, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, java.lang.String, java.lang.String, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.streaming.Duration, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, String, String, String, String, InitialPositionInStream, Duration, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, java.lang.String, java.lang.String, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.streaming.Duration, org.apache.spark.storage.StorageLevel, java.lang.String, java.lang.String)"><B>createStream(StreamingContext, String, String, String, String, InitialPositionInStream, Duration, StorageLevel, String, String)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, String, String, Duration, InitialPositionInStream, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.lang.String, java.lang.String, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.streaming.Duration, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, String, String, String, InitialPositionInStream, Duration, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.lang.String, java.lang.String, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.streaming.Duration, org.apache.spark.storage.StorageLevel, java.lang.String, java.lang.String)"><B>createStream(JavaStreamingContext, String, String, String, String, InitialPositionInStream, Duration, StorageLevel, String, String)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, String, Duration, InitialPositionInStream, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>Create an input stream that pulls messages from a Kinesis stream.
<DT><A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, String, String, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.mqtt.<A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</A>
<DD>Create an input stream that receives messages pushed by a MQTT publisher.
<DT><A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String)"><B>createStream(JavaStreamingContext, String, String)</B></A> - 
Static method in class org.apache.spark.streaming.mqtt.<A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</A>
<DD>Create an input stream that receives messages pushed by a MQTT publisher.
<DT><A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, String, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.mqtt.<A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</A>
<DD>Create an input stream that receives messages pushed by a MQTT publisher.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.StreamingContext, scala.Option, scala.collection.Seq, org.apache.spark.storage.StorageLevel)"><B>createStream(StreamingContext, Option&lt;Authorization&gt;, Seq&lt;String&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext)"><B>createStream(JavaStreamingContext)</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String[])"><B>createStream(JavaStreamingContext, String[])</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String[], org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String[], StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization)"><B>createStream(JavaStreamingContext, Authorization)</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization, java.lang.String[])"><B>createStream(JavaStreamingContext, Authorization, String[])</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter.
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization, java.lang.String[], org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, Authorization, String[], StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>Create a input stream that returns tweets received from Twitter.
<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, akka.zeromq.Subscribe, scala.Function1, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy, scala.reflect.ClassTag)"><B>createStream(StreamingContext, String, Subscribe, Function1&lt;Seq&lt;ByteString&gt;, Iterator&lt;T&gt;&gt;, StorageLevel, SupervisorStrategy, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.zeromq.<A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</A>
<DD>Create an input stream that receives messages pushed by a zeromq publisher.
<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)"><B>createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;, StorageLevel, SupervisorStrategy)</B></A> - 
Static method in class org.apache.spark.streaming.zeromq.<A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</A>
<DD>Create an input stream that receives messages pushed by a zeromq publisher.
<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)"><B>createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;, StorageLevel)</B></A> - 
Static method in class org.apache.spark.streaming.zeromq.<A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</A>
<DD>Create an input stream that receives messages pushed by a zeromq publisher.
<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function)"><B>createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.zeromq.<A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</A>
<DD>Create an input stream that receives messages pushed by a zeromq publisher.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createStructField(java.lang.String, org.apache.spark.sql.types.DataType, boolean, org.apache.spark.sql.types.Metadata)"><B>createStructField(String, DataType, boolean, Metadata)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a StructField by specifying the name (<code>name</code>), data type (<code>dataType</code>) and
 whether values of this field can be null values (<code>nullable</code>).
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createStructField(java.lang.String, org.apache.spark.sql.types.DataType, boolean)"><B>createStructField(String, DataType, boolean)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a StructField with empty metadata.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createStructType(java.util.List)"><B>createStructType(List&lt;StructField&gt;)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a StructType with the given list of StructFields (<code>fields</code>).
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#createStructType(org.apache.spark.sql.types.StructField[])"><B>createStructType(StructField[])</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Creates a StructType with the given StructField array (<code>fields</code>).
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#createTopic(java.lang.String)"><B>createTopic(String)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Create a Kafka topic and wait until it propagated to the whole cluster
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#createTopicAndPartition(java.lang.String, java.lang.Integer)"><B>createTopicAndPartition(String, Integer)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#creationSite()"><B>creationSite()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>User code that created this RDD (e.g.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#creationSite()"><B>creationSite()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#crosstab(java.lang.String, java.lang.String)"><B>crosstab(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Computes a pair-wise frequency table of the given columns.
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning"><B>CrossValidator</B></A> - Class in <A HREF="./org/apache/spark/ml/tuning/package-summary.html">org.apache.spark.ml.tuning</A><DD>:: Experimental ::
 K-fold cross validation.<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#CrossValidator(java.lang.String)"><B>CrossValidator(String)</B></A> - 
Constructor for class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#CrossValidator()"><B>CrossValidator()</B></A> - 
Constructor for class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning"><B>CrossValidatorModel</B></A> - Class in <A HREF="./org/apache/spark/ml/tuning/package-summary.html">org.apache.spark.ml.tuning</A><DD>:: Experimental ::
 Model from k-fold cross validation.<DT><A HREF="./org/apache/spark/sql/DataFrame.html#cube(org.apache.spark.sql.Column...)"><B>cube(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional cube for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#cube(java.lang.String, java.lang.String...)"><B>cube(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional cube for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#cube(scala.collection.Seq)"><B>cube(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional cube for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#cube(java.lang.String, scala.collection.Seq)"><B>cube(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional cube for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/functions.html#cumeDist()"><B>cumeDist()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the cumulative distribution of values within a window partition,
 i.e.
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#currentAttemptId()"><B>currentAttemptId()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#currentAttemptId()"><B>currentAttemptId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#currPrefLocs(org.apache.spark.Partition)"><B>currPrefLocs(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_D_"><!-- --></A><H2>
<B>D</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcType.html#databaseTypeDefinition()"><B>databaseTypeDefinition()</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcType.html" title="class in org.apache.spark.sql.jdbc">JdbcType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#dataDistribution()"><B>dataDistribution()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><B>DataFrame</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 A distributed collection of data organized into named columns.<DT><A HREF="./org/apache/spark/sql/DataFrame.html#DataFrame(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)"><B>DataFrame(SQLContext, LogicalPlan)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>A constructor that automatically analyzes the logical plan.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><B>DataFrameNaFunctions</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 Functionality for working with missing data in <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>s.<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><B>DataFrameReader</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 Interface used to load a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> from external storage systems (e.g.<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><B>DataFrameStatFunctions</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 Statistic functions for <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>s.<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><B>DataFrameWriter</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 Interface used to write a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> to external storage systems (e.g.<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#dataSchema()"><B>dataSchema()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Specifies schema of actual data files.
<DT><A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types"><B>DataType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The base type of all Spark SQL data types.<DT><A HREF="./org/apache/spark/sql/types/DataType.html#DataType()"><B>DataType()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructField.html#dataType()"><B>dataType()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/UserDefinedFunction.html#dataType()"><B>dataType()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types"><B>DataTypes</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>To get/create specific data type, users should use singleton objects and factory methods
 provided by this class.<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#DataTypes()"><B>DataTypes()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util"><B>DataValidators</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 A collection of methods used to validate data before applying ML algorithms.<DT><A HREF="./org/apache/spark/mllib/util/DataValidators.html#DataValidators()"><B>DataValidators()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util">DataValidators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#date()"><B>date()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type date.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#DateType"><B>DateType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the DateType object.
<DT><A HREF="./org/apache/spark/sql/types/DateType.html" title="class in org.apache.spark.sql.types"><B>DateType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>java.sql.Date</code> values.<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#decayFactor()"><B>decayFactor()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#decimal()"><B>decimal()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type decimal.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#decimal(int, int)"><B>decimal(int, int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type decimal.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types"><B>Decimal</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>A mutable implementation of BigDecimal that can hold a Long if values are small enough.<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#Decimal()"><B>Decimal()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types"><B>DecimalType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#DecimalType(scala.Option)"><B>DecimalType(Option&lt;PrecisionInfo&gt;)</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree"><B>DecisionTree</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/package-summary.html">org.apache.spark.mllib.tree</A><DD>:: Experimental ::
 A class which implements a decision tree learning algorithm for classification and regression.<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#DecisionTree(org.apache.spark.mllib.tree.configuration.Strategy)"><B>DecisionTree(Strategy)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification"><B>DecisionTreeClassificationModel</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Decision tree</CODE> model for classification.<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification"><B>DecisionTreeClassifier</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Decision tree</CODE> learning algorithm
 for classification.<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#DecisionTreeClassifier(java.lang.String)"><B>DecisionTreeClassifier(String)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#DecisionTreeClassifier()"><B>DecisionTreeClassifier()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model"><B>DecisionTreeModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: Experimental ::
 Decision tree model for classification or regression.<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#DecisionTreeModel(org.apache.spark.mllib.tree.model.Node, scala.Enumeration.Value)"><B>DecisionTreeModel(Node, Enumeration.Value)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression"><B>DecisionTreeRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 <CODE>Decision tree</CODE> model for regression.<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression"><B>DecisionTreeRegressor</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 <CODE>Decision tree</CODE> learning algorithm
 for regression.<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#DecisionTreeRegressor(java.lang.String)"><B>DecisionTreeRegressor(String)</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#DecisionTreeRegressor()"><B>DecisionTreeRegressor()</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#defaultAttr()"><B>defaultAttr()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>The default binary attribute.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#defaultAttr()"><B>defaultAttr()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>The default nominal attribute.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#defaultAttr()"><B>defaultAttr()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>The default numeric attribute.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#defaultCopy(org.apache.spark.ml.param.ParamMap)"><B>defaultCopy(ParamMap)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Default implementation of copy with extra params.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinPartitions()"><B>defaultMinPartitions()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Default min number of partitions for Hadoop RDDs when not given by user
<DT><A HREF="./org/apache/spark/SparkContext.html#defaultMinPartitions()"><B>defaultMinPartitions()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Default min number of partitions for Hadoop RDDs when not given by user
 Notice that we use math.min so the "defaultMinPartitions" cannot be higher than 2.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinSplits()"><B>defaultMinSplits()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of Spark 1.0.0, defaultMinSplits is deprecated, use
            <A HREF="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinPartitions()"><CODE>JavaSparkContext.defaultMinPartitions()</CODE></A> instead</I>
<DT><A HREF="./org/apache/spark/SparkContext.html#defaultMinSplits()"><B>defaultMinSplits()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Default min number of partitions for Hadoop RDDs when not given by user
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#defaultParallelism()"><B>defaultParallelism()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Default level of parallelism to use when not given by user (e.g.
<DT><A HREF="./org/apache/spark/SparkContext.html#defaultParallelism()"><B>defaultParallelism()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Default level of parallelism to use when not given by user (e.g.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#defaultParamMap()"><B>defaultParamMap()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Internal param map for default values.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#defaultParams(java.lang.String)"><B>defaultParams(String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#defaultParams(scala.Enumeration.Value)"><B>defaultParams(Enumeration.Value)</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partitioner.html#defaultPartitioner(org.apache.spark.rdd.RDD, scala.collection.Seq)"><B>defaultPartitioner(RDD&lt;?&gt;, Seq&lt;RDD&lt;?&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>
<DD>Choose a partitioner to use for a cogroup-like operation between a number of RDDs.
<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>The default size of a value of the ArrayType is 100 * the default size of the element type.
<DT><A HREF="./org/apache/spark/sql/types/BinaryType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BinaryType.html" title="class in org.apache.spark.sql.types">BinaryType</A>
<DD>The default size of a value of the BinaryType is 4096 bytes.
<DT><A HREF="./org/apache/spark/sql/types/BooleanType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BooleanType.html" title="class in org.apache.spark.sql.types">BooleanType</A>
<DD>The default size of a value of the BooleanType is 1 byte.
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>The default size of a value of the ByteType is 1 byte.
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>The default size of a value of this data type, used internally for size estimation.
<DT><A HREF="./org/apache/spark/sql/types/DateType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DateType.html" title="class in org.apache.spark.sql.types">DateType</A>
<DD>The default size of a value of the DateType is 4 bytes.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>The default size of a value of the DecimalType is 4096 bytes.
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>The default size of a value of the DoubleType is 8 bytes.
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>The default size of a value of the FloatType is 4 bytes.
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>The default size of a value of the IntegerType is 4 bytes.
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>The default size of a value of the LongType is 8 bytes.
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>The default size of a value of the MapType is
 100 * (the default size of the key type + the default size of the value type).
<DT><A HREF="./org/apache/spark/sql/types/NullType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/NullType.html" title="class in org.apache.spark.sql.types">NullType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>The default size of a value of the ShortType is 2 bytes.
<DT><A HREF="./org/apache/spark/sql/types/StringType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StringType.html" title="class in org.apache.spark.sql.types">StringType</A>
<DD>The default size of a value of the StringType is 4096 bytes.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>The default size of a value of the StructType is the total default sizes of all field types.
<DT><A HREF="./org/apache/spark/sql/types/TimestampType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/TimestampType.html" title="class in org.apache.spark.sql.types">TimestampType</A>
<DD>The default size of a value of the TimestampType is 12 bytes.
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#defaultSize()"><B>defaultSize()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>The default size of a value of the UserDefinedType is 4096 bytes.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#defaultStategy(scala.Enumeration.Value)"><B>defaultStategy(Enumeration.Value)</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Construct a default set of parameters for <A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree"><CODE>DecisionTree</CODE></A>
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#defaultStrategy(java.lang.String)"><B>defaultStrategy(String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Construct a default set of parameters for <A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree"><CODE>DecisionTree</CODE></A>
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html#defaultStrategy()"><B>defaultStrategy()</B></A> - 
Static method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver">ActorSupervisorStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#degree()"><B>degree()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>The polynomial degree to expand, which should be >= 1.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#degrees()"><B>degrees()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>The degree of each vertex in the graph.
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#degreesOfFreedom()"><B>degreesOfFreedom()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html#degreesOfFreedom()"><B>degreesOfFreedom()</B></A> - 
Method in interface org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</A>
<DD>Returns the degree(s) of freedom of the hypothesis test.
<DT><A HREF="./org/apache/spark/InterruptibleIterator.html#delegate()"><B>delegate()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#dense(int, int, double[])"><B>dense(int, int, double[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Creates a column-major dense matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#dense(double, double...)"><B>dense(double, double...)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a dense vector from its values.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#dense(double, scala.collection.Seq)"><B>dense(double, Seq&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a dense vector from its values.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#dense(double[])"><B>dense(double[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a dense vector from a double array.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg"><B>DenseMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>Column-major dense matrix.<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#DenseMatrix(int, int, double[], boolean)"><B>DenseMatrix(int, int, double[], boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#DenseMatrix(int, int, double[])"><B>DenseMatrix(int, int, double[])</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Column-major dense matrix.
<DT><A HREF="./org/apache/spark/sql/functions.html#denseRank()"><B>denseRank()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the rank of rows within a window partition, without any gaps.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg"><B>DenseVector</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>A dense vector represented by a value array.<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#DenseVector(double[])"><B>DenseVector(double[])</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#dependencies()"><B>dependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Get the list of dependencies of this RDD, taking into account whether the
 RDD is checkpointed or not.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#dependencies()"><B>dependencies()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>List of parent DStreams on which this DStream depends on
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#dependencies()"><B>dependencies()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Dependency.html" title="class in org.apache.spark"><B>Dependency</B></A>&lt;<A HREF="./org/apache/spark/Dependency.html" title="type parameter in Dependency">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Base class for dependencies.<DT><A HREF="./org/apache/spark/Dependency.html#Dependency()"><B>Dependency()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#depth()"><B>depth()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Get depth of tree.
<DT><A HREF="./org/apache/spark/sql/Column.html#desc()"><B>desc()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Returns an ordering used in sorting.
<DT><A HREF="./org/apache/spark/sql/functions.html#desc(java.lang.String)"><B>desc(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns a sort expression based on the descending order of the column.
<DT><A HREF="./org/apache/spark/util/MethodIdentifier.html#desc()"><B>desc()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MethodIdentifier.html" title="class in org.apache.spark.util">MethodIdentifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#describe(java.lang.String...)"><B>describe(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Computes statistics for numeric columns, including count, mean, stddev, min, and max.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#describe(scala.collection.Seq)"><B>describe(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Computes statistics for numeric columns, including count, mean, stddev, min, and max.
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#describeTopics(int)"><B>describeTopics(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html#describeTopics(int)"><B>describeTopics(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering">LDAModel</A>
<DD>Return the topics described by weighted terms.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html#describeTopics()"><B>describeTopics()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering">LDAModel</A>
<DD>Return the topics described by weighted terms.
<DT><A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html#describeTopics(int)"><B>describeTopics(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html" title="class in org.apache.spark.mllib.clustering">LocalLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#description()"><B>description()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#description()"><B>description()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#description()"><B>description()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer"><B>DeserializationStream</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>:: DeveloperApi ::
 A stream for reading serialized objects.<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#DeserializationStream()"><B>DeserializationStream()</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#deserialize(java.nio.ByteBuffer, scala.reflect.ClassTag)"><B>deserialize(ByteBuffer, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#deserialize(java.nio.ByteBuffer, java.lang.ClassLoader, scala.reflect.ClassTag)"><B>deserialize(ByteBuffer, ClassLoader, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#deserialize(java.lang.Object)"><B>deserialize(Object)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>Convert a SQL datum to the user type
<DT><A HREF="./org/apache/spark/storage/MemoryEntry.html#deserialized()"><B>deserialized()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/MemoryEntry.html" title="class in org.apache.spark.storage">MemoryEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#deserialized()"><B>deserialized()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#deserializeStream(java.io.InputStream)"><B>deserializeStream(InputStream)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#destroy()"><B>destroy()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>Destroy all data and metadata related to this broadcast variable.
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#details()"><B>details()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#details()"><B>details()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html#determineBounds(scala.collection.mutable.ArrayBuffer, int, scala.math.Ordering, scala.reflect.ClassTag)"><B>determineBounds(ArrayBuffer&lt;Tuple2&lt;K, Object&gt;&gt;, int, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>Determines the bounds for range partitioning from candidates with weights indicating how many
 items each represents.
<DT><A HREF="./org/apache/spark/annotation/DeveloperApi.html" title="annotation in org.apache.spark.annotation"><B>DeveloperApi</B></A> - Annotation Type in <A HREF="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</A><DD>A lower-level, unstable API intended for developers.<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#diag(org.apache.spark.mllib.linalg.Vector)"><B>diag(Vector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a diagonal matrix in <code>DenseMatrix</code> format from the supplied values.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#diag(org.apache.spark.mllib.linalg.Vector)"><B>diag(Vector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a diagonal matrix in <code>Matrix</code> format from the supplied values.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#diff(org.apache.spark.rdd.RDD)"><B>diff(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#diff(org.apache.spark.graphx.VertexRDD)"><B>diff(VertexRDD&lt;VD&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#diff(org.apache.spark.rdd.RDD)"><B>diff(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#diff(org.apache.spark.graphx.VertexRDD)"><B>diff(VertexRDD&lt;VD&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>For each vertex present in both <code>this</code> and <code>other</code>, <code>diff</code> returns only those vertices with
 differing values; for values that are different, keeps the values from <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#disableOutputSpecValidation()"><B>disableOutputSpecValidation()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#DISK_ONLY"><B>DISK_ONLY</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#DISK_ONLY()"><B>DISK_ONLY()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#DISK_ONLY_2"><B>DISK_ONLY_2</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#DISK_ONLY_2()"><B>DISK_ONLY_2()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#diskBytesSpilled()"><B>diskBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#diskBytesSpilled()"><B>diskBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#diskBytesSpilled()"><B>diskBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#diskBytesSpilled()"><B>diskBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#diskSize()"><B>diskSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#diskSize()"><B>diskSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#diskUsed()"><B>diskUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html#diskUsed()"><B>diskUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html" title="class in org.apache.spark.status.api.v1">RDDDataDistribution</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html#diskUsed()"><B>diskUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1">RDDPartitionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#diskUsed()"><B>diskUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#diskUsed()"><B>diskUsed()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the disk space used by this block manager.
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#diskUsedByRdd(int)"><B>diskUsedByRdd(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the disk space used by the given RDD in this block manager in O(1) time.
<DT><A HREF="./org/apache/spark/util/Vector.html#dist(org.apache.spark.util.Vector)"><B>dist(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#distinct()"><B>distinct()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#distinct(int)"><B>distinct(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#distinct()"><B>distinct()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#distinct(int)"><B>distinct(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#distinct()"><B>distinct()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#distinct(int)"><B>distinct(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#distinct(int, scala.math.Ordering)"><B>distinct(int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#distinct()"><B>distinct()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD containing the distinct elements in this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#distinct()"><B>distinct()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that contains only the unique rows from this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering"><B>DistributedLDAModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed"><B>DistributedMatrix</B></A> - Interface in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>Represents a distributively stored matrix backed by one or more RDDs.<DT><A HREF="./org/apache/spark/streaming/Duration.html#div(org.apache.spark.streaming.Duration)"><B>div(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#divide(java.lang.Object)"><B>divide(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Division this expression by another expression.
<DT><A HREF="./org/apache/spark/util/Vector.html#divide(double)"><B>divide(double)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#doc()"><B>doc()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#docConcentration()"><B>docConcentration()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#dot(org.apache.spark.util.Vector)"><B>dot(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#doubleAccumulator(double)"><B>doubleAccumulator(double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> double variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#doubleAccumulator(double, java.lang.String)"><B>doubleAccumulator(double, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> double variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html" title="class in org.apache.spark.ml.param"><B>DoubleArrayParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Array[Double</CODE>} for Java.<DT><A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html#DoubleArrayParam(org.apache.spark.ml.param.Params, java.lang.String, java.lang.String, scala.Function1)"><B>DoubleArrayParam(Params, String, String, Function1&lt;double[], Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html" title="class in org.apache.spark.ml.param">DoubleArrayParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html#DoubleArrayParam(org.apache.spark.ml.param.Params, java.lang.String, java.lang.String)"><B>DoubleArrayParam(Params, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html" title="class in org.apache.spark.ml.param">DoubleArrayParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><B>DoubleFlatMapFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="type parameter in DoubleFlatMapFunction">T</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that returns zero or more records of type Double from each input record.<DT><A HREF="./org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function"><B>DoubleFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/DoubleFunction.html" title="type parameter in DoubleFunction">T</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that returns Doubles, and can be used to construct DoubleRDDs.<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param"><B>DoubleParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Double</CODE>] for Java.<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html#DoubleParam(java.lang.String, java.lang.String, java.lang.String, scala.Function1)"><B>DoubleParam(String, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param">DoubleParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html#DoubleParam(java.lang.String, java.lang.String, java.lang.String)"><B>DoubleParam(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param">DoubleParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html#DoubleParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String, scala.Function1)"><B>DoubleParam(org.apache.spark.ml.util.Identifiable, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param">DoubleParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html#DoubleParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>DoubleParam(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param">DoubleParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd"><B>DoubleRDDFunctions</B></A> - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>Extra functions available on RDDs of Doubles through an implicit conversion.<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#DoubleRDDFunctions(org.apache.spark.rdd.RDD)"><B>DoubleRDDFunctions(RDD&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#doubleRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD)"><B>doubleRDDToDoubleRDDFunctions(RDD&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#doubleRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD)"><B>doubleRDDToDoubleRDDFunctions(RDD&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#doubleToDoubleWritable(double)"><B>doubleToDoubleWritable(double)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#doubleToMultiplier(double)"><B>doubleToMultiplier(double)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#DoubleType"><B>DoubleType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the DoubleType object.
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types"><B>DoubleType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Double</code> values.<DT><A HREF="./org/apache/spark/SparkContext.html#doubleWritableConverter()"><B>doubleWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#DRIVER_EXTRA_CLASSPATH"><B>DRIVER_EXTRA_CLASSPATH</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the driver class path.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#DRIVER_EXTRA_JAVA_OPTIONS"><B>DRIVER_EXTRA_JAVA_OPTIONS</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the driver VM options.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#DRIVER_EXTRA_LIBRARY_PATH"><B>DRIVER_EXTRA_LIBRARY_PATH</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the driver native library path.
<DT><A HREF="./org/apache/spark/SparkContext.html#DRIVER_IDENTIFIER()"><B>DRIVER_IDENTIFIER()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Executor id for the driver.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#DRIVER_MEMORY"><B>DRIVER_MEMORY</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the driver memory.
<DT><A HREF="./org/apache/spark/SparkEnv.html#driverActorSystemName()"><B>driverActorSystemName()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#drop(java.lang.String)"><B>drop(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with a column dropped.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#drop(org.apache.spark.sql.Column)"><B>drop(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with a column dropped.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop()"><B>drop()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing any null values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(java.lang.String)"><B>drop(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing null values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(java.lang.String[])"><B>drop(String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing any null values
 in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(scala.collection.Seq)"><B>drop(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing any null values
 in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(java.lang.String, java.lang.String[])"><B>drop(String, String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing null values
 in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(java.lang.String, scala.collection.Seq)"><B>drop(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing null values
 in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(int)"><B>drop(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing less than <code>minNonNulls</code> non-null values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(int, java.lang.String[])"><B>drop(int, String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing less than <code>minNonNulls</code> non-null
 values in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#drop(int, scala.collection.Seq)"><B>drop(int, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that drops rows containing less than
 <code>minNonNulls</code> non-null values in the specified columns.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#dropDuplicates()"><B>dropDuplicates()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that contains only the unique rows from this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#dropDuplicates(scala.collection.Seq)"><B>dropDuplicates(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with duplicate rows removed, considering only
 the subset of columns.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#dropDuplicates(java.lang.String[])"><B>dropDuplicates(String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with duplicate rows removed, considering only
 the subset of columns.
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#dropLast()"><B>dropLast()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>Whether to drop the last category in the encoded vector (default: true)
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)"><B>dropTempTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#Dst"><B>Dst</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Expose the destination and edge fields but not the source field.
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#dstAttr()"><B>dstAttr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>The vertex attribute of the edge's destination vertex.
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#dstAttr()"><B>dstAttr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>The destination vertex attribute
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#dstAttr()"><B>dstAttr()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Edge.html#dstId()"><B>dstId()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#dstId()"><B>dstId()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>The vertex id of the edge's destination vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#dstId()"><B>dstId()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#dstream()"><B>dstream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#dstream()"><B>dstream()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#dstream()"><B>dstream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><B>DStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="type parameter in DStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</A><DD>A Discretized Stream (DStream), the basic abstraction in Spark Streaming, is a continuous
 sequence of RDDs (of the same type) representing a continuous stream of data (see
 org.apache.spark.rdd.RDD in the Spark core documentation for more details on RDDs).<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#DStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)"><B>DStream(StreamingContext, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#dtypes()"><B>dtypes()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns all column names and their data types as an array.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#duration()"><B>duration()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><B>Duration</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/Duration.html#Duration(long)"><B>Duration(long)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Durations.html" title="class in org.apache.spark.streaming"><B>Durations</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/Durations.html#Durations()"><B>Durations()</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Durations.html" title="class in org.apache.spark.streaming">Durations</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_E_"><!-- --></A><H2>
<B>E</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx"><B>Edge</B></A>&lt;<A HREF="./org/apache/spark/graphx/Edge.html" title="type parameter in Edge">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>A single directed edge consisting of a source id, target id,
 and the data associated with the edge.<DT><A HREF="./org/apache/spark/graphx/Edge.html#Edge(long, long, ED)"><B>Edge(long, long, ED)</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeActiveness.html" title="enum in org.apache.spark.graphx.impl"><B>EdgeActiveness</B></A> - Enum in <A HREF="./org/apache/spark/graphx/impl/package-summary.html">org.apache.spark.graphx.impl</A><DD>Criteria for filtering edges based on activeness.<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx"><B>EdgeContext</B></A>&lt;<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="type parameter in EdgeContext">VD</A>,<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="type parameter in EdgeContext">ED</A>,<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="type parameter in EdgeContext">A</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Represents an edge along with its neighboring vertices and allows sending messages along the
 edge.<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#EdgeContext()"><B>EdgeContext()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx"><B>EdgeDirection</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>The direction of a directed edge relative to a vertex.<DT><A HREF="./org/apache/spark/graphx/GraphLoader.html#edgeListFile(org.apache.spark.SparkContext, java.lang.String, boolean, int, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel)"><B>edgeListFile(SparkContext, String, boolean, int, StorageLevel, StorageLevel)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphLoader.html" title="class in org.apache.spark.graphx">GraphLoader</A>
<DD>Loads a graph from an edge list formatted file where each line contains two integers: a source
 id and a target id.
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#EdgeOnly"><B>EdgeOnly</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Expose only the edge field and not the source or destination field.
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><B>EdgeRDD</B></A>&lt;<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="type parameter in EdgeRDD">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD><code>EdgeRDD[ED, VD]</code> extends <code>RDD[Edge[ED}</code> by storing the edges in columnar format on each
 partition for performance.<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#EdgeRDD(org.apache.spark.SparkContext, scala.collection.Seq)"><B>EdgeRDD(SparkContext, Seq&lt;Dependency&lt;?&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl"><B>EdgeRDDImpl</B></A>&lt;<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="type parameter in EdgeRDDImpl">ED</A>,<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="type parameter in EdgeRDDImpl">VD</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/impl/package-summary.html">org.apache.spark.graphx.impl</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/Graph.html#edges()"><B>edges()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>An RDD containing the edges and their associated attributes.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#edges()"><B>edges()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx"><B>EdgeTriplet</B></A>&lt;<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="type parameter in EdgeTriplet">VD</A>,<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="type parameter in EdgeTriplet">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>An edge triplet represents an edge along with the vertex attributes of its neighboring vertices.<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#EdgeTriplet()"><B>EdgeTriplet()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#Either()"><B>Either()</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>Edges originating from *or* arriving at a vertex of interest.
<DT><A HREF="./org/apache/spark/util/Vector.html#elements()"><B>elements()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#elementType()"><B>elementType()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature"><B>ElementwiseProduct</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Outputs the Hadamard product (i.e., the element-wise product) of each input vector with a
 provided "weight" vector.<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#ElementwiseProduct(java.lang.String)"><B>ElementwiseProduct(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#ElementwiseProduct()"><B>ElementwiseProduct()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html" title="class in org.apache.spark.mllib.feature"><B>ElementwiseProduct</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Outputs the Hadamard product (i.e., the element-wise product) of each input vector with a
 provided "weight" vector.<DT><A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html#ElementwiseProduct(org.apache.spark.mllib.linalg.Vector)"><B>ElementwiseProduct(Vector)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html" title="class in org.apache.spark.mllib.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering"><B>EMLDAOptimizer</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#EMLDAOptimizer()"><B>EMLDAOptimizer()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#empty()"><B>empty()</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Returns an empty param map.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#empty()"><B>empty()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Returns an empty Metadata.
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#empty()"><B>empty()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#emptyDataFrame()"><B>emptyDataFrame()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>:: Experimental ::
 Returns a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with no rows or columns.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#emptyNode(int)"><B>emptyNode(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return a node with the given node id (but nothing else set).
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#emptyRDD()"><B>emptyRDD()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD that has no partitions or elements.
<DT><A HREF="./org/apache/spark/SparkContext.html#emptyRDD(scala.reflect.ClassTag)"><B>emptyRDD(ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD that has no partitions or elements.
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#endpoint()"><B>endpoint()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#endsWith(org.apache.spark.sql.Column)"><B>endsWith(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>String ends with.
<DT><A HREF="./org/apache/spark/sql/Column.html#endsWith(java.lang.String)"><B>endsWith(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>String ends with another string literal.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#endsWith(org.apache.spark.sql.types.UTF8String)"><B>endsWith(UTF8String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html#endTime()"><B>endTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationAttemptInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#entries()"><B>entries()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity"><B>Entropy</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</A><DD>:: Experimental ::
 Class for calculating <CODE>entropy</CODE> during
 binary classification.<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html#Entropy()"><B>Entropy()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/EnumUtil.html" title="class in org.apache.spark.util"><B>EnumUtil</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/EnumUtil.html#EnumUtil()"><B>EnumUtil()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/EnumUtil.html" title="class in org.apache.spark.util">EnumUtil</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#env()"><B>env()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#env()"><B>env()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html#environmentDetails()"><B>environmentDetails()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerEnvironmentUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env"><B>EnvironmentListener</B></A> - Class in <A HREF="./org/apache/spark/ui/env/package-summary.html">org.apache.spark.ui.env</A><DD>:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the EnvironmentTab<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#EnvironmentListener()"><B>EnvironmentListener()</B></A> - 
Constructor for class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#EPSILON()"><B>EPSILON()</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#eqNullSafe(java.lang.Object)"><B>eqNullSafe(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Equality test that is safe for null values.
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/HashPartitioner.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html" title="class in org.apache.spark.ml.tree">CategoricalSplit</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html" title="class in org.apache.spark.ml.tree">ContinuousSplit</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>Broker's port
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>exclusive ending offset
<DT><A HREF="./org/apache/spark/sql/Column.html#equalTo(java.lang.Object)"><B>equalTo(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Equality test.
<DT><A HREF="./org/apache/spark/sql/sources/EqualTo.html" title="class in org.apache.spark.sql.sources"><B>EqualTo</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a value
 equal to <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/EqualTo.html#EqualTo(java.lang.String, java.lang.Object)"><B>EqualTo(String, Object)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/EqualTo.html" title="class in org.apache.spark.sql.sources">EqualTo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#errorMessage()"><B>errorMessage()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#estimate(double[])"><B>estimate(double[])</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>Estimates probability density function at the given array of points.
<DT><A HREF="./org/apache/spark/util/SizeEstimator.html#estimate(java.lang.Object)"><B>estimate(Object)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/SizeEstimator.html" title="class in org.apache.spark.util">SizeEstimator</A>
<DD>Estimate the number of bytes that the given object takes up on the JVM heap.
<DT><A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml"><B>Estimator</B></A>&lt;<A HREF="./org/apache/spark/ml/Estimator.html" title="type parameter in Estimator">M</A> extends <A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>&lt;<A HREF="./org/apache/spark/ml/Estimator.html" title="type parameter in Estimator">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 Abstract class for estimators that fit models to data.<DT><A HREF="./org/apache/spark/ml/Estimator.html#Estimator()"><B>Estimator()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#evaluate(org.apache.spark.sql.DataFrame)"><B>evaluate(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/Evaluator.html#evaluate(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamMap)"><B>evaluate(DataFrame, ParamMap)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/Evaluator.html" title="class in org.apache.spark.ml.evaluation">Evaluator</A>
<DD>Evaluates model output and returns a scalar metric (larger is better).
<DT><A HREF="./org/apache/spark/ml/evaluation/Evaluator.html#evaluate(org.apache.spark.sql.DataFrame)"><B>evaluate(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/Evaluator.html" title="class in org.apache.spark.ml.evaluation">Evaluator</A>
<DD>Evaluates the output.
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#evaluate(org.apache.spark.sql.DataFrame)"><B>evaluate(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#evaluateEachIteration(org.apache.spark.rdd.RDD, org.apache.spark.mllib.tree.loss.Loss)"><B>evaluateEachIteration(RDD&lt;LabeledPoint&gt;, Loss)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>Method to compute error or loss for every iteration of gradient boosting.
<DT><A HREF="./org/apache/spark/ml/evaluation/Evaluator.html" title="class in org.apache.spark.ml.evaluation"><B>Evaluator</B></A> - Class in <A HREF="./org/apache/spark/ml/evaluation/package-summary.html">org.apache.spark.ml.evaluation</A><DD>:: DeveloperApi ::
 Abstract class for evaluators that compute metrics from predictions.<DT><A HREF="./org/apache/spark/ml/evaluation/Evaluator.html#Evaluator()"><B>Evaluator()</B></A> - 
Constructor for class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/Evaluator.html" title="class in org.apache.spark.ml.evaluation">Evaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#event()"><B>event()</B></A> - 
Method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#eventually(org.apache.spark.streaming.Time, org.apache.spark.streaming.Time, scala.Function0)"><B>eventually(Time, Time, Function0&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#except(org.apache.spark.sql.DataFrame)"><B>except(DataFrame)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> containing rows in this frame but not in another frame.
<DT><A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark"><B>ExceptionFailure</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Task failed due to a runtime exception.<DT><A HREF="./org/apache/spark/ExceptionFailure.html#ExceptionFailure(java.lang.String, java.lang.String, java.lang.StackTraceElement[], java.lang.String, scala.Option)"><B>ExceptionFailure(String, String, StackTraceElement[], String, Option&lt;TaskMetrics&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExecutorLostFailure.html#execId()"><B>execId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark">ExecutorLostFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#execId()"><B>execId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#executor_()"><B>executor_()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Handler object that runs the receiver.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#EXECUTOR_CORES"><B>EXECUTOR_CORES</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the number of executor CPU cores.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#EXECUTOR_EXTRA_CLASSPATH"><B>EXECUTOR_EXTRA_CLASSPATH</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the executor class path.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#EXECUTOR_EXTRA_JAVA_OPTIONS"><B>EXECUTOR_EXTRA_JAVA_OPTIONS</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the executor VM options.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#EXECUTOR_EXTRA_LIBRARY_PATH"><B>EXECUTOR_EXTRA_LIBRARY_PATH</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the executor native library path.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#EXECUTOR_MEMORY"><B>EXECUTOR_MEMORY</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Configuration key for the executor memory.
<DT><A HREF="./org/apache/spark/SparkEnv.html#executorActorSystemName()"><B>executorActorSystemName()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#executorDeserializeTime()"><B>executorDeserializeTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#executorDeserializeTime()"><B>executorDeserializeTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#executorEnvs()"><B>executorEnvs()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#executorHost()"><B>executorHost()</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#executorId()"><B>executorId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#executorIdToBlockManagerId()"><B>executorIdToBlockManagerId()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorIdToData()"><B>executorIdToData()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#executorIdToStorageStatus()"><B>executorIdToStorageStatus()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster"><B>ExecutorInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/cluster/package-summary.html">org.apache.spark.scheduler.cluster</A><DD>:: DeveloperApi ::
 Stores information about an executor to pass from the scheduler to SparkListeners.<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#ExecutorInfo(java.lang.String, int, scala.collection.immutable.Map)"><B>ExecutorInfo(String, int, Map&lt;String, String&gt;)</B></A> - 
Constructor for class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html#executorInfo()"><B>executorInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#executorLogs()"><B>executorLogs()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark"><B>ExecutorLostFailure</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 The task failed because the executor that it was running on was lost.<DT><A HREF="./org/apache/spark/ExecutorLostFailure.html#ExecutorLostFailure(java.lang.String)"><B>ExecutorLostFailure(String)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark">ExecutorLostFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#executorMemoryManager()"><B>executorMemoryManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html#executorPct()"><B>executorPct()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler">RuntimePercentage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#executorRunTime()"><B>executorRunTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#executorRunTime()"><B>executorRunTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#executorRunTime()"><B>executorRunTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html#executors()"><B>executors()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1">RDDPartitionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec"><B>ExecutorsListener</B></A> - Class in <A HREF="./org/apache/spark/ui/exec/package-summary.html">org.apache.spark.ui.exec</A><DD>:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the ExecutorsTab<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#ExecutorsListener(org.apache.spark.storage.StorageStatusListener)"><B>ExecutorsListener(StorageStatusListener)</B></A> - 
Constructor for class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1"><B>ExecutorStageSummary</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1"><B>ExecutorSummary</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#executorSummary()"><B>executorSummary()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToDuration()"><B>executorToDuration()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToInputBytes()"><B>executorToInputBytes()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToInputRecords()"><B>executorToInputRecords()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToLogUrls()"><B>executorToLogUrls()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToOutputBytes()"><B>executorToOutputBytes()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToOutputRecords()"><B>executorToOutputRecords()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToShuffleRead()"><B>executorToShuffleRead()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToShuffleWrite()"><B>executorToShuffleWrite()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksActive()"><B>executorToTasksActive()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksComplete()"><B>executorToTasksComplete()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksFailed()"><B>executorToTasksFailed()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#exp(org.apache.spark.sql.Column)"><B>exp(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the exponential of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#exp(java.lang.String)"><B>exp(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the exponential of the given column.
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#expand(org.apache.spark.mllib.linalg.Vector, int)"><B>expand(Vector, int)</B></A> - 
Static method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering"><B>ExpectationSum</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#ExpectationSum(double, double[], breeze.linalg.DenseVector[], breeze.linalg.DenseMatrix[])"><B>ExpectationSum(double, double[], DenseVector&lt;Object&gt;[], DenseMatrix&lt;Object&gt;[])</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/annotation/Experimental.html" title="annotation in org.apache.spark.annotation"><B>Experimental</B></A> - Annotation Type in <A HREF="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</A><DD>An experimental user-facing API.<DT><A HREF="./org/apache/spark/sql/SQLContext.html#experimental()"><B>experimental()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.
<DT><A HREF="./org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql"><B>ExperimentalMethods</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 Holder for experimental methods for the bravest.<DT><A HREF="./org/apache/spark/sql/Column.html#explain(boolean)"><B>explain(boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Prints the expression to the console for debugging purpose.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#explain(boolean)"><B>explain(boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Prints the plans (logical and physical) to the console for debugging purposes.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#explain()"><B>explain()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Only prints the physical plan to the console for debugging purposes.
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#explainedVariance()"><B>explainedVariance()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>Returns the explained variance regression score.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#explainParam(org.apache.spark.ml.param.Param)"><B>explainParam(Param&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Explains a param.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#explainParams()"><B>explainParams()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Explains all params of this instance.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#explode(scala.collection.Seq, scala.Function1, scala.reflect.api.TypeTags.TypeTag)"><B>explode(Seq&lt;Column&gt;, Function1&lt;Row, TraversableOnce&lt;A&gt;&gt;, TypeTags.TypeTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> where each row has been expanded to zero or more
 rows by the provided function.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#explode(java.lang.String, java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)"><B>explode(String, String, Function1&lt;A, TraversableOnce&lt;B&gt;&gt;, TypeTags.TypeTag&lt;B&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> where a single column has been expanded to zero
 or more rows by the provided function.
<DT><A HREF="./org/apache/spark/sql/functions.html#explode(org.apache.spark.sql.Column)"><B>explode(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new row for each element in the given array or map column.
<DT><A HREF="./org/apache/spark/sql/functions.html#expm1(org.apache.spark.sql.Column)"><B>expm1(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the exponential of the given value minus one.
<DT><A HREF="./org/apache/spark/sql/functions.html#expm1(java.lang.String)"><B>expm1(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the exponential of the given column.
<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random"><B>ExponentialGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html#ExponentialGenerator(double)"><B>ExponentialGenerator(double)</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random">ExponentialGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><B>exponentialJavaRDD(JavaSparkContext, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialRDD(org.apache.spark.SparkContext, double, long, int, long)"><CODE>RandomRDDs.exponentialRDD(org.apache.spark.SparkContext, double, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)"><B>exponentialJavaRDD(JavaSparkContext, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><CODE>RandomRDDs.exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long)"><B>exponentialJavaRDD(JavaSparkContext, double, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><CODE>RandomRDDs.exponentialJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><B>exponentialJavaVectorRDD(JavaSparkContext, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)"><CODE>RandomRDDs.exponentialVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int)"><B>exponentialJavaVectorRDD(JavaSparkContext, double, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><CODE>RandomRDDs.exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)"><B>exponentialJavaVectorRDD(JavaSparkContext, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><CODE>RandomRDDs.exponentialJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</CODE></A> with the default number of partitions
 and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialRDD(org.apache.spark.SparkContext, double, long, int, long)"><B>exponentialRDD(SparkContext, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the exponential distribution with
 the input mean.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#exponentialVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)"><B>exponentialVectorRDD(SparkContext, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from the
 exponential distribution with the input mean.
<DT><A HREF="./org/apache/spark/SparkContext.html#externalBlockStoreFolderName()"><B>externalBlockStoreFolderName()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#externalBlockStoreSize()"><B>externalBlockStoreSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#externalBlockStoreSize()"><B>externalBlockStoreSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#extractDistribution(scala.Function1)"><B>extractDistribution(Function1&lt;BatchInfo, Option&lt;Object&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#extractDoubleDistribution(scala.collection.Seq, scala.Function2)"><B>extractDoubleDistribution(Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#extractLongDistribution(scala.collection.Seq, scala.Function2)"><B>extractLongDistribution(Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Params.html#extractParamMap(org.apache.spark.ml.param.ParamMap)"><B>extractParamMap(ParamMap)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Extracts the embedded default param values and user-supplied values, and then merges them with
 extra values from input into a flat param map, where the latter value is used if there exist
 conflicts, i.e., with ordering: default param values < user-supplied values < extra.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#extractParamMap()"><B>extractParamMap()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD><CODE>extractParamMap</CODE> with no extra values.
<DT><A HREF="./org/apache/spark/sql/ExperimentalMethods.html#extraStrategies()"><B>extraStrategies()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</A>
<DD>Allows extra strategies to be injected into the query planner at runtime.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#eye(int)"><B>eye(int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate an Identity Matrix in <code>DenseMatrix</code> format.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#eye(int)"><B>eye(int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a dense Identity Matrix in <code>Matrix</code> format.
</DL>
<HR>
<A NAME="_F_"><!-- --></A><H2>
<B>F</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/sql/UserDefinedFunction.html#f()"><B>f()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql">UserDefinedFunction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#f1Measure()"><B>f1Measure()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns document-based f1-measure averaged by the number of documents
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#f1Measure(double)"><B>f1Measure(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns f1-measure for a given label (category)
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#failed()"><B>failed()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#failedJobs()"><B>failedJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#failedStages()"><B>failedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#failedTasks()"><B>failedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#failedTasks()"><B>failedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#failureReason()"><B>failureReason()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>If the stage failed, the reason why.
<DT><A HREF="./org/apache/spark/scheduler/SchedulingMode.html#FAIR()"><B>FAIR()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#falsePositiveRate(double)"><B>falsePositiveRate(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns false positive rate for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#feature()"><B>feature()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html#featureIndex()"><B>featureIndex()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html" title="class in org.apache.spark.ml.tree">CategoricalSplit</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html#featureIndex()"><B>featureIndex()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html" title="class in org.apache.spark.ml.tree">ContinuousSplit</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/Split.html#featureIndex()"><B>featureIndex()</B></A> - 
Method in interface org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Split.html" title="interface in org.apache.spark.ml.tree">Split</A>
<DD>Index of feature which this split tests
<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html#features()"><B>features()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration"><B>FeatureType</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</A><DD>:: Experimental ::
 Enum to describe whether a feature is "continuous" or "categorical"<DT><A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html#FeatureType()"><B>FeatureType()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#featureType()"><B>featureType()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark"><B>FetchFailed</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Task failed to fetch shuffle data from a remote node.<DT><A HREF="./org/apache/spark/FetchFailed.html#FetchFailed(org.apache.spark.storage.BlockManagerId, int, int, int, java.lang.String)"><B>FetchFailed(BlockManagerId, int, int, int, String)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html#fetchPct()"><B>fetchPct()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler">RuntimePercentage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#fetchWaitTime()"><B>fetchWaitTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#fetchWaitTime()"><B>fetchWaitTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BroadcastBlockId.html#field()"><B>field()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#fieldIndex(java.lang.String)"><B>fieldIndex(String)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the index of a given field name.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#fieldIndex(java.lang.String)"><B>fieldIndex(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>Returns index of a given field
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#fieldNames()"><B>fieldNames()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>Returns all field names in an array.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#fields()"><B>fields()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SchedulingMode.html#FIFO()"><B>FIFO()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#files()"><B>files()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>fileStream(String, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean)"><B>fileStream(String, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;F&gt;, Function&lt;Path, Boolean&gt;, boolean)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.spark.api.java.function.Function, boolean, org.apache.hadoop.conf.Configuration)"><B>fileStream(String, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;F&gt;, Function&lt;Path, Boolean&gt;, boolean, Configuration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#fileStream(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fileStream(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#fileStream(java.lang.String, scala.Function1, boolean, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fileStream(String, Function1&lt;Path, Object&gt;, boolean, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#fileStream(java.lang.String, scala.Function1, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fileStream(String, Function1&lt;Path, Object&gt;, boolean, Configuration, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(double)"><B>fill(double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in numeric columns with <code>value</code>.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(java.lang.String)"><B>fill(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in string columns with <code>value</code>.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(double, java.lang.String[])"><B>fill(double, String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in specified numeric columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(double, scala.collection.Seq)"><B>fill(double, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in specified
 numeric columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(java.lang.String, java.lang.String[])"><B>fill(String, String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in specified string columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(java.lang.String, scala.collection.Seq)"><B>fill(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values in
 specified string columns.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(java.util.Map)"><B>fill(Map&lt;String, Object&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#fill(scala.collection.immutable.Map)"><B>fill(Map&lt;String, Object&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that replaces null values.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#filter(org.apache.spark.api.java.function.Function)"><B>filter(Function&lt;Double, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#filter(org.apache.spark.api.java.function.Function)"><B>filter(Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#filter(org.apache.spark.api.java.function.Function)"><B>filter(Function&lt;T, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#filter(scala.Function1, scala.Function1, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>filter(Function1&lt;Graph&lt;VD, ED&gt;, Graph&lt;VD2, ED2&gt;&gt;, Function1&lt;EdgeTriplet&lt;VD2, ED2&gt;, Object&gt;, Function2&lt;Object, VD2, Object&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Filter the graph by computing some values to filter on, and applying the predicates.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#filter(scala.Function1, scala.Function2)"><B>filter(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Object&gt;, Function2&lt;Object, VD, Object&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#filter(scala.Function1)"><B>filter(Function1&lt;Tuple2&lt;Object, VD&gt;, Object&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Restricts the vertex set to the set of vertices satisfying the given predicate.
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#filter(org.apache.spark.ml.param.Params)"><B>filter(Params)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Filters this param map for the given parent.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#filter(scala.Function1)"><B>filter(Function1&lt;T, Object&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#filter(org.apache.spark.sql.Column)"><B>filter(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Filters rows using the given condition.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#filter(java.lang.String)"><B>filter(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Filters rows using the given SQL expression.
<DT><A HREF="./org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources"><B>Filter</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter predicate for data sources.<DT><A HREF="./org/apache/spark/sql/sources/Filter.html#Filter()"><B>Filter()</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources">Filter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#filter(org.apache.spark.api.java.function.Function)"><B>filter(Function&lt;T, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Return a new DStream containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#filter(org.apache.spark.api.java.function.Function)"><B>filter(Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#filter(scala.Function1)"><B>filter(Function1&lt;T, Object&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream containing only the elements that satisfy a predicate.
<DT><A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html#filterByRange(K, K)"><B>filterByRange(K, K)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</A>
<DD>Returns an RDD containing only the elements in the the inclusive range <code>lower</code> to <code>upper</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#filterWith(scala.Function1, scala.Function2)"><B>filterWith(Function1&lt;Object, A&gt;, Function2&lt;T, A, Object&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Filters this RDD with p, where p takes an additional parameter of type A.
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#findSynonyms(java.lang.String, int)"><B>findSynonyms(String, int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>Find synonyms of a word
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#findSynonyms(org.apache.spark.mllib.linalg.Vector, int)"><B>findSynonyms(Vector, int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>Find synonyms of the vector representation of a word
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#finished()"><B>finished()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#finishTime()"><B>finishTime()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>The time when the task has completed successfully (including the time to remotely fetch
 results, if necessary).
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#first()"><B>first()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#first()"><B>first()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#first()"><B>first()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return the first element in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#first()"><B>first()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the first element in this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#first()"><B>first()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the first row.
<DT><A HREF="./org/apache/spark/sql/functions.html#first(org.apache.spark.sql.Column)"><B>first(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the first value in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#first(java.lang.String)"><B>first(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the first value of a column in a group.
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Estimator.html#fit(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamPair, org.apache.spark.ml.param.ParamPair...)"><B>fit(DataFrame, ParamPair&lt;?&gt;, ParamPair&lt;?&gt;...)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>Fits a single model to the input data with optional parameters.
<DT><A HREF="./org/apache/spark/ml/Estimator.html#fit(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamPair, scala.collection.Seq)"><B>fit(DataFrame, ParamPair&lt;?&gt;, Seq&lt;ParamPair&lt;?&gt;&gt;)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>Fits a single model to the input data with optional parameters.
<DT><A HREF="./org/apache/spark/ml/Estimator.html#fit(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamMap)"><B>fit(DataFrame, ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>Fits a single model to the input data with provided parameter map.
<DT><A HREF="./org/apache/spark/ml/Estimator.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>Fits a model to the input data.
<DT><A HREF="./org/apache/spark/ml/Estimator.html#fit(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamMap[])"><B>fit(DataFrame, ParamMap[])</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml">Estimator</A>
<DD>Fits multiple models to the input data with multiple sets of parameters.
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>Fits the pipeline to the input dataset with additional parameters.
<DT><A HREF="./org/apache/spark/ml/Predictor.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#fit(org.apache.spark.sql.DataFrame)"><B>fit(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html#fit(org.apache.spark.rdd.RDD)"><B>fit(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html" title="class in org.apache.spark.mllib.feature">ChiSqSelector</A>
<DD>Returns a ChiSquared feature selector.
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html#fit(org.apache.spark.rdd.RDD)"><B>fit(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</A>
<DD>Computes the inverse document frequency.
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html#fit(org.apache.spark.api.java.JavaRDD)"><B>fit(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</A>
<DD>Computes the inverse document frequency.
<DT><A HREF="./org/apache/spark/mllib/feature/PCA.html#fit(org.apache.spark.rdd.RDD)"><B>fit(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature">PCA</A>
<DD>Computes a <A HREF="./org/apache/spark/mllib/feature/PCAModel.html" title="class in org.apache.spark.mllib.feature"><CODE>PCAModel</CODE></A> that contains the principal components of the input vectors.
<DT><A HREF="./org/apache/spark/mllib/feature/PCA.html#fit(org.apache.spark.api.java.JavaRDD)"><B>fit(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature">PCA</A>
<DD>Java-friendly version of <CODE>fit()</CODE>
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScaler.html#fit(org.apache.spark.rdd.RDD)"><B>fit(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</A>
<DD>Computes the mean and variance and stores as a model to be used for later scaling.
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#fit(org.apache.spark.rdd.RDD)"><B>fit(RDD&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#fit(org.apache.spark.api.java.JavaRDD)"><B>fit(JavaRDD&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>Computes the vector representation of each word in vocabulary (Java version).
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction)"><B>flatMap(FlatMapFunction&lt;T, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#flatMap(scala.Function1, scala.reflect.ClassTag)"><B>flatMap(Function1&lt;T, TraversableOnce&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#flatMap(scala.Function1, scala.reflect.ClassTag)"><B>flatMap(Function1&lt;Row, TraversableOnce&lt;R&gt;&gt;, ClassTag&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new RDD by first applying a function to all rows of this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>,
 and then flattening the results.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction)"><B>flatMap(FlatMapFunction&lt;T, U&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#flatMap(scala.Function1, scala.reflect.ClassTag)"><B>flatMap(Function1&lt;T, Traversable&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results
<DT><A HREF="./org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><B>FlatMapFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/FlatMapFunction.html" title="type parameter in FlatMapFunction">T</A>,<A HREF="./org/apache/spark/api/java/function/FlatMapFunction.html" title="type parameter in FlatMapFunction">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that returns zero or more output records from each input record.<DT><A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function"><B>FlatMapFunction2</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">T1</A>,<A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">T2</A>,<A HREF="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that takes two inputs and returns zero or more output records.<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#flatMapToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)"><B>flatMapToDouble(DoubleFlatMapFunction&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><B>flatMapToPair(PairFlatMapFunction&lt;T, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><B>flatMapToPair(PairFlatMapFunction&lt;T, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#flatMapValues(org.apache.spark.api.java.function.Function)"><B>flatMapValues(Function&lt;V, Iterable&lt;U&gt;&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#flatMapValues(scala.Function1)"><B>flatMapValues(Function1&lt;V, TraversableOnce&lt;U&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#flatMapValues(org.apache.spark.api.java.function.Function)"><B>flatMapValues(Function&lt;V, Iterable&lt;U&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#flatMapValues(scala.Function1, scala.reflect.ClassTag)"><B>flatMapValues(Function1&lt;V, TraversableOnce&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)"><B>flatMapWith(Function1&lt;Object, A&gt;, boolean, Function2&lt;T, A, Seq&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>FlatMaps f over this RDD, where f takes an additional parameter of type A.
<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param"><B>FloatParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Float</CODE>] for Java.<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html#FloatParam(java.lang.String, java.lang.String, java.lang.String, scala.Function1)"><B>FloatParam(String, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param">FloatParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html#FloatParam(java.lang.String, java.lang.String, java.lang.String)"><B>FloatParam(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param">FloatParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html#FloatParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String, scala.Function1)"><B>FloatParam(org.apache.spark.ml.util.Identifiable, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param">FloatParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html#FloatParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>FloatParam(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param">FloatParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#floatToFloatWritable(float)"><B>floatToFloatWritable(float)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#FloatType"><B>FloatType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the FloatType object.
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types"><B>FloatType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Float</code> values.<DT><A HREF="./org/apache/spark/SparkContext.html#floatWritableConverter()"><B>floatWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#floor(org.apache.spark.sql.Column)"><B>floor(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the floor of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#floor(java.lang.String)"><B>floor(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the floor of the given column.
<DT><A HREF="./org/apache/spark/streaming/Time.html#floor(org.apache.spark.streaming.Duration)"><B>floor(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#floor(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Time)"><B>floor(Duration, Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume"><B>FlumeUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/flume/package-summary.html">org.apache.spark.streaming.flume</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html#FlumeUtils()"><B>FlumeUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#flush()"><B>flush()</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#flush()"><B>flush()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#flush()"><B>flush()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure(double, double)"><B>fMeasure(double, double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns f-measure for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure(double)"><B>fMeasure(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns f1-measure for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure()"><B>fMeasure()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns f-measure
 (equals to precision and recall because precision equals recall)
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#fMeasureByThreshold(double)"><B>fMeasureByThreshold(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the (threshold, F-Measure) curve.
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#fMeasureByThreshold()"><B>fMeasureByThreshold()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the (threshold, F-Measure) curve with beta = 1.0.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#fold(T, org.apache.spark.api.java.function.Function2)"><B>fold(T, Function2&lt;T, T, T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative and commutative function and a neutral "zero value".
<DT><A HREF="./org/apache/spark/rdd/RDD.html#fold(T, scala.Function2)"><B>fold(T, Function2&lt;T, T, T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative and commutative function and a neutral "zero value".
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2)"><B>foldByKey(V, Partitioner, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g ., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, int, org.apache.spark.api.java.function.Function2)"><B>foldByKey(V, int, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g ., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, org.apache.spark.api.java.function.Function2)"><B>foldByKey(V, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value"
 which may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, org.apache.spark.Partitioner, scala.Function2)"><B>foldByKey(V, Partitioner, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, int, scala.Function2)"><B>foldByKey(V, int, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, scala.Function2)"><B>foldByKey(V, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#foreach(org.apache.spark.api.java.function.VoidFunction)"><B>foreach(VoidFunction&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Applies a function f to all elements of this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#foreach(scala.Function1)"><B>foreach(Function1&lt;T, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Applies a function f to all elements of this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#foreach(scala.Function1)"><B>foreach(Function1&lt;Row, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Applies a function <code>f</code> to all rows.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function)"><B>foreach(Function&lt;R, Void&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of release 0.9.0, replaced by foreachRDD</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function2)"><B>foreach(Function2&lt;R, Time, Void&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of release 0.9.0, replaced by foreachRDD</I>
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function1)"><B>foreach(Function1&lt;RDD&lt;T&gt;, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 0.9.0, replaced by <code>foreachRDD</code>.</I>
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function2)"><B>foreach(Function2&lt;RDD&lt;T&gt;, Time, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 0.9.0, replaced by <code>foreachRDD</code>.</I>
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#foreachActive(scala.Function3)"><B>foreachActive(Function3&lt;Object, Object, Object, BoxedUnit&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Applies a function <code>f</code> to all the active elements of dense and sparse matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#foreachActive(scala.Function2)"><B>foreachActive(Function2&lt;Object, Object, BoxedUnit&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Applies a function <code>f</code> to all the active elements of dense and sparse vector.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#foreachAsync(org.apache.spark.api.java.function.VoidFunction)"><B>foreachAsync(VoidFunction&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The asynchronous version of the <code>foreach</code> action, which
 applies a function f to all the elements of this RDD.
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#foreachAsync(scala.Function1)"><B>foreachAsync(Function1&lt;T, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>Applies a function f to all elements of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#foreachPartition(org.apache.spark.api.java.function.VoidFunction)"><B>foreachPartition(VoidFunction&lt;Iterator&lt;T&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Applies a function f to each partition of this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)"><B>foreachPartition(Function1&lt;Iterator&lt;T&gt;, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Applies a function f to each partition of this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#foreachPartition(scala.Function1)"><B>foreachPartition(Function1&lt;Iterator&lt;Row&gt;, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Applies a function f to each partition of this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#foreachPartitionAsync(org.apache.spark.api.java.function.VoidFunction)"><B>foreachPartitionAsync(VoidFunction&lt;Iterator&lt;T&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The asynchronous version of the <code>foreachPartition</code> action, which
 applies a function f to each partition of this RDD.
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#foreachPartitionAsync(scala.Function1)"><B>foreachPartitionAsync(Function1&lt;Iterator&lt;T&gt;, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>Applies a function f to each partition of this RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreachRDD(org.apache.spark.api.java.function.Function)"><B>foreachRDD(Function&lt;R, Void&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Apply a function to each RDD in this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreachRDD(org.apache.spark.api.java.function.Function2)"><B>foreachRDD(Function2&lt;R, Time, Void&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Apply a function to each RDD in this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#foreachRDD(scala.Function1)"><B>foreachRDD(Function1&lt;RDD&lt;T&gt;, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Apply a function to each RDD in this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#foreachRDD(scala.Function2)"><B>foreachRDD(Function2&lt;RDD&lt;T&gt;, Time, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Apply a function to each RDD in this DStream.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1, scala.Function2)"><B>foreachWith(Function1&lt;Object, A&gt;, Function2&lt;T, A, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Applies f to each element of this RDD, where f takes an additional parameter of type A.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#format(java.lang.String)"><B>format(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Specifies the input data source format.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#format(java.lang.String)"><B>format(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Specifies the underlying output data source.
<DT><A HREF="./org/apache/spark/mllib/util/Saveable.html#formatVersion()"><B>formatVersion()</B></A> - 
Method in interface org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/Saveable.html" title="interface in org.apache.spark.mllib.util">Saveable</A>
<DD>Current version of model save/load format.
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm"><B>FPGrowth</B></A> - Class in <A HREF="./org/apache/spark/mllib/fpm/package-summary.html">org.apache.spark.mllib.fpm</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html#FPGrowth()"><B>FPGrowth()</B></A> - 
Constructor for class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm">FPGrowth</A>
<DD>Constructs a default instance with default parameters {minSupport: <code>0.3</code>, numPartitions: same
 as the input data}.
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="class in org.apache.spark.mllib.fpm"><B>FPGrowth.FreqItemset</B></A>&lt;<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="type parameter in FPGrowth.FreqItemset">Item</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/fpm/package-summary.html">org.apache.spark.mllib.fpm</A><DD>Frequent itemset.<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html#FPGrowth.FreqItemset(java.lang.Object, long)"><B>FPGrowth.FreqItemset(Object, long)</B></A> - 
Constructor for class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="class in org.apache.spark.mllib.fpm">FPGrowth.FreqItemset</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html" title="class in org.apache.spark.mllib.fpm"><B>FPGrowthModel</B></A>&lt;<A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html" title="type parameter in FPGrowthModel">Item</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/fpm/package-summary.html">org.apache.spark.mllib.fpm</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html#FPGrowthModel(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>FPGrowthModel(RDD&lt;FPGrowth.FreqItemset&lt;Item&gt;&gt;, ClassTag&lt;Item&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html" title="class in org.apache.spark.mllib.fpm">FPGrowthModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#fractional()"><B>fractional()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#fractional()"><B>fractional()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#fractional()"><B>fractional()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html#freq()"><B>freq()</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="class in org.apache.spark.mllib.fpm">FPGrowth.FreqItemset</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(java.lang.String[], double)"><B>freqItems(String[], double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Finding frequent items for columns, possibly with false positives.
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(java.lang.String[])"><B>freqItems(String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>Finding frequent items for columns, possibly with false positives.
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(scala.collection.Seq, double)"><B>freqItems(Seq&lt;String&gt;, double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>(Scala-specific) Finding frequent items for columns, possibly with false positives.
<DT><A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(scala.collection.Seq)"><B>freqItems(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</A>
<DD>(Scala-specific) Finding frequent items for columns, possibly with false positives.
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html#freqItemsets()"><B>freqItemsets()</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowthModel.html" title="class in org.apache.spark.mllib.fpm">FPGrowthModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#fromAvroFlumeEvent(org.apache.flume.source.avro.AvroFlumeEvent)"><B>fromAvroFlumeEvent(AvroFlumeEvent)</B></A> - 
Static method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#fromCaseClassString(java.lang.String)"><B>fromCaseClassString(String)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.2.0, replaced by <code>DataType.fromJson()</code></I>
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#fromCOO(int, int, scala.collection.Iterable)"><B>fromCOO(int, int, Iterable&lt;Tuple3&lt;Object, Object, Object&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate a <code>SparseMatrix</code> from Coordinate List (COO) format.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#fromDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>fromDStream(DStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Convert a scala <A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>DStream</CODE></A> to a Java-friendly
 <A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaDStream</CODE></A>.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#fromEdgePartitions(org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromEdgePartitions(RDD&lt;Tuple2&lt;Object, EdgePartition&lt;ED, VD&gt;&gt;&gt;, VD, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Create a graph from EdgePartitions, setting referenced vertices to `defaultVertexAttr`.
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#fromEdges(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromEdges(RDD&lt;Edge&lt;ED&gt;&gt;, ClassTag&lt;ED&gt;, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>Creates an EdgeRDD from a set of edges.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#fromEdges(org.apache.spark.rdd.RDD, VD, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromEdges(RDD&lt;Edge&lt;ED&gt;&gt;, VD, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Construct a graph from a collection of edges.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#fromEdges(org.apache.spark.graphx.EdgeRDD, int, VD, scala.reflect.ClassTag)"><B>fromEdges(EdgeRDD&lt;?&gt;, int, VD, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Constructs a <code>VertexRDD</code> containing all vertices referred to in <code>edges</code>.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#fromEdgeTuples(org.apache.spark.rdd.RDD, VD, scala.Option, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)"><B>fromEdgeTuples(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;, VD, Option&lt;PartitionStrategy&gt;, StorageLevel, StorageLevel, ClassTag&lt;VD&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Construct a graph from a collection of edges encoded as vertex id pairs.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#fromExistingRDDs(org.apache.spark.graphx.VertexRDD, org.apache.spark.graphx.EdgeRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromExistingRDDs(VertexRDD&lt;VD&gt;, EdgeRDD&lt;ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Create a graph from a VertexRDD and an EdgeRDD with the same replicated vertex type as the
 vertices.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html#fromInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag)"><B>fromInputDStream(InputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>
<DD>Convert a scala <A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>InputDStream</CODE></A> to a Java-friendly
 <A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaInputDStream</CODE></A>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#fromInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromInputDStream(InputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>
<DD>Convert a scala <A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>InputDStream</CODE></A> of pairs to a
 Java-friendly <A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaPairInputDStream</CODE></A>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fromJavaDStream(org.apache.spark.streaming.api.java.JavaDStream)"><B>fromJavaDStream(JavaDStream&lt;Tuple2&lt;K, V&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#fromJavaRDD(org.apache.spark.api.java.JavaRDD)"><B>fromJavaRDD(JavaRDD&lt;Tuple2&lt;K, V&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Convert a JavaRDD of key-value pairs to JavaPairRDD.
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#fromJson(java.lang.String)"><B>fromJson(String)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#fromJson(java.lang.String)"><B>fromJson(String)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Creates a Metadata instance from JSON.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#fromName(java.lang.String)"><B>fromName(String)</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>Gets the <A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute"><CODE>AttributeType</CODE></A> object from its name.
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#fromOffset()"><B>fromOffset()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>inclusive starting offset
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html#fromOld(org.apache.spark.mllib.tree.model.DecisionTreeModel, org.apache.spark.ml.classification.DecisionTreeClassifier, scala.collection.immutable.Map)"><B>fromOld(DecisionTreeModel, DecisionTreeClassifier, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassificationModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#fromOld(org.apache.spark.mllib.tree.model.GradientBoostedTreesModel, org.apache.spark.ml.classification.GBTClassifier, scala.collection.immutable.Map)"><B>fromOld(GradientBoostedTreesModel, GBTClassifier, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#fromOld(org.apache.spark.mllib.tree.model.RandomForestModel, org.apache.spark.ml.classification.RandomForestClassifier, scala.collection.immutable.Map)"><B>fromOld(RandomForestModel, RandomForestClassifier, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html#fromOld(org.apache.spark.mllib.tree.model.DecisionTreeModel, org.apache.spark.ml.regression.DecisionTreeRegressor, scala.collection.immutable.Map)"><B>fromOld(DecisionTreeModel, DecisionTreeRegressor, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressionModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#fromOld(org.apache.spark.mllib.tree.model.GradientBoostedTreesModel, org.apache.spark.ml.regression.GBTRegressor, scala.collection.immutable.Map)"><B>fromOld(GradientBoostedTreesModel, GBTRegressor, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#fromOld(org.apache.spark.mllib.tree.model.RandomForestModel, org.apache.spark.ml.regression.RandomForestRegressor, scala.collection.immutable.Map)"><B>fromOld(RandomForestModel, RandomForestRegressor, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>(private[ml]) Convert a model from the old API
<DT><A HREF="./org/apache/spark/ml/tree/Node.html#fromOld(org.apache.spark.mllib.tree.model.Node, scala.collection.immutable.Map)"><B>fromOld(Node, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Node.html" title="class in org.apache.spark.ml.tree">Node</A>
<DD>Create a new Node from the old Node format, recursively creating child nodes as needed.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fromPairDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromPairDStream(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html#fromPairRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromPairRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="class in org.apache.spark.mllib.rdd">MLPairRDDFunctions</A>
<DD>Implicit conversion from a pair RDD to MLPairRDDFunctions.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#fromRDD(org.apache.spark.rdd.RDD)"><B>fromRDD(RDD&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#fromRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#fromRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>fromRDD(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html#fromRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>fromRDD(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd">RDDFunctions</A>
<DD>Implicit conversion from an RDD to RDDFunctions.
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#fromRdd(org.apache.spark.rdd.RDD)"><B>fromRdd(RDD&lt;?&gt;)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#fromReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>fromReceiverInputDStream(ReceiverInputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</A>
<DD>Convert a scala <A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>ReceiverInputDStream</CODE></A> to a Java-friendly
 <A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaReceiverInputDStream</CODE></A>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#fromReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag)"><B>fromReceiverInputDStream(ReceiverInputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>
<DD>Convert a scala <A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>ReceiverInputDStream</CODE></A> to a Java-friendly
 <A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><CODE>JavaReceiverInputDStream</CODE></A>.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#fromSparkContext(org.apache.spark.SparkContext)"><B>fromSparkContext(SparkContext)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#fromStage(org.apache.spark.scheduler.Stage, scala.Option)"><B>fromStage(Stage, Option&lt;Object&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>Construct a StageInfo from a Stage.
<DT><A HREF="./org/apache/spark/JobExecutionStatus.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in enum org.apache.spark.<A HREF="./org/apache/spark/JobExecutionStatus.html" title="enum in org.apache.spark">JobExecutionStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/loss/Losses.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/Losses.html" title="class in org.apache.spark.mllib.tree.loss">Losses</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html" title="enum in org.apache.spark.status.api.v1">ApplicationStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageStatus.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageStatus.html" title="enum in org.apache.spark.status.api.v1">StageStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskSorting.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskSorting.html" title="enum in org.apache.spark.status.api.v1">TaskSorting</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#fromString(java.lang.String)"><B>fromString(String)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Return the StorageLevel object with the specified name.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#fromStructField(org.apache.spark.sql.types.StructField)"><B>fromStructField(StructField)</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Creates an attribute group from a <CODE>StructField</CODE> instance.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#fullOuterJoin(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>fullOuterJoin(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#fullOuterJoin(org.apache.spark.api.java.JavaPairRDD)"><B>fullOuterJoin(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#fullOuterJoin(org.apache.spark.api.java.JavaPairRDD, int)"><B>fullOuterJoin(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#fullOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>fullOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#fullOuterJoin(org.apache.spark.rdd.RDD)"><B>fullOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#fullOuterJoin(org.apache.spark.rdd.RDD, int)"><B>fullOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a full outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fullOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>fullOuterJoin(JavaPairDStream&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fullOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, int)"><B>fullOuterJoin(JavaPairDStream&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fullOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)"><B>fullOuterJoin(JavaPairDStream&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>fullOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><B>fullOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>fullOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#fullStackTrace()"><B>fullStackTrace()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function"><B>Function</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/Function.html" title="type parameter in Function">T1</A>,<A HREF="./org/apache/spark/api/java/function/Function.html" title="type parameter in Function">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>Base interface for functions whose return types do not create special RDDs.<DT><A HREF="./org/apache/spark/api/java/function/Function0.html" title="interface in org.apache.spark.api.java.function"><B>Function0</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/Function0.html" title="type parameter in Function0">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A zero-argument function that returns an R.<DT><A HREF="./org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function"><B>Function2</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">T1</A>,<A HREF="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">T2</A>,<A HREF="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A two-argument function that takes arguments of type T1 and T2 and returns an R.<DT><A HREF="./org/apache/spark/api/java/function/Function3.html" title="interface in org.apache.spark.api.java.function"><B>Function3</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T1</A>,<A HREF="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T2</A>,<A HREF="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T3</A>,<A HREF="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">R</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A three-argument function that takes arguments of type T1, T2 and T3 and returns an R.<DT><A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql"><B>functions</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/functions.html#functions()"><B>functions()</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><B>FutureAction</B></A>&lt;<A HREF="./org/apache/spark/FutureAction.html" title="type parameter in FutureAction">T</A>&gt; - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A future for the result of an action to support cancellation.<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#futureExecutionContext()"><B>futureExecutionContext()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_G_"><!-- --></A><H2>
<B>G</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#gain()"><B>gain()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#gain()"><B>gain()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#gamma1()"><B>gamma1()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#gamma2()"><B>gamma2()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#gamma6()"><B>gamma6()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#gamma7()"><B>gamma7()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random"><B>GammaGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#GammaGenerator(double, double)"><B>GammaGenerator(double, double)</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><B>gammaJavaRDD(JavaSparkContext, double, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaRDD(org.apache.spark.SparkContext, double, double, long, int, long)"><CODE>RandomRDDs.gammaRDD(org.apache.spark.SparkContext, double, double, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int)"><B>gammaJavaRDD(JavaSparkContext, double, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><CODE>RandomRDDs.gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long)"><B>gammaJavaRDD(JavaSparkContext, double, double, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><CODE>RandomRDDs.gammaJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><B>gammaJavaVectorRDD(JavaSparkContext, double, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.gammaVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int)"><B>gammaJavaVectorRDD(JavaSparkContext, double, double, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int)"><B>gammaJavaVectorRDD(JavaSparkContext, double, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.gammaJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaRDD(org.apache.spark.SparkContext, double, double, long, int, long)"><B>gammaRDD(SparkContext, double, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the gamma distribution with the input
  shape and scale.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#gammaVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)"><B>gammaVectorRDD(SparkContext, double, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from the
 gamma distribution with the input shape and scale.
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#gaps()"><B>gaps()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>Indicates whether regex splits on gaps (true) or matches tokens (false).
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering"><B>GaussianMixture</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#GaussianMixture()"><B>GaussianMixture()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Constructs a default instance.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering"><B>GaussianMixtureModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#GaussianMixtureModel(double[], org.apache.spark.mllib.stat.distribution.MultivariateGaussian[])"><B>GaussianMixtureModel(double[], MultivariateGaussian[])</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#gaussians()"><B>gaussians()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification"><B>GBTClassificationModel</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Gradient-Boosted Trees (GBTs)</CODE>
 model for classification.<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#GBTClassificationModel(java.lang.String, org.apache.spark.ml.regression.DecisionTreeRegressionModel[], double[])"><B>GBTClassificationModel(String, DecisionTreeRegressionModel[], double[])</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification"><B>GBTClassifier</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Gradient-Boosted Trees (GBTs)</CODE>
 learning algorithm for classification.<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#GBTClassifier(java.lang.String)"><B>GBTClassifier(String)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#GBTClassifier()"><B>GBTClassifier()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression"><B>GBTRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#GBTRegressionModel(java.lang.String, org.apache.spark.ml.regression.DecisionTreeRegressionModel[], double[])"><B>GBTRegressionModel(String, DecisionTreeRegressionModel[], double[])</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression"><B>GBTRegressor</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 <CODE>Gradient-Boosted Trees (GBTs)</CODE>
 learning algorithm for regression.<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#GBTRegressor(java.lang.String)"><B>GBTRegressor(String)</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#GBTRegressor()"><B>GBTRegressor()</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression"><B>GeneralizedLinearAlgorithm</B></A>&lt;<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="type parameter in GeneralizedLinearAlgorithm">M</A> extends <A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>:: DeveloperApi ::
 GeneralizedLinearAlgorithm implements methods to train a Generalized Linear Model (GLM).<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#GeneralizedLinearAlgorithm()"><B>GeneralizedLinearAlgorithm()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression"><B>GeneralizedLinearModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>:: DeveloperApi ::
 GeneralizedLinearModel (GLM) represents a model trained using
 GeneralizedLinearAlgorithm.<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#GeneralizedLinearModel(org.apache.spark.mllib.linalg.Vector, double)"><B>GeneralizedLinearModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html#generate(java.lang.String, java.lang.String, int, int)"><B>generate(String, String, int, int)</B></A> - 
Static method in class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html" title="class in org.apache.spark.examples.streaming">KinesisWordProducerASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#generatedRDDs()"><B>generatedRDDs()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html#generateKMeansRDD(org.apache.spark.SparkContext, int, int, int, double, int)"><B>generateKMeansRDD(SparkContext, int, int, int, double, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</A>
<DD>Generate an RDD containing test data for KMeans.
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearInput(double, double[], int, int, double)"><B>generateLinearInput(double, double[], int, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>For compatibility, the generated data without specifying the mean and variance
 will have zero mean and variance of (1.0/3.0) since the original output range is
 [-1, 1] with uniform distribution, and the variance of uniform distribution
 is (b - a)^2^ / 12 which will be (1.0/3.0)
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearInput(double, double[], double[], double[], int, int, double)"><B>generateLinearInput(double, double[], double[], double[], int, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearInputAsList(double, double[], int, int, double)"><B>generateLinearInputAsList(double, double[], int, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>Return a Java List of synthetic data randomly generated according to a multi
 collinear model.
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearRDD(org.apache.spark.SparkContext, int, int, double, int, double)"><B>generateLinearRDD(SparkContext, int, int, double, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>Generate an RDD containing sample data for Linear Regression models - including Ridge, Lasso,
 and uregularized variants.
<DT><A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#generateLogisticRDD(org.apache.spark.SparkContext, int, int, double, int, double)"><B>generateLogisticRDD(SparkContext, int, int, double, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</A>
<DD>Generate an RDD containing test data for LogisticRegression.
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#generateRandomEdges(int, int, int, long)"><B>generateRandomEdges(int, int, int, long)</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#geq(java.lang.Object)"><B>geq(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Greater than or equal to an expression.
<DT><A HREF="./org/apache/spark/FutureAction.html#get()"><B>get()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Blocks and returns the result of this job.
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#get(org.apache.spark.ml.param.Param)"><B>get(Param&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Optionally returns the value associated with a param.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#get(org.apache.spark.ml.param.Param)"><B>get(Param&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Optionally returns the user-supplied value of a param.
<DT><A HREF="./org/apache/spark/SparkConf.html#get(java.lang.String)"><B>get(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter; throws a NoSuchElementException if it's not set
<DT><A HREF="./org/apache/spark/SparkConf.html#get(java.lang.String, java.lang.String)"><B>get(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter, falling back to a default if not set
<DT><A HREF="./org/apache/spark/SparkEnv.html#get()"><B>get()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>Returns the SparkEnv.
<DT><A HREF="./org/apache/spark/SparkFiles.html#get(java.lang.String)"><B>get(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</A>
<DD>Get the absolute path of a file added through <code>SparkContext.addFile()</code>.
<DT><A HREF="./org/apache/spark/sql/Row.html#get(int)"><B>get(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i.
<DT><A HREF="./org/apache/spark/TaskContext.html#get()"><B>get()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Return the currently active TaskContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#getActive()"><B>getActive()</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html#getActiveJobIds()"><B>getActiveJobIds()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java">JavaSparkStatusTracker</A>
<DD>Returns an array containing the ids of all active jobs.
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html#getActiveJobIds()"><B>getActiveJobIds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark">SparkStatusTracker</A>
<DD>Returns an array containing the ids of all active jobs.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#getActiveOrCreate(scala.Function0)"><B>getActiveOrCreate(Function0&lt;StreamingContext&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#getActiveOrCreate(java.lang.String, scala.Function0, org.apache.hadoop.conf.Configuration, boolean)"><B>getActiveOrCreate(String, Function0&lt;StreamingContext&gt;, Configuration, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>:: Experimental ::
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html#getActiveStageIds()"><B>getActiveStageIds()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java">JavaSparkStatusTracker</A>
<DD>Returns an array containing the ids of all active stages.
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html#getActiveStageIds()"><B>getActiveStageIds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark">SparkStatusTracker</A>
<DD>Returns an array containing the ids of all active stages.
<DT><A HREF="./org/apache/spark/SparkConf.html#getAkkaConf()"><B>getAkkaConf()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get all akka conf variables set on this SparkConf
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getAlgo()"><B>getAlgo()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#getAll()"><B>getAll()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get all parameters as a list of pairs
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#getAllConfs()"><B>getAllConfs()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Return all the configuration properties that have been set (i.e.
<DT><A HREF="./org/apache/spark/SparkContext.html#getAllPools()"><B>getAllPools()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Return pools for fair scheduler
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getAlpha()"><B>getAlpha()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Alias for <CODE>getDocConcentration</CODE>
<DT><A HREF="./org/apache/spark/SparkConf.html#getAppId()"><B>getAppId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Returns the Spark application id, valid in the Driver after TaskScheduler registration and
 from the start in the Executor.
<DT><A HREF="./org/apache/spark/sql/Row.html#getAs(int)"><B>getAs(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i.
<DT><A HREF="./org/apache/spark/sql/Row.html#getAs(java.lang.String)"><B>getAs(String)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value of a given fieldName.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#getAttr(java.lang.String)"><B>getAttr(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Gets an attribute by its name.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#getAttr(int)"><B>getAttr(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Gets an attribute by its index.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getBeta()"><B>getBeta()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Alias for <CODE>getTopicConcentration</CODE>
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#getBlock(org.apache.spark.storage.BlockId)"><B>getBlock(BlockId)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the given block stored in this block manager in O(1) time.
<DT><A HREF="./org/apache/spark/SparkConf.html#getBoolean(java.lang.String, boolean)"><B>getBoolean(String, boolean)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter as a boolean, falling back to a default if not set
<DT><A HREF="./org/apache/spark/sql/Row.html#getBoolean(int)"><B>getBoolean(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive boolean.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getBoolean(java.lang.String)"><B>getBoolean(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Boolean.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getBooleanArray(java.lang.String)"><B>getBooleanArray(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Boolean array.
<DT><A HREF="./org/apache/spark/sql/Row.html#getByte(int)"><B>getByte(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive byte.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#getBytes()"><B>getBytes()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#getCachedBlockManagerId(org.apache.spark.storage.BlockManagerId)"><B>getCachedBlockManagerId(BlockManagerId)</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#getCachedMetadata(java.lang.String)"><B>getCachedMetadata(String)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>The three methods below are helpers for accessing the local map, a property of the SparkEnv of
 the local process.
<DT><A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html#getCatalystType(int, java.lang.String, int, org.apache.spark.sql.types.MetadataBuilder)"><B>getCatalystType(int, String, int, MetadataBuilder)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html" title="class in org.apache.spark.sql.jdbc">AggregatedDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html#getCatalystType(int, java.lang.String, int, org.apache.spark.sql.types.MetadataBuilder)"><B>getCatalystType(int, String, int, MetadataBuilder)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc">JdbcDialect</A>
<DD>Get the custom datatype mapping for the given jdbc meta information.
<DT><A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html#getCatalystType(int, java.lang.String, int, org.apache.spark.sql.types.MetadataBuilder)"><B>getCatalystType(int, String, int, MetadataBuilder)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html" title="class in org.apache.spark.sql.jdbc">MySQLDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html#getCatalystType(int, java.lang.String, int, org.apache.spark.sql.types.MetadataBuilder)"><B>getCatalystType(int, String, int, MetadataBuilder)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html" title="class in org.apache.spark.sql.jdbc">PostgresDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getCategoricalFeaturesInfo()"><B>getCategoricalFeaturesInfo()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html#getCategoryMaps()"><B>getCategoryMaps()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html" title="class in org.apache.spark.ml.feature">VectorIndexer.CategoryStats</A>
<DD>Based on stats collected, decide which features are categorical,
 and choose indices for categories.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#getCheckpointDir()"><B>getCheckpointDir()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#getCheckpointDir()"><B>getCheckpointDir()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#getCheckpointFile()"><B>getCheckpointFile()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Gets the name of the file to which this RDD was checkpointed
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#getCheckpointFile()"><B>getCheckpointFile()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#getCheckpointFile()"><B>getCheckpointFile()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#getCheckpointFile()"><B>getCheckpointFile()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Gets the name of the file to which this RDD was checkpointed
<DT><A HREF="./org/apache/spark/graphx/Graph.html#getCheckpointFiles()"><B>getCheckpointFiles()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Gets the name of the files to which this Graph was checkpointed.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#getCheckpointFiles()"><B>getCheckpointFiles()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getCheckpointInterval()"><B>getCheckpointInterval()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Period (in iterations) between checkpoints.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getCheckpointInterval()"><B>getCheckpointInterval()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#getConf()"><B>getConf()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Return a copy of this JavaSparkContext's configuration.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#getConf()"><B>getConf()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#getConf()"><B>getConf()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#getConf()"><B>getConf()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Return a copy of this SparkContext's configuration.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#getConf(java.lang.String)"><B>getConf(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Return the value of Spark SQL configuration property for the given key.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#getConf(java.lang.String, java.lang.String)"><B>getConf(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Return the value of Spark SQL configuration property for the given key.
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html#getConnection()"><B>getConnection()</B></A> - 
Method in interface org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#getConvergenceTol()"><B>getConvergenceTol()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Return the largest change in log-likelihood at which convergence is
 considered to have occurred.
<DT><A HREF="./org/apache/spark/sql/Row.html#getDate(int)"><B>getDate(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of date type as java.sql.Date.
<DT><A HREF="./org/apache/spark/sql/Row.html#getDecimal(int)"><B>getDecimal(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of decimal type as java.math.BigDecimal.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#getDefault(org.apache.spark.ml.param.Param)"><B>getDefault(Param&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Gets the default value of a parameter.
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#getDegree()"><B>getDegree()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#getDependencies()"><B>getDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#getDependencies()"><B>getDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#getDependencies()"><B>getDependencies()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#getDeprecatedConfig(java.lang.String, org.apache.spark.SparkConf)"><B>getDeprecatedConfig(String, SparkConf)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Looks for available deprecated keys for the given config option, and return the first
 value available.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getDocConcentration()"><B>getDocConcentration()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Concentration parameter (commonly named "alpha") for the prior placed on documents'
 distributions over topics ("theta").
<DT><A HREF="./org/apache/spark/SparkConf.html#getDouble(java.lang.String, double)"><B>getDouble(String, double)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter as a double, falling back to a default if not set
<DT><A HREF="./org/apache/spark/sql/Row.html#getDouble(int)"><B>getDouble(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive double.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getDouble(java.lang.String)"><B>getDouble(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Double.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getDoubleArray(java.lang.String)"><B>getDoubleArray(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Double array.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getEpsilon()"><B>getEpsilon()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>The distance threshold within which we've consider centers to have converged.
<DT><A HREF="./org/apache/spark/SparkConf.html#getExecutorEnv()"><B>getExecutorEnv()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get all executor environment variables set on this SparkConf
<DT><A HREF="./org/apache/spark/SparkContext.html#getExecutorMemoryStatus()"><B>getExecutorMemoryStatus()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Return a map from the slave to the max memory available for caching and the remaining
 memory available for caching.
<DT><A HREF="./org/apache/spark/SparkContext.html#getExecutorStorageStatus()"><B>getExecutorStorageStatus()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Return information about blocks stored in all of the slaves
<DT><A HREF="./org/apache/spark/sql/Column.html#getField(java.lang.String)"><B>getField(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>An expression that gets a field by name in a <CODE>StructType</CODE>.
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#getFinalValue()"><B>getFinalValue()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>Blocking method to wait for and return the final value.
<DT><A HREF="./org/apache/spark/sql/Row.html#getFloat(int)"><B>getFloat(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive float.
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#getGaps()"><B>getGaps()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getImpurity()"><B>getImpurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getInitializationMode()"><B>getInitializationMode()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>The initialization algorithm.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getInitializationSteps()"><B>getInitializationSteps()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Number of steps for the k-means|| initialization mode
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#getInitialModel()"><B>getInitialModel()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Return the user supplied initial GMM, if supplied
<DT><A HREF="./org/apache/spark/SparkConf.html#getInt(java.lang.String, int)"><B>getInt(String, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter as an integer, falling back to a default if not set
<DT><A HREF="./org/apache/spark/sql/Row.html#getInt(int)"><B>getInt(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive int.
<DT><A HREF="./org/apache/spark/sql/Column.html#getItem(java.lang.Object)"><B>getItem(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>An expression that gets an item at position <code>ordinal</code> out of an array,
 or gets a value by key <code>key</code> in a <CODE>MapType</CODE>.
<DT><A HREF="./org/apache/spark/sql/Row.html#getJavaMap(int)"><B>getJavaMap(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of array type as a <CODE>Map</CODE>.
<DT><A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html#getJDBCType(org.apache.spark.sql.types.DataType)"><B>getJDBCType(DataType)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/AggregatedDialect.html" title="class in org.apache.spark.sql.jdbc">AggregatedDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html#getJDBCType(org.apache.spark.sql.types.DataType)"><B>getJDBCType(DataType)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc">JdbcDialect</A>
<DD>Retrieve the jdbc / sql type for a given datatype.
<DT><A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html#getJDBCType(org.apache.spark.sql.types.DataType)"><B>getJDBCType(DataType)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html" title="class in org.apache.spark.sql.jdbc">PostgresDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html#getJobIdsForGroup(java.lang.String)"><B>getJobIdsForGroup(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java">JavaSparkStatusTracker</A>
<DD>Return a list of all known jobs in a particular job group.
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html#getJobIdsForGroup(java.lang.String)"><B>getJobIdsForGroup(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark">SparkStatusTracker</A>
<DD>Return a list of all known jobs in a particular job group.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html#getJobInfo(int)"><B>getJobInfo(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java">JavaSparkStatusTracker</A>
<DD>Returns job information, or <code>null</code> if the job info could not be found or was garbage collected.
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html#getJobInfo(int)"><B>getJobInfo(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark">SparkStatusTracker</A>
<DD>Returns job information, or <code>None</code> if the job info could not be found or was garbage collected.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#getK()"><B>getK()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Return the number of Gaussians in the mixture model
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getK()"><B>getK()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Number of clusters to create (k).
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getK()"><B>getK()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Number of topics to infer.
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#getKappa()"><B>getKappa()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>Learning rate: exponential decay rate
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#getLambda()"><B>getLambda()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Get the smoothing parameter.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html#getLDAModel(double[])"><B>getLDAModel(double[])</B></A> - 
Method in interface org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html" title="interface in org.apache.spark.mllib.clustering">LDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#getLearningRate()"><B>getLearningRate()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#getLeastGroupHash(java.lang.String)"><B>getLeastGroupHash(String)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>Sorts and gets the least element of the list associated with key in groupHash
 The returned PartitionGroup is the least loaded of all groups that represent the machine "key"
<DT><A HREF="./org/apache/spark/sql/Row.html#getList(int)"><B>getList(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of array type as <CODE>List</CODE>.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#getLocalProperty(java.lang.String)"><B>getLocalProperty(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get a local property set in this thread, or null if it is missing.
<DT><A HREF="./org/apache/spark/SparkContext.html#getLocalProperty(java.lang.String)"><B>getLocalProperty(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get a local property set in this thread, or null if it is missing.
<DT><A HREF="./org/apache/spark/SparkConf.html#getLong(java.lang.String, long)"><B>getLong(String, long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter as a long, falling back to a default if not set
<DT><A HREF="./org/apache/spark/sql/Row.html#getLong(int)"><B>getLong(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive long.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getLong(java.lang.String)"><B>getLong(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Long.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getLongArray(java.lang.String)"><B>getLongArray(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Long array.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#getLoss()"><B>getLoss()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#getLossType()"><B>getLossType()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#getLossType()"><B>getLossType()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#getMap(int)"><B>getMap(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of map type as a Scala Map.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getMaxBins()"><B>getMaxBins()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getMaxDepth()"><B>getMaxDepth()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#getMaxIterations()"><B>getMaxIterations()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Return the maximum number of iterations to run
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getMaxIterations()"><B>getMaxIterations()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Maximum number of iterations to run.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getMaxIterations()"><B>getMaxIterations()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Maximum number of iterations for learning.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getMaxMemoryInMB()"><B>getMaxMemoryInMB()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/AnalysisException.html#getMessage()"><B>getMessage()</B></A> - 
Method in exception org.apache.spark.sql.<A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getMetadata(java.lang.String)"><B>getMetadata(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Metadata.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getMetadataArray(java.lang.String)"><B>getMetadataArray(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a Metadata array.
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#getMetricName()"><B>getMetricName()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#getMetricName()"><B>getMetricName()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#getMiniBatchFraction()"><B>getMiniBatchFraction()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>Mini-batch fraction, which sets the fraction of document sampled and used in each iteration
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getMinInfoGain()"><B>getMinInfoGain()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getMinInstancesPerNode()"><B>getMinInstancesPerNode()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#getMinTokenLength()"><B>getMinTokenLength()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#getModelType()"><B>getModelType()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Get the model type.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#getNode(int, org.apache.spark.mllib.tree.model.Node)"><B>getNode(int, Node)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Traces down from a root node to get the node with the given node index.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getNumClasses()"><B>getNumClasses()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#getNumFeatures()"><B>getNumFeatures()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#getNumFeatures()"><B>getNumFeatures()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>The dimension of training features.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#getNumIterations()"><B>getNumIterations()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#getNumValues()"><B>getNumValues()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Get the number of values, either from <code>numValues</code> or from <code>values</code>.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getOptimizer()"><B>getOptimizer()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>:: DeveloperApi ::
<DT><A HREF="./org/apache/spark/SparkConf.html#getOption(java.lang.String)"><B>getOption(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a parameter as an Option
<DT><A HREF="./org/apache/spark/SparkContext.html#getOrCreate(org.apache.spark.SparkConf)"><B>getOrCreate(SparkConf)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>This function may be used to get or instantiate a SparkContext and register it as a
 singleton object.
<DT><A HREF="./org/apache/spark/SparkContext.html#getOrCreate()"><B>getOrCreate()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>This function may be used to get or instantiate a SparkContext and register it as a
 singleton object.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#getOrCreate(org.apache.spark.SparkContext)"><B>getOrCreate(SparkContext)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Get the singleton SQLContext if it exists or create a new one using the given SparkContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)"><B>getOrCreate(String, JavaStreamingContextFactory)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)"><B>getOrCreate(String, Configuration, JavaStreamingContextFactory)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory, boolean)"><B>getOrCreate(String, Configuration, JavaStreamingContextFactory, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>getOrCreate</code> without JavaStreamingContextFactor.</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0)"><B>getOrCreate(String, Function0&lt;JavaStreamingContext&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration)"><B>getOrCreate(String, Function0&lt;JavaStreamingContext&gt;, Configuration)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.api.java.function.Function0, org.apache.hadoop.conf.Configuration, boolean)"><B>getOrCreate(String, Function0&lt;JavaStreamingContext&gt;, Configuration, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#getOrCreate(java.lang.String, scala.Function0, org.apache.hadoop.conf.Configuration, boolean)"><B>getOrCreate(String, Function0&lt;StreamingContext&gt;, Configuration, boolean)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#getOrDefault(org.apache.spark.ml.param.Param)"><B>getOrDefault(Param&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Gets the value of a param in the embedded param map or its default value.
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#getOrElse(org.apache.spark.ml.param.Param, T)"><B>getOrElse(Param&lt;T&gt;, T)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Returns the value associated with a param or a default value.
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#getP()"><B>getP()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Params.html#getParam(java.lang.String)"><B>getParam(String)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Gets a param by its name.
<DT><A HREF="./org/apache/spark/NarrowDependency.html#getParents(int)"><B>getParents(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</A>
<DD>Get the parent partitions for a child partition.
<DT><A HREF="./org/apache/spark/OneToOneDependency.html#getParents(int)"><B>getParents(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark">OneToOneDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangeDependency.html#getParents(int)"><B>getParents(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark">RangeDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html#getPartition(long, long, int)"><B>getPartition(long, long, int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.CanonicalRandomVertexCut$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html#getPartition(long, long, int)"><B>getPartition(long, long, int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition1D$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html#getPartition(long, long, int)"><B>getPartition(long, long, int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition2D$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.html#getPartition(long, long, int)"><B>getPartition(long, long, int)</B></A> - 
Method in interface org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx">PartitionStrategy</A>
<DD>Returns the partition number for a given edge.
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html#getPartition(long, long, int)"><B>getPartition(long, long, int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.RandomVertexCut$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/HashPartitioner.html#getPartition(java.lang.Object)"><B>getPartition(Object)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partitioner.html#getPartition(java.lang.Object)"><B>getPartition(Object)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html#getPartition(java.lang.Object)"><B>getPartition(Object)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/BaseRRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/BaseRRDD.html" title="class in org.apache.spark.api.r">BaseRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#getPartitions()"><B>getPartitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/input/PortableDataStream.html#getPath()"><B>getPath()</B></A> - 
Method in class org.apache.spark.input.<A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input">PortableDataStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#getPattern()"><B>getPattern()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#getPersistentRDDs()"><B>getPersistentRDDs()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Returns an immutable map of RDDs that have marked themselves as persistent via cache() call.
<DT><A HREF="./org/apache/spark/SparkContext.html#getPoolForName(java.lang.String)"><B>getPoolForName(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Return the pool associated with the given name, if one exists
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#getPreferredLocations(org.apache.spark.Partition)"><B>getPreferredLocations(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#getPreferredLocations(org.apache.spark.Partition)"><B>getPreferredLocations(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#getPreferredLocations(org.apache.spark.Partition)"><B>getPreferredLocations(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getQuantileCalculationStrategy()"><B>getQuantileCalculationStrategy()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#getRDDStorageInfo()"><B>getRDDStorageInfo()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Return information about what RDDs are cached, if they are in mem or on disk, how much space
 they take, etc.
<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#getReceiver()"><B>getReceiver()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</A>
<DD>Gets the receiver object that will be sent to the worker nodes
 to receive data.
<DT><A HREF="./org/apache/spark/SparkFiles.html#getRootDirectory()"><B>getRootDirectory()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</A>
<DD>Get the root directory that contains files added through <code>SparkContext.addFile()</code>.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getRuns()"><B>getRuns()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>:: Experimental ::
 Number of runs of the algorithm to execute in parallel.
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#getScalingVec()"><B>getScalingVec()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#getSchedulingMode()"><B>getSchedulingMode()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Return current scheduling mode
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#getSeed()"><B>getSeed()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Return the random seed
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#getSeed()"><B>getSeed()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>The random seed for cluster initialization.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getSeed()"><B>getSeed()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Random seed
<DT><A HREF="./org/apache/spark/sql/Row.html#getSeq(int)"><B>getSeq(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of array type as a Scala Seq.
<DT><A HREF="./org/apache/spark/serializer/Serializer.html#getSerializer(org.apache.spark.serializer.Serializer)"><B>getSerializer(Serializer)</B></A> - 
Static method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/Serializer.html#getSerializer(scala.Option)"><B>getSerializer(Option&lt;Serializer&gt;)</B></A> - 
Static method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#getShort(int)"><B>getShort(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a primitive short.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsBytes(java.lang.String)"><B>getSizeAsBytes(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as bytes; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsBytes(java.lang.String, java.lang.String)"><B>getSizeAsBytes(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as bytes, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsGb(java.lang.String)"><B>getSizeAsGb(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Gibibytes; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsGb(java.lang.String, java.lang.String)"><B>getSizeAsGb(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Gibibytes, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsKb(java.lang.String)"><B>getSizeAsKb(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Kibibytes; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsKb(java.lang.String, java.lang.String)"><B>getSizeAsKb(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Kibibytes, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsMb(java.lang.String)"><B>getSizeAsMb(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Mebibytes; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getSizeAsMb(java.lang.String, java.lang.String)"><B>getSizeAsMb(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a size parameter as Mebibytes, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#getSparkHome()"><B>getSparkHome()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get Spark's home location from either a value set through the constructor,
 or the spark.home Java property, or the SPARK_HOME environment variable
 (in that order of preference).
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#getSplits()"><B>getSplits()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html#getStageInfo(int)"><B>getStageInfo(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java">JavaSparkStatusTracker</A>
<DD>Returns stage information, or <code>null</code> if the stage info could not be found or was
 garbage collected.
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html#getStageInfo(int)"><B>getStageInfo(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark">SparkStatusTracker</A>
<DD>Returns stage information, or <code>None</code> if the stage info could not be found or was
 garbage collected.
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#getStages()"><B>getStages()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getState()"><B>getState()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>:: DeveloperApi ::
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#getState()"><B>getState()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>:: DeveloperApi ::
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#getStorageLevel()"><B>getStorageLevel()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Get the RDD's current storage level, or StorageLevel.NONE if none is set.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#getStorageLevel()"><B>getStorageLevel()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#getStorageLevel()"><B>getStorageLevel()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#getStorageLevel()"><B>getStorageLevel()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Get the RDD's current storage level, or StorageLevel.NONE if none is set.
<DT><A HREF="./org/apache/spark/sql/Row.html#getString(int)"><B>getString(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i as a String object.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getString(java.lang.String)"><B>getString(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a String.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#getStringArray(java.lang.String)"><B>getStringArray(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Gets a String array.
<DT><A HREF="./org/apache/spark/sql/Row.html#getStruct(int)"><B>getStruct(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns the value at position i of struct type as an <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A> object.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getSubsamplingRate()"><B>getSubsamplingRate()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#getTau0()"><B>getTau0()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>A (positive) learning parameter that downweights early iterations.
<DT><A HREF="./org/apache/spark/SparkEnv.html#getThreadLocal()"><B>getThreadLocal()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>Returns the ThreadLocal SparkEnv.
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#getThreshold()"><B>getThreshold()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#getThreshold()"><B>getThreshold()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>:: Experimental ::
 Returns the threshold (if any) used for converting raw prediction scores into 0/1 predictions.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#getThreshold()"><B>getThreshold()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>:: Experimental ::
 Returns the threshold (if any) used for converting raw prediction scores into 0/1 predictions.
<DT><A HREF="./org/apache/spark/SparkConf.html#getTimeAsMs(java.lang.String)"><B>getTimeAsMs(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a time parameter as milliseconds; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getTimeAsMs(java.lang.String, java.lang.String)"><B>getTimeAsMs(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a time parameter as milliseconds, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getTimeAsSeconds(java.lang.String)"><B>getTimeAsSeconds(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a time parameter as seconds; throws a NoSuchElementException if it's not set.
<DT><A HREF="./org/apache/spark/SparkConf.html#getTimeAsSeconds(java.lang.String, java.lang.String)"><B>getTimeAsSeconds(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Get a time parameter as seconds, falling back to a default if not set.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#gettingResult()"><B>gettingResult()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#gettingResultTime()"><B>gettingResultTime()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>The time when the task started remotely getting the result.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#getTopicConcentration()"><B>getTopicConcentration()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Concentration parameter (commonly named "beta" or "eta") for the prior placed on topics'
 distributions over terms.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#getTreeStrategy()"><B>getTreeStrategy()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#getUseNodeIdCache()"><B>getUseNodeIdCache()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#getValidationTol()"><B>getValidationTol()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#getValue(int)"><B>getValue(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Gets a value given its index.
<DT><A HREF="./org/apache/spark/sql/Row.html#getValuesMap(scala.collection.Seq)"><B>getValuesMap(Seq&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Returns a Map(name -> value) for the requested fieldNames
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#getVectors()"><B>getVectors()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>Returns a map of words to their vector representations.
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity"><B>Gini</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</A><DD>:: Experimental ::
 Class for calculating the
 <CODE>Gini impurity</CODE>
 during binary classification.<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html#Gini()"><B>Gini()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#globalTopicTotals()"><B>globalTopicTotals()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>Aggregate distributions over topics from all term vertices.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#glom()"><B>glom()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD created by coalescing all elements within each partition into an array.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#glom()"><B>glom()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD created by coalescing all elements within each partition into an array.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#glom()"><B>glom()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying glom() to each RDD of
 this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#glom()"><B>glom()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying glom() to each RDD of
 this DStream.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#gradient()"><B>gradient()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#gradient()"><B>gradient()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization"><B>Gradient</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Class used to compute the gradient for a loss function, given a single data point.<DT><A HREF="./org/apache/spark/mllib/optimization/Gradient.html#Gradient()"><B>Gradient()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/loss/AbsoluteError.html#gradient(double, double)"><B>gradient(double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/AbsoluteError.html" title="class in org.apache.spark.mllib.tree.loss">AbsoluteError</A>
<DD>Method to calculate the gradients for the gradient boosting calculation for least
 absolute error calculation.
<DT><A HREF="./org/apache/spark/mllib/tree/loss/LogLoss.html#gradient(double, double)"><B>gradient(double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/LogLoss.html" title="class in org.apache.spark.mllib.tree.loss">LogLoss</A>
<DD>Method to calculate the loss gradients for the gradient boosting calculation for binary
 classification
 The gradient with respect to F(x) is: - 4 y / (1 + exp(2 y F(x)))
<DT><A HREF="./org/apache/spark/mllib/tree/loss/Loss.html#gradient(double, double)"><B>gradient(double, double)</B></A> - 
Method in interface org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/Loss.html" title="interface in org.apache.spark.mllib.tree.loss">Loss</A>
<DD>Method to calculate the gradients for the gradient boosting calculation.
<DT><A HREF="./org/apache/spark/mllib/tree/loss/SquaredError.html#gradient(double, double)"><B>gradient(double, double)</B></A> - 
Static method in class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/SquaredError.html" title="class in org.apache.spark.mllib.tree.loss">SquaredError</A>
<DD>Method to calculate the gradients for the gradient boosting calculation for least
 squares error calculation.
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree"><B>GradientBoostedTrees</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/package-summary.html">org.apache.spark.mllib.tree</A><DD>:: Experimental ::
 A class that implements
 <CODE>Stochastic Gradient Boosting</CODE>
 for regression and binary classification.<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#GradientBoostedTrees(org.apache.spark.mllib.tree.configuration.BoostingStrategy)"><B>GradientBoostedTrees(BoostingStrategy)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model"><B>GradientBoostedTreesModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: Experimental ::
 Represents a gradient boosted trees model.<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#GradientBoostedTreesModel(scala.Enumeration.Value, org.apache.spark.mllib.tree.model.DecisionTreeModel[], double[])"><B>GradientBoostedTreesModel(Enumeration.Value, DecisionTreeModel[], double[])</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization"><B>GradientDescent</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>Class used to solve an optimization problem using Gradient Descent.<DT><A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx"><B>Graph</B></A>&lt;<A HREF="./org/apache/spark/graphx/Graph.html" title="type parameter in Graph">VD</A>,<A HREF="./org/apache/spark/graphx/Graph.html" title="type parameter in Graph">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>The Graph abstractly represents a graph with arbitrary objects
 associated with vertices and edges.<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#graph()"><B>graph()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>The following fields will only be initialized through the initialize() method
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#graph()"><B>graph()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#graph()"><B>graph()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util"><B>GraphGenerators</B></A> - Class in <A HREF="./org/apache/spark/graphx/util/package-summary.html">org.apache.spark.graphx.util</A><DD>A collection of graph generating functions.<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#GraphGenerators()"><B>GraphGenerators()</B></A> - 
Constructor for class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl"><B>GraphImpl</B></A>&lt;<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="type parameter in GraphImpl">VD</A>,<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="type parameter in GraphImpl">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/impl/package-summary.html">org.apache.spark.graphx.impl</A><DD>An implementation of <A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx"><CODE>Graph</CODE></A> to support computation on graphs.<DT><A HREF="./org/apache/spark/graphx/GraphKryoRegistrator.html" title="class in org.apache.spark.graphx"><B>GraphKryoRegistrator</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Registers GraphX classes with Kryo for improved performance.<DT><A HREF="./org/apache/spark/graphx/GraphKryoRegistrator.html#GraphKryoRegistrator()"><B>GraphKryoRegistrator()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphKryoRegistrator.html" title="class in org.apache.spark.graphx">GraphKryoRegistrator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphLoader.html" title="class in org.apache.spark.graphx"><B>GraphLoader</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Provides utilities for loading <A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx"><CODE>Graph</CODE></A>s from files.<DT><A HREF="./org/apache/spark/graphx/GraphLoader.html#GraphLoader()"><B>GraphLoader()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphLoader.html" title="class in org.apache.spark.graphx">GraphLoader</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><B>GraphOps</B></A>&lt;<A HREF="./org/apache/spark/graphx/GraphOps.html" title="type parameter in GraphOps">VD</A>,<A HREF="./org/apache/spark/graphx/GraphOps.html" title="type parameter in GraphOps">ED</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Contains additional functionality for <A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx"><CODE>Graph</CODE></A>.<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#GraphOps(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>GraphOps(Graph&lt;VD, ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#graphToGraphOps(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>graphToGraphOps(Graph&lt;VD, ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Implicitly extracts the <A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> member from a graph.
<DT><A HREF="./org/apache/spark/graphx/GraphXUtils.html" title="class in org.apache.spark.graphx"><B>GraphXUtils</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/GraphXUtils.html#GraphXUtils()"><B>GraphXUtils()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphXUtils.html" title="class in org.apache.spark.graphx">GraphXUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#greater(org.apache.spark.streaming.Duration)"><B>greater(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#greater(org.apache.spark.streaming.Time)"><B>greater(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#greaterEq(org.apache.spark.streaming.Duration)"><B>greaterEq(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#greaterEq(org.apache.spark.streaming.Time)"><B>greaterEq(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThan.html" title="class in org.apache.spark.sql.sources"><B>GreaterThan</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a value
 greater than <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/GreaterThan.html#GreaterThan(java.lang.String, java.lang.Object)"><B>GreaterThan(String, Object)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThan.html" title="class in org.apache.spark.sql.sources">GreaterThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources"><B>GreaterThanOrEqual</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a value
 greater than or equal to <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html#GreaterThanOrEqual(java.lang.String, java.lang.Object)"><B>GreaterThanOrEqual(String, Object)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources">GreaterThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#gridGraph(org.apache.spark.SparkContext, int, int)"><B>gridGraph(SparkContext, int, int)</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>Create <code>rows</code> by <code>cols</code> grid graph with each vertex connected to its
 row+1 and col+1 neighbors.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#groupArr()"><B>groupArr()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function)"><B>groupBy(Function&lt;T, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD of grouped elements.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function, int)"><B>groupBy(Function&lt;T, U&gt;, int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD of grouped elements.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, scala.reflect.ClassTag)"><B>groupBy(Function1&lt;T, K&gt;, ClassTag&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD of grouped items.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, int, scala.reflect.ClassTag)"><B>groupBy(Function1&lt;T, K&gt;, int, ClassTag&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD of grouped elements.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, org.apache.spark.Partitioner, scala.reflect.ClassTag, scala.math.Ordering)"><B>groupBy(Function1&lt;T, K&gt;, Partitioner, ClassTag&lt;K&gt;, Ordering&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD of grouped items.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#groupBy(org.apache.spark.sql.Column...)"><B>groupBy(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Groups the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns, so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#groupBy(java.lang.String, java.lang.String...)"><B>groupBy(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Groups the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns, so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#groupBy(scala.collection.Seq)"><B>groupBy(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Groups the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns, so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#groupBy(java.lang.String, scala.collection.Seq)"><B>groupBy(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Groups the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns, so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey(org.apache.spark.Partitioner)"><B>groupByKey(Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey(int)"><B>groupByKey(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey()"><B>groupByKey()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(org.apache.spark.Partitioner)"><B>groupByKey(Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(int)"><B>groupByKey(int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey()"><B>groupByKey()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Group the values for each key in the RDD into a single sequence.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey()"><B>groupByKey()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey(int)"><B>groupByKey(int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey(org.apache.spark.Partitioner)"><B>groupByKey(Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> on each RDD of <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey()"><B>groupByKey()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(int)"><B>groupByKey(int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(org.apache.spark.Partitioner)"><B>groupByKey(Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> on each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration)"><B>groupByKeyAndWindow(Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>groupByKeyAndWindow(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><B>groupByKeyAndWindow(Duration, Duration, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><B>groupByKeyAndWindow(Duration, Duration, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration)"><B>groupByKeyAndWindow(Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>groupByKeyAndWindow(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><B>groupByKeyAndWindow(Duration, Duration, int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><B>groupByKeyAndWindow(Duration, Duration, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql"><B>GroupedData</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 A set of methods for aggregations on a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, created by <CODE>DataFrame.groupBy</CODE>.<DT><A HREF="./org/apache/spark/graphx/Graph.html#groupEdges(scala.Function2)"><B>groupEdges(Function2&lt;ED, ED, ED&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Merges multiple edges between two vertices into a single edge.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#groupEdges(scala.Function2)"><B>groupEdges(Function2&lt;ED, ED, ED&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#groupHash()"><B>groupHash()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD)"><B>groupWith(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)"><B>groupWith(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)"><B>groupWith(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD)"><B>groupWith(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>groupWith(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>groupWith(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Alias for cogroup.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#gt(double)"><B>gt(double)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check if value > lowerBound
<DT><A HREF="./org/apache/spark/sql/Column.html#gt(java.lang.Object)"><B>gt(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Greater than.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#gtEq(double)"><B>gtEq(double)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check if value >= lowerBound
</DL>
<HR>
<A NAME="_H_"><!-- --></A><H2>
<B>H</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#hadoopConfiguration()"><B>hadoopConfiguration()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Returns the Hadoop configuration used for the Hadoop code (e.g.
<DT><A HREF="./org/apache/spark/SparkContext.html#hadoopConfiguration()"><B>hadoopConfiguration()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>A default Hadoop Configuration for the Hadoop code (e.g.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>hadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop file with an arbitrary InputFormat.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>hadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop file with an arbitrary InputFormat
<DT><A HREF="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>hadoopFile(String, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a Hadoop file with an arbitrary InputFormat
<DT><A HREF="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, int, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>hadoopFile(String, int, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Smarter version of hadoopFile() that uses class tags to figure out the classes of keys,
 values and the InputFormat so that users don't need to pass them directly.
<DT><A HREF="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>hadoopFile(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Smarter version of hadoopFile() that uses class tags to figure out the classes of keys,
 values and the InputFormat so that users don't need to pass them directly.
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources"><B>HadoopFsRelation</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::Experimental::
 A <A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><CODE>BaseRelation</CODE></A> that provides much of the common code required for formats that store their
 data to an HDFS compatible filesystem.<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation()"><B>HadoopFsRelation()</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>HadoopFsRelationProvider</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::Experimental::
 Implemented by objects that produce relations for a specific kind of data source
 with a given schema and partitioned columns.<DT><A HREF="./org/apache/spark/SparkEnv.html#hadoopJobMetadata()"><B>hadoopJobMetadata()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>hadoopRDD(JobConf, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop-readable dataset from a Hadooop JobConf giving its InputFormat and any
 other necessary info (e.g.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class)"><B>hadoopRDD(JobConf, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop-readable dataset from a Hadooop JobConf giving its InputFormat and any
 other necessary info (e.g.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd"><B>HadoopRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</A>,<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the older MapReduce API (<code>org.apache.hadoop.mapred</code>).<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#HadoopRDD(org.apache.spark.SparkContext, org.apache.spark.broadcast.Broadcast, scala.Option, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>HadoopRDD(SparkContext, Broadcast&lt;SerializableWritable&lt;Configuration&gt;&gt;, Option&lt;Function1&lt;JobConf, BoxedUnit&gt;&gt;, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#HadoopRDD(org.apache.spark.SparkContext, org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>HadoopRDD(SparkContext, JobConf, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)"><B>hadoopRDD(JobConf, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a Hadoop-readable dataset from a Hadoop JobConf given its InputFormat and other
 necessary info (e.g.
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#hammingLoss()"><B>hammingLoss()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns Hamming-loss
<DT><A HREF="./org/apache/spark/util/SignalLoggerHandler.html#handle(sun.misc.Signal)"><B>handle(Signal)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/SignalLoggerHandler.html" title="class in org.apache.spark.util">SignalLoggerHandler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#hasAttr(java.lang.String)"><B>hasAttr(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Test whether this attribute group contains a specific attribute.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#hasDefault(org.apache.spark.ml.param.Param)"><B>hasDefault(Param&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Tests whether the input param has a default value set.
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/HashPartitioner.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#hashCode()"><B>hashCode()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Returns a hash code value for the vector.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partition.html#hashCode()"><B>hashCode()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#hashCode()"><B>hashCode()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#hashCode()"><B>hashCode()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature"><B>HashingTF</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Maps a sequence of terms to their term frequencies using the hashing trick.<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#HashingTF(java.lang.String)"><B>HashingTF(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#HashingTF()"><B>HashingTF()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature"><B>HashingTF</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Maps a sequence of terms to their term frequencies using the hashing trick.<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#HashingTF(int)"><B>HashingTF(int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#HashingTF()"><B>HashingTF()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark"><B>HashPartitioner</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A <A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><CODE>Partitioner</CODE></A> that implements hash-based partitioning using
 Java's <code>Object.hashCode</code>.<DT><A HREF="./org/apache/spark/HashPartitioner.html#HashPartitioner(int)"><B>HashPartitioner(int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/InterruptibleIterator.html#hasNext()"><B>hasNext()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#hasNext()"><B>hasNext()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html#hasNext()"><B>hasNext()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="class in org.apache.spark.streaming.receiver">CountingIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/HasOffsetRanges.html" title="interface in org.apache.spark.streaming.kafka"><B>HasOffsetRanges</B></A> - Interface in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>:: Experimental ::
 Represents any object that has a collection of <A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka"><CODE>OffsetRange</CODE></A>s.<DT><A HREF="./org/apache/spark/ml/param/Params.html#hasParam(java.lang.String)"><B>hasParam(String)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Tests whether this instance contains a param with a given name.
<DT><A HREF="./org/apache/spark/ml/Model.html#hasParent()"><B>hasParent()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>
<DD>Indicates whether this <A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml"><CODE>Model</CODE></A> has a corresponding parent.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#hasValue(java.lang.String)"><B>hasValue(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Tests whether this attribute contains a specific value.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#head(int)"><B>head(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the first <code>n</code> rows.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#head()"><B>head()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the first row.
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#high()"><B>high()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization"><B>HingeGradient</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Compute gradient and loss for a Hinge loss function, as used in SVM binary classification.<DT><A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html#HingeGradient()"><B>HingeGradient()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(int)"><B>histogram(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute a histogram of the data using bucketCount number of buckets evenly
  spaced between the minimum and maximum of the RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(double[])"><B>histogram(double[])</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute a histogram using the provided buckets.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(java.lang.Double[], boolean)"><B>histogram(Double[], boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#histogram(int)"><B>histogram(int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute a histogram of the data using bucketCount number of buckets evenly
  spaced between the minimum and maximum of the RDD.
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#histogram(double[], boolean)"><B>histogram(double[], boolean)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute a histogram using the provided buckets.
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_JARS()"><B>HIVE_METASTORE_JARS()</B></A> - 
Static method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_VERSION()"><B>HIVE_METASTORE_VERSION()</B></A> - 
Static method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive"><B>HiveContext</B></A> - Class in <A HREF="./org/apache/spark/sql/hive/package-summary.html">org.apache.spark.sql.hive</A><DD>An instance of the Spark SQL execution engine that integrates with data stored in Hive.<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#HiveContext(org.apache.spark.SparkContext)"><B>HiveContext(SparkContext)</B></A> - 
Constructor for class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#hiveExecutionVersion()"><B>hiveExecutionVersion()</B></A> - 
Static method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>The version of hive used internally by Spark SQL.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#horzcat(org.apache.spark.mllib.linalg.Matrix[])"><B>horzcat(Matrix[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Horizontally concatenate a sequence of matrices.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#host()"><B>host()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#host()"><B>host()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#host()"><B>host()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#host()"><B>host()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>Broker's hostname
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#hostLocation()"><B>hostLocation()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#hostPort()"><B>hostPort()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#hostPort()"><B>hostPort()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#hours()"><B>hours()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast"><B>HttpBroadcastFactory</B></A> - Class in <A HREF="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</A><DD>A <A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast"><CODE>BroadcastFactory</CODE></A> implementation that uses a
 HTTP server as the broadcast mechanism.<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html#HttpBroadcastFactory()"><B>HttpBroadcastFactory()</B></A> - 
Constructor for class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#httpFileServer()"><B>httpFileServer()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>hypot(Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, java.lang.String)"><B>hypot(Column, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(java.lang.String, org.apache.spark.sql.Column)"><B>hypot(String, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(java.lang.String, java.lang.String)"><B>hypot(String, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(org.apache.spark.sql.Column, double)"><B>hypot(Column, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(java.lang.String, double)"><B>hypot(String, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(double, org.apache.spark.sql.Column)"><B>hypot(double, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
<DT><A HREF="./org/apache/spark/sql/functions.html#hypot(double, java.lang.String)"><B>hypot(double, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes <code>sqrt(a^2^ + b^2^)</code> without intermediate overflow or underflow.
</DL>
<HR>
<A NAME="_I_"><!-- --></A><H2>
<B>I</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#i()"><B>i()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#id()"><B>id()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>A unique ID for this RDD (within its SparkContext).
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering.Assignment</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>A unique ID for this RDD (within its SparkContext).
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html" title="class in org.apache.spark.status.api.v1">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#id()"><B>id()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>This is an unique identifier for the input stream.
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature"><B>IDF</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Compute the Inverse Document Frequency (IDF) given a collection of documents.<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#IDF(java.lang.String)"><B>IDF(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#IDF()"><B>IDF()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature"><B>IDF</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Inverse document frequency (IDF).<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html#IDF(int)"><B>IDF(int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html#IDF()"><B>IDF()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#idf()"><B>idf()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>Returns the current IDF vector.
<DT><A HREF="./org/apache/spark/mllib/feature/IDFModel.html#idf()"><B>idf()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature"><B>IDF.DocumentFrequencyAggregator</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>Document frequency aggregator.<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#IDF.DocumentFrequencyAggregator(int)"><B>IDF.DocumentFrequencyAggregator(int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#IDF.DocumentFrequencyAggregator()"><B>IDF.DocumentFrequencyAggregator()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature"><B>IDFModel</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature"><B>IDFModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Represents an IDF model that can transform term frequency vectors.<DT><A HREF="./org/apache/spark/sql/SQLContext.html#implicits()"><B>implicits()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Accessor for nested Scala object
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/LeafNode.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/LeafNode.html" title="class in org.apache.spark.ml.tree">LeafNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/Node.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Node.html" title="class in org.apache.spark.ml.tree">Node</A>
<DD>Impurity measure at this node (for training data)
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity"><B>Impurity</B></A> - Interface in <A HREF="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</A><DD>:: Experimental ::
 Trait for calculating information gain.<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#impurity()"><B>impurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#In()"><B>In()</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>Edges arriving at a vertex.
<DT><A HREF="./org/apache/spark/sql/Column.html#in(org.apache.spark.sql.Column...)"><B>in(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>A boolean expression that is evaluated to true if the value of this expression is contained
 by the evaluated values of the arguments.
<DT><A HREF="./org/apache/spark/sql/Column.html#in(scala.collection.Seq)"><B>in(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>A boolean expression that is evaluated to true if the value of this expression is contained
 by the evaluated values of the arguments.
<DT><A HREF="./org/apache/spark/sql/sources/In.html" title="class in org.apache.spark.sql.sources"><B>In</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to one of the values in the array.<DT><A HREF="./org/apache/spark/sql/sources/In.html#In(java.lang.String, java.lang.Object[])"><B>In(String, Object[])</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/In.html" title="class in org.apache.spark.sql.sources">In</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#inArray(java.lang.Object)"><B>inArray(Object)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check for value in an allowed set of values.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#inArray(java.util.List)"><B>inArray(List&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check for value in an allowed set of values.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#inDegrees()"><B>inDegrees()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>The in-degree of each vertex in the graph.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Index of the attribute.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#index()"><B>index()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#index(int, int)"><B>index(int, int)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Return the index for the (i, j)-th element in the backing array.
<DT><A HREF="./org/apache/spark/Partition.html#index()"><B>index()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</A>
<DD>Get the partition's index within its parent RDD
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#index()"><B>index()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>IndexedRow</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>:: Experimental ::
 Represents a row of <A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><CODE>IndexedRowMatrix</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#IndexedRow(long, org.apache.spark.mllib.linalg.Vector)"><B>IndexedRow(long, Vector)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>IndexedRowMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#IndexedRowMatrix(org.apache.spark.rdd.RDD, long, int)"><B>IndexedRowMatrix(RDD&lt;IndexedRow&gt;, long, int)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#IndexedRowMatrix(org.apache.spark.rdd.RDD)"><B>IndexedRowMatrix(RDD&lt;IndexedRow&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#indexOf(java.lang.String)"><B>indexOf(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Index of an attribute specified by name.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#indexOf(java.lang.String)"><B>indexOf(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Index of a specific value.
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#indexOf(java.lang.Object)"><B>indexOf(Object)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>Returns the index of the input term.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#indexToLevel(int)"><B>indexToLevel(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return the level of a tree which the given node is in.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#indices()"><B>indices()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model"><B>InformationGainStats</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: DeveloperApi ::
 Information gain statistics for each split
 param:  gain information gain value
 param:  impurity current node impurity
 param:  leftImpurity left node impurity
 param:  rightImpurity right node impurity
 param:  leftPredict left node predict
 param:  rightPredict right node predict<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#InformationGainStats(double, double, double, double, org.apache.spark.mllib.tree.model.Predict, org.apache.spark.mllib.tree.model.Predict)"><B>InformationGainStats(double, double, double, double, Predict, Predict)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#initialHash()"><B>initialHash()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/BroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)"><B>initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</B></A> - 
Method in interface org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)"><B>initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)"><B>initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html#initialize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.clustering.LDA)"><B>initialize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, LDA)</B></A> - 
Method in interface org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html" title="interface in org.apache.spark.mllib.clustering">LDAOptimizer</A>
<DD>Initializer for the optimizer.
<DT><A HREF="./org/apache/spark/Logging.html#initializeIfNecessary()"><B>initializeIfNecessary()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#initializeLogging()"><B>initializeLogging()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#initialValue()"><B>initialValue()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#initLocalProperties()"><B>initLocalProperties()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/InnerClosureFinder.html" title="class in org.apache.spark.util"><B>InnerClosureFinder</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/InnerClosureFinder.html#InnerClosureFinder(scala.collection.mutable.Set)"><B>InnerClosureFinder(Set&lt;Class&lt;?&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/InnerClosureFinder.html" title="class in org.apache.spark.util">InnerClosureFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#innerJoin(org.apache.spark.graphx.EdgeRDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerJoin(EdgeRDD&lt;ED2&gt;, Function4&lt;Object, Object, ED, ED2, ED3&gt;, ClassTag&lt;ED2&gt;, ClassTag&lt;ED3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>Inner joins this EdgeRDD with another EdgeRDD, assuming both are partitioned using the same
 <A HREF="./org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx"><CODE>PartitionStrategy</CODE></A>.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#innerJoin(org.apache.spark.graphx.EdgeRDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerJoin(EdgeRDD&lt;ED2&gt;, Function4&lt;Object, Object, ED, ED2, ED3&gt;, ClassTag&lt;ED2&gt;, ClassTag&lt;ED3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#innerJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerJoin(RDD&lt;Tuple2&lt;Object, U&gt;&gt;, Function3&lt;Object, VD, U, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#innerJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerJoin(RDD&lt;Tuple2&lt;Object, U&gt;&gt;, Function3&lt;Object, VD, U, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Inner joins this VertexRDD with an RDD containing vertex attribute pairs.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#innerZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerZipJoin(VertexRDD&lt;U&gt;, Function3&lt;Object, VD, U, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#innerZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>innerZipJoin(VertexRDD&lt;U&gt;, Function3&lt;Object, VD, U, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Efficiently inner joins this VertexRDD with another VertexRDD sharing the same index.
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#inputBytes()"><B>inputBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#inputBytes()"><B>inputBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html#inputDStream()"><B>inputDStream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#inputDStream()"><B>inputDStream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>InputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="type parameter in InputDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</A><DD>This is the abstract base class for all input streams.<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#InputDStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)"><B>InputDStream(StreamingContext, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#inputFormatClazz()"><B>inputFormatClazz()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#inputFormatClazz()"><B>inputFormatClazz()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler"><B>InputFormatInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Parses and holds information about inputFormat (and files) specified as a parameter.<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#InputFormatInfo(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.String)"><B>InputFormatInfo(Configuration, Class&lt;?&gt;, String)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/InputMetricDistributions.html" title="class in org.apache.spark.status.api.v1"><B>InputMetricDistributions</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/InputMetrics.html" title="class in org.apache.spark.status.api.v1"><B>InputMetrics</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#inputMetrics()"><B>inputMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#inputMetrics()"><B>inputMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#inputRecords()"><B>inputRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#inRange(double, double, boolean, boolean)"><B>inRange(double, double, boolean, boolean)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check for value in range lowerBound to upperBound.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#inRange(double, double)"><B>inRange(double, double)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Version of <CODE>inRange()</CODE> which uses inclusive be default: [lowerBound, upperBound]
<DT><A HREF="./org/apache/spark/sql/sources/InsertableRelation.html#insert(org.apache.spark.sql.DataFrame, boolean)"><B>insert(DataFrame, boolean)</B></A> - 
Method in interface org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/InsertableRelation.html" title="interface in org.apache.spark.sql.sources">InsertableRelation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/InsertableRelation.html" title="interface in org.apache.spark.sql.sources"><B>InsertableRelation</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 A BaseRelation that can be used to insert data into it through the insert method.<DT><A HREF="./org/apache/spark/sql/DataFrame.html#insertInto(java.lang.String, boolean)"><B>insertInto(String, boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().mode(SaveMode.Append|SaveMode.Overwrite).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#insertInto(java.lang.String)"><B>insertInto(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().mode(SaveMode.Append).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#insertInto(java.lang.String)"><B>insertInto(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Inserts the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> to the specified table.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#insertIntoJDBC(java.lang.String, java.lang.String, boolean)"><B>insertIntoJDBC(String, String, boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().jdbc()</code>.</I>
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html#instance()"><B>instance()</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</A>
<DD>Get this impurity instance.
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html#instance()"><B>instance()</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</A>
<DD>Get this impurity instance.
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html#instance()"><B>instance()</B></A> - 
Static method in class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</A>
<DD>Get this impurity instance.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#intAccumulator(int)"><B>intAccumulator(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> integer variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#intAccumulator(int, java.lang.String)"><B>intAccumulator(int, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create an <A HREF="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><CODE>Accumulator</CODE></A> integer variable, which tasks can "add" values
 to using the <code>add</code> method.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#IntegerType"><B>IntegerType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the IntegerType object.
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types"><B>IntegerType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Int</code> values.<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#integral()"><B>integral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#integral()"><B>integral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#integral()"><B>integral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#integral()"><B>integral()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html" title="class in org.apache.spark.ml.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#intercept()"><B>intercept()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree"><B>InternalNode</B></A> - Class in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Internal Decision Tree node.<DT><A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark"><B>InterruptibleIterator</B></A>&lt;<A HREF="./org/apache/spark/InterruptibleIterator.html" title="type parameter in InterruptibleIterator">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 An iterator that wraps around an existing iterator to provide task killing functionality.<DT><A HREF="./org/apache/spark/InterruptibleIterator.html#InterruptibleIterator(org.apache.spark.TaskContext, scala.collection.Iterator)"><B>InterruptibleIterator(TaskContext, Iterator&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/local/KillTask.html#interruptThread()"><B>interruptThread()</B></A> - 
Method in class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/KillTask.html" title="class in org.apache.spark.scheduler.local">KillTask</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#intersect(org.apache.spark.sql.DataFrame)"><B>intersect(DataFrame)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> containing rows only in both this frame and another frame.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#intersection(org.apache.spark.api.java.JavaDoubleRDD)"><B>intersection(JavaDoubleRDD)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#intersection(org.apache.spark.api.java.JavaPairRDD)"><B>intersection(JavaPairRDD&lt;K, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#intersection(org.apache.spark.api.java.JavaRDD)"><B>intersection(JavaRDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)"><B>intersection(RDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)"><B>intersection(RDD&lt;T&gt;, Partitioner, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, int)"><B>intersection(RDD&lt;T&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the intersection of this RDD and another one.
<DT><A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param"><B>IntParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Int</CODE>] for Java.<DT><A HREF="./org/apache/spark/ml/param/IntParam.html#IntParam(java.lang.String, java.lang.String, java.lang.String, scala.Function1)"><B>IntParam(String, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param">IntParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/IntParam.html#IntParam(java.lang.String, java.lang.String, java.lang.String)"><B>IntParam(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param">IntParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/IntParam.html#IntParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String, scala.Function1)"><B>IntParam(org.apache.spark.ml.util.Identifiable, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param">IntParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/IntParam.html#IntParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>IntParam(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param">IntParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#intRddToDataFrameHolder(org.apache.spark.rdd.RDD)"><B>intRddToDataFrameHolder(RDD&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#intToIntWritable(int)"><B>intToIntWritable(int)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#intWritableConverter()"><B>intWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#invalidInformationGainStats()"><B>invalidInformationGainStats()</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>An <A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model"><CODE>InformationGainStats</CODE></A> object to
 denote that current split doesn't satisfies minimum info gain or
 minimum number of instances per node.
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#isAddIntercept()"><B>isAddIntercept()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>Get if the algorithm uses addIntercept
<DT><A HREF="./org/apache/spark/SparkConf.html#isAkkaConf(java.lang.String)"><B>isAkkaConf(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Return whether the given config is an akka config (e.g.
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#isAllowed(scala.Enumeration.Value, scala.Enumeration.Value)"><B>isAllowed(Enumeration.Value, Enumeration.Value)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#isBroadcast()"><B>isBroadcast()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)"><B>isCached(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Returns true if the table is currently cached in-memory.
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#isCached()"><B>isCached()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#isCached()"><B>isCached()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#isCancelled()"><B>isCancelled()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#isCancelled()"><B>isCancelled()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Returns whether the action has been cancelled.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#isCancelled()"><B>isCancelled()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return whether this RDD has been checkpointed or not
<DT><A HREF="./org/apache/spark/graphx/Graph.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Return whether this Graph has been checkpointed or not.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#isCheckpointed()"><B>isCheckpointed()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return whether this RDD has been checkpointed or not
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#isCheckpointPresent()"><B>isCheckpointPresent()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#isCompleted()"><B>isCompleted()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#isCompleted()"><B>isCompleted()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Returns whether the action has already been completed with a value or an exception.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#isCompleted()"><B>isCompleted()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#isCompleted()"><B>isCompleted()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Returns true if the task has completed.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#isDefined(org.apache.spark.ml.param.Param)"><B>isDefined(Param&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Checks whether a param is explicitly set or has a default value.
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#isDriver()"><B>isDriver()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#isEmpty()"><B>isEmpty()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#isEmpty()"><B>isEmpty()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#isEmpty()"><B>isEmpty()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#isExecutorStartupConf(java.lang.String)"><B>isExecutorStartupConf(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Return whether the given config should be passed to an executor on start-up.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#isFixed(org.apache.spark.sql.types.DataType)"><B>isFixed(DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#isInitialValueFinal()"><B>isInitialValueFinal()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#isInterrupted()"><B>isInterrupted()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Returns true if the task has been killed.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#isLeaf()"><B>isLeaf()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#isLeftChild(int)"><B>isLeftChild(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Returns true if this is a left child.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#isLocal()"><B>isLocal()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#isLocal()"><B>isLocal()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#isLocal()"><B>isLocal()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
 (without any Spark executors).
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#isMulticlassClassification()"><B>isMulticlassClassification()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#isMulticlassWithCategoricalFeatures()"><B>isMulticlassWithCategoricalFeatures()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#isMultipleOf(org.apache.spark.streaming.Duration)"><B>isMultipleOf(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#isMultipleOf(org.apache.spark.streaming.Duration)"><B>isMultipleOf(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#isNominal()"><B>isNominal()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Tests whether this attribute is nominal, true for <A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute"><CODE>NominalAttribute</CODE></A> and <A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute"><CODE>BinaryAttribute</CODE></A>.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#isNominal()"><B>isNominal()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#isNominal()"><B>isNominal()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#isNominal()"><B>isNominal()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#isNominal()"><B>isNominal()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#isNotNull()"><B>isNotNull()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>True if the current expression is NOT null.
<DT><A HREF="./org/apache/spark/sql/sources/IsNotNull.html" title="class in org.apache.spark.sql.sources"><B>IsNotNull</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a non-null value.<DT><A HREF="./org/apache/spark/sql/sources/IsNotNull.html#IsNotNull(java.lang.String)"><B>IsNotNull(String)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/IsNotNull.html" title="class in org.apache.spark.sql.sources">IsNotNull</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#isNull()"><B>isNull()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>True if the current expression is null.
<DT><A HREF="./org/apache/spark/sql/sources/IsNull.html" title="class in org.apache.spark.sql.sources"><B>IsNull</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to null.<DT><A HREF="./org/apache/spark/sql/sources/IsNull.html#IsNull(java.lang.String)"><B>IsNull(String)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/IsNull.html" title="class in org.apache.spark.sql.sources">IsNull</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#isNullAt(int)"><B>isNullAt(int)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Checks whether the value at position i is null.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#isNumeric()"><B>isNumeric()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Tests whether this attribute is numeric, true for <A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute"><CODE>NumericAttribute</CODE></A> and <A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute"><CODE>BinaryAttribute</CODE></A>.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#isNumeric()"><B>isNumeric()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#isNumeric()"><B>isNumeric()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#isNumeric()"><B>isNumeric()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#isNumeric()"><B>isNumeric()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#isOrdinal()"><B>isOrdinal()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#isotonic()"><B>isotonic()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html" title="class in org.apache.spark.mllib.regression"><B>IsotonicRegression</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html#IsotonicRegression()"><B>IsotonicRegression()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html" title="class in org.apache.spark.mllib.regression">IsotonicRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression"><B>IsotonicRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#IsotonicRegressionModel(double[], double[], boolean)"><B>IsotonicRegressionModel(double[], double[], boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#IsotonicRegressionModel(java.lang.Iterable, java.lang.Iterable, java.lang.Boolean)"><B>IsotonicRegressionModel(Iterable&lt;Object&gt;, Iterable&lt;Object&gt;, Boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>A Java-friendly constructor that takes two Iterable parameters and one Boolean parameter.
<DT><A HREF="./org/apache/spark/storage/BlockId.html#isRDD()"><B>isRDD()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#isRunningLocally()"><B>isRunningLocally()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>Returns true if the task is running locally in the driver program.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#isSet(org.apache.spark.ml.param.Param)"><B>isSet(Param&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Checks whether a param is explicitly set.
<DT><A HREF="./org/apache/spark/storage/BlockId.html#isShuffle()"><B>isShuffle()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#isSparkPortConf(java.lang.String)"><B>isSparkPortConf(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Return true if the given config matches either <code>spark.*.port</code> or <code>spark.port.*</code>.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#isStarted()"><B>isStarted()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Check if the receiver has started or not.
<DT><A HREF="./org/apache/spark/SparkEnv.html#isStopped()"><B>isStopped()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#isStopped()"><B>isStopped()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Check if receiver has been marked for stopping.
<DT><A HREF="./org/apache/spark/Logging.html#isTraceEnabled()"><B>isTraceEnabled()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#isTransposed()"><B>isTransposed()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#isTransposed()"><B>isTransposed()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Flag that keeps track whether the matrix is transposed or not.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#isTransposed()"><B>isTransposed()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#isValid()"><B>isValid()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#isValid()"><B>isValid()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#isZero()"><B>isZero()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#isZero()"><B>isZero()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#it()"><B>it()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html#item()"><B>item()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#itemFactors()"><B>itemFactors()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html#items()"><B>items()</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="class in org.apache.spark.mllib.fpm">FPGrowth.FreqItemset</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#iterationTimes()"><B>iterationTimes()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>iterator(Partition, TaskContext)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Internal method to this RDD; will read from cache if applicable, or otherwise compute it.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)"><B>iterator(Partition, TaskContext)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Internal method to this RDD; will read from cache if applicable, or otherwise compute it.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#iterator()"><B>iterator()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_J_"><!-- --></A><H2>
<B>J</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#j()"><B>j()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/json/JacksonUtils.html" title="class in org.apache.spark.sql.json"><B>JacksonUtils</B></A> - Class in <A HREF="./org/apache/spark/sql/json/package-summary.html">org.apache.spark.sql.json</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/json/JacksonUtils.html#JacksonUtils()"><B>JacksonUtils()</B></A> - 
Constructor for class org.apache.spark.sql.json.<A HREF="./org/apache/spark/sql/json/JacksonUtils.html" title="class in org.apache.spark.sql.json">JacksonUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#jarOfClass(java.lang.Class)"><B>jarOfClass(Class&lt;?&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to SparkContext.
<DT><A HREF="./org/apache/spark/SparkContext.html#jarOfClass(java.lang.Class)"><B>jarOfClass(Class&lt;?&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to SparkContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#jarOfClass(java.lang.Class)"><B>jarOfClass(Class&lt;?&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#jarOfClass(java.lang.Class)"><B>jarOfClass(Class&lt;?&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#jarOfObject(java.lang.Object)"><B>jarOfObject(Object)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Find the JAR that contains the class of a particular object, to make it easy for users
 to pass their JARs to SparkContext.
<DT><A HREF="./org/apache/spark/SparkContext.html#jarOfObject(java.lang.Object)"><B>jarOfObject(Object)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Find the JAR that contains the class of a particular object, to make it easy for users
 to pass their JARs to SparkContext.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#jars()"><B>jars()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#jars()"><B>jars()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#javaCategoryMaps()"><B>javaCategoryMaps()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>Java-friendly version of <CODE>categoryMaps</CODE>
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java"><B>JavaDoubleRDD</B></A> - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#JavaDoubleRDD(org.apache.spark.rdd.RDD)"><B>JavaDoubleRDD(RDD&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="type parameter in JavaDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to <A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>DStream</CODE></A>, the basic
 abstraction in Spark Streaming that represents a continuous stream of data.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#JavaDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>JavaDStream(DStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java"><B>JavaDStreamLike</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">This</A> extends <A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">This</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</A>&gt;,<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</A> extends <A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</A>&gt;&gt; - Interface in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java"><B>JavaFutureAction</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaFutureAction.html" title="type parameter in JavaFutureAction">T</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java"><B>JavaHadoopRDD</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="type parameter in JavaHadoopRDD">K</A>,<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="type parameter in JavaHadoopRDD">V</A>&gt; - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html#JavaHadoopRDD(org.apache.spark.rdd.HadoopRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaHadoopRDD(HadoopRDD&lt;K, V&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="type parameter in JavaInputDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to <A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>InputDStream</CODE></A>.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html#JavaInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag)"><B>JavaInputDStream(InputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html#javaItems()"><B>javaItems()</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.FreqItemset.html" title="class in org.apache.spark.mllib.fpm">FPGrowth.FreqItemset</A>
<DD>Returns items in a Java List.
<DT><A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html" title="class in org.apache.spark.serializer"><B>JavaIterableWrapperSerializer</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>A Kryo serializer for serializing results returned by asJavaIterable.<DT><A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html#JavaIterableWrapperSerializer()"><B>JavaIterableWrapperSerializer()</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html" title="class in org.apache.spark.serializer">JavaIterableWrapperSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming"><B>JavaKinesisWordCountASL</B></A> - Class in <A HREF="./org/apache/spark/examples/streaming/package-summary.html">org.apache.spark.examples.streaming</A><DD>Consumes messages from a Amazon Kinesis streams and does wordcount.<DT><A HREF="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html#JavaKinesisWordCountASL()"><B>JavaKinesisWordCountASL()</B></A> - 
Constructor for class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming">JavaKinesisWordCountASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java"><B>JavaNewHadoopRDD</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="type parameter in JavaNewHadoopRDD">K</A>,<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="type parameter in JavaNewHadoopRDD">V</A>&gt; - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html#JavaNewHadoopRDD(org.apache.spark.rdd.NewHadoopRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaNewHadoopRDD(NewHadoopRDD&lt;K, V&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaPairDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="type parameter in JavaPairDStream">K</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="type parameter in JavaPairDStream">V</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to a DStream of key-value pairs, which provides extra methods
 like <code>reduceByKey</code> and <code>join</code>.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#JavaPairDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaPairDStream(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaPairInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="type parameter in JavaPairInputDStream">K</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="type parameter in JavaPairInputDStream">V</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to <A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>InputDStream</CODE></A> of
 key-value pairs.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#JavaPairInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaPairInputDStream(InputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java"><B>JavaPairRDD</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="type parameter in JavaPairRDD">K</A>,<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="type parameter in JavaPairRDD">V</A>&gt; - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#JavaPairRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaPairRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaPairReceiverInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="type parameter in JavaPairReceiverInputDStream">K</A>,<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="type parameter in JavaPairReceiverInputDStream">V</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to <A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>ReceiverInputDStream</CODE></A>, the
 abstract class for defining any input stream that receives data over the network.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#JavaPairReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>JavaPairReceiverInputDStream(ReceiverInputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/JavaParams.html" title="class in org.apache.spark.ml.param"><B>JavaParams</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Java-friendly wrapper for <A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param"><CODE>Params</CODE></A>.<DT><A HREF="./org/apache/spark/ml/param/JavaParams.html#JavaParams()"><B>JavaParams()</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/JavaParams.html" title="class in org.apache.spark.ml.param">JavaParams</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><B>JavaRDD</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="type parameter in JavaRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#JavaRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>JavaRDD(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#javaRDD()"><B>javaRDD()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as a <CODE>JavaRDD</CODE> of <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A>s.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java"><B>JavaRDDLike</B></A>&lt;<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</A> extends <A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>&lt;<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</A>,<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</A>&gt;&gt; - Interface in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>Defines operations common to several Java RDD implementations.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><B>JavaReceiverInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="type parameter in JavaReceiverInputDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly interface to <A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>ReceiverInputDStream</CODE></A>, the
 abstract class for defining any input stream that receives data over the network.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#JavaReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag)"><B>JavaReceiverInputDStream(ReceiverInputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer"><B>JavaSerializer</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>:: DeveloperApi ::
 A Spark serializer that uses Java's built-in serialization.<DT><A HREF="./org/apache/spark/serializer/JavaSerializer.html#JavaSerializer(org.apache.spark.SparkConf)"><B>JavaSerializer(SparkConf)</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java"><B>JavaSparkContext</B></A> - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>A Java-friendly version of <A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><CODE>SparkContext</CODE></A> that returns
 <A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><CODE>JavaRDD</CODE></A>s and works with Java collections instead of Scala ones.<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(org.apache.spark.SparkContext)"><B>JavaSparkContext(SparkContext)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext()"><B>JavaSparkContext()</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Create a JavaSparkContext that loads settings from system properties (for instance, when
 launching with ./bin/spark-submit).
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(org.apache.spark.SparkConf)"><B>JavaSparkContext(SparkConf)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String)"><B>JavaSparkContext(String, String)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, org.apache.spark.SparkConf)"><B>JavaSparkContext(String, String, SparkConf)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String)"><B>JavaSparkContext(String, String, String, String)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String[])"><B>JavaSparkContext(String, String, String, String[])</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String[], java.util.Map)"><B>JavaSparkContext(String, String, String, String[], Map&lt;String, String&gt;)</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark"><B>JavaSparkListener</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Java clients should extend this class instead of implementing
 SparkListener directly.<DT><A HREF="./org/apache/spark/JavaSparkListener.html#JavaSparkListener()"><B>JavaSparkListener()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkStatusTracker.html" title="class in org.apache.spark.api.java"><B>JavaSparkStatusTracker</B></A> - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>Low-level status reporting APIs for monitoring job and stage progress.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java"><B>JavaStreamingContext</B></A> - Class in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>A Java-friendly version of <A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><CODE>StreamingContext</CODE></A> which is the main
 entry point for Spark Streaming functionality.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.streaming.StreamingContext)"><B>JavaStreamingContext(StreamingContext)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration)"><B>JavaStreamingContext(String, String, Duration)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String)"><B>JavaStreamingContext(String, String, Duration, String, String)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[])"><B>JavaStreamingContext(String, String, Duration, String, String[])</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[], java.util.Map)"><B>JavaStreamingContext(String, String, Duration, String, String[], Map&lt;String, String&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a StreamingContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.streaming.Duration)"><B>JavaStreamingContext(JavaSparkContext, Duration)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a JavaStreamingContext using an existing JavaSparkContext.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)"><B>JavaStreamingContext(SparkConf, Duration)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a JavaStreamingContext using a SparkConf configuration.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String)"><B>JavaStreamingContext(String)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Recreate a JavaStreamingContext from a checkpoint file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)"><B>JavaStreamingContext(String, Configuration)</B></A> - 
Constructor for class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Re-creates a JavaStreamingContext from a checkpoint file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java"><B>JavaStreamingContextFactory</B></A> - Interface in <A HREF="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</A><DD>Factory interface for creating a new JavaStreamingContext<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#javaTopicDistributions()"><B>javaTopicDistributions()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>Java-friendly version of <CODE>topicDistributions</CODE>
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#jdbc(java.lang.String, java.lang.String, java.util.Properties)"><B>jdbc(String, String, Properties)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Construct a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> representing the database table accessible via JDBC URL
 url named table and connection properties.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#jdbc(java.lang.String, java.lang.String, java.lang.String, long, long, int, java.util.Properties)"><B>jdbc(String, String, String, long, long, int, Properties)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Construct a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> representing the database table accessible via JDBC URL
 url named table.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#jdbc(java.lang.String, java.lang.String, java.lang.String[], java.util.Properties)"><B>jdbc(String, String, String[], Properties)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Construct a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> representing the database table accessible via JDBC URL
 url named table using connection properties.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#jdbc(java.lang.String, java.lang.String, java.util.Properties)"><B>jdbc(String, String, Properties)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> to a external database table via JDBC.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String)"><B>jdbc(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String, java.lang.String, long, long, int)"><B>jdbc(String, String, String, long, long, int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String, java.lang.String, java.lang.String[])"><B>jdbc(String, String, String[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().jdbc()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc"><B>JdbcDialect</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 Encapsulates everything (extensions, workarounds, quirks) to handle the
 SQL dialect of a certain database or jdbc driver.<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html#JdbcDialect()"><B>JdbcDialect()</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc">JdbcDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html" title="class in org.apache.spark.sql.jdbc"><B>JdbcDialects</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 Registry of dialects that apply to every new jdbc <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html#JdbcDialects()"><B>JdbcDialects()</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html" title="class in org.apache.spark.sql.jdbc">JdbcDialects</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcType.html#jdbcNullType()"><B>jdbcNullType()</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcType.html" title="class in org.apache.spark.sql.jdbc">JdbcType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd"><B>JdbcRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>An RDD that executes an SQL query on a JDBC connection and reads results.<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#JdbcRDD(org.apache.spark.SparkContext, scala.Function0, java.lang.String, long, long, int, scala.Function1, scala.reflect.ClassTag)"><B>JdbcRDD(SparkContext, Function0&lt;Connection&gt;, String, long, long, int, Function1&lt;ResultSet, T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd"><B>JdbcRDD.ConnectionFactory</B></A> - Interface in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcType.html" title="class in org.apache.spark.sql.jdbc"><B>JdbcType</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 A database type definition coupled with the jdbc type needed to send null
 values to the database.<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcType.html#JdbcType(java.lang.String, int)"><B>JdbcType(String, int)</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcType.html" title="class in org.apache.spark.sql.jdbc">JdbcType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1"><B>JobData</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/JobExecutionStatus.html" title="enum in org.apache.spark"><B>JobExecutionStatus</B></A> - Enum in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#jobGroup()"><B>jobGroup()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#jobGroupToJobIds()"><B>jobGroupToJobIds()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html#jobId()"><B>jobId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#jobId()"><B>jobId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfo.html#jobId()"><B>jobId()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfo.html" title="interface in org.apache.spark">SparkJobInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfoImpl.html#jobId()"><B>jobId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfoImpl.html" title="class in org.apache.spark">SparkJobInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#jobId()"><B>jobId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskCommitDenied.html#jobID()"><B>jobID()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark">TaskCommitDenied</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaFutureAction.html#jobIds()"><B>jobIds()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaFutureAction.html" title="interface in org.apache.spark.api.java">JavaFutureAction</A>
<DD>Returns the job IDs run by the underlying async operation.
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#jobIds()"><B>jobIds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#jobIds()"><B>jobIds()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Returns the job IDs run by the underlying async operation.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#jobIds()"><B>jobIds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#jobIdToData()"><B>jobIdToData()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler"><B>JobLogger</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 A logger class to record runtime information for jobs in Spark.<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#JobLogger(java.lang.String, java.lang.String)"><B>JobLogger(String, String)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#JobLogger()"><B>JobLogger()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs"><B>JobProgressListener</B></A> - Class in <A HREF="./org/apache/spark/ui/jobs/package-summary.html">org.apache.spark.ui.jobs</A><DD>:: DeveloperApi ::
 Tracks task-level information to be displayed in the UI.<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#JobProgressListener(org.apache.spark.SparkConf)"><B>JobProgressListener(SparkConf)</B></A> - 
Constructor for class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobResult.html" title="interface in org.apache.spark.scheduler"><B>JobResult</B></A> - Interface in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 A result of a job in the DAGScheduler.<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html#jobResult()"><B>jobResult()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobSucceeded.html" title="class in org.apache.spark.scheduler"><B>JobSucceeded</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/JobSucceeded.html#JobSucceeded()"><B>JobSucceeded()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobSucceeded.html" title="class in org.apache.spark.scheduler">JobSucceeded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html#jobUIData()"><B>jobUIData()</B></A> - 
Method in class org.apache.spark.streaming.ui.<A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html" title="class in org.apache.spark.streaming.ui">SparkJobIdWithUIData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>join(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD)"><B>join(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD, int)"><B>join(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>join(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD)"><B>join(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, int)"><B>join(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#join(org.apache.spark.sql.DataFrame)"><B>join(DataFrame)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Cartesian join with another <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#join(org.apache.spark.sql.DataFrame, java.lang.String)"><B>join(DataFrame, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Inner equi-join with another <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the given column.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#join(org.apache.spark.sql.DataFrame, org.apache.spark.sql.Column)"><B>join(DataFrame, Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Inner join with another <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, using the given join expression.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#join(org.apache.spark.sql.DataFrame, org.apache.spark.sql.Column, java.lang.String)"><B>join(DataFrame, Column, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Join with another <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, using the given join expression.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>join(JavaPairDStream&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream, int)"><B>join(JavaPairDStream&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)"><B>join(JavaPairDStream&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><B>join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#joinVertices(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag)"><B>joinVertices(RDD&lt;Tuple2&lt;Object, U&gt;&gt;, Function3&lt;Object, VD, U, VD&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Join the vertices with an RDD and then apply a function from the
 vertex and RDD entry to a new vertex value.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#json(java.lang.String)"><B>json(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads a JSON file (one object per line) and returns the result as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#json(org.apache.spark.api.java.JavaRDD)"><B>json(JavaRDD&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads an <code>JavaRDD[String]</code> storing JSON objects (one object per record) and
 returns the result as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#json(org.apache.spark.rdd.RDD)"><B>json(RDD&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads an <code>RDD[String]</code> storing JSON objects (one object per record) and
 returns the result as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#json(java.lang.String)"><B>json(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> in JSON format at the specified path.
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#json()"><B>json()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>The compact JSON representation of this data type.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#json()"><B>json()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>Converts to its JSON representation.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)"><B>jsonFile(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.types.StructType)"><B>jsonFile(String, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)"><B>jsonFile(String, double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)"><B>jsonRDD(RDD&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD)"><B>jsonRDD(JavaRDD&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)"><B>jsonRDD(RDD&lt;String&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)"><B>jsonRDD(JavaRDD&lt;String&gt;, StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)"><B>jsonRDD(RDD&lt;String&gt;, double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD, double)"><B>jsonRDD(JavaRDD&lt;String&gt;, double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().json()</code>.</I>
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#jvmGcTime()"><B>jvmGcTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#jvmGcTime()"><B>jvmGcTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#jvmInformation()"><B>jvmInformation()</B></A> - 
Method in class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_K_"><!-- --></A><H2>
<B>K</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>Number of gaussians in mixture
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>Total number of clusters.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering">LDAModel</A>
<DD>Number of topics
<DT><A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html" title="class in org.apache.spark.mllib.clustering">LocalLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClusteringModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/PCA.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature">PCA</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/PCAModel.html#k()"><B>k()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCAModel.html" title="class in org.apache.spark.mllib.feature">PCAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#K_MEANS_PARALLEL()"><B>K_MEANS_PARALLEL()</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka"><B>KafkaTestUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>This is a helper class for Kafka test suites.<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#KafkaTestUtils()"><B>KafkaTestUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka"><B>KafkaUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html#KafkaUtils()"><B>KafkaUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka"><B>KafkaUtilsPythonHelper</B></A> - Class in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>This is a helper class that wraps the KafkaUtils.createStream() into more
 Python-friendly class and function so that it can be easily
 instantiated and called from Python's KafkaUtils (see SPARK-6027).<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html#KafkaUtilsPythonHelper()"><B>KafkaUtilsPythonHelper()</B></A> - 
Constructor for class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaUtilsPythonHelper.html" title="class in org.apache.spark.streaming.kafka">KafkaUtilsPythonHelper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html#kClassTag()"><B>kClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html#kClassTag()"><B>kClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#kClassTag()"><B>kClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#kClassTag()"><B>kClassTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#kClassTag()"><B>kClassTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat"><B>KernelDensity</B></A> - Class in <A HREF="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</A><DD>:: Experimental ::
 Kernel density estimation.<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#KernelDensity()"><B>KernelDensity()</B></A> - 
Constructor for class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#keyBy(org.apache.spark.api.java.function.Function)"><B>keyBy(Function&lt;T, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Creates tuples of the elements in this RDD by applying <code>f</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)"><B>keyBy(Function1&lt;T, K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Creates tuples of the elements in this RDD by applying <code>f</code>.
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#keyOrdering()"><B>keyOrdering()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#keys()"><B>keys()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the keys of each tuple.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#keys()"><B>keys()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD with the keys of each tuple.
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#keyType()"><B>keyType()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#kFold(org.apache.spark.rdd.RDD, int, int, scala.reflect.ClassTag)"><B>kFold(RDD&lt;T&gt;, int, int, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>:: Experimental ::
 Return a k element array of pairs of RDDs with the first element of each pair
 containing the training data, a complement of the validation data and the second
 element, the validation data, containing a unique 1/kth of the data.
<DT><A HREF="./org/apache/spark/SparkContext.html#killExecutor(java.lang.String)"><B>killExecutor(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Request that cluster manager the kill the specified executor.
<DT><A HREF="./org/apache/spark/SparkContext.html#killExecutors(scala.collection.Seq)"><B>killExecutors(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Request that the cluster manager kill the specified executors.
<DT><A HREF="./org/apache/spark/scheduler/local/KillTask.html" title="class in org.apache.spark.scheduler.local"><B>KillTask</B></A> - Class in <A HREF="./org/apache/spark/scheduler/local/package-summary.html">org.apache.spark.scheduler.local</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/local/KillTask.html#KillTask(long, boolean)"><B>KillTask(long, boolean)</B></A> - 
Constructor for class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/KillTask.html" title="class in org.apache.spark.scheduler.local">KillTask</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis"><B>KinesisUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/kinesis/package-summary.html">org.apache.spark.streaming.kinesis</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html#KinesisUtils()"><B>KinesisUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.kinesis.<A HREF="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming"><B>KinesisWordCountASL</B></A> - Class in <A HREF="./org/apache/spark/examples/streaming/package-summary.html">org.apache.spark.examples.streaming</A><DD>Consumes messages from a Amazon Kinesis streams and does wordcount.<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordCountASL.html#KinesisWordCountASL()"><B>KinesisWordCountASL()</B></A> - 
Constructor for class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/KinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming">KinesisWordCountASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html" title="class in org.apache.spark.examples.streaming"><B>KinesisWordProducerASL</B></A> - Class in <A HREF="./org/apache/spark/examples/streaming/package-summary.html">org.apache.spark.examples.streaming</A><DD>Usage: KinesisWordProducerASL <stream-name> <endpoint-url> \
   <records-per-sec> <words-per-record><DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html#KinesisWordProducerASL()"><B>KinesisWordProducerASL()</B></A> - 
Constructor for class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html" title="class in org.apache.spark.examples.streaming">KinesisWordProducerASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#kManifest()"><B>kManifest()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering"><B>KMeans</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>K-means clustering with support for multiple parallel runs and a k-means++ like initialization
 mode (the k-means|| algorithm by Bahmani et al).<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#KMeans()"><B>KMeans()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Constructs a KMeans instance with default parameters: {k: 2, maxIterations: 20, runs: 1,
 initializationMode: "k-means||", initializationSteps: 5, epsilon: 1e-4, seed: random}.
<DT><A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util"><B>KMeansDataGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 Generate test data for KMeans.<DT><A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html#KMeansDataGenerator()"><B>KMeansDataGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering"><B>KMeansModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>A clustering model for K-means.<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#KMeansModel(org.apache.spark.mllib.linalg.Vector[])"><B>KMeansModel(Vector[])</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#KMeansModel(java.lang.Iterable)"><B>KMeansModel(Iterable&lt;Vector&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>A Java-friendly constructor that takes an Iterable of Vectors.
<DT><A HREF="./org/apache/spark/serializer/KryoRegistrator.html" title="interface in org.apache.spark.serializer"><B>KryoRegistrator</B></A> - Interface in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>Interface implemented by clients to register their classes with Kryo when using Kryo
 serialization.<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer"><B>KryoSerializer</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>A Spark serializer that uses the <CODE>Kryo serialization library</CODE>.<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#KryoSerializer(org.apache.spark.SparkConf)"><B>KryoSerializer(SparkConf)</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_L_"><!-- --></A><H2>
<B>L</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization"><B>L1Updater</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Updater for L1 regularized problems.<DT><A HREF="./org/apache/spark/mllib/optimization/L1Updater.html#L1Updater()"><B>L1Updater()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization">L1Updater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html#label()"><B>label()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression"><B>LabeledPoint</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Class that represents the features and labels of a data point.<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html#LabeledPoint(double, org.apache.spark.mllib.linalg.Vector)"><B>LabeledPoint(double, Vector)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/LabelPropagation.html" title="class in org.apache.spark.graphx.lib"><B>LabelPropagation</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Label Propagation algorithm.<DT><A HREF="./org/apache/spark/graphx/lib/LabelPropagation.html#LabelPropagation()"><B>LabelPropagation()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/LabelPropagation.html" title="class in org.apache.spark.graphx.lib">LabelPropagation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#labels()"><B>labels()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#labels()"><B>labels()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns the sequence of labels in ascending order
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#labels()"><B>labels()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns the sequence of labels in ascending order
<DT><A HREF="./org/apache/spark/sql/functions.html#lag(org.apache.spark.sql.Column, int)"><B>lag(Column, int)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lag(java.lang.String, int)"><B>lag(String, int)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>null</code> if there is less than <code>offset</code> rows before the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lag(java.lang.String, int, java.lang.Object)"><B>lag(String, int, Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lag(org.apache.spark.sql.Column, int, java.lang.Object)"><B>lag(Column, int, Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows before the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows before the current row.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression"><B>LassoModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Regression model trained using Lasso.<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html#LassoModel(org.apache.spark.mllib.linalg.Vector, double)"><B>LassoModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression"><B>LassoWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Train a regression model with L1-regularization using Stochastic Gradient Descent.<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#LassoWithSGD()"><B>LassoWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>Construct a Lasso object with default parameters: {stepSize: 1.0, numIterations: 100,
 regParam: 0.01, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/sql/functions.html#last(org.apache.spark.sql.Column)"><B>last(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the last value in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#last(java.lang.String)"><B>last(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the last value of the column in a group.
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#lastError()"><B>lastError()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#lastErrorMessage()"><B>lastErrorMessage()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#lastErrorTime()"><B>lastErrorTime()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#lastValidTime()"><B>lastValidTime()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#latestModel()"><B>latestModel()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Return the latest model.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#latestModel()"><B>latestModel()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Return the latest model.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#launch()"><B>launch()</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Launches a sub-process that will start the configured Spark application.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#launchTime()"><B>launchTime()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#launchTime()"><B>launchTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization"><B>LBFGS</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Class used to solve an optimization problem using Limited-memory BFGS.<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#LBFGS(org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater)"><B>LBFGS(Gradient, Updater)</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering"><B>LDA</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#LDA()"><B>LDA()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering"><B>LDAModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html" title="interface in org.apache.spark.mllib.clustering"><B>LDAOptimizer</B></A> - Interface in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/sql/functions.html#lead(java.lang.String, int)"><B>lead(String, int)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lead(org.apache.spark.sql.Column, int)"><B>lead(Column, int)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>null</code> if there is less than <code>offset</code> rows after the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lead(java.lang.String, int, java.lang.Object)"><B>lead(String, int, Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row.
<DT><A HREF="./org/apache/spark/sql/functions.html#lead(org.apache.spark.sql.Column, int, java.lang.Object)"><B>lead(Column, int, Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the value that is <code>offset</code> rows after the current row, and
 <code>defaultValue</code> if there is less than <code>offset</code> rows after the current row.
<DT><A HREF="./org/apache/spark/ml/tree/LeafNode.html" title="class in org.apache.spark.ml.tree"><B>LeafNode</B></A> - Class in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Decision tree leaf node.<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#learningRate()"><B>learningRate()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression"><B>LeastSquaresAggregator</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>LeastSquaresAggregator computes the gradient and loss for a Least-squared loss function,
 as used in linear regression for samples in sparse or dense vector in a online fashion.<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#LeastSquaresAggregator(org.apache.spark.mllib.linalg.Vector, double, double, double[], double[])"><B>LeastSquaresAggregator(Vector, double, double, double[], double[])</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresCostFun.html" title="class in org.apache.spark.ml.regression"><B>LeastSquaresCostFun</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>LeastSquaresCostFun implements Breeze's DiffFunction[T] for Least Squares cost.<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresCostFun.html#LeastSquaresCostFun(org.apache.spark.rdd.RDD, double, double, double[], double[], double)"><B>LeastSquaresCostFun(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, double, double, double[], double[], double)</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresCostFun.html" title="class in org.apache.spark.ml.regression">LeastSquaresCostFun</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization"><B>LeastSquaresGradient</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Compute gradient and loss for a Least-squared loss function, as used in linear regression.<DT><A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#LeastSquaresGradient()"><B>LeastSquaresGradient()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/And.html#left()"><B>left()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/And.html" title="class in org.apache.spark.sql.sources">And</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/Or.html#left()"><B>left()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Or.html" title="class in org.apache.spark.sql.sources">Or</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html#leftCategories()"><B>leftCategories()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html" title="class in org.apache.spark.ml.tree">CategoricalSplit</A>
<DD>Get sorted categories which split to the left
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#leftChild()"><B>leftChild()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#leftChildIndex(int)"><B>leftChildIndex(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return the index of the left child of this node.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#leftImpurity()"><B>leftImpurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#leftJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>leftJoin(RDD&lt;Tuple2&lt;Object, VD2&gt;&gt;, Function3&lt;Object, VD, Option&lt;VD2&gt;, VD3&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;VD3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#leftJoin(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>leftJoin(RDD&lt;Tuple2&lt;Object, VD2&gt;&gt;, Function3&lt;Object, VD, Option&lt;VD2&gt;, VD3&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;VD3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Left joins this VertexRDD with an RDD containing vertex attribute pairs.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#leftNode()"><B>leftNode()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>leftOuterJoin(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD)"><B>leftOuterJoin(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD, int)"><B>leftOuterJoin(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD)"><B>leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, int)"><B>leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a left outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>leftOuterJoin(JavaPairDStream&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, int)"><B>leftOuterJoin(JavaPairDStream&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)"><B>leftOuterJoin(JavaPairDStream&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><B>leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#leftPredict()"><B>leftPredict()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#leftZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>leftZipJoin(VertexRDD&lt;VD2&gt;, Function3&lt;Object, VD, Option&lt;VD2&gt;, VD3&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;VD3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#leftZipJoin(org.apache.spark.graphx.VertexRDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>leftZipJoin(VertexRDD&lt;VD2&gt;, Function3&lt;Object, VD, Option&lt;VD2&gt;, VD3&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;VD3&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Left joins this RDD with another VertexRDD with the same index.
<DT><A HREF="./org/apache/spark/SparkContext.html#LEGACY_DRIVER_IDENTIFIER()"><B>LEGACY_DRIVER_IDENTIFIER()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Legacy version of DRIVER_IDENTIFIER, retained for backwards-compatibility.
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#length()"><B>length()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#length()"><B>length()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Number of elements in the Row.
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#length()"><B>length()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#length()"><B>length()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Return the number of code points in it.
<DT><A HREF="./org/apache/spark/util/Vector.html#length()"><B>length()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#leq(java.lang.Object)"><B>leq(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Less than or equal to.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#less(org.apache.spark.streaming.Duration)"><B>less(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#less(org.apache.spark.streaming.Time)"><B>less(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#lessEq(org.apache.spark.streaming.Duration)"><B>lessEq(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#lessEq(org.apache.spark.streaming.Time)"><B>lessEq(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThan.html" title="class in org.apache.spark.sql.sources"><B>LessThan</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a value
 less than <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/LessThan.html#LessThan(java.lang.String, java.lang.Object)"><B>LessThan(String, Object)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThan.html" title="class in org.apache.spark.sql.sources">LessThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html" title="class in org.apache.spark.sql.sources"><B>LessThanOrEqual</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to a value
 less than or equal to <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html#LessThanOrEqual(java.lang.String, java.lang.Object)"><B>LessThanOrEqual(String, Object)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html" title="class in org.apache.spark.sql.sources">LessThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#like(java.lang.String)"><B>like(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>SQL like expression.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#limit(int)"><B>limit(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> by taking the first <code>n</code> rows.
<DT><A HREF="./org/apache/spark/sql/AnalysisException.html#line()"><B>line()</B></A> - 
Method in exception org.apache.spark.sql.<A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util"><B>LinearDataGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 Generate sample data used for Linear Data.<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#LinearDataGenerator()"><B>LinearDataGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression"><B>LinearRegression</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 Linear regression.<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#LinearRegression(java.lang.String)"><B>LinearRegression(String)</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#LinearRegression()"><B>LinearRegression()</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html" title="class in org.apache.spark.ml.regression"><B>LinearRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 Model produced by <A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression"><CODE>LinearRegression</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression"><B>LinearRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Regression model trained using LinearRegression.<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html#LinearRegressionModel(org.apache.spark.mllib.linalg.Vector, double)"><B>LinearRegressionModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><B>LinearRegressionWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Train a linear regression model with no regularization using Stochastic Gradient Descent.<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#LinearRegressionWithSGD()"><B>LinearRegressionWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>Construct a LinearRegression object with default parameters: {stepSize: 1.0,
 numIterations: 100, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/SparkContext.html#listenerBus()"><B>listenerBus()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#lit(java.lang.Object)"><B>lit(Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A> of literal value.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClusteringModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model">RandomForestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/Loader.html#load(org.apache.spark.SparkContext, java.lang.String)"><B>load(SparkContext, String)</B></A> - 
Method in interface org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/Loader.html" title="interface in org.apache.spark.mllib.util">Loader</A>
<DD>Load a model from the given path.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#load(java.lang.String)"><B>load(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads input in as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, for data sources that require a path (e.g.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#load()"><B>load()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads input in as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>, for data sources that don't require a path (e.g.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String)"><B>load(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().load(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String, java.lang.String)"><B>load(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).load(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String, java.util.Map)"><B>load(String, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String, scala.collection.immutable.Map)"><B>load(String, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)"><B>load(String, StructType, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#load(java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)"><B>load(String, StructType, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</I>
<DT><A HREF="./org/apache/spark/mllib/util/Loader.html" title="interface in org.apache.spark.mllib.util"><B>Loader</B></A>&lt;<A HREF="./org/apache/spark/mllib/util/Loader.html" title="type parameter in Loader">M</A> extends <A HREF="./org/apache/spark/mllib/util/Saveable.html" title="interface in org.apache.spark.mllib.util">Saveable</A>&gt; - Interface in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledData(org.apache.spark.SparkContext, java.lang.String)"><B>loadLabeledData(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD><B>Deprecated.</B>&nbsp;<I>Should use <A HREF="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><CODE>RDD.saveAsTextFile(java.lang.String)</CODE></A> for saving and
            <A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><CODE>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</CODE></A> for loading.</I>
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><B>loadLabeledPoints(SparkContext, String, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads labeled points saved using <code>RDD[LabeledPoint].saveAsTextFile</code>.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String)"><B>loadLabeledPoints(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads labeled points saved using <code>RDD[LabeledPoint].saveAsTextFile</code> with the default number of
 partitions.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, int, int)"><B>loadLibSVMFile(SparkContext, String, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads labeled data in the LIBSVM format into an RDD[LabeledPoint].
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean, int, int)"><B>loadLibSVMFile(SparkContext, String, boolean, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, int)"><B>loadLibSVMFile(SparkContext, String, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads labeled data in the LIBSVM format into an RDD[LabeledPoint], with the default number of
 partitions.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean, int)"><B>loadLibSVMFile(SparkContext, String, boolean, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean)"><B>loadLibSVMFile(SparkContext, String, boolean)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String)"><B>loadLibSVMFile(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads binary labeled data in the LIBSVM format into an RDD[LabeledPoint], with number of
 features determined automatically and the default number of partitions.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadVectors(org.apache.spark.SparkContext, java.lang.String, int)"><B>loadVectors(SparkContext, String, int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads vectors saved using <code>RDD[Vector].saveAsTextFile</code>.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadVectors(org.apache.spark.SparkContext, java.lang.String)"><B>loadVectors(SparkContext, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Loads vectors saved using <code>RDD[Vector].saveAsTextFile</code> with the default number of partitions.
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#localBlocksFetched()"><B>localBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#localBlocksFetched()"><B>localBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html" title="class in org.apache.spark.mllib.clustering"><B>LocalLDAModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#localSeqToDataFrameHolder(scala.collection.Seq, scala.reflect.api.TypeTags.TypeTag)"><B>localSeqToDataFrameHolder(Seq&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/test/LocalSQLContext.html" title="class in org.apache.spark.sql.test"><B>LocalSQLContext</B></A> - Class in <A HREF="./org/apache/spark/sql/test/package-summary.html">org.apache.spark.sql.test</A><DD>A SQLContext that can be used for local testing.<DT><A HREF="./org/apache/spark/sql/test/LocalSQLContext.html#LocalSQLContext()"><B>LocalSQLContext()</B></A> - 
Constructor for class org.apache.spark.sql.test.<A HREF="./org/apache/spark/sql/test/LocalSQLContext.html" title="class in org.apache.spark.sql.test">LocalSQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#localValue()"><B>localValue()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>Get the current value of this accumulator from within a task.
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#location()"><B>location()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#log()"><B>log()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#log(org.apache.spark.sql.Column)"><B>log(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the natural logarithm of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#log(java.lang.String)"><B>log(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the natural logarithm of the given column.
<DT><A HREF="./org/apache/spark/sql/functions.html#log10(org.apache.spark.sql.Column)"><B>log10(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the logarithm of the given value in Base 10.
<DT><A HREF="./org/apache/spark/sql/functions.html#log10(java.lang.String)"><B>log10(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the logarithm of the given value in Base 10.
<DT><A HREF="./org/apache/spark/sql/functions.html#log1p(org.apache.spark.sql.Column)"><B>log1p(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the natural logarithm of the given value plus one.
<DT><A HREF="./org/apache/spark/sql/functions.html#log1p(java.lang.String)"><B>log1p(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the natural logarithm of the given column plus one.
<DT><A HREF="./org/apache/spark/Logging.html#log_()"><B>log_()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logDebug(scala.Function0)"><B>logDebug(Function0&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)"><B>logDebug(Function0&lt;String&gt;, Throwable)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#logDeprecationWarning(java.lang.String)"><B>logDeprecationWarning(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Logs a warning message if the given config key is deprecated.
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#logDirName()"><B>logDirName()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logError(scala.Function0)"><B>logError(Function0&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)"><B>logError(Function0&lt;String&gt;, Throwable)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark"><B>Logging</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Utility trait for classes that want to log data.<DT><A HREF="./org/apache/spark/Logging.html#logInfo(scala.Function0)"><B>logInfo(Function0&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)"><B>logInfo(Function0&lt;String&gt;, Throwable)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification"><B>LogisticAggregator</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>LogisticAggregator computes the gradient and loss for binary logistic loss function, as used
 in binary classification for samples in sparse or dense vector in a online fashion.<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#LogisticAggregator(org.apache.spark.mllib.linalg.Vector, int, boolean, double[], double[])"><B>LogisticAggregator(Vector, int, boolean, double[], double[])</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticCostFun.html" title="class in org.apache.spark.ml.classification"><B>LogisticCostFun</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>LogisticCostFun implements Breeze's DiffFunction[T] for a multinomial logistic loss function,
 as used in multi-class classification (it is also used in binary logistic regression).<DT><A HREF="./org/apache/spark/ml/classification/LogisticCostFun.html#LogisticCostFun(org.apache.spark.rdd.RDD, int, boolean, double[], double[], double)"><B>LogisticCostFun(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, int, boolean, double[], double[], double)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticCostFun.html" title="class in org.apache.spark.ml.classification">LogisticCostFun</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization"><B>LogisticGradient</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Compute gradient and loss for a multinomial logistic loss function, as used
 in multi-class classification (it is also used in binary logistic regression).<DT><A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html#LogisticGradient(int)"><B>LogisticGradient(int)</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html#LogisticGradient()"><B>LogisticGradient()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification"><B>LogisticRegression</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 Logistic regression.<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#LogisticRegression(java.lang.String)"><B>LogisticRegression(String)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#LogisticRegression()"><B>LogisticRegression()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util"><B>LogisticRegressionDataGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 Generate test data for LogisticRegression.<DT><A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#LogisticRegressionDataGenerator()"><B>LogisticRegressionDataGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification"><B>LogisticRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 Model produced by <A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification"><CODE>LogisticRegression</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification"><B>LogisticRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Classification model trained using Multinomial/Binary Logistic Regression.<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#LogisticRegressionModel(org.apache.spark.mllib.linalg.Vector, double, int, int)"><B>LogisticRegressionModel(Vector, double, int, int)</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#LogisticRegressionModel(org.apache.spark.mllib.linalg.Vector, double)"><B>LogisticRegressionModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>Constructs a <A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification"><CODE>LogisticRegressionModel</CODE></A> with weights and intercept for binary classification.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification"><B>LogisticRegressionWithLBFGS</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Train a classification model for Multinomial/Binary Logistic Regression using
 Limited-memory BFGS.<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html#LogisticRegressionWithLBFGS()"><B>LogisticRegressionWithLBFGS()</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithLBFGS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification"><B>LogisticRegressionWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Train a classification model for Binary Logistic Regression
 using Stochastic Gradient Descent.<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#LogisticRegressionWithSGD()"><B>LogisticRegressionWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>Construct a LogisticRegression object with default parameters: {stepSize: 1.0,
 numIterations: 100, regParm: 0.01, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#logLikelihood()"><B>logLikelihood()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>Log likelihood of the observed tokens in the training set,
 given the current parameter estimates:
  log P(docs | topics, topic distributions for docs, alpha, eta)
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#logLikelihood()"><B>logLikelihood()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/loss/LogLoss.html" title="class in org.apache.spark.mllib.tree.loss"><B>LogLoss</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html">org.apache.spark.mllib.tree.loss</A><DD>:: DeveloperApi ::
 Class for log loss calculation (for classification).<DT><A HREF="./org/apache/spark/mllib/tree/loss/LogLoss.html#LogLoss()"><B>LogLoss()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/LogLoss.html" title="class in org.apache.spark.mllib.tree.loss">LogLoss</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logName()"><B>logName()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random"><B>LogNormalGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#LogNormalGenerator(double, double)"><B>LogNormalGenerator(double, double)</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#logNormalGraph(org.apache.spark.SparkContext, int, int, double, double, long)"><B>logNormalGraph(SparkContext, int, int, double, double, long)</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>Generate a graph whose vertex out degree distribution is log normal.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><B>logNormalJavaRDD(JavaSparkContext, double, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalRDD(org.apache.spark.SparkContext, double, double, long, int, long)"><CODE>RandomRDDs.logNormalRDD(org.apache.spark.SparkContext, double, double, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int)"><B>logNormalJavaRDD(JavaSparkContext, double, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><CODE>RandomRDDs.logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long)"><B>logNormalJavaRDD(JavaSparkContext, double, double, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)"><CODE>RandomRDDs.logNormalJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><B>logNormalJavaVectorRDD(JavaSparkContext, double, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.logNormalVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int)"><B>logNormalJavaVectorRDD(JavaSparkContext, double, double, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int)"><B>logNormalJavaVectorRDD(JavaSparkContext, double, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)"><CODE>RandomRDDs.logNormalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, double, long, int, int, long)</CODE></A> with the default number of partitions and
 the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalRDD(org.apache.spark.SparkContext, double, double, long, int, long)"><B>logNormalRDD(SparkContext, double, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the log normal distribution with the input
  mean and standard deviation
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#logNormalVectorRDD(org.apache.spark.SparkContext, double, double, long, int, int, long)"><B>logNormalVectorRDD(SparkContext, double, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from a
 log normal distribution.
<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html#logpdf(org.apache.spark.mllib.linalg.Vector)"><B>logpdf(Vector)</B></A> - 
Method in class org.apache.spark.mllib.stat.distribution.<A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution">MultivariateGaussian</A>
<DD>Returns the log-density of this multivariate Gaussian at given point, x
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#logPrior()"><B>logPrior()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>Log probability of the current parameter estimate:
  log P(topics, topic distributions for docs | alpha, eta)
<DT><A HREF="./org/apache/spark/Logging.html#logTrace(scala.Function0)"><B>logTrace(Function0&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)"><B>logTrace(Function0&lt;String&gt;, Throwable)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#logUrlMap()"><B>logUrlMap()</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logWarning(scala.Function0)"><B>logWarning(Function0&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)"><B>logWarning(Function0&lt;String&gt;, Throwable)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param"><B>LongParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Long</CODE>] for Java.<DT><A HREF="./org/apache/spark/ml/param/LongParam.html#LongParam(java.lang.String, java.lang.String, java.lang.String, scala.Function1)"><B>LongParam(String, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param">LongParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/LongParam.html#LongParam(java.lang.String, java.lang.String, java.lang.String)"><B>LongParam(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param">LongParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/LongParam.html#LongParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String, scala.Function1)"><B>LongParam(org.apache.spark.ml.util.Identifiable, String, String, Function1&lt;Object, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param">LongParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/LongParam.html#LongParam(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>LongParam(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param">LongParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#longRddToDataFrameHolder(org.apache.spark.rdd.RDD)"><B>longRddToDataFrameHolder(RDD&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#longToLongWritable(long)"><B>longToLongWritable(long)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#LongType"><B>LongType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the LongType object.
<DT><A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types"><B>LongType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Long</code> values.<DT><A HREF="./org/apache/spark/SparkContext.html#longWritableConverter()"><B>longWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#lookup(K)"><B>lookup(K)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return the list of values in the RDD for key <code>key</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#lookup(K)"><B>lookup(K)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return the list of values in the RDD for key <code>key</code>.
<DT><A HREF="./org/apache/spark/util/RpcUtils.html#lookupTimeout(org.apache.spark.SparkConf)"><B>lookupTimeout(SparkConf)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>Returns the default Spark timeout to use for RPC remote endpoint lookup.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#loss()"><B>loss()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#loss()"><B>loss()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#loss()"><B>loss()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/loss/Loss.html" title="interface in org.apache.spark.mllib.tree.loss"><B>Loss</B></A> - Interface in <A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html">org.apache.spark.mllib.tree.loss</A><DD>:: DeveloperApi ::
 Trait for adding "pluggable" loss functions for the gradient boosting algorithm.<DT><A HREF="./org/apache/spark/mllib/tree/loss/Losses.html" title="class in org.apache.spark.mllib.tree.loss"><B>Losses</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html">org.apache.spark.mllib.tree.loss</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/loss/Losses.html#Losses()"><B>Losses()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/Losses.html" title="class in org.apache.spark.mllib.tree.loss">Losses</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#lossType()"><B>lossType()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>Loss function which GBT tries to minimize.
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#lossType()"><B>lossType()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>Loss function which GBT tries to minimize.
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#low()"><B>low()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#lower(org.apache.spark.sql.Column)"><B>lower(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts a string exprsesion to lower case.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#lt(double)"><B>lt(double)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check if value < upperBound
<DT><A HREF="./org/apache/spark/sql/Column.html#lt(java.lang.Object)"><B>lt(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Less than.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#ltEq(double)"><B>ltEq(double)</B></A> - 
Static method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>Check if value <= upperBound
<DT><A HREF="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io"><B>LZ4CompressionCodec</B></A> - Class in <A HREF="./org/apache/spark/io/package-summary.html">org.apache.spark.io</A><DD>:: DeveloperApi ::
 LZ4 implementation of <A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><CODE>CompressionCodec</CODE></A>.<DT><A HREF="./org/apache/spark/io/LZ4CompressionCodec.html#LZ4CompressionCodec(org.apache.spark.SparkConf)"><B>LZ4CompressionCodec(SparkConf)</B></A> - 
Constructor for class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io"><B>LZFCompressionCodec</B></A> - Class in <A HREF="./org/apache/spark/io/package-summary.html">org.apache.spark.io</A><DD>:: DeveloperApi ::
 LZF implementation of <A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><CODE>CompressionCodec</CODE></A>.<DT><A HREF="./org/apache/spark/io/LZFCompressionCodec.html#LZFCompressionCodec(org.apache.spark.SparkConf)"><B>LZFCompressionCodec(SparkConf)</B></A> - 
Constructor for class org.apache.spark.io.<A HREF="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_M_"><!-- --></A><H2>
<B>M</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming">JavaKinesisWordCountASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordCountASL.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/KinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming">KinesisWordCountASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.examples.streaming.<A HREF="./org/apache/spark/examples/streaming/KinesisWordProducerASL.html" title="class in org.apache.spark.examples.streaming">KinesisWordProducerASL</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MFDataGenerator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util">MFDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/SVMDataGenerator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util">SVMDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/RpcUtils.html#makeDriverRef(java.lang.String, org.apache.spark.SparkConf, org.apache.spark.rpc.RpcEnv)"><B>makeDriverRef(String, SparkConf, org.apache.spark.rpc.RpcEnv)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>Retrieve a <CODE>RpcEndpointRef</CODE> which is located in the driver via its name.
<DT><A HREF="./org/apache/spark/SparkContext.html#makeRDD(scala.collection.Seq, int, scala.reflect.ClassTag)"><B>makeRDD(Seq&lt;T&gt;, int, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/SparkContext.html#makeRDD(scala.collection.Seq, scala.reflect.ClassTag)"><B>makeRDD(Seq&lt;Tuple2&lt;T, Seq&lt;String&gt;&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Distribute a local Scala collection to form an RDD, with one or more
 location preferences (hostnames of Spark nodes) for each object.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#map(org.apache.spark.api.java.function.Function)"><B>map(Function&lt;T, R&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#map(scala.Function1)"><B>map(Function1&lt;Object, Object&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Map the values of this matrix using a function.
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#map(scala.Function1)"><B>map(Function1&lt;R, T&gt;)</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>Transform this PartialResult into a PartialResult of type T.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#map(scala.Function1, scala.reflect.ClassTag)"><B>map(Function1&lt;T, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#map(org.apache.spark.sql.types.DataType, org.apache.spark.sql.types.DataType)"><B>map(DataType, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type map.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#map(org.apache.spark.sql.types.MapType)"><B>map(MapType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#map(scala.Function1, scala.reflect.ClassTag)"><B>map(Function1&lt;Row, R&gt;, ClassTag&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new RDD by applying a function to all rows of this DataFrame.
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#map()"><B>map()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#map(org.apache.spark.api.java.function.Function)"><B>map(Function&lt;T, R&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream by applying a function to all elements of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#map(scala.Function1, scala.reflect.ClassTag)"><B>map(Function1&lt;T, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream by applying a function to all elements of this DStream.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#mapEdgePartitions(scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>mapEdgePartitions(Function2&lt;Object, EdgePartition&lt;ED, VD&gt;, EdgePartition&lt;ED2, VD2&gt;&gt;, ClassTag&lt;ED2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapEdges(scala.Function1, scala.reflect.ClassTag)"><B>mapEdges(Function1&lt;Edge&lt;ED&gt;, ED2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each edge attribute in the graph using the map function.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapEdges(scala.Function2, scala.reflect.ClassTag)"><B>mapEdges(Function2&lt;Object, Iterator&lt;Edge&lt;ED&gt;&gt;, Iterator&lt;ED2&gt;&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each edge attribute using the map function, passing it a whole partition at a
 time.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#mapEdges(scala.Function2, scala.reflect.ClassTag)"><B>mapEdges(Function2&lt;Object, Iterator&lt;Edge&lt;ED&gt;&gt;, Iterator&lt;ED2&gt;&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html#mapId()"><B>mapId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html#mapId()"><B>mapId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html#mapId()"><B>mapId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage">ShuffleDataBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html#mapId()"><B>mapId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#mapOutputTracker()"><B>mapOutputTracker()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)"><B>mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction, boolean)"><B>mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;, boolean)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)"><B>mapPartitions(Function1&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#mapPartitions(scala.Function1, scala.reflect.ClassTag)"><B>mapPartitions(Function1&lt;Iterator&lt;Row&gt;, Iterator&lt;R&gt;&gt;, ClassTag&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new RDD by applying a function to each partition of this DataFrame.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)"><B>mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)"><B>mapPartitions(Function1&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)"><B>mapPartitionsToDouble(DoubleFlatMapFunction&lt;Iterator&lt;T&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction, boolean)"><B>mapPartitionsToDouble(DoubleFlatMapFunction&lt;Iterator&lt;T&gt;&gt;, boolean)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><B>mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction, boolean)"><B>mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;, boolean)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)"><B>mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2, boolean, scala.reflect.ClassTag)"><B>mapPartitionsWithContext(Function2&lt;TaskContext, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>:: DeveloperApi ::
 Return a new RDD by applying a function to each partition of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsWithIndex(org.apache.spark.api.java.function.Function2, boolean)"><B>mapPartitionsWithIndex(Function2&lt;Integer, Iterator&lt;T&gt;, Iterator&lt;R&gt;&gt;, boolean)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2, boolean, scala.reflect.ClassTag)"><B>mapPartitionsWithIndex(Function2&lt;Object, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.
<DT><A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html#mapPartitionsWithInputSplit(org.apache.spark.api.java.function.Function2, boolean)"><B>mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;R&gt;&gt;, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</A>
<DD>Maps over a partition, providing the InputSplit that was used as the base of the partition.
<DT><A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html#mapPartitionsWithInputSplit(org.apache.spark.api.java.function.Function2, boolean)"><B>mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;R&gt;&gt;, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</A>
<DD>Maps over a partition, providing the InputSplit that was used as the base of the partition.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithInputSplit(scala.Function2, boolean, scala.reflect.ClassTag)"><B>mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>Maps over a partition, providing the InputSplit that was used as the base of the partition.
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#mapPartitionsWithInputSplit(scala.Function2, boolean, scala.reflect.ClassTag)"><B>mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>Maps over a partition, providing the InputSplit that was used as the base of the partition.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2, boolean, scala.reflect.ClassTag)"><B>mapPartitionsWithSplit(Function2&lt;Object, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#mapredInputFormat()"><B>mapredInputFormat()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#mapreduceInputFormat()"><B>mapreduceInputFormat()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapReduceTriplets(scala.Function1, scala.Function2, scala.Option, scala.reflect.ClassTag)"><B>mapReduceTriplets(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Iterator&lt;Tuple2&lt;Object, A&gt;&gt;&gt;, Function2&lt;A, A, A&gt;, Option&lt;Tuple2&lt;VertexRDD&lt;?&gt;, EdgeDirection&gt;&gt;, ClassTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Aggregates values from the neighboring edges and vertices of each vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#mapReduceTriplets(scala.Function1, scala.Function2, scala.Option, scala.reflect.ClassTag)"><B>mapReduceTriplets(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Iterator&lt;Tuple2&lt;Object, A&gt;&gt;&gt;, Function2&lt;A, A, A&gt;, Option&lt;Tuple2&lt;VertexRDD&lt;?&gt;, EdgeDirection&gt;&gt;, ClassTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#mapSideCombine()"><B>mapSideCombine()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapToDouble(org.apache.spark.api.java.function.DoubleFunction)"><B>mapToDouble(DoubleFunction&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#mapToPair(org.apache.spark.api.java.function.PairFunction)"><B>mapToPair(PairFunction&lt;T, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return a new RDD by applying a function to all elements of this RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapToPair(org.apache.spark.api.java.function.PairFunction)"><B>mapToPair(PairFunction&lt;T, K2, V2&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream by applying a function to all elements of this DStream.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function1, scala.reflect.ClassTag)"><B>mapTriplets(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, ED2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function1, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><B>mapTriplets(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, ED2&gt;, TripletFields, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each edge attribute using the map function, passing it the adjacent vertex
 attributes as well.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapTriplets(scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><B>mapTriplets(Function2&lt;Object, Iterator&lt;EdgeTriplet&lt;VD, ED&gt;&gt;, Iterator&lt;ED2&gt;&gt;, TripletFields, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each edge attribute a partition at a time using the map function, passing it the
 adjacent vertex attributes as well.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#mapTriplets(scala.Function2, org.apache.spark.graphx.TripletFields, scala.reflect.ClassTag)"><B>mapTriplets(Function2&lt;Object, Iterator&lt;EdgeTriplet&lt;VD, ED&gt;&gt;, Iterator&lt;ED2&gt;&gt;, TripletFields, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types"><B>MapType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type for Maps.<DT><A HREF="./org/apache/spark/sql/types/MapType.html#MapType(org.apache.spark.sql.types.DataType, org.apache.spark.sql.types.DataType, boolean)"><B>MapType(DataType, DataType, boolean)</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#MapType()"><B>MapType()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>No-arg constructor for kryo.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#mapValues(org.apache.spark.api.java.function.Function)"><B>mapValues(Function&lt;V, U&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#mapValues(scala.Function1, scala.reflect.ClassTag)"><B>mapValues(Function1&lt;Edge&lt;ED&gt;, ED2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>Map the values in an edge partitioning preserving the structure but changing the values.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#mapValues(scala.Function1, scala.reflect.ClassTag)"><B>mapValues(Function1&lt;Edge&lt;ED&gt;, ED2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#mapValues(scala.Function1, scala.reflect.ClassTag)"><B>mapValues(Function1&lt;VD, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#mapValues(scala.Function2, scala.reflect.ClassTag)"><B>mapValues(Function2&lt;Object, VD, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#mapValues(scala.Function1, scala.reflect.ClassTag)"><B>mapValues(Function1&lt;VD, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Maps each vertex attribute, preserving the index.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#mapValues(scala.Function2, scala.reflect.ClassTag)"><B>mapValues(Function2&lt;Object, VD, VD2&gt;, ClassTag&lt;VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Maps each vertex attribute, additionally supplying the vertex ID.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#mapValues(scala.Function1)"><B>mapValues(Function1&lt;V, U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#mapValues(org.apache.spark.api.java.function.Function)"><B>mapValues(Function&lt;V, U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapValues(scala.Function1, scala.reflect.ClassTag)"><B>mapValues(Function1&lt;V, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mapVertices(scala.Function2, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><B>mapVertices(Function2&lt;Object, VD, VD2&gt;, ClassTag&lt;VD2&gt;, Predef.$eq$colon$eq&lt;VD, VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Transforms each vertex attribute in the graph using the map function.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#mapVertices(scala.Function2, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><B>mapVertices(Function2&lt;Object, VD, VD2&gt;, ClassTag&lt;VD2&gt;, Predef.$eq$colon$eq&lt;VD, VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#mapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)"><B>mapWith(Function1&lt;Object, A&gt;, boolean, Function2&lt;T, A, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Maps f over this RDD, where f takes an additional parameter of type A.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#mask(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>mask(Graph&lt;VD2, ED2&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Restricts the graph to only the vertices and edges that are also in <code>other</code>, but keeps the
 attributes from this graph.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#mask(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>mask(Graph&lt;VD2, ED2&gt;, ClassTag&lt;VD2&gt;, ClassTag&lt;ED2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#master()"><B>master()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#master()"><B>master()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg"><B>Matrices</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>Factory methods for <A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg"><CODE>Matrix</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#Matrices()"><B>Matrices()</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg"><B>Matrix</B></A> - Interface in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>Trait for a local matrix.<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>MatrixEntry</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>:: Experimental ::
 Represents an entry in an distributed matrix.<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#MatrixEntry(long, long, double)"><B>MatrixEntry(long, long, double)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation"><B>MatrixFactorizationModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</A><DD>Model representing the result of matrix factorization.<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#MatrixFactorizationModel(int, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>MatrixFactorizationModel(int, RDD&lt;Tuple2&lt;Object, double[]&gt;&gt;, RDD&lt;Tuple2&lt;Object, double[]&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#max()"><B>max()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Returns the maximum element from this RDD as defined by
 the default comparator natural order.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#max(java.util.Comparator)"><B>max(Comparator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the maximum element from this RDD as defined by the specified
 Comparator[T].
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#max()"><B>max()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#max()"><B>max()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#max()"><B>max()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Maximum value of each column.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)"><B>max(Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Returns the max of this RDD as defined by the implicit Ordering[T].
<DT><A HREF="./org/apache/spark/sql/functions.html#max(org.apache.spark.sql.Column)"><B>max(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the maximum value of the expression in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#max(java.lang.String)"><B>max(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the maximum value of the column in a group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#max(java.lang.String...)"><B>max(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the max value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#max(scala.collection.Seq)"><B>max(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the max value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#max(org.apache.spark.streaming.Duration)"><B>max(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#max(org.apache.spark.streaming.Time)"><B>max(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#max()"><B>max()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#MAX_LONG_DIGITS()"><B>MAX_LONG_DIGITS()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Maximum number of decimal digits a Long can represent
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxBins()"><B>maxBins()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#maxBufferSizeMb()"><B>maxBufferSizeMb()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxDepth()"><B>maxDepth()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#maxIters()"><B>maxIters()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#maxMem()"><B>maxMem()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#maxMem()"><B>maxMem()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#maxMemory()"><B>maxMemory()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxMemoryInMB()"><B>maxMemoryInMB()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#maxNodesInLevel(int)"><B>maxNodesInLevel(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return the maximum number of nodes which can be in the given level of the tree.
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#maxVal()"><B>maxVal()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute the mean of this RDD's elements.
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random">ExponentialGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#mean()"><B>mean()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Sample mean vector.
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute the mean of this RDD's elements.
<DT><A HREF="./org/apache/spark/sql/functions.html#mean(org.apache.spark.sql.Column)"><B>mean(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the average of the values in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#mean(java.lang.String)"><B>mean(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the average of the values in a group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#mean(java.lang.String...)"><B>mean(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the average value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#mean(scala.collection.Seq)"><B>mean(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the average value for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#mean()"><B>mean()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#meanAbsoluteError()"><B>meanAbsoluteError()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>Returns the mean absolute error, which is a risk function corresponding to the
 expected value of the absolute error loss or l1-norm loss.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#meanApprox(long, java.lang.Double)"><B>meanApprox(long, Double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return the approximate mean of the elements in this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#meanApprox(long)"><B>meanApprox(long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>:: Experimental ::
 Approximate operation to return the mean within a timeout.
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#meanApprox(long, double)"><B>meanApprox(long, double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>:: Experimental ::
 Approximate operation to return the mean within a timeout.
<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html#meanAveragePrecision()"><B>meanAveragePrecision()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation">RankingMetrics</A>
<DD>Returns the mean average precision (MAP) of all the queries.
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#means()"><B>means()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#meanSquaredError()"><B>meanSquaredError()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>Returns the mean squared error, which is a risk function corresponding to the
 expected value of the squared error loss or quadratic loss.
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK"><B>MEMORY_AND_DISK</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK()"><B>MEMORY_AND_DISK()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_2"><B>MEMORY_AND_DISK_2</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_2()"><B>MEMORY_AND_DISK_2()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_SER"><B>MEMORY_AND_DISK_SER</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_SER()"><B>MEMORY_AND_DISK_SER()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_SER_2"><B>MEMORY_AND_DISK_SER_2</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_SER_2()"><B>MEMORY_AND_DISK_SER_2()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY"><B>MEMORY_ONLY</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY()"><B>MEMORY_ONLY()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_2"><B>MEMORY_ONLY_2</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_2()"><B>MEMORY_ONLY_2()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_SER"><B>MEMORY_ONLY_SER</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_SER()"><B>MEMORY_ONLY_SER()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_SER_2"><B>MEMORY_ONLY_SER_2</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_SER_2()"><B>MEMORY_ONLY_SER_2()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#memoryBytesSpilled()"><B>memoryBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#memoryBytesSpilled()"><B>memoryBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#memoryBytesSpilled()"><B>memoryBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#memoryBytesSpilled()"><B>memoryBytesSpilled()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/MemoryEntry.html" title="class in org.apache.spark.storage"><B>MemoryEntry</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/MemoryEntry.html#MemoryEntry(java.lang.Object, long, boolean)"><B>MemoryEntry(Object, long, boolean)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/MemoryEntry.html" title="class in org.apache.spark.storage">MemoryEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html#memoryRemaining()"><B>memoryRemaining()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html" title="class in org.apache.spark.status.api.v1">RDDDataDistribution</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#memoryUsed()"><B>memoryUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html#memoryUsed()"><B>memoryUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html" title="class in org.apache.spark.status.api.v1">RDDDataDistribution</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html#memoryUsed()"><B>memoryUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1">RDDPartitionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#memoryUsed()"><B>memoryUsed()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#memRemaining()"><B>memRemaining()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the memory remaining in this block manager.
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#memSize()"><B>memSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#memSize()"><B>memSize()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#memUsed()"><B>memUsed()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the memory used by this block manager.
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#memUsedByRdd(int)"><B>memUsedByRdd(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the memory used by the given RDD in this block manager in O(1) time.
<DT><A HREF="./org/apache/spark/Accumulable.html#merge(R)"><B>merge(R)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>Merge two accumulable objects together
<DT><A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html#merge(org.apache.spark.ml.classification.LogisticAggregator)"><B>merge(LogisticAggregator)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticAggregator.html" title="class in org.apache.spark.ml.classification">LogisticAggregator</A>
<DD>Merge another LogisticAggregator, and update the loss and gradient
 of the objective function.
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html#merge(org.apache.spark.ml.feature.VectorIndexer.CategoryStats)"><B>merge(VectorIndexer.CategoryStats)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html" title="class in org.apache.spark.ml.feature">VectorIndexer.CategoryStats</A>
<DD>Merge with another instance, modifying this instance.
<DT><A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html#merge(org.apache.spark.ml.regression.LeastSquaresAggregator)"><B>merge(LeastSquaresAggregator)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LeastSquaresAggregator.html" title="class in org.apache.spark.ml.regression">LeastSquaresAggregator</A>
<DD>Merge another LeastSquaresAggregator, and update the loss and gradient
 of the objective function.
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#merge(org.apache.spark.mllib.feature.IDF.DocumentFrequencyAggregator)"><B>merge(IDF.DocumentFrequencyAggregator)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>Merges another.
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#merge(org.apache.spark.mllib.stat.MultivariateOnlineSummarizer)"><B>merge(MultivariateOnlineSummarizer)</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>Merge another MultivariateOnlineSummarizer, and update the statistical summary.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#merge(double)"><B>merge(double)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Add a value into this StatCounter, updating the internal statistics.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#merge(scala.collection.TraversableOnce)"><B>merge(TraversableOnce&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Add multiple values into this StatCounter, updating the internal statistics.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#merge(org.apache.spark.util.StatCounter)"><B>merge(StatCounter)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Merge another StatCounter into this one, adding up the internal statistics.
<DT><A HREF="./org/apache/spark/Aggregator.html#mergeCombiners()"><B>mergeCombiners()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Aggregator.html#mergeValue()"><B>mergeValue()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html#message()"><B>message()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/AnalysisException.html#message()"><B>message()</B></A> - 
Method in exception org.apache.spark.sql.<A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types"><B>Metadata</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/sql/types/StructField.html#metadata()"><B>metadata()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types"><B>MetadataBuilder</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#MetadataBuilder()"><B>MetadataBuilder()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#method()"><B>method()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MethodIdentifier.html" title="class in org.apache.spark.util"><B>MethodIdentifier</B></A>&lt;<A HREF="./org/apache/spark/util/MethodIdentifier.html" title="type parameter in MethodIdentifier">T</A>&gt; - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>Helper class to identify a method.<DT><A HREF="./org/apache/spark/util/MethodIdentifier.html#MethodIdentifier(java.lang.Class, java.lang.String, java.lang.String)"><B>MethodIdentifier(Class&lt;T&gt;, String, String)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/MethodIdentifier.html" title="class in org.apache.spark.util">MethodIdentifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#metricName()"><B>metricName()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>param for metric name in evaluation
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#metricName()"><B>metricName()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>param for metric name in evaluation (supports <code>"rmse"</code> (default), <code>"mse"</code>, <code>"r2"</code>, and <code>"mae"</code>)
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#metrics()"><B>metrics()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#metricsSystem()"><B>metricsSystem()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#metricsSystem()"><B>metricsSystem()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util"><B>MFDataGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 Generate RDD(s) containing data for Matrix Factorization.<DT><A HREF="./org/apache/spark/mllib/util/MFDataGenerator.html#MFDataGenerator()"><B>MFDataGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util">MFDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#microF1Measure()"><B>microF1Measure()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns micro-averaged label-based f1-measure
 (equals to micro-averaged document-based f1-measure)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#microPrecision()"><B>microPrecision()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns micro-averaged label-based precision
 (equals to micro-averaged document-based precision)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#microRecall()"><B>microRecall()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns micro-averaged label-based recall
 (equals to micro-averaged document-based recall)
<DT><A HREF="./org/apache/spark/streaming/Duration.html#milliseconds()"><B>milliseconds()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Durations.html#milliseconds(long)"><B>milliseconds(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Durations.html" title="class in org.apache.spark.streaming">Durations</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming"><B>Milliseconds</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>Helper object that creates instance of <A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><CODE>Duration</CODE></A> representing
 a given number of milliseconds.<DT><A HREF="./org/apache/spark/streaming/Milliseconds.html#Milliseconds()"><B>Milliseconds()</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming">Milliseconds</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#milliseconds()"><B>milliseconds()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#millisToString(long)"><B>millisToString(long)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>Reformat a time interval in milliseconds to a prettier format for output
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#min()"><B>min()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Returns the minimum element from this RDD as defined by
 the default comparator natural order.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#min(java.util.Comparator)"><B>min(Comparator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the minimum element from this RDD as defined by the specified
 Comparator[T].
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#min()"><B>min()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#min()"><B>min()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#min()"><B>min()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Minimum value of each column.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)"><B>min(Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Returns the min of this RDD as defined by the implicit Ordering[T].
<DT><A HREF="./org/apache/spark/sql/functions.html#min(org.apache.spark.sql.Column)"><B>min(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the minimum value of the expression in a group.
<DT><A HREF="./org/apache/spark/sql/functions.html#min(java.lang.String)"><B>min(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the minimum value of the column in a group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#min(java.lang.String...)"><B>min(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the min value for each numeric column for each group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#min(scala.collection.Seq)"><B>min(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the min value for each numeric column for each group.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#min(org.apache.spark.streaming.Duration)"><B>min(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#min(org.apache.spark.streaming.Time)"><B>min(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#min()"><B>min()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#minDocFreq()"><B>minDocFreq()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/IDF.html#minDocFreq()"><B>minDocFreq()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#minInfoGain()"><B>minInfoGain()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#minInstancesPerNode()"><B>minInstancesPerNode()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#MinMax()"><B>MinMax()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#minTokenLength()"><B>minTokenLength()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>Minimum token length, >= 0.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#minus(org.apache.spark.rdd.RDD)"><B>minus(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#minus(org.apache.spark.graphx.VertexRDD)"><B>minus(VertexRDD&lt;VD&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#minus(org.apache.spark.rdd.RDD)"><B>minus(RDD&lt;Tuple2&lt;Object, VD&gt;&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#minus(org.apache.spark.graphx.VertexRDD)"><B>minus(VertexRDD&lt;VD&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>For each VertexId present in both <code>this</code> and <code>other</code>, minus will act as a set difference
 operation returning only those unique VertexId's present in <code>this</code>.
<DT><A HREF="./org/apache/spark/sql/Column.html#minus(java.lang.Object)"><B>minus(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Subtraction.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#minus(org.apache.spark.streaming.Duration)"><B>minus(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#minus(org.apache.spark.streaming.Time)"><B>minus(Time)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#minus(org.apache.spark.streaming.Duration)"><B>minus(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#minutes()"><B>minutes()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Durations.html#minutes(long)"><B>minutes(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Durations.html" title="class in org.apache.spark.streaming">Durations</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming"><B>Minutes</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>Helper object that creates instance of <A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><CODE>Duration</CODE></A> representing
 a given number of minutes.<DT><A HREF="./org/apache/spark/streaming/Minutes.html#Minutes()"><B>Minutes()</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming">Minutes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#minVal()"><B>minVal()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#mkString()"><B>mkString()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Displays all elements of this sequence in a string (without a separator).
<DT><A HREF="./org/apache/spark/sql/Row.html#mkString(java.lang.String)"><B>mkString(String)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Displays all elements of this sequence in a string using a separator string.
<DT><A HREF="./org/apache/spark/sql/Row.html#mkString(java.lang.String, java.lang.String, java.lang.String)"><B>mkString(String, String, String)</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Displays all elements of this traversable or iterator in a string using
 start, end, and separator strings.
<DT><A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="class in org.apache.spark.mllib.rdd"><B>MLPairRDDFunctions</B></A>&lt;<A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="type parameter in MLPairRDDFunctions">K</A>,<A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="type parameter in MLPairRDDFunctions">V</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/rdd/package-summary.html">org.apache.spark.mllib.rdd</A><DD>Machine learning specific Pair RDD functions.<DT><A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html#MLPairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>MLPairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="class in org.apache.spark.mllib.rdd">MLPairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util"><B>MLUtils</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>Helper methods to load, save and pre-process data used in ML Lib.<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#MLUtils()"><B>MLUtils()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#mod(java.lang.Object)"><B>mod(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Modulo (a.k.a.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#mode(org.apache.spark.sql.SaveMode)"><B>mode(SaveMode)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Specifies the behavior when data or table already exists.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#mode(java.lang.String)"><B>mode(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Specifies the behavior when data or table already exists.
<DT><A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml"><B>Model</B></A>&lt;<A HREF="./org/apache/spark/ml/Model.html" title="type parameter in Model">M</A> extends <A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>&lt;<A HREF="./org/apache/spark/ml/Model.html" title="type parameter in Model">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 A fitted model, i.e., a <A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml"><CODE>Transformer</CODE></A> produced by an <A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml"><CODE>Estimator</CODE></A>.<DT><A HREF="./org/apache/spark/ml/Model.html#Model()"><B>Model()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html#models()"><B>models()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification">OneVsRestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#modelType()"><B>modelType()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.DoubleAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.FloatAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.IntAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.LongAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.CanonicalRandomVertexCut$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition1D$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition2D$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.RandomVertexCut$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating$.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment$.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering.Assignment$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html#MODULE$"><B>MODULE$</B></A> - 
Static variable in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</A>
<DD>Static reference to the singleton instance of this Scala object.
<DT><A HREF="./org/apache/spark/sql/functions.html#monotonicallyIncreasingId()"><B>monotonicallyIncreasingId()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>A column expression that generates monotonically increasing 64-bit integers.
<DT><A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt"><B>MQTTUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/mqtt/package-summary.html">org.apache.spark.streaming.mqtt</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html#MQTTUtils()"><B>MQTTUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.mqtt.<A HREF="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html#mu()"><B>mu()</B></A> - 
Method in class org.apache.spark.mllib.stat.distribution.<A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution">MultivariateGaussian</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation"><B>MulticlassMetrics</B></A> - Class in <A HREF="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</A><DD>::Experimental::
 Evaluator for multiclass classification.<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#MulticlassMetrics(org.apache.spark.rdd.RDD)"><B>MulticlassMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation"><B>MultilabelMetrics</B></A> - Class in <A HREF="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</A><DD>Evaluator for multilabel classification.<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#MultilabelMetrics(org.apache.spark.rdd.RDD)"><B>MultilabelMetrics(RDD&lt;Tuple2&lt;double[], double[]&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/DataValidators.html#multiLabelValidator(int)"><B>multiLabelValidator(int)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util">DataValidators</A>
<DD>Function to check if labels used for k class multi-label classification are
 in the range of {0, 1, ..., k - 1}.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#Multinomial()"><B>Multinomial()</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>String name for multinomial model type.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#multiply(org.apache.spark.mllib.linalg.distributed.BlockMatrix)"><B>multiply(BlockMatrix)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Left multiplies this <A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><CODE>BlockMatrix</CODE></A> to <code>other</code>, another <A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><CODE>BlockMatrix</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#multiply(org.apache.spark.mllib.linalg.Matrix)"><B>multiply(Matrix)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#multiply(org.apache.spark.mllib.linalg.Matrix)"><B>multiply(Matrix)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Multiply this matrix by a local matrix on the right.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#multiply(org.apache.spark.mllib.linalg.DenseMatrix)"><B>multiply(DenseMatrix)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Convenience method for `Matrix`-`DenseMatrix` multiplication.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#multiply(org.apache.spark.mllib.linalg.DenseVector)"><B>multiply(DenseVector)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Convenience method for `Matrix`-`DenseVector` multiplication.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#multiply(org.apache.spark.mllib.linalg.Vector)"><B>multiply(Vector)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Convenience method for `Matrix`-`Vector` multiplication.
<DT><A HREF="./org/apache/spark/sql/Column.html#multiply(java.lang.Object)"><B>multiply(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Multiplication of this expression and another expression.
<DT><A HREF="./org/apache/spark/util/Vector.html#multiply(double)"><B>multiply(double)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution"><B>MultivariateGaussian</B></A> - Class in <A HREF="./org/apache/spark/mllib/stat/distribution/package-summary.html">org.apache.spark.mllib.stat.distribution</A><DD>:: DeveloperApi ::
 This class provides basic functionality for a Multivariate Gaussian (Normal) Distribution.<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html#MultivariateGaussian(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Matrix)"><B>MultivariateGaussian(Vector, Matrix)</B></A> - 
Constructor for class org.apache.spark.mllib.stat.distribution.<A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution">MultivariateGaussian</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat"><B>MultivariateOnlineSummarizer</B></A> - Class in <A HREF="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</A><DD>:: DeveloperApi ::
 MultivariateOnlineSummarizer implements <A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat"><CODE>MultivariateStatisticalSummary</CODE></A> to compute the mean,
 variance, minimum, maximum, counts, and nonzero counts for samples in sparse or dense vector
 format in a online fashion.<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#MultivariateOnlineSummarizer()"><B>MultivariateOnlineSummarizer()</B></A> - 
Constructor for class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat"><B>MultivariateStatisticalSummary</B></A> - Interface in <A HREF="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</A><DD>Trait for multivariate statistical summary of a data matrix.<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#mustCheckpoint()"><B>mustCheckpoint()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util"><B>MutablePair</B></A>&lt;<A HREF="./org/apache/spark/util/MutablePair.html" title="type parameter in MutablePair">T1</A>,<A HREF="./org/apache/spark/util/MutablePair.html" title="type parameter in MutablePair">T2</A>&gt; - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>:: DeveloperApi ::
 A tuple of 2 elements.<DT><A HREF="./org/apache/spark/util/MutablePair.html#MutablePair(T1, T2)"><B>MutablePair(T1, T2)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html#MutablePair()"><B>MutablePair()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>No-arg constructor for serialization
<DT><A HREF="./org/apache/spark/util/InnerClosureFinder.html#myName()"><B>myName()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/InnerClosureFinder.html" title="class in org.apache.spark.util">InnerClosureFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html" title="class in org.apache.spark.sql.jdbc"><B>MySQLDialect</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 Default mysql dialect to read bit/bitsets correctly.<DT><A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html#MySQLDialect()"><B>MySQLDialect()</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html" title="class in org.apache.spark.sql.jdbc">MySQLDialect</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_N_"><!-- --></A><H2>
<B>N</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#na()"><B>na()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a <A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><CODE>DataFrameNaFunctions</CODE></A> for working with missing data.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification"><B>NaiveBayes</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#NaiveBayes(double)"><B>NaiveBayes(double)</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#NaiveBayes()"><B>NaiveBayes()</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification"><B>NaiveBayesModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Model for Naive Bayes Classifiers.<DT><A HREF="./org/apache/spark/Accumulable.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#name()"><B>name()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Name of the attribute.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#name()"><B>name()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>A friendly name for this RDD
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#name()"><B>name()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructField.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html" title="class in org.apache.spark.status.api.v1">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>A globally unique identifier for this Block.
<DT><A HREF="./org/apache/spark/storage/BroadcastBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage">ShuffleDataBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StreamBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TaskResultBlockId.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MethodIdentifier.html#name()"><B>name()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MethodIdentifier.html" title="class in org.apache.spark.util">MethodIdentifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark"><B>NarrowDependency</B></A>&lt;<A HREF="./org/apache/spark/NarrowDependency.html" title="type parameter in NarrowDependency">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Base class for dependencies where each partition of the child RDD depends on a small number
 of partitions of the parent RDD.<DT><A HREF="./org/apache/spark/NarrowDependency.html#NarrowDependency(org.apache.spark.rdd.RDD)"><B>NarrowDependency(RDD&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html#ndcgAt(int)"><B>ndcgAt(int)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation">RankingMetrics</A>
<DD>Compute the average NDCG value of all the queries, truncated at ranking position k.
<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html#needConversion()"><B>needConversion()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A>
<DD>Whether does it need to convert the objects in Row to internal representation, for example:
  java.lang.String -> UTF8String
  java.lang.Decimal -> Decimal
<DT><A HREF="./org/apache/spark/sql/functions.html#negate(org.apache.spark.sql.Column)"><B>negate(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Unary minus, i.e.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#networkStream(org.apache.spark.streaming.receiver.Receiver, scala.reflect.ClassTag)"><B>networkStream(Receiver&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.0.0", replaced by <code>receiverStream</code>.</I>
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#newAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>newAPIHadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.
<DT><A HREF="./org/apache/spark/SparkContext.html#newAPIHadoopFile(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>newAPIHadoopFile(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a Hadoop file with an arbitrary new API InputFormat.
<DT><A HREF="./org/apache/spark/SparkContext.html#newAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>newAPIHadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#newAPIHadoopRDD(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.Class, java.lang.Class)"><B>newAPIHadoopRDD(Configuration, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.
<DT><A HREF="./org/apache/spark/SparkContext.html#newAPIHadoopRDD(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.Class, java.lang.Class)"><B>newAPIHadoopRDD(Configuration, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.
<DT><A HREF="./org/apache/spark/broadcast/BroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)"><B>newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</A>
<DD>Creates a new broadcast variable.
<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)"><B>newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)"><B>newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd"><B>NewHadoopRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</A>,<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the new MapReduce API (<code>org.apache.hadoop.mapreduce</code>).<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#NewHadoopRDD(org.apache.spark.SparkContext, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>NewHadoopRDD(SparkContext, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaSerializer.html#newInstance()"><B>newInstance()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#newInstance()"><B>newInstance()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/Serializer.html#newInstance()"><B>newInstance()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</A>
<DD>Creates a new <A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer"><CODE>SerializerInstance</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html#newInstance(java.lang.String, org.apache.spark.sql.types.StructType, org.apache.hadoop.mapreduce.TaskAttemptContext)"><B>newInstance(String, StructType, TaskAttemptContext)</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</A>
<DD>When writing to a <A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources"><CODE>HadoopFsRelation</CODE></A>, this method gets called by each task on executor side
 to instantiate new <A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriter</CODE></A>s.
<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#newKryo()"><B>newKryo()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#newKryoOutput()"><B>newKryoOutput()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#newTemporaryConfiguration()"><B>newTemporaryConfiguration()</B></A> - 
Static method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>Constructs a configuration for hive, where the metastore is located in a temp directory.
<DT><A HREF="./org/apache/spark/InterruptibleIterator.html#next()"><B>next()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html#next()"><B>next()</B></A> - 
Method in interface org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAOptimizer.html" title="interface in org.apache.spark.mllib.clustering">LDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#next()"><B>next()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html#next()"><B>next()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/CountingIterator.html" title="class in org.apache.spark.streaming.receiver">CountingIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/json/JacksonUtils.html#nextUntil(com.fasterxml.jackson.core.JsonParser, com.fasterxml.jackson.core.JsonToken)"><B>nextUntil(JsonParser, JsonToken)</B></A> - 
Static method in class org.apache.spark.sql.json.<A HREF="./org/apache/spark/sql/json/JacksonUtils.html" title="class in org.apache.spark.sql.json">JacksonUtils</A>
<DD>Advance the parser until a null or a specific token is found
<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random">ExponentialGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in interface org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random">RandomDataGenerator</A>
<DD>Returns an i.i.d.
<DT><A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/UniformGenerator.html#nextValue()"><B>nextValue()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#NO_PREF()"><B>NO_PREF()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/Node.html" title="class in org.apache.spark.ml.tree"><B>Node</B></A> - Class in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Decision tree node interface.<DT><A HREF="./org/apache/spark/ml/tree/Node.html#Node()"><B>Node()</B></A> - 
Constructor for class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Node.html" title="class in org.apache.spark.ml.tree">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model"><B>Node</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: DeveloperApi ::
 Node in a decision tree.<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#Node(int, org.apache.spark.mllib.tree.model.Predict, double, boolean, scala.Option, scala.Option, scala.Option, scala.Option)"><B>Node(int, Predict, double, boolean, Option&lt;Split&gt;, Option&lt;Node&gt;, Option&lt;Node&gt;, Option&lt;InformationGainStats&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#NODE_LOCAL()"><B>NODE_LOCAL()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#noLocality()"><B>noLocality()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#Nominal()"><B>Nominal()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>Nominal type.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute"><B>NominalAttribute</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 A nominal attribute.<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#NONE"><B>NONE</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#None"><B>None</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>None of the triplet fields are exposed.
<DT><A HREF="./org/apache/spark/scheduler/SchedulingMode.html#NONE()"><B>NONE()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#NONE()"><B>NONE()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/NoopDialect.html" title="class in org.apache.spark.sql.jdbc"><B>NoopDialect</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 NOOP dialect object, always returning the neutral element.<DT><A HREF="./org/apache/spark/sql/jdbc/NoopDialect.html#NoopDialect()"><B>NoopDialect()</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/NoopDialect.html" title="class in org.apache.spark.sql.jdbc">NoopDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#norm(org.apache.spark.mllib.linalg.Vector, double)"><B>norm(Vector, double)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Returns the p-norm of this vector.
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature"><B>Normalizer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Normalize a vector to have unit norm using the given p-norm.<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#Normalizer(java.lang.String)"><B>Normalizer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#Normalizer()"><B>Normalizer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature"><B>Normalizer</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Normalizes samples individually to unit L^p^ norm<DT><A HREF="./org/apache/spark/mllib/feature/Normalizer.html#Normalizer(double)"><B>Normalizer(double)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Normalizer.html#Normalizer()"><B>Normalizer()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><B>normalJavaRDD(JavaSparkContext, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalRDD(org.apache.spark.SparkContext, long, int, long)"><CODE>RandomRDDs.normalRDD(org.apache.spark.SparkContext, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int)"><B>normalJavaRDD(JavaSparkContext, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><CODE>RandomRDDs.normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long)"><B>normalJavaRDD(JavaSparkContext, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><CODE>RandomRDDs.normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><B>normalJavaVectorRDD(JavaSparkContext, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><CODE>RandomRDDs.normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int)"><B>normalJavaVectorRDD(JavaSparkContext, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><CODE>RandomRDDs.normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int)"><B>normalJavaVectorRDD(JavaSparkContext, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><CODE>RandomRDDs.normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalRDD(org.apache.spark.SparkContext, long, int, long)"><B>normalRDD(SparkContext, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the standard normal distribution.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><B>normalVectorRDD(SparkContext, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from the
 standard normal distribution.
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#normL1()"><B>normL1()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#normL1()"><B>normL1()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>L1 norm of each column
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#normL2()"><B>normL2()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#normL2()"><B>normL2()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Euclidean magnitude of each column
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#normPdf(double, double, double, double)"><B>normPdf(double, double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>Evaluates the PDF of a normal distribution.
<DT><A HREF="./org/apache/spark/sql/functions.html#not(org.apache.spark.sql.Column)"><B>not(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Inversion of boolean expression, i.e.
<DT><A HREF="./org/apache/spark/sql/sources/Not.html" title="class in org.apache.spark.sql.sources"><B>Not</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff <code>child</code> is evaluated to <code>false</code>.<DT><A HREF="./org/apache/spark/sql/sources/Not.html#Not(org.apache.spark.sql.sources.Filter)"><B>Not(Filter)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Not.html" title="class in org.apache.spark.sql.sources">Not</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#notEqual(java.lang.Object)"><B>notEqual(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Inequality test.
<DT><A HREF="./org/apache/spark/sql/functions.html#ntile(int)"><B>ntile(int)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the ntile group id (from 1 to <code>n</code> inclusive) in an ordered window
 partition.
<DT><A HREF="./org/apache/spark/sql/types/StructField.html#nullable()"><B>nullable()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#nullHypothesis()"><B>nullHypothesis()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html#nullHypothesis()"><B>nullHypothesis()</B></A> - 
Method in interface org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</A>
<DD>Null hypothesis of the test.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#NullType"><B>NullType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the NullType object.
<DT><A HREF="./org/apache/spark/sql/types/NullType.html" title="class in org.apache.spark.sql.types"><B>NullType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>NULL</code> values.<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#numActives()"><B>numActives()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#numActives()"><B>numActives()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#numActives()"><B>numActives()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Number of active entries.
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numActiveStages()"><B>numActiveStages()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#numActiveTasks()"><B>numActiveTasks()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#numActiveTasks()"><B>numActiveTasks()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numActiveTasks()"><B>numActiveTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#numActiveTasks()"><B>numActiveTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#numAttributes()"><B>numAttributes()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html#numberOfHiccups()"><B>numberOfHiccups()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html#numberOfMsgs()"><B>numberOfMsgs()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html#numberOfWorkers()"><B>numberOfWorkers()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#numBins()"><B>numBins()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#numBlocks()"><B>numBlocks()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the number of blocks stored in this block manager in O(RDDs) time.
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#numCachedPartitions()"><B>numCachedPartitions()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#numCachedPartitions()"><B>numCachedPartitions()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/ClassificationModel.html#numClasses()"><B>numClasses()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>
<DD>Number of classes (values which the label can take).
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#numClasses()"><B>numClasses()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#numClasses()"><B>numClasses()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#numClasses()"><B>numClasses()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#numColBlocks()"><B>numColBlocks()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</A>
<DD>Gets or computes the number of columns.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Gets or computes the number of columns.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#numCols()"><B>numCols()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Number of columns.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#numCols()"><B>numCols()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#numCompletedJobs()"><B>numCompletedJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numCompletedStages()"><B>numCompletedStages()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#numCompletedStages()"><B>numCompletedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#numCompletedTasks()"><B>numCompletedTasks()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#numCompletedTasks()"><B>numCompletedTasks()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numCompletedTasks()"><B>numCompletedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#numCompleteTasks()"><B>numCompleteTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#numEdges()"><B>numEdges()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>The number of edges in the graph.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#Numeric()"><B>Numeric()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>Numeric type.
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/NumericType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/NumericType.html" title="class in org.apache.spark.sql.types">NumericType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#numeric()"><B>numeric()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute"><B>NumericAttribute</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 A numeric attribute with optional summary statistics.<DT><A HREF="./org/apache/spark/rdd/RDD.html#numericRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Numeric)"><B>numericRDDToDoubleRDDFunctions(RDD&lt;T&gt;, Numeric&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#numericRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Numeric)"><B>numericRDDToDoubleRDDFunctions(RDD&lt;T&gt;, Numeric&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/NumericType.html" title="class in org.apache.spark.sql.types"><B>NumericType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 Numeric data types.<DT><A HREF="./org/apache/spark/sql/types/NumericType.html#NumericType()"><B>NumericType()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/NumericType.html" title="class in org.apache.spark.sql.types">NumericType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#numFailedJobs()"><B>numFailedJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numFailedStages()"><B>numFailedStages()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#numFailedStages()"><B>numFailedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#numFailedTasks()"><B>numFailedTasks()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#numFailedTasks()"><B>numFailedTasks()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numFailedTasks()"><B>numFailedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#numFailedTasks()"><B>numFailedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#numFeatures()"><B>numFeatures()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>Number of features.
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#numFeatures()"><B>numFeatures()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#numFeatures()"><B>numFeatures()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#numFeatures()"><B>numFeatures()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#numIterations()"><B>numIterations()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#numNodes()"><B>numNodes()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Get number of nodes in tree, including leaf nodes.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#numNonzeros()"><B>numNonzeros()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#numNonzeros()"><B>numNonzeros()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#numNonzeros()"><B>numNonzeros()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Number of nonzero elements.
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#numNonzeros()"><B>numNonzeros()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#numNonzeros()"><B>numNonzeros()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Number of nonzero elements (including explicitly presented zero values) in each column.
<DT><A HREF="./org/apache/spark/HashPartitioner.html#numPartitions()"><B>numPartitions()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partitioner.html#numPartitions()"><B>numPartitions()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html#numPartitions()"><B>numPartitions()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#numPartitions()"><B>numPartitions()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#numPartitions()"><B>numPartitions()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#numRddBlocks()"><B>numRddBlocks()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the number of RDD blocks stored in this block manager in O(RDDs) time.
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#numRddBlocksById(int)"><B>numRddBlocksById(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the number of blocks that belong to the given RDD in O(1) time.
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#numRecords()"><B>numRecords()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>The number of recorders received by the receivers in this batch.
<DT><A HREF="./org/apache/spark/util/RpcUtils.html#numRetries(org.apache.spark.SparkConf)"><B>numRetries(SparkConf)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>Returns the configured number of times to retry connecting
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#numRowBlocks()"><B>numRowBlocks()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</A>
<DD>Gets or computes the number of rows.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Gets or computes the number of rows.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#numRows()"><B>numRows()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Number of rows.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#numRows()"><B>numRows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numSkippedStages()"><B>numSkippedStages()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numSkippedTasks()"><B>numSkippedTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#numTasks()"><B>numTasks()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#numTasks()"><B>numTasks()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#numTasks()"><B>numTasks()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#numTasks()"><B>numTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html#numTopFeatures()"><B>numTopFeatures()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelector.html" title="class in org.apache.spark.mllib.feature">ChiSqSelector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#numValues()"><B>numValues()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#numVertices()"><B>numVertices()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>The number of vertices in the graph.
</DL>
<HR>
<A NAME="_O_"><!-- --></A><H2>
<B>O</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#objectFile(java.lang.String, int)"><B>objectFile(String, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#objectFile(java.lang.String)"><B>objectFile(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.
<DT><A HREF="./org/apache/spark/SparkContext.html#objectFile(java.lang.String, int, scala.reflect.ClassTag)"><B>objectFile(String, int, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.
<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html#of(org.apache.spark.api.java.JavaRDD)"><B>of(JavaRDD&lt;Tuple2&lt;T, T&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation">RankingMetrics</A>
<DD>Creates a <A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation"><CODE>RankingMetrics</CODE></A> instance (for Java users).
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#OFF_HEAP"><B>OFF_HEAP</B></A> - 
Static variable in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#OFF_HEAP()"><B>OFF_HEAP()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#offHeapUsed()"><B>offHeapUsed()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the off-heap space used by this block manager.
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#offHeapUsedByRdd(int)"><B>offHeapUsedByRdd(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the off-heap space used by the given RDD in this block manager in O(1) time.
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka"><B>OffsetRange</B></A> - Class in <A HREF="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</A><DD>:: Experimental ::
 Represents a range of offsets from a single Kafka TopicAndPartition.<DT><A HREF="./org/apache/spark/streaming/kafka/HasOffsetRanges.html#offsetRanges()"><B>offsetRanges()</B></A> - 
Method in interface org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/HasOffsetRanges.html" title="interface in org.apache.spark.streaming.kafka">HasOffsetRanges</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onApplicationEnd(org.apache.spark.scheduler.SparkListenerApplicationEnd)"><B>onApplicationEnd(SparkListenerApplicationEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onApplicationEnd(org.apache.spark.scheduler.SparkListenerApplicationEnd)"><B>onApplicationEnd(SparkListenerApplicationEnd)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when the application ends
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onApplicationEnd(org.apache.spark.scheduler.SparkListenerApplicationEnd)"><B>onApplicationEnd(SparkListenerApplicationEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)"><B>onApplicationStart(SparkListenerApplicationStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)"><B>onApplicationStart(SparkListenerApplicationStart)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when the application starts
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)"><B>onApplicationStart(SparkListenerApplicationStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)"><B>onApplicationStart(SparkListenerApplicationStart)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#onBatchCompleted(org.apache.spark.streaming.scheduler.StreamingListenerBatchCompleted)"><B>onBatchCompleted(StreamingListenerBatchCompleted)</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchCompleted(org.apache.spark.streaming.scheduler.StreamingListenerBatchCompleted)"><B>onBatchCompleted(StreamingListenerBatchCompleted)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when processing of a batch of jobs has completed.
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchStarted(org.apache.spark.streaming.scheduler.StreamingListenerBatchStarted)"><B>onBatchStarted(StreamingListenerBatchStarted)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when processing of a batch of jobs has started.
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchSubmitted(org.apache.spark.streaming.scheduler.StreamingListenerBatchSubmitted)"><B>onBatchSubmitted(StreamingListenerBatchSubmitted)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when a batch of jobs has been submitted for processing.
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)"><B>onBlockManagerAdded(SparkListenerBlockManagerAdded)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)"><B>onBlockManagerAdded(SparkListenerBlockManagerAdded)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a new block manager has joined
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)"><B>onBlockManagerAdded(SparkListenerBlockManagerAdded)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)"><B>onBlockManagerAdded(SparkListenerBlockManagerAdded)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)"><B>onBlockManagerAdded(SparkListenerBlockManagerAdded)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)"><B>onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)"><B>onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when an existing block manager has been removed
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)"><B>onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)"><B>onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)"><B>onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)"><B>onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)"><B>onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>When this action is completed, either through an exception, or a value, applies the provided
 function.
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#onComplete(scala.Function1)"><B>onComplete(Function1&lt;R, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>Set a handler to be called when this PartialResult completes.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)"><B>onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature"><B>OneHotEncoder</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 A one-hot encoder that maps a column of category indices to a column of binary vectors, with
 at most a single one-value per row that indicates the input category index.<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#OneHotEncoder(java.lang.String)"><B>OneHotEncoder(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#OneHotEncoder()"><B>OneHotEncoder()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)"><B>onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)"><B>onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when environment properties have been updated
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)"><B>onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)"><B>onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</B></A> - 
Method in class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)"><B>onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#ones(int, int)"><B>ones(int, int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a <code>DenseMatrix</code> consisting of ones.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#ones(int, int)"><B>ones(int, int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>DenseMatrix</code> consisting of ones.
<DT><A HREF="./org/apache/spark/util/Vector.html#ones(int)"><B>ones(int)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark"><B>OneToOneDependency</B></A>&lt;<A HREF="./org/apache/spark/OneToOneDependency.html" title="type parameter in OneToOneDependency">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Represents a one-to-one dependency between partitions of the parent and child RDDs.<DT><A HREF="./org/apache/spark/OneToOneDependency.html#OneToOneDependency(org.apache.spark.rdd.RDD)"><B>OneToOneDependency(RDD&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark">OneToOneDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onEvent(org.apache.spark.scheduler.SparkListenerEvent)"><B>onEvent(SparkListenerEvent)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification"><B>OneVsRest</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#OneVsRest(java.lang.String)"><B>OneVsRest(String)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#OneVsRest()"><B>OneVsRest()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification"><B>OneVsRestModel</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 Model produced by <A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification"><CODE>OneVsRest</CODE></A>.<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onExecutorAdded(org.apache.spark.scheduler.SparkListenerExecutorAdded)"><B>onExecutorAdded(SparkListenerExecutorAdded)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onExecutorAdded(org.apache.spark.scheduler.SparkListenerExecutorAdded)"><B>onExecutorAdded(SparkListenerExecutorAdded)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when the driver registers a new executor.
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onExecutorAdded(org.apache.spark.scheduler.SparkListenerExecutorAdded)"><B>onExecutorAdded(SparkListenerExecutorAdded)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#onExecutorAdded(org.apache.spark.scheduler.SparkListenerExecutorAdded)"><B>onExecutorAdded(SparkListenerExecutorAdded)</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)"><B>onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)"><B>onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when the driver receives task metrics from an executor in a heartbeat.
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)"><B>onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)"><B>onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onExecutorRemoved(org.apache.spark.scheduler.SparkListenerExecutorRemoved)"><B>onExecutorRemoved(SparkListenerExecutorRemoved)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onExecutorRemoved(org.apache.spark.scheduler.SparkListenerExecutorRemoved)"><B>onExecutorRemoved(SparkListenerExecutorRemoved)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when the driver removes an executor.
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onExecutorRemoved(org.apache.spark.scheduler.SparkListenerExecutorRemoved)"><B>onExecutorRemoved(SparkListenerExecutorRemoved)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#onExecutorRemoved(org.apache.spark.scheduler.SparkListenerExecutorRemoved)"><B>onExecutorRemoved(SparkListenerExecutorRemoved)</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#onFail(scala.Function1)"><B>onFail(Function1&lt;Exception, BoxedUnit&gt;)</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>Set a handler to be called if this PartialResult's job fails.
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)"><B>onJobEnd(SparkListenerJobEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)"><B>onJobEnd(SparkListenerJobEnd)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>When job ends, recording job completion status and close log file
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)"><B>onJobEnd(SparkListenerJobEnd)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a job ends
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)"><B>onJobEnd(SparkListenerJobEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)"><B>onJobEnd(SparkListenerJobEnd)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)"><B>onJobStart(SparkListenerJobStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)"><B>onJobStart(SparkListenerJobStart)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>When job starts, record job property and stage graph
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)"><B>onJobStart(SparkListenerJobStart)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a job starts
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)"><B>onJobStart(SparkListenerJobStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)"><B>onJobStart(SparkListenerJobStart)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering"><B>OnlineLDAOptimizer</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#OnlineLDAOptimizer()"><B>OnlineLDAOptimizer()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverError(org.apache.spark.streaming.scheduler.StreamingListenerReceiverError)"><B>onReceiverError(StreamingListenerReceiverError)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when a receiver has reported an error
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverStarted(org.apache.spark.streaming.scheduler.StreamingListenerReceiverStarted)"><B>onReceiverStarted(StreamingListenerReceiverStarted)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when a receiver has been started
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverStopped(org.apache.spark.streaming.scheduler.StreamingListenerReceiverStopped)"><B>onReceiverStopped(StreamingListenerReceiverStopped)</B></A> - 
Method in interface org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</A>
<DD>Called when a receiver has been stopped
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>When stage is completed, record stage completion status
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a stage completes successfully or fails, with information on the completed stage.
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)"><B>onStageCompleted(SparkListenerStageCompleted)</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>When stage is submitted, record stage submit info
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a stage is submitted
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>For FIFO, all stages are contained by "default" pool but "default" pool here is meaningless
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)"><B>onStageSubmitted(SparkListenerStageSubmitted)</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#onStart()"><B>onStart()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>This method is called by the system when the receiver is started.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#onStop()"><B>onStop()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>This method is called by the system when the receiver is stopped.
<DT><A HREF="./org/apache/spark/util/TaskCompletionListener.html#onTaskCompletion(org.apache.spark.TaskContext)"><B>onTaskCompletion(TaskContext)</B></A> - 
Method in interface org.apache.spark.util.<A HREF="./org/apache/spark/util/TaskCompletionListener.html" title="interface in org.apache.spark.util">TaskCompletionListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>When task ends, record task completion status and metrics
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a task ends
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)"><B>onTaskEnd(SparkListenerTaskEnd)</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>Assumes the storage status list is fully up-to-date.
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)"><B>onTaskGettingResult(SparkListenerTaskGettingResult)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)"><B>onTaskGettingResult(SparkListenerTaskGettingResult)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a task begins remotely fetching its result (will not be called for tasks that do
 not need to fetch the result remotely).
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)"><B>onTaskGettingResult(SparkListenerTaskGettingResult)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)"><B>onTaskGettingResult(SparkListenerTaskGettingResult)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)"><B>onTaskStart(SparkListenerTaskStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)"><B>onTaskStart(SparkListenerTaskStart)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when a task starts
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)"><B>onTaskStart(SparkListenerTaskStart)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)"><B>onTaskStart(SparkListenerTaskStart)</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)"><B>onTaskStart(SparkListenerTaskStart)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/JavaSparkListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)"><B>onUnpersistRDD(SparkListenerUnpersistRDD)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/JavaSparkListener.html" title="class in org.apache.spark">JavaSparkListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)"><B>onUnpersistRDD(SparkListenerUnpersistRDD)</B></A> - 
Method in interface org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</A>
<DD>Called when an RDD is manually unpersisted by the application
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)"><B>onUnpersistRDD(SparkListenerUnpersistRDD)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)"><B>onUnpersistRDD(SparkListenerUnpersistRDD)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)"><B>onUnpersistRDD(SparkListenerUnpersistRDD)</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/input/PortableDataStream.html#open()"><B>open()</B></A> - 
Method in class org.apache.spark.input.<A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input">PortableDataStream</A>
<DD>Create a new DataInputStream from the split and context
<DT><A HREF="./org/apache/spark/graphx/Graph.html#ops()"><B>ops()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>The associated <A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx"><CODE>GraphOps</CODE></A> object.
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)"><B>optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>:: DeveloperApi ::
 Runs gradient descent on the given training data.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)"><B>optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/Optimizer.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)"><B>optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</B></A> - 
Method in interface org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Optimizer.html" title="interface in org.apache.spark.mllib.optimization">Optimizer</A>
<DD>Solve the provided convex optimization problem.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithLBFGS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/Optimizer.html" title="interface in org.apache.spark.mllib.optimization"><B>Optimizer</B></A> - Interface in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Trait for optimization problem solvers.<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>The optimizer to solve the problem.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#optimizer()"><B>optimizer()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#option(java.lang.String, java.lang.String)"><B>option(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Adds an input option for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#option(java.lang.String, java.lang.String)"><B>option(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Adds an output option for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#options(scala.collection.Map)"><B>options(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>(Scala-specific) Adds input options for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#options(java.util.Map)"><B>options(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Adds input options for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#options(scala.collection.Map)"><B>options(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>(Scala-specific) Adds output options for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#options(java.util.Map)"><B>options(Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Adds output options for the underlying data source.
<DT><A HREF="./org/apache/spark/sql/Column.html#or(org.apache.spark.sql.Column)"><B>or(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Boolean OR.
<DT><A HREF="./org/apache/spark/sql/sources/Or.html" title="class in org.apache.spark.sql.sources"><B>Or</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff at least one of <code>left</code> or <code>right</code> evaluates to <code>true</code>.<DT><A HREF="./org/apache/spark/sql/sources/Or.html#Or(org.apache.spark.sql.sources.Filter, org.apache.spark.sql.sources.Filter)"><B>Or(Filter, Filter)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Or.html" title="class in org.apache.spark.sql.sources">Or</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#orderBy(java.lang.String, java.lang.String...)"><B>orderBy(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#orderBy(org.apache.spark.sql.Column...)"><B>orderBy(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#orderBy(java.lang.String, scala.collection.Seq)"><B>orderBy(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#orderBy(scala.collection.Seq)"><B>orderBy(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#orderBy(java.lang.String, java.lang.String...)"><B>orderBy(String, String...)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the ordering defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#orderBy(org.apache.spark.sql.Column...)"><B>orderBy(Column...)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the ordering defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#orderBy(java.lang.String, scala.collection.Seq)"><B>orderBy(String, Seq&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the ordering defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#orderBy(scala.collection.Seq)"><B>orderBy(Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the ordering defined.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#orderBy(java.lang.String, java.lang.String...)"><B>orderBy(String, String...)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the ordering columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#orderBy(org.apache.spark.sql.Column...)"><B>orderBy(Column...)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the ordering columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#orderBy(java.lang.String, scala.collection.Seq)"><B>orderBy(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the ordering columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#orderBy(scala.collection.Seq)"><B>orderBy(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the ordering columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd"><B>OrderedRDDFunctions</B></A>&lt;<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">K</A>,<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">V</A>,<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">P</A> extends scala.Product2&lt;<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">K</A>,<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">V</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>Extra functions available on RDDs of (key, value) pairs where the key is sortable through
 an implicit conversion.<DT><A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html#OrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>OrderedRDDFunctions(RDD&lt;P&gt;, Ordering&lt;K&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;P&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/BinaryType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BinaryType.html" title="class in org.apache.spark.sql.types">BinaryType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/BooleanType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BooleanType.html" title="class in org.apache.spark.sql.types">BooleanType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DateType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DateType.html" title="class in org.apache.spark.sql.types">DateType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StringType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StringType.html" title="class in org.apache.spark.sql.types">StringType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/TimestampType.html#ordering()"><B>ordering()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/TimestampType.html" title="class in org.apache.spark.sql.types">TimestampType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#ordering()"><B>ordering()</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/package-summary.html"><B>org.apache.spark</B></A> - package org.apache.spark<DD>Core Spark classes in Scala.<DT><A HREF="./org/apache/spark/annotation/package-summary.html"><B>org.apache.spark.annotation</B></A> - package org.apache.spark.annotation<DD>Spark annotations to mark an API experimental or intended only for advanced usages by developers.<DT><A HREF="./org/apache/spark/api/java/package-summary.html"><B>org.apache.spark.api.java</B></A> - package org.apache.spark.api.java<DD>Spark Java programming APIs.<DT><A HREF="./org/apache/spark/api/java/function/package-summary.html"><B>org.apache.spark.api.java.function</B></A> - package org.apache.spark.api.java.function<DD>Set of interfaces to represent functions in Spark's Java API.<DT><A HREF="./org/apache/spark/api/r/package-summary.html"><B>org.apache.spark.api.r</B></A> - package org.apache.spark.api.r<DD>&nbsp;<DT><A HREF="./org/apache/spark/broadcast/package-summary.html"><B>org.apache.spark.broadcast</B></A> - package org.apache.spark.broadcast<DD>Spark's broadcast variables, used to broadcast immutable datasets to all nodes.<DT><A HREF="./org/apache/spark/examples/streaming/package-summary.html"><B>org.apache.spark.examples.streaming</B></A> - package org.apache.spark.examples.streaming<DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/package-summary.html"><B>org.apache.spark.graphx</B></A> - package org.apache.spark.graphx<DD>ALPHA COMPONENT
 GraphX is a graph processing framework built on top of Spark.<DT><A HREF="./org/apache/spark/graphx/impl/package-summary.html"><B>org.apache.spark.graphx.impl</B></A> - package org.apache.spark.graphx.impl<DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/lib/package-summary.html"><B>org.apache.spark.graphx.lib</B></A> - package org.apache.spark.graphx.lib<DD>Various analytics functions for graphs.<DT><A HREF="./org/apache/spark/graphx/util/package-summary.html"><B>org.apache.spark.graphx.util</B></A> - package org.apache.spark.graphx.util<DD>Collections of utilities used by graphx.<DT><A HREF="./org/apache/spark/input/package-summary.html"><B>org.apache.spark.input</B></A> - package org.apache.spark.input<DD>&nbsp;<DT><A HREF="./org/apache/spark/io/package-summary.html"><B>org.apache.spark.io</B></A> - package org.apache.spark.io<DD>IO codecs used for compression.<DT><A HREF="./org/apache/spark/launcher/package-summary.html"><B>org.apache.spark.launcher</B></A> - package org.apache.spark.launcher<DD>Library for launching Spark applications.<DT><A HREF="./org/apache/spark/ml/package-summary.html"><B>org.apache.spark.ml</B></A> - package org.apache.spark.ml<DD>Spark ML is a BETA component that adds a new set of machine learning APIs to let users quickly
 assemble and configure practical machine learning pipelines.<DT><A HREF="./org/apache/spark/ml/attribute/package-summary.html"><B>org.apache.spark.ml.attribute</B></A> - package org.apache.spark.ml.attribute<DD>ML attributes<DT><A HREF="./org/apache/spark/ml/classification/package-summary.html"><B>org.apache.spark.ml.classification</B></A> - package org.apache.spark.ml.classification<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/evaluation/package-summary.html"><B>org.apache.spark.ml.evaluation</B></A> - package org.apache.spark.ml.evaluation<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/feature/package-summary.html"><B>org.apache.spark.ml.feature</B></A> - package org.apache.spark.ml.feature<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/param/package-summary.html"><B>org.apache.spark.ml.param</B></A> - package org.apache.spark.ml.param<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/recommendation/package-summary.html"><B>org.apache.spark.ml.recommendation</B></A> - package org.apache.spark.ml.recommendation<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/regression/package-summary.html"><B>org.apache.spark.ml.regression</B></A> - package org.apache.spark.ml.regression<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/tree/package-summary.html"><B>org.apache.spark.ml.tree</B></A> - package org.apache.spark.ml.tree<DD>&nbsp;<DT><A HREF="./org/apache/spark/ml/tuning/package-summary.html"><B>org.apache.spark.ml.tuning</B></A> - package org.apache.spark.ml.tuning<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/classification/package-summary.html"><B>org.apache.spark.mllib.classification</B></A> - package org.apache.spark.mllib.classification<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/clustering/package-summary.html"><B>org.apache.spark.mllib.clustering</B></A> - package org.apache.spark.mllib.clustering<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/evaluation/package-summary.html"><B>org.apache.spark.mllib.evaluation</B></A> - package org.apache.spark.mllib.evaluation<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/feature/package-summary.html"><B>org.apache.spark.mllib.feature</B></A> - package org.apache.spark.mllib.feature<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/fpm/package-summary.html"><B>org.apache.spark.mllib.fpm</B></A> - package org.apache.spark.mllib.fpm<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/linalg/package-summary.html"><B>org.apache.spark.mllib.linalg</B></A> - package org.apache.spark.mllib.linalg<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html"><B>org.apache.spark.mllib.linalg.distributed</B></A> - package org.apache.spark.mllib.linalg.distributed<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/optimization/package-summary.html"><B>org.apache.spark.mllib.optimization</B></A> - package org.apache.spark.mllib.optimization<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/pmml/package-summary.html"><B>org.apache.spark.mllib.pmml</B></A> - package org.apache.spark.mllib.pmml<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/random/package-summary.html"><B>org.apache.spark.mllib.random</B></A> - package org.apache.spark.mllib.random<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/rdd/package-summary.html"><B>org.apache.spark.mllib.rdd</B></A> - package org.apache.spark.mllib.rdd<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/recommendation/package-summary.html"><B>org.apache.spark.mllib.recommendation</B></A> - package org.apache.spark.mllib.recommendation<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/regression/package-summary.html"><B>org.apache.spark.mllib.regression</B></A> - package org.apache.spark.mllib.regression<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/stat/package-summary.html"><B>org.apache.spark.mllib.stat</B></A> - package org.apache.spark.mllib.stat<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/stat/distribution/package-summary.html"><B>org.apache.spark.mllib.stat.distribution</B></A> - package org.apache.spark.mllib.stat.distribution<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/stat/test/package-summary.html"><B>org.apache.spark.mllib.stat.test</B></A> - package org.apache.spark.mllib.stat.test<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/package-summary.html"><B>org.apache.spark.mllib.tree</B></A> - package org.apache.spark.mllib.tree<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html"><B>org.apache.spark.mllib.tree.configuration</B></A> - package org.apache.spark.mllib.tree.configuration<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/impurity/package-summary.html"><B>org.apache.spark.mllib.tree.impurity</B></A> - package org.apache.spark.mllib.tree.impurity<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html"><B>org.apache.spark.mllib.tree.loss</B></A> - package org.apache.spark.mllib.tree.loss<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/tree/model/package-summary.html"><B>org.apache.spark.mllib.tree.model</B></A> - package org.apache.spark.mllib.tree.model<DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/util/package-summary.html"><B>org.apache.spark.mllib.util</B></A> - package org.apache.spark.mllib.util<DD>&nbsp;<DT><A HREF="./org/apache/spark/partial/package-summary.html"><B>org.apache.spark.partial</B></A> - package org.apache.spark.partial<DD>&nbsp;<DT><A HREF="./org/apache/spark/rdd/package-summary.html"><B>org.apache.spark.rdd</B></A> - package org.apache.spark.rdd<DD>Provides implementation's of various RDDs.<DT><A HREF="./org/apache/spark/scheduler/package-summary.html"><B>org.apache.spark.scheduler</B></A> - package org.apache.spark.scheduler<DD>Spark's DAG scheduler.<DT><A HREF="./org/apache/spark/scheduler/cluster/package-summary.html"><B>org.apache.spark.scheduler.cluster</B></A> - package org.apache.spark.scheduler.cluster<DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/local/package-summary.html"><B>org.apache.spark.scheduler.local</B></A> - package org.apache.spark.scheduler.local<DD>&nbsp;<DT><A HREF="./org/apache/spark/serializer/package-summary.html"><B>org.apache.spark.serializer</B></A> - package org.apache.spark.serializer<DD>Pluggable serializers for RDD and shuffle data.<DT><A HREF="./org/apache/spark/sql/package-summary.html"><B>org.apache.spark.sql</B></A> - package org.apache.spark.sql<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/api/java/package-summary.html"><B>org.apache.spark.sql.api.java</B></A> - package org.apache.spark.sql.api.java<DD>Allows the execution of relational queries, including those expressed in SQL using Spark.<DT><A HREF="./org/apache/spark/sql/expressions/package-summary.html"><B>org.apache.spark.sql.expressions</B></A> - package org.apache.spark.sql.expressions<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/hive/package-summary.html"><B>org.apache.spark.sql.hive</B></A> - package org.apache.spark.sql.hive<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/jdbc/package-summary.html"><B>org.apache.spark.sql.jdbc</B></A> - package org.apache.spark.sql.jdbc<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/json/package-summary.html"><B>org.apache.spark.sql.json</B></A> - package org.apache.spark.sql.json<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/sources/package-summary.html"><B>org.apache.spark.sql.sources</B></A> - package org.apache.spark.sql.sources<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/test/package-summary.html"><B>org.apache.spark.sql.test</B></A> - package org.apache.spark.sql.test<DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/types/package-summary.html"><B>org.apache.spark.sql.types</B></A> - package org.apache.spark.sql.types<DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/package-summary.html"><B>org.apache.spark.status.api.v1</B></A> - package org.apache.spark.status.api.v1<DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/package-summary.html"><B>org.apache.spark.storage</B></A> - package org.apache.spark.storage<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/package-summary.html"><B>org.apache.spark.streaming</B></A> - package org.apache.spark.streaming<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/api/java/package-summary.html"><B>org.apache.spark.streaming.api.java</B></A> - package org.apache.spark.streaming.api.java<DD>Java APIs for spark streaming.<DT><A HREF="./org/apache/spark/streaming/dstream/package-summary.html"><B>org.apache.spark.streaming.dstream</B></A> - package org.apache.spark.streaming.dstream<DD>Various implementations of DStreams.<DT><A HREF="./org/apache/spark/streaming/flume/package-summary.html"><B>org.apache.spark.streaming.flume</B></A> - package org.apache.spark.streaming.flume<DD>Spark streaming receiver for Flume.<DT><A HREF="./org/apache/spark/streaming/kafka/package-summary.html"><B>org.apache.spark.streaming.kafka</B></A> - package org.apache.spark.streaming.kafka<DD>Kafka receiver for spark streaming.<DT><A HREF="./org/apache/spark/streaming/kinesis/package-summary.html"><B>org.apache.spark.streaming.kinesis</B></A> - package org.apache.spark.streaming.kinesis<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/mqtt/package-summary.html"><B>org.apache.spark.streaming.mqtt</B></A> - package org.apache.spark.streaming.mqtt<DD>MQTT receiver for Spark Streaming.<DT><A HREF="./org/apache/spark/streaming/receiver/package-summary.html"><B>org.apache.spark.streaming.receiver</B></A> - package org.apache.spark.streaming.receiver<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/package-summary.html"><B>org.apache.spark.streaming.scheduler</B></A> - package org.apache.spark.streaming.scheduler<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/twitter/package-summary.html"><B>org.apache.spark.streaming.twitter</B></A> - package org.apache.spark.streaming.twitter<DD>Twitter feed receiver for spark streaming.<DT><A HREF="./org/apache/spark/streaming/ui/package-summary.html"><B>org.apache.spark.streaming.ui</B></A> - package org.apache.spark.streaming.ui<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/util/package-summary.html"><B>org.apache.spark.streaming.util</B></A> - package org.apache.spark.streaming.util<DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/zeromq/package-summary.html"><B>org.apache.spark.streaming.zeromq</B></A> - package org.apache.spark.streaming.zeromq<DD>Zeromq receiver for spark streaming.<DT><A HREF="./org/apache/spark/ui/env/package-summary.html"><B>org.apache.spark.ui.env</B></A> - package org.apache.spark.ui.env<DD>&nbsp;<DT><A HREF="./org/apache/spark/ui/exec/package-summary.html"><B>org.apache.spark.ui.exec</B></A> - package org.apache.spark.ui.exec<DD>&nbsp;<DT><A HREF="./org/apache/spark/ui/jobs/package-summary.html"><B>org.apache.spark.ui.jobs</B></A> - package org.apache.spark.ui.jobs<DD>&nbsp;<DT><A HREF="./org/apache/spark/ui/storage/package-summary.html"><B>org.apache.spark.ui.storage</B></A> - package org.apache.spark.ui.storage<DD>&nbsp;<DT><A HREF="./org/apache/spark/util/package-summary.html"><B>org.apache.spark.util</B></A> - package org.apache.spark.util<DD>Spark utilities.<DT><A HREF="./org/apache/spark/util/random/package-summary.html"><B>org.apache.spark.util.random</B></A> - package org.apache.spark.util.random<DD>Utilities for random number generation.<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html#other()"><B>other()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler">RuntimePercentage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html#otherInfo()"><B>otherInfo()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#otherVertexAttr(long)"><B>otherVertexAttr(long)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>Given one vertex in the edge return the other vertex.
<DT><A HREF="./org/apache/spark/graphx/Edge.html#otherVertexId(long)"><B>otherVertexId(long)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>Given one vertex in the edge return the other vertex.
<DT><A HREF="./org/apache/spark/sql/Column.html#otherwise(java.lang.Object)"><B>otherwise(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Evaluates a list of conditions and returns one of multiple possible result expressions.
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#Out()"><B>Out()</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>Edges originating from a vertex.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#outDegrees()"><B>outDegrees()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>The out-degree of each vertex in the graph.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#outerJoinVertices(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><B>outerJoinVertices(RDD&lt;Tuple2&lt;Object, U&gt;&gt;, Function3&lt;Object, VD, Option&lt;U&gt;, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;, Predef.$eq$colon$eq&lt;VD, VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Joins the vertices with entries in the <code>table</code> RDD and merges the results using <code>mapFunc</code>.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#outerJoinVertices(org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Predef.$eq$colon$eq)"><B>outerJoinVertices(RDD&lt;Tuple2&lt;Object, U&gt;&gt;, Function3&lt;Object, VD, Option&lt;U&gt;, VD2&gt;, ClassTag&lt;U&gt;, ClassTag&lt;VD2&gt;, Predef.$eq$colon$eq&lt;VD, VD2&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#outputBytes()"><B>outputBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#outputBytes()"><B>outputBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/OutputCommitCoordinationMessage.html" title="interface in org.apache.spark.scheduler"><B>OutputCommitCoordinationMessage</B></A> - Interface in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkEnv.html#outputCommitCoordinator()"><B>outputCommitCoordinator()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetricDistributions.html" title="class in org.apache.spark.status.api.v1"><B>OutputMetricDistributions</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetrics.html" title="class in org.apache.spark.status.api.v1"><B>OutputMetrics</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#outputMetrics()"><B>outputMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#outputMetrics()"><B>outputMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#outputRecords()"><B>outputRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources"><B>OutputWriter</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::Experimental::
 <A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriter</CODE></A> is used together with <A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources"><CODE>HadoopFsRelation</CODE></A> for persisting rows to the
 underlying file system.<DT><A HREF="./org/apache/spark/sql/sources/OutputWriter.html#OutputWriter()"><B>OutputWriter()</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources">OutputWriter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><B>OutputWriterFactory</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::Experimental::
 A factory that produces <A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriter</CODE></A>s.<DT><A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html#OutputWriterFactory()"><B>OutputWriterFactory()</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#over(org.apache.spark.sql.expressions.WindowSpec)"><B>over(WindowSpec)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Define a windowing column.
</DL>
<HR>
<A NAME="_P_"><!-- --></A><H2>
<B>P</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#p()"><B>p()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>Normalization in L^p^ space.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#pageRank(double, double)"><B>pageRank(double, double)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Run a dynamic version of PageRank returning a graph with vertex attributes containing the
 PageRank and edge attributes containing the normalized edge weight.
<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib"><B>PageRank</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>PageRank algorithm implementation.<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html#PageRank()"><B>PageRank()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib">PageRank</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream"><B>PairDStreamFunctions</B></A>&lt;<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</A>,<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</A><DD>Extra functions available on DStream of (key, value) pairs through an implicit conversion.<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#PairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>PairDStreamFunctions(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><B>PairFlatMapFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">T</A>,<A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">K</A>,<A HREF="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">V</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that returns zero or more key-value pair records from each input record.<DT><A HREF="./org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function"><B>PairFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">T</A>,<A HREF="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">K</A>,<A HREF="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">V</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function that returns key-value pairs (Tuple2&lt;K, V&gt;), and can be used to
 construct PairRDDs.<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd"><B>PairRDDFunctions</B></A>&lt;<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</A>,<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>Extra functions available on RDDs of (key, value) pairs through an implicit conversion.<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#PairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>PairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/PairwiseRRDD.html" title="class in org.apache.spark.api.r"><B>PairwiseRRDD</B></A>&lt;<A HREF="./org/apache/spark/api/r/PairwiseRRDD.html" title="type parameter in PairwiseRRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/api/r/package-summary.html">org.apache.spark.api.r</A><DD>Form an RDD[(Int, Array[Byte])] from key-value pairs returned from R.<DT><A HREF="./org/apache/spark/api/r/PairwiseRRDD.html#PairwiseRRDD(org.apache.spark.rdd.RDD, int, byte[], java.lang.String, byte[], java.lang.String, java.lang.Object[], scala.reflect.ClassTag)"><B>PairwiseRRDD(RDD&lt;T&gt;, int, byte[], String, byte[], String, Object[], ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/PairwiseRRDD.html" title="class in org.apache.spark.api.r">PairwiseRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelize(java.util.List, int)"><B>parallelize(List&lt;T&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelize(java.util.List)"><B>parallelize(List&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/SparkContext.html#parallelize(scala.collection.Seq, int, scala.reflect.ClassTag)"><B>parallelize(Seq&lt;T&gt;, int, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelizeDoubles(java.util.List, int)"><B>parallelizeDoubles(List&lt;Double&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelizeDoubles(java.util.List)"><B>parallelizeDoubles(List&lt;Double&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelizePairs(java.util.List, int)"><B>parallelizePairs(List&lt;Tuple2&lt;K, V&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#parallelizePairs(java.util.List)"><B>parallelizePairs(List&lt;Tuple2&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Distribute a local Scala collection to form an RDD.
<DT><A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param"><B>Param</B></A>&lt;<A HREF="./org/apache/spark/ml/param/Param.html" title="type parameter in Param">T</A>&gt; - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 A param with self-contained documentation and optionally default value.<DT><A HREF="./org/apache/spark/ml/param/Param.html#Param(java.lang.String, java.lang.String, java.lang.String, scala.Function1)"><B>Param(String, String, String, Function1&lt;T, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#Param(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String, scala.Function1)"><B>Param(org.apache.spark.ml.util.Identifiable, String, String, Function1&lt;T, Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#Param(java.lang.String, java.lang.String, java.lang.String)"><B>Param(String, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#Param(org.apache.spark.ml.util.Identifiable, java.lang.String, java.lang.String)"><B>Param(org.apache.spark.ml.util.Identifiable, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamPair.html#param()"><B>param()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamPair.html" title="class in org.apache.spark.ml.param">ParamPair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning"><B>ParamGridBuilder</B></A> - Class in <A HREF="./org/apache/spark/ml/tuning/package-summary.html">org.apache.spark.ml.tuning</A><DD>:: Experimental ::
 Builder for a param grid used in grid search-based model selection.<DT><A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html#ParamGridBuilder()"><B>ParamGridBuilder()</B></A> - 
Constructor for class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/ParamGridBuilder.html" title="class in org.apache.spark.ml.tuning">ParamGridBuilder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param"><B>ParamMap</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: Experimental ::
 A param to value map.<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#ParamMap()"><B>ParamMap()</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Creates an empty param map.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#paramMap()"><B>paramMap()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Internal param map for user-supplied values.
<DT><A HREF="./org/apache/spark/ml/param/ParamPair.html" title="class in org.apache.spark.ml.param"><B>ParamPair</B></A>&lt;<A HREF="./org/apache/spark/ml/param/ParamPair.html" title="type parameter in ParamPair">T</A>&gt; - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: Experimental ::
 A param and its value.<DT><A HREF="./org/apache/spark/ml/param/ParamPair.html#ParamPair(org.apache.spark.ml.param.Param, T)"><B>ParamPair(Param&lt;T&gt;, T)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamPair.html" title="class in org.apache.spark.ml.param">ParamPair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param"><B>Params</B></A> - Interface in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Trait for components that take parameters.<DT><A HREF="./org/apache/spark/ml/param/Params.html#params()"><B>params()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Returns all params sorted by their names.
<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param"><B>ParamValidators</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Factory methods for common validation functions for <CODE>Param.isValid</CODE>.<DT><A HREF="./org/apache/spark/ml/param/ParamValidators.html#ParamValidators()"><B>ParamValidators()</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamValidators.html" title="class in org.apache.spark.ml.param">ParamValidators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Model.html#parent()"><B>parent()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>
<DD>The parent estimator that produced this model.
<DT><A HREF="./org/apache/spark/ml/param/Param.html#parent()"><B>parent()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#parentIds()"><B>parentIds()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#parentIds()"><B>parentIds()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#parentIndex(int)"><B>parentIndex(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Get the parent index of the given node, or 0 if it is the root.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#parquet(java.lang.String...)"><B>parquet(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads a Parquet file, returning the result as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#parquet(scala.collection.Seq)"><B>parquet(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Loads a Parquet file, returning the result as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#parquet(java.lang.String)"><B>parquet(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> in Parquet format at the specified path.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String...)"><B>parquetFile(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>read().parquet()</code>.</I>
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#parquetFile(scala.collection.Seq)"><B>parquetFile(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#parse(java.lang.String)"><B>parse(String)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Parses a string resulted from <CODE>Vector.toString</CODE> into a <A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg"><CODE>Vector</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html#parse(java.lang.String)"><B>parse(String)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/EnumUtil.html#parseIgnoreCase(java.lang.Class, java.lang.String)"><B>parseIgnoreCase(Class&lt;E&gt;, String)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/EnumUtil.html" title="class in org.apache.spark.util">EnumUtil</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial"><B>PartialResult</B></A>&lt;<A HREF="./org/apache/spark/partial/PartialResult.html" title="type parameter in PartialResult">R</A>&gt; - Class in <A HREF="./org/apache/spark/partial/package-summary.html">org.apache.spark.partial</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/partial/PartialResult.html#PartialResult(R, boolean)"><B>PartialResult(R, boolean)</B></A> - 
Constructor for class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partition.html" title="interface in org.apache.spark"><B>Partition</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>An identifier for a partition in an RDD.<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#partition()"><B>partition()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>Kafka partition id
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#partitionBy(org.apache.spark.Partitioner)"><B>partitionBy(Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a copy of the RDD partitioned using the specified partitioner.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#partitionBy(org.apache.spark.graphx.PartitionStrategy)"><B>partitionBy(PartitionStrategy)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Repartitions the edges in the graph according to <code>partitionStrategy</code>.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#partitionBy(org.apache.spark.graphx.PartitionStrategy, int)"><B>partitionBy(PartitionStrategy, int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Repartitions the edges in the graph according to <code>partitionStrategy</code>.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#partitionBy(org.apache.spark.graphx.PartitionStrategy)"><B>partitionBy(PartitionStrategy)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#partitionBy(org.apache.spark.graphx.PartitionStrategy, int)"><B>partitionBy(PartitionStrategy, int)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#partitionBy(org.apache.spark.Partitioner)"><B>partitionBy(Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return a copy of the RDD partitioned using the specified partitioner.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#partitionBy(java.lang.String...)"><B>partitionBy(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Partitions the output by the given columns on the file system.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#partitionBy(scala.collection.Seq)"><B>partitionBy(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Partitions the output by the given columns on the file system.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#partitionBy(java.lang.String, java.lang.String...)"><B>partitionBy(String, String...)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the partitioning defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#partitionBy(org.apache.spark.sql.Column...)"><B>partitionBy(Column...)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the partitioning defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#partitionBy(java.lang.String, scala.collection.Seq)"><B>partitionBy(String, Seq&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the partitioning defined.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html#partitionBy(scala.collection.Seq)"><B>partitionBy(Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions">Window</A>
<DD>Creates a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A> with the partitioning defined.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#partitionBy(java.lang.String, java.lang.String...)"><B>partitionBy(String, String...)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the partitioning columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#partitionBy(org.apache.spark.sql.Column...)"><B>partitionBy(Column...)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the partitioning columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#partitionBy(java.lang.String, scala.collection.Seq)"><B>partitionBy(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the partitioning columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#partitionBy(scala.collection.Seq)"><B>partitionBy(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the partitioning columns in a <A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><CODE>WindowSpec</CODE></A>.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd"><B>PartitionCoalescer</B></A> - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>Coalesce the partitions of a parent RDD (<code>prev</code>) into fewer partitions, so that each partition of
 this RDD computes one or more of the parent ones.<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#PartitionCoalescer(int, org.apache.spark.rdd.RDD, double)"><B>PartitionCoalescer(int, RDD&lt;?&gt;, double)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd"><B>PartitionCoalescer.LocationIterator</B></A> - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#PartitionCoalescer.LocationIterator(org.apache.spark.rdd.RDD)"><B>PartitionCoalescer.LocationIterator(RDD&lt;?&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#partitionColumns()"><B>partitionColumns()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Partition columns.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>If <code>partitionsRDD</code> already has a partitioner, use it.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><B>Partitioner</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>An object that defines how the elements in a key-value pair RDD are partitioned by key.<DT><A HREF="./org/apache/spark/Partitioner.html#Partitioner()"><B>Partitioner()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Optionally overridden by subclasses to specify how they are partitioned.
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#partitioner()"><B>partitioner()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd"><B>PartitionGroup</B></A> - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html#PartitionGroup(scala.Option)"><B>PartitionGroup(Option&lt;String&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd">PartitionGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskCommitDenied.html#partitionID()"><B>partitionID()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark">TaskCommitDenied</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#partitionId()"><B>partitionId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>The ID of the RDD partition that is computed by this task.
<DT><A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd"><B>PartitionPruningRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html" title="type parameter in PartitionPruningRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>:: DeveloperApi ::
 A RDD used to prune RDD partitions/partitions so we can avoid launching tasks on
 all partitions.<DT><A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html#PartitionPruningRDD(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag)"><B>PartitionPruningRDD(RDD&lt;T&gt;, Function1&lt;Object, Object&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#partitions()"><B>partitions()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Set of partitions in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#partitions()"><B>partitions()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Get the array of partitions of this RDD, taking into account whether the
 RDD is checkpointed or not.
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#partitions()"><B>partitions()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#partitionsRDD()"><B>partitionsRDD()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#partitionsRDD()"><B>partitionsRDD()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.html" title="interface in org.apache.spark.graphx"><B>PartitionStrategy</B></A> - Interface in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Represents the way edges are assigned to edge partitions based on their source and destination
 vertex IDs.<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html" title="class in org.apache.spark.graphx"><B>PartitionStrategy.CanonicalRandomVertexCut$</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Assigns edges to partitions by hashing the source and destination vertex IDs in a canonical
 direction, resulting in a random vertex cut that colocates all edges between two vertices,
 regardless of direction.<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html#PartitionStrategy.CanonicalRandomVertexCut$()"><B>PartitionStrategy.CanonicalRandomVertexCut$()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.CanonicalRandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.CanonicalRandomVertexCut$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html" title="class in org.apache.spark.graphx"><B>PartitionStrategy.EdgePartition1D$</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Assigns edges to partitions using only the source vertex ID, colocating edges with the same
 source.<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html#PartitionStrategy.EdgePartition1D$()"><B>PartitionStrategy.EdgePartition1D$()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition1D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition1D$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html" title="class in org.apache.spark.graphx"><B>PartitionStrategy.EdgePartition2D$</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Assigns edges to partitions using a 2D partitioning of the sparse edge adjacency matrix,
 guaranteeing a <code>2 * sqrt(numParts) - 1</code> bound on vertex replication.<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html#PartitionStrategy.EdgePartition2D$()"><B>PartitionStrategy.EdgePartition2D$()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.EdgePartition2D$.html" title="class in org.apache.spark.graphx">PartitionStrategy.EdgePartition2D$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html" title="class in org.apache.spark.graphx"><B>PartitionStrategy.RandomVertexCut$</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Assigns edges to partitions by hashing the source and destination vertex IDs, resulting in a
 random vertex cut that colocates all same-direction edges between two vertices.<DT><A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html#PartitionStrategy.RandomVertexCut$()"><B>PartitionStrategy.RandomVertexCut$()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/PartitionStrategy.RandomVertexCut$.html" title="class in org.apache.spark.graphx">PartitionStrategy.RandomVertexCut$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#path()"><B>path()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#path()"><B>path()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#paths()"><B>paths()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Base paths of this relation.
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#pattern()"><B>pattern()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>Regex pattern used to match delimiters if <CODE>gaps</CODE> is true or tokens if <CODE>gaps</CODE> is false.
<DT><A HREF="./org/apache/spark/mllib/feature/PCAModel.html#pc()"><B>pc()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCAModel.html" title="class in org.apache.spark.mllib.feature">PCAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature"><B>PCA</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>A feature transformer that projects vectors to a low-dimensional space using PCA.<DT><A HREF="./org/apache/spark/mllib/feature/PCA.html#PCA(int)"><B>PCA(int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature">PCA</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/PCAModel.html" title="class in org.apache.spark.mllib.feature"><B>PCAModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>Model fitted by <A HREF="./org/apache/spark/mllib/feature/PCA.html" title="class in org.apache.spark.mllib.feature"><CODE>PCA</CODE></A> that can project vectors to a low-dimensional space using PCA.<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html#pdf(org.apache.spark.mllib.linalg.Vector)"><B>pdf(Vector)</B></A> - 
Method in class org.apache.spark.mllib.stat.distribution.<A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution">MultivariateGaussian</A>
<DD>Returns density of this multivariate Gaussian at given point, x
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#pendingStages()"><B>pendingStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#percentiles()"><B>percentiles()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#percentilesHeader()"><B>percentilesHeader()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#percentRank()"><B>percentRank()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the relative rank (i.e.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Set this RDD's storage level to persist its values across operations after the first time
 it is computed.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Set this RDD's storage level to persist its values across operations after the first time
 it is computed.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Set this RDD's storage level to persist its values across operations after the first time
 it is computed.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Caches the vertices and edges associated with this graph at the specified storage level,
 ignoring any target storage levels previously set.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>Persists the edge partitions at the specified storage level, ignoring any existing target
 storage level.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>Persists the vertex partitions at the specified storage level, ignoring any existing target
 storage level.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Persists the underlying RDD with the specified storage level.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/NewHadoopRDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Set this RDD's storage level to persist its values across operations after the first time
 it is computed.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#persist()"><B>persist()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Persist this RDD with the default storage level (`MEMORY_ONLY`).
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#persist()"><B>persist()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#persist()"><B>persist()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Persist the RDDs of this DStream with the given storage level
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#persist()"><B>persist()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Persist the RDDs of this DStream with the given storage level
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#persist(org.apache.spark.storage.StorageLevel)"><B>persist(StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Persist the RDDs of this DStream with the given storage level
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#persist()"><B>persist()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)
<DT><A HREF="./org/apache/spark/SparkContext.html#persistentRdds()"><B>persistentRdds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#personalizedPageRank(long, double, double)"><B>personalizedPageRank(long, double, double)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Run personalized PageRank for a given vertex, such that all random walks
 are started relative to the source node.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#pi()"><B>pi()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#pickBin(org.apache.spark.Partition)"><B>pickBin(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>Takes a parent RDD partition and decides which of the partition groups to put it in
 Takes locality into account, but also uses power of 2 choices to load balance
 It strikes a balance between the two use the balanceSlack variable
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#pickRandomVertex()"><B>pickRandomVertex()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Picks a random vertex from the graph and returns its ID.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.lang.String)"><B>pipe(String)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List)"><B>pipe(List&lt;String&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List, java.util.Map)"><B>pipe(List&lt;String&gt;, Map&lt;String, String&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#pipe(java.lang.String)"><B>pipe(String)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#pipe(java.lang.String, scala.collection.Map)"><B>pipe(String, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq, scala.collection.Map, scala.Function1, scala.Function2, boolean)"><B>pipe(Seq&lt;String&gt;, Map&lt;String, String&gt;, Function1&lt;Function1&lt;String, BoxedUnit&gt;, BoxedUnit&gt;, Function2&lt;T, Function1&lt;String, BoxedUnit&gt;, BoxedUnit&gt;, boolean)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD created by piping elements to a forked external process.
<DT><A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml"><B>Pipeline</B></A> - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: Experimental ::
 A simple pipeline, which acts as an estimator.<DT><A HREF="./org/apache/spark/ml/Pipeline.html#Pipeline(java.lang.String)"><B>Pipeline(String)</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#Pipeline()"><B>Pipeline()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml"><B>PipelineModel</B></A> - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: Experimental ::
 Represents a fitted pipeline.<DT><A HREF="./org/apache/spark/ml/PipelineStage.html" title="class in org.apache.spark.ml"><B>PipelineStage</B></A> - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 A stage in a pipeline, either an <A HREF="./org/apache/spark/ml/Estimator.html" title="class in org.apache.spark.ml"><CODE>Estimator</CODE></A> or a <A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml"><CODE>Transformer</CODE></A>.<DT><A HREF="./org/apache/spark/ml/PipelineStage.html#PipelineStage()"><B>PipelineStage()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineStage.html" title="class in org.apache.spark.ml">PipelineStage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#plus(java.lang.Object)"><B>plus(Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Sum of this expression and another expression.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#plus(org.apache.spark.streaming.Duration)"><B>plus(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#plus(org.apache.spark.streaming.Duration)"><B>plus(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#plusDot(org.apache.spark.util.Vector, org.apache.spark.util.Vector)"><B>plusDot(Vector, Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>return (this + plus) dot other, but without creating any intermediate storage
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml"><B>PMMLExportable</B></A> - Interface in <A HREF="./org/apache/spark/mllib/pmml/package-summary.html">org.apache.spark.mllib.pmml</A><DD>:: DeveloperApi ::
 Export model to the PMML format
 Predictive Model Markup Language (PMML) is an XML-based file format
 developed by the Data Mining Group (www.dmg.org).<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#point()"><B>point()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#POINTS()"><B>POINTS()</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random"><B>PoissonGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html#PoissonGenerator(double)"><B>PoissonGenerator(double)</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><B>poissonJavaRDD(JavaSparkContext, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonRDD(org.apache.spark.SparkContext, double, long, int, long)"><CODE>RandomRDDs.poissonRDD(org.apache.spark.SparkContext, double, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)"><B>poissonJavaRDD(JavaSparkContext, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><CODE>RandomRDDs.poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long)"><B>poissonJavaRDD(JavaSparkContext, double, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><CODE>RandomRDDs.poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><B>poissonJavaVectorRDD(JavaSparkContext, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)"><CODE>RandomRDDs.poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int)"><B>poissonJavaVectorRDD(JavaSparkContext, double, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><CODE>RandomRDDs.poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)"><B>poissonJavaVectorRDD(JavaSparkContext, double, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><CODE>RandomRDDs.poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonRDD(org.apache.spark.SparkContext, double, long, int, long)"><B>poissonRDD(SparkContext, double, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the Poisson distribution with the input
 mean.
<DT><A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random"><B>PoissonSampler</B></A>&lt;<A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="type parameter in PoissonSampler">T</A>&gt; - Class in <A HREF="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</A><DD>:: DeveloperApi ::
 A sampler for sampling with replacement, based on values drawn from Poisson distribution.<DT><A HREF="./org/apache/spark/util/random/PoissonSampler.html#PoissonSampler(double, scala.reflect.ClassTag)"><B>PoissonSampler(double, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)"><B>poissonVectorRDD(SparkContext, double, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from the
 Poisson distribution with the input mean.
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature"><B>PolynomialExpansion</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Perform feature expansion in a polynomial space.<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#PolynomialExpansion(java.lang.String)"><B>PolynomialExpansion(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#PolynomialExpansion()"><B>PolynomialExpansion()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#poolToActiveStages()"><B>poolToActiveStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#port()"><B>port()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#port()"><B>port()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>Broker's port
<DT><A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input"><B>PortableDataStream</B></A> - Class in <A HREF="./org/apache/spark/input/package-summary.html">org.apache.spark.input</A><DD>A class that allows DataStreams to be serialized and moved around by not creating them
 until they need to be read<DT><A HREF="./org/apache/spark/input/PortableDataStream.html#PortableDataStream(org.apache.hadoop.mapreduce.lib.input.CombineFileSplit, org.apache.hadoop.mapreduce.TaskAttemptContext, java.lang.Integer)"><B>PortableDataStream(CombineFileSplit, TaskAttemptContext, Integer)</B></A> - 
Constructor for class org.apache.spark.input.<A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input">PortableDataStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html" title="class in org.apache.spark.sql.jdbc"><B>PostgresDialect</B></A> - Class in <A HREF="./org/apache/spark/sql/jdbc/package-summary.html">org.apache.spark.sql.jdbc</A><DD>:: DeveloperApi ::
 Default postgres dialect, mapping bit/cidr/inet on read and string/binary/boolean on write.<DT><A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html#PostgresDialect()"><B>PostgresDialect()</B></A> - 
Constructor for class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/PostgresDialect.html" title="class in org.apache.spark.sql.jdbc">PostgresDialect</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>pow(Column, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, java.lang.String)"><B>pow(Column, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(java.lang.String, org.apache.spark.sql.Column)"><B>pow(String, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(java.lang.String, java.lang.String)"><B>pow(String, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(org.apache.spark.sql.Column, double)"><B>pow(Column, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(java.lang.String, double)"><B>pow(String, double)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(double, org.apache.spark.sql.Column)"><B>pow(double, Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/sql/functions.html#pow(double, java.lang.String)"><B>pow(double, String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the value of the first argument raised to the power of the second argument.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering"><B>PowerIterationClustering</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#PowerIterationClustering()"><B>PowerIterationClustering()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html" title="class in org.apache.spark.mllib.clustering"><B>PowerIterationClustering.Assignment</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::
 Cluster assignment.<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html#PowerIterationClustering.Assignment(long, int)"><B>PowerIterationClustering.Assignment(long, int)</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering.Assignment</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment$.html" title="class in org.apache.spark.mllib.clustering"><B>PowerIterationClustering.Assignment$</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment$.html#PowerIterationClustering.Assignment$()"><B>PowerIterationClustering.Assignment$()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.Assignment$.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering.Assignment$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering"><B>PowerIterationClusteringModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html#PowerIterationClusteringModel(int, org.apache.spark.rdd.RDD)"><B>PowerIterationClusteringModel(int, RDD&lt;PowerIterationClustering.Assignment&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClusteringModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#pr()"><B>pr()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the precision-recall curve, which is an RDD of (recall, precision),
 NOT (precision, recall), with (0.0, 1.0) prepended to it.
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#precision(double)"><B>precision(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns precision for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#precision()"><B>precision()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns precision
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#precision()"><B>precision()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns document-based precision averaged by the number of documents
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#precision(double)"><B>precision(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns precision for a given label (category)
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#precision()"><B>precision()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#precision()"><B>precision()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/PrecisionInfo.html#precision()"><B>precision()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/PrecisionInfo.html" title="class in org.apache.spark.sql.types">PrecisionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html#precisionAt(int)"><B>precisionAt(int)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation">RankingMetrics</A>
<DD>Compute the average precision of all the queries, truncated at ranking position k.
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#precisionByThreshold()"><B>precisionByThreshold()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the (threshold, precision) curve.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#precisionInfo()"><B>precisionInfo()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/PrecisionInfo.html" title="class in org.apache.spark.sql.types"><B>PrecisionInfo</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>Precision parameters for a Decimal<DT><A HREF="./org/apache/spark/sql/types/PrecisionInfo.html#PrecisionInfo(int, int)"><B>PrecisionInfo(int, int)</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/PrecisionInfo.html" title="class in org.apache.spark.sql.types">PrecisionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</A>
<DD>Predict values for the given data set using the model trained.
<DT><A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in interface org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</A>
<DD>Predict values for a single data point using the model trained.
<DT><A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.api.java.JavaRDD)"><B>predict(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</A>
<DD>Predict values for examples stored in a JavaRDD.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>Maps given points to their cluster indices.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#predict(org.apache.spark.api.java.JavaRDD)"><B>predict(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>Java-friendly version of <CODE>predict()</CODE>
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>Returns the cluster index that a given point belongs to.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>Maps given points to their cluster indices.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.api.java.JavaRDD)"><B>predict(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>Maps given points to their cluster indices.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(int, int)"><B>predict(int, int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Predict the rating of one user for one product.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Predict the rating of many users for many products.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(org.apache.spark.api.java.JavaPairRDD)"><B>predict(JavaPairRDD&lt;Integer, Integer&gt;)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Java-friendly version of <CODE>MatrixFactorizationModel.predict</CODE>.
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>Predict values for the given data set using the model trained.
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>Predict values for a single data point using the model trained.
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>Predict labels for provided features.
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#predict(org.apache.spark.api.java.JavaDoubleRDD)"><B>predict(JavaDoubleRDD)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>Predict labels for provided features.
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#predict(double)"><B>predict(double)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>Predict a single label.
<DT><A HREF="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</A>
<DD>Predict values for the given data set using the model trained.
<DT><A HREF="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in interface org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</A>
<DD>Predict values for a single data point using the model trained.
<DT><A HREF="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.api.java.JavaRDD)"><B>predict(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</A>
<DD>Predict values for examples stored in a JavaRDD.
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Predict values for a single data point using the model trained.
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#predict(org.apache.spark.rdd.RDD)"><B>predict(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Predict values for the given data set using the model trained.
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#predict(org.apache.spark.api.java.JavaRDD)"><B>predict(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Predict values for the given data set using the model trained.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#predict()"><B>predict()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#predict(org.apache.spark.mllib.linalg.Vector)"><B>predict(Vector)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>predict value if node is not leaf
<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model"><B>Predict</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>Predicted value for a node
 param:  predict predicted value
 param:  prob probability of the label (classification only)<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#Predict(double, double)"><B>Predict(double, double)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#predict()"><B>predict()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#prediction()"><B>prediction()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/LeafNode.html#prediction()"><B>prediction()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/LeafNode.html" title="class in org.apache.spark.ml.tree">LeafNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/Node.html#prediction()"><B>prediction()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Node.html" title="class in org.apache.spark.ml.tree">Node</A>
<DD>Prediction a leaf node makes, or which an internal node would make if it were a leaf node
<DT><A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml"><B>PredictionModel</B></A>&lt;<A HREF="./org/apache/spark/ml/PredictionModel.html" title="type parameter in PredictionModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/PredictionModel.html" title="type parameter in PredictionModel">M</A> extends <A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>&lt;<A HREF="./org/apache/spark/ml/PredictionModel.html" title="type parameter in PredictionModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/PredictionModel.html" title="type parameter in PredictionModel">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 Abstraction for a model for prediction tasks (regression and classification).<DT><A HREF="./org/apache/spark/ml/PredictionModel.html#PredictionModel()"><B>PredictionModel()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#predictions()"><B>predictions()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#predictOn(org.apache.spark.streaming.dstream.DStream)"><B>predictOn(DStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Use the clustering model to make predictions on batches of data from a DStream.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#predictOn(org.apache.spark.streaming.api.java.JavaDStream)"><B>predictOn(JavaDStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Java-friendly version of `predictOn`.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOn(org.apache.spark.streaming.dstream.DStream)"><B>predictOn(DStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Use the model to make predictions on batches of data from a DStream
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOn(org.apache.spark.streaming.api.java.JavaDStream)"><B>predictOn(JavaDStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Java-friendly version of `predictOn`.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#predictOnValues(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>predictOnValues(DStream&lt;Tuple2&lt;K, Vector&gt;&gt;, ClassTag&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Use the model to make predictions on the values of a DStream and carry over its keys.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#predictOnValues(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>predictOnValues(JavaPairDStream&lt;K, Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Java-friendly version of `predictOnValues`.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOnValues(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>predictOnValues(DStream&lt;Tuple2&lt;K, Vector&gt;&gt;, ClassTag&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Use the model to make predictions on the values of a DStream and carry over its keys.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOnValues(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>predictOnValues(JavaPairDStream&lt;K, Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Java-friendly version of `predictOnValues`.
<DT><A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml"><B>Predictor</B></A>&lt;<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">FeaturesType</A>,<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">Learner</A> extends <A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>&lt;<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">FeaturesType</A>,<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">Learner</A>,<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">M</A>&gt;,<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">M</A> extends <A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>&lt;<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">FeaturesType</A>,<A HREF="./org/apache/spark/ml/Predictor.html" title="type parameter in Predictor">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 Abstraction for prediction problems (regression and classification).<DT><A HREF="./org/apache/spark/ml/Predictor.html#Predictor()"><B>Predictor()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#predictSoft(org.apache.spark.rdd.RDD)"><B>predictSoft(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>Given the input vectors, return the membership value of each vector
 to all mixture components.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#preferredLocation()"><B>preferredLocation()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Override this to specify a preferred location (hostname).
<DT><A HREF="./org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)"><B>preferredLocations(Partition)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Get the preferred locations of a partition, taking into account whether the
 RDD is checkpointed.
<DT><A HREF="./org/apache/spark/SparkContext.html#preferredNodeLocationData()"><B>preferredNodeLocationData()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html#prefLoc()"><B>prefLoc()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd">PartitionGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#pregel(A, int, org.apache.spark.graphx.EdgeDirection, scala.Function3, scala.Function1, scala.Function2, scala.reflect.ClassTag)"><B>pregel(A, int, EdgeDirection, Function3&lt;Object, VD, A, VD&gt;, Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Iterator&lt;Tuple2&lt;Object, A&gt;&gt;&gt;, Function2&lt;A, A, A&gt;, ClassTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Execute a Pregel-like iterative vertex-parallel abstraction.
<DT><A HREF="./org/apache/spark/graphx/Pregel.html" title="class in org.apache.spark.graphx"><B>Pregel</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Implements a Pregel-like bulk-synchronous message-passing API.<DT><A HREF="./org/apache/spark/graphx/Pregel.html#Pregel()"><B>Pregel()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Pregel.html" title="class in org.apache.spark.graphx">Pregel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#prepareJobForWrite(org.apache.hadoop.mapreduce.Job)"><B>prepareJobForWrite(Job)</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Prepares a write job and returns an <A HREF="./org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><CODE>OutputWriterFactory</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#prettyJson()"><B>prettyJson()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>The pretty (i.e.
<DT><A HREF="./org/apache/spark/streaming/Duration.html#prettyPrint()"><B>prettyPrint()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#prev()"><B>prev()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/SignalLoggerHandler.html#prevHandler()"><B>prevHandler()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/SignalLoggerHandler.html" title="class in org.apache.spark.util">SignalLoggerHandler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#print()"><B>print()</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Print the first ten elements of each RDD generated in this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#print(int)"><B>print(int)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Print the first num elements of each RDD generated in this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#print()"><B>print()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Print the first ten elements of each RDD generated in this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#print(int)"><B>print(int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Print the first num elements of each RDD generated in this DStream.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#printSchema()"><B>printSchema()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Prints the schema to the console in a nice tree format.
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#printStats()"><B>printStats()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#printTreeString()"><B>printTreeString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/annotation/Private.html" title="annotation in org.apache.spark.annotation"><B>Private</B></A> - Annotation Type in <A HREF="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</A><DD>A class that is considered private to the internals of Spark -- there is a high-likelihood
 they will be changed in future versions of Spark.<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#prob()"><B>prob()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#probabilities()"><B>probabilities()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#PROCESS_LOCAL()"><B>PROCESS_LOCAL()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingDelay()"><B>processingDelay()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>Time taken for the all jobs of this batch to finish processing from the time they started
 processing.
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingEndTime()"><B>processingEndTime()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingStartTime()"><B>processingStartTime()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/Rating.html#product()"><B>product()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#productFeatures()"><B>productFeatures()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#progressListener()"><B>progressListener()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#properties()"><B>properties()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#properties()"><B>properties()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/PrunedFilteredScan.html" title="interface in org.apache.spark.sql.sources"><B>PrunedFilteredScan</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 A BaseRelation that can eliminate unneeded columns and filter using selected
 predicates before producing an RDD containing all matching tuples as Row objects.<DT><A HREF="./org/apache/spark/sql/sources/PrunedScan.html" title="interface in org.apache.spark.sql.sources"><B>PrunedScan</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 A BaseRelation that can eliminate unneeded columns before producing an RDD
 containing all of its tuples as Row objects.<DT><A HREF="./org/apache/spark/util/random/Pseudorandom.html" title="interface in org.apache.spark.util.random"><B>Pseudorandom</B></A> - Interface in <A HREF="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</A><DD>:: DeveloperApi ::
 A class with pseudorandom behavior.<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#put(org.apache.spark.ml.param.ParamPair...)"><B>put(ParamPair&lt;?&gt;...)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Puts a list of param pairs (overwrites if the input params exists).
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#put(org.apache.spark.ml.param.Param, T)"><B>put(Param&lt;T&gt;, T)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Puts a (param, value) pair (overwrites if the input param exists).
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#put(scala.collection.Seq)"><B>put(Seq&lt;ParamPair&lt;?&gt;&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Puts a list of param pairs (overwrites if the input params exists).
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putBoolean(java.lang.String, boolean)"><B>putBoolean(String, boolean)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Boolean.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putBooleanArray(java.lang.String, boolean[])"><B>putBooleanArray(String, boolean[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Boolean array.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putDouble(java.lang.String, double)"><B>putDouble(String, double)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Double.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putDoubleArray(java.lang.String, double[])"><B>putDoubleArray(String, double[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Double array.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putLong(java.lang.String, long)"><B>putLong(String, long)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Long.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putLongArray(java.lang.String, long[])"><B>putLongArray(String, long[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a Long array.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putMetadata(java.lang.String, org.apache.spark.sql.types.Metadata)"><B>putMetadata(String, Metadata)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a <A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types"><CODE>Metadata</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putMetadataArray(java.lang.String, org.apache.spark.sql.types.Metadata[])"><B>putMetadataArray(String, Metadata[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a <A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types"><CODE>Metadata</CODE></A> array.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putString(java.lang.String, java.lang.String)"><B>putString(String, String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a String.
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#putStringArray(java.lang.String, java.lang.String[])"><B>putStringArray(String, String[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Puts a String array.
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#pValue()"><B>pValue()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html#pValue()"><B>pValue()</B></A> - 
Method in interface org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</A>
<DD>The probability of obtaining a test statistic result at least as extreme as the one that was
 actually observed, assuming that the null hypothesis is true.
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#pyUDT()"><B>pyUDT()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>Paired Python UDT class, if exists.
</DL>
<HR>
<A NAME="_Q_"><!-- --></A><H2>
<B>Q</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#quantileCalculationStrategy()"><B>quantileCalculationStrategy()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#quantiles()"><B>quantiles()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration"><B>QuantileStrategy</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</A><DD>:: Experimental ::
 Enum for selecting the quantile calculation strategy<DT><A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#QuantileStrategy()"><B>QuantileStrategy()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#queryExecution()"><B>queryExecution()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue)"><B>queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from an queue of RDDs.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean)"><B>queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;, boolean)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from an queue of RDDs.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean, org.apache.spark.api.java.JavaRDD)"><B>queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;, boolean, JavaRDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from an queue of RDDs.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#queueStream(scala.collection.mutable.Queue, boolean, scala.reflect.ClassTag)"><B>queueStream(Queue&lt;RDD&lt;T&gt;&gt;, boolean, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create an input stream from a queue of RDDs.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#queueStream(scala.collection.mutable.Queue, boolean, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>queueStream(Queue&lt;RDD&lt;T&gt;&gt;, boolean, RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create an input stream from a queue of RDDs.
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html#quoteIdentifier(java.lang.String)"><B>quoteIdentifier(String)</B></A> - 
Method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialect.html" title="class in org.apache.spark.sql.jdbc">JdbcDialect</A>
<DD>Quotes the identifier.
<DT><A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html#quoteIdentifier(java.lang.String)"><B>quoteIdentifier(String)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/MySQLDialect.html" title="class in org.apache.spark.sql.jdbc">MySQLDialect</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_R_"><!-- --></A><H2>
<B>R</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#r2()"><B>r2()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>Returns R^2^, the coefficient of determination.
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#RACK_LOCAL()"><B>RACK_LOCAL()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#rand(int, int, java.util.Random)"><B>rand(int, int, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a <code>DenseMatrix</code> consisting of <code>i.i.d.</code> uniform random numbers.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#rand(int, int, java.util.Random)"><B>rand(int, int, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>DenseMatrix</code> consisting of <code>i.i.d.</code> uniform random numbers.
<DT><A HREF="./org/apache/spark/sql/functions.html#rand(long)"><B>rand(long)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Generate a random column with i.i.d.
<DT><A HREF="./org/apache/spark/sql/functions.html#rand()"><B>rand()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Generate a random column with i.i.d.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#randn(int, int, java.util.Random)"><B>randn(int, int, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a <code>DenseMatrix</code> consisting of <code>i.i.d.</code> gaussian random numbers.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#randn(int, int, java.util.Random)"><B>randn(int, int, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>DenseMatrix</code> consisting of <code>i.i.d.</code> gaussian random numbers.
<DT><A HREF="./org/apache/spark/sql/functions.html#randn(long)"><B>randn(long)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Generate a column with i.i.d.
<DT><A HREF="./org/apache/spark/sql/functions.html#randn()"><B>randn()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Generate a column with i.i.d.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#RANDOM()"><B>RANDOM()</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#random(int, scala.util.Random)"><B>random(int, Random)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>Creates this <A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util"><CODE>Vector</CODE></A> of given length containing random numbers
 between 0.0 and 1.0.
<DT><A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random"><B>RandomDataGenerator</B></A>&lt;<A HREF="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="type parameter in RandomDataGenerator">T</A>&gt; - Interface in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Trait for random data generators that generate i.i.d.<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree"><B>RandomForest</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/package-summary.html">org.apache.spark.mllib.tree</A><DD>:: Experimental ::
 A class that implements a <CODE>Random Forest</CODE>
 learning algorithm for classification and regression.<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#RandomForest(org.apache.spark.mllib.tree.configuration.Strategy, int, java.lang.String, int)"><B>RandomForest(Strategy, int, String, int)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification"><B>RandomForestClassificationModel</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Random Forest</CODE> model for classification.<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification"><B>RandomForestClassifier</B></A> - Class in <A HREF="./org/apache/spark/ml/classification/package-summary.html">org.apache.spark.ml.classification</A><DD>:: Experimental ::
 <CODE>Random Forest</CODE> learning algorithm for
 classification.<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#RandomForestClassifier(java.lang.String)"><B>RandomForestClassifier(String)</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#RandomForestClassifier()"><B>RandomForestClassifier()</B></A> - 
Constructor for class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model"><B>RandomForestModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: Experimental ::
 Represents a random forest model.<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html#RandomForestModel(scala.Enumeration.Value, org.apache.spark.mllib.tree.model.DecisionTreeModel[])"><B>RandomForestModel(Enumeration.Value, DecisionTreeModel[])</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model">RandomForestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression"><B>RandomForestRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 <CODE>Random Forest</CODE> model for regression.<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression"><B>RandomForestRegressor</B></A> - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: Experimental ::
 <CODE>Random Forest</CODE> learning algorithm for regression.<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#RandomForestRegressor(java.lang.String)"><B>RandomForestRegressor(String)</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#RandomForestRegressor()"><B>RandomForestRegressor()</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#randomRDD(org.apache.spark.SparkContext, org.apache.spark.mllib.random.RandomDataGenerator, long, int, long, scala.reflect.ClassTag)"><B>randomRDD(SparkContext, RandomDataGenerator&lt;T&gt;, long, int, long, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>:: DeveloperApi ::
 Generates an RDD comprised of <code>i.i.d.</code> samples produced by the input RandomDataGenerator.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random"><B>RandomRDDs</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: Experimental ::
 Generator methods for creating RDDs comprised of <code>i.i.d.</code> samples from some distribution.<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#RandomRDDs()"><B>RandomRDDs()</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random"><B>RandomSampler</B></A>&lt;<A HREF="./org/apache/spark/util/random/RandomSampler.html" title="type parameter in RandomSampler">T</A>,<A HREF="./org/apache/spark/util/random/RandomSampler.html" title="type parameter in RandomSampler">U</A>&gt; - Interface in <A HREF="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</A><DD>:: DeveloperApi ::
 A pseudorandom sampler.<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#randomSplit(double[])"><B>randomSplit(double[])</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Randomly splits this RDD with the provided weights.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#randomSplit(double[], long)"><B>randomSplit(double[], long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Randomly splits this RDD with the provided weights.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#randomSplit(double[], long)"><B>randomSplit(double[], long)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Randomly splits this RDD with the provided weights.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#randomSplit(double[], long)"><B>randomSplit(double[], long)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Randomly splits this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with the provided weights.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#randomSplit(double[])"><B>randomSplit(double[])</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Randomly splits this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with the provided weights.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#randomVectorRDD(org.apache.spark.SparkContext, org.apache.spark.mllib.random.RandomDataGenerator, long, int, int, long)"><B>randomVectorRDD(SparkContext, RandomDataGenerator&lt;Object&gt;, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>:: DeveloperApi ::
 Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples produced by the
 input RandomDataGenerator.
<DT><A HREF="./org/apache/spark/SparkContext.html#range(long, long, long, int)"><B>range(long, long, long, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Creates a new RDD[Long] containing elements from <code>start</code> to <code>end</code>(exclusive), increased by
 <code>step</code> every element.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#range(long, long)"><B>range(long, long)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#range(long)"><B>range(long)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#range(long, long, long, int)"><B>range(long, long, long, int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#rangeBetween(long, long)"><B>rangeBetween(long, long)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the frame boundaries, from <code>start</code> (inclusive) to <code>end</code> (inclusive).
<DT><A HREF="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark"><B>RangeDependency</B></A>&lt;<A HREF="./org/apache/spark/RangeDependency.html" title="type parameter in RangeDependency">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Represents a one-to-one dependency between ranges of partitions in the parent and child RDDs.<DT><A HREF="./org/apache/spark/RangeDependency.html#RangeDependency(org.apache.spark.rdd.RDD, int, int, int)"><B>RangeDependency(RDD&lt;T&gt;, int, int, int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark">RangeDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark"><B>RangePartitioner</B></A>&lt;<A HREF="./org/apache/spark/RangePartitioner.html" title="type parameter in RangePartitioner">K</A>,<A HREF="./org/apache/spark/RangePartitioner.html" title="type parameter in RangePartitioner">V</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A <A HREF="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><CODE>Partitioner</CODE></A> that partitions sortable records by range into roughly
 equal ranges.<DT><A HREF="./org/apache/spark/RangePartitioner.html#RangePartitioner(int, org.apache.spark.rdd.RDD, boolean, scala.math.Ordering, scala.reflect.ClassTag)"><B>RangePartitioner(int, RDD&lt;? extends Product2&lt;K, V&gt;&gt;, boolean, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#rank()"><B>rank()</B></A> - 
Method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#rank()"><B>rank()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#rank()"><B>rank()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#rank()"><B>rank()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns the rank of rows within a window partition.
<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation"><B>RankingMetrics</B></A>&lt;<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="type parameter in RankingMetrics">T</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</A><DD>::Experimental::
 Evaluator for ranking algorithms.<DT><A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html#RankingMetrics(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>RankingMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RankingMetrics.html" title="class in org.apache.spark.mllib.evaluation">RankingMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html#rating()"><B>rating()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation"><B>Rating</B></A> - Class in <A HREF="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</A><DD>A more compact class to represent a rating than Tuple3[Int, Int, Double].<DT><A HREF="./org/apache/spark/mllib/recommendation/Rating.html#Rating(int, int, double)"><B>Rating(int, int, double)</B></A> - 
Constructor for class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/Rating.html#rating()"><B>rating()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>rawSocketStream(String, int, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int)"><B>rawSocketStream(String, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)"><B>rawSocketStream(String, int, StorageLevel, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#rdd()"><B>rdd()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Dependency.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/NarrowDependency.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd"><B>RDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/RDD.html" title="type parameter in RDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.<DT><A HREF="./org/apache/spark/rdd/RDD.html#RDD(org.apache.spark.SparkContext, scala.collection.Seq, scala.reflect.ClassTag)"><B>RDD(SparkContext, Seq&lt;Dependency&lt;?&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#RDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>RDD(RDD&lt;?&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Construct an RDD with just a one-to-one dependency on one parent
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#rdd()"><B>rdd()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Represents the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as an <CODE>RDD</CODE> of <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A>s.
<DT><A HREF="./org/apache/spark/storage/BlockId.html#RDD()"><B>RDD()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#RDD_SCOPE_KEY()"><B>RDD_SCOPE_KEY()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#RDD_SCOPE_NO_OVERRIDE_KEY()"><B>RDD_SCOPE_NO_OVERRIDE_KEY()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage"><B>RDDBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/RDDBlockId.html#RDDBlockId(int, int)"><B>RDDBlockId(int, int)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#rddBlocks()"><B>rddBlocks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#rddBlocks()"><B>rddBlocks()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the RDD blocks stored in this block manager.
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#rddBlocksById(int)"><B>rddBlocksById(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the blocks that belong to the given RDD stored in this block manager.
<DT><A HREF="./org/apache/spark/status/api/v1/RDDDataDistribution.html" title="class in org.apache.spark.status.api.v1"><B>RDDDataDistribution</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd"><B>RDDFunctions</B></A>&lt;<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="type parameter in RDDFunctions">T</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/rdd/package-summary.html">org.apache.spark.mllib.rdd</A><DD>Machine learning specific RDD functions.<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html#RDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>RDDFunctions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd">RDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanCheckpoint.html#rddId()"><B>rddId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanCheckpoint.html" title="class in org.apache.spark">CleanCheckpoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanRDD.html#rddId()"><B>rddId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanRDD.html" title="class in org.apache.spark">CleanRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html#rddId()"><B>rddId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler">SparkListenerUnpersistRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDBlockId.html#rddId()"><B>rddId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage"><B>RDDInfo</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#RDDInfo(int, java.lang.String, int, org.apache.spark.storage.StorageLevel, scala.collection.Seq, scala.Option)"><B>RDDInfo(int, String, int, StorageLevel, Seq&lt;Object&gt;, Option&lt;org.apache.spark.rdd.RDDOperationScope&gt;)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#rddInfoList()"><B>rddInfoList()</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>Filter RDD info to include only those with cached partitions
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#rddInfos()"><B>rddInfos()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1"><B>RDDPartitionInfo</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#rdds()"><B>rdds()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#rdds()"><B>rdds()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1"><B>RDDStorageInfo</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#rddStorageLevel(int)"><B>rddStorageLevel(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Return the storage level, if any, used by the given RDD in this block manager.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#rddToAsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>rddToAsyncRDDActions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#rddToAsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>rddToAsyncRDDActions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#rddToDataFrameHolder(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)"><B>rddToDataFrameHolder(RDD&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#rddToOrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>rddToOrderedRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Ordering&lt;K&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#rddToOrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>rddToOrderedRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Ordering&lt;K&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#rddToPairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>rddToPairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#rddToPairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>rddToPairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, , )"><B>rddToSequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, &lt;any&gt;, &lt;any&gt;)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag, scala.Function1, scala.reflect.ClassTag)"><B>rddToSequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Function1&lt;K, Writable&gt;, ClassTag&lt;K&gt;, Function1&lt;V, Writable&gt;, ClassTag&lt;V&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html#read(com.esotericsoftware.kryo.Kryo, com.esotericsoftware.kryo.io.Input, java.lang.Class)"><B>read(Kryo, Input, Class&lt;Iterable&lt;?&gt;&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html" title="class in org.apache.spark.serializer">JavaIterableWrapperSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#read()"><B>read()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#read(org.apache.spark.streaming.util.WriteAheadLogRecordHandle)"><B>read(WriteAheadLogRecordHandle)</B></A> - 
Method in class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>Read a written record based on the given record handle.
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#readAll()"><B>readAll()</B></A> - 
Method in class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>Read and return an iterator of all the records that have been written but not yet cleaned up.
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#readBytes()"><B>readBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaSerializer.html#readExternal(java.io.ObjectInput)"><B>readExternal(ObjectInput)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#readExternal(java.io.ObjectInput)"><B>readExternal(ObjectInput)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#readExternal(java.io.ObjectInput)"><B>readExternal(ObjectInput)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#readExternal(java.io.ObjectInput)"><B>readExternal(ObjectInput)</B></A> - 
Method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#readKey(scala.reflect.ClassTag)"><B>readKey(ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>Reads the object representing the key of a key-value pair.
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#readObject(scala.reflect.ClassTag)"><B>readObject(ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>The most general-purpose method to read an object.
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#readRecords()"><B>readRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/DeserializationStream.html#readValue(scala.reflect.ClassTag)"><B>readValue(ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</A>
<DD>Reads the object representing the value of a key-value pair.
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>ready(Duration, CanAwait)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>ready(Duration, CanAwait)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Blocks until this action completes.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>ready(Duration, CanAwait)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html#reason()"><B>reason()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#reason()"><B>reason()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#recall(double)"><B>recall(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns recall for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#recall()"><B>recall()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns recall
 (equals to precision for multiclass classifier
 because sum of all false positives is equal to sum
 of all false negatives)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#recall()"><B>recall()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns document-based recall averaged by the number of documents
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#recall(double)"><B>recall(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns recall for a given label (category)
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#recallByThreshold()"><B>recallByThreshold()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the (threshold, recall) curve.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver"><B>Receiver</B></A>&lt;<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="type parameter in Receiver">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</A><DD>:: DeveloperApi ::
 Abstract class of a receiver that can be run on worker nodes to receive external data.<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#Receiver(org.apache.spark.storage.StorageLevel)"><B>Receiver(StorageLevel)</B></A> - 
Constructor for class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler"><B>ReceiverInfo</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>:: DeveloperApi ::
 Class having information about a receiver<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#ReceiverInfo(int, java.lang.String, org.apache.spark.rpc.RpcEndpointRef, boolean, java.lang.String, java.lang.String, java.lang.String, long)"><B>ReceiverInfo(int, String, org.apache.spark.rpc.RpcEndpointRef, boolean, String, String, String, long)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html#receiverInfo()"><B>receiverInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverError</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html#receiverInfo()"><B>receiverInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStarted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html#receiverInfo()"><B>receiverInfo()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStopped</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#receiverInputDStream()"><B>receiverInputDStream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#receiverInputDStream()"><B>receiverInputDStream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><B>ReceiverInputDStream</B></A>&lt;<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="type parameter in ReceiverInputDStream">T</A>&gt; - Class in <A HREF="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</A><DD>Abstract class for defining any <A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><CODE>InputDStream</CODE></A>
 that has to start a receiver on worker nodes to receive external data.<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#ReceiverInputDStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)"><B>ReceiverInputDStream(StreamingContext, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#receiverStream(org.apache.spark.streaming.receiver.Receiver)"><B>receiverStream(Receiver&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented receiver.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#receiverStream(org.apache.spark.streaming.receiver.Receiver, scala.reflect.ClassTag)"><B>receiverStream(Receiver&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create an input stream with any arbitrary user implemented receiver.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendProducts(int, int)"><B>recommendProducts(int, int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Recommends products to a user.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendProductsForUsers(int)"><B>recommendProductsForUsers(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Recommends topK products for all users.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendUsers(int, int)"><B>recommendUsers(int, int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Recommends users to a product.
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendUsersForProducts(int)"><B>recommendUsersForProducts(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>Recommends topK users for all products.
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES()"><B>RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>Update the input bytes read metric each time this number of records has been read
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#RECORDS_BETWEEN_BYTES_WRITTEN_METRIC_UPDATES()"><B>RECORDS_BETWEEN_BYTES_WRITTEN_METRIC_UPDATES()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/InputMetricDistributions.html#recordsRead()"><B>recordsRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/InputMetricDistributions.html" title="class in org.apache.spark.status.api.v1">InputMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/InputMetrics.html#recordsRead()"><B>recordsRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/InputMetrics.html" title="class in org.apache.spark.status.api.v1">InputMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#recordsRead()"><B>recordsRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetricDistributions.html#recordsWritten()"><B>recordsWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/OutputMetricDistributions.html" title="class in org.apache.spark.status.api.v1">OutputMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/OutputMetrics.html#recordsWritten()"><B>recordsWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/OutputMetrics.html" title="class in org.apache.spark.status.api.v1">OutputMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html#recordsWritten()"><B>recordsWritten()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#reduce(org.apache.spark.api.java.function.Function2)"><B>reduce(Function2&lt;T, T, T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Reduces the elements of this RDD using the specified commutative and associative binary
 operator.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#reduce(scala.Function2)"><B>reduce(Function2&lt;T, T, T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Reduces the elements of this RDD using the specified commutative and
 associative binary operator.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduce(org.apache.spark.api.java.function.Function2)"><B>reduce(Function2&lt;T, T, T&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing each RDD
 of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#reduce(scala.Function2)"><B>reduce(Function2&lt;T, T, T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing each RDD
 of this DStream.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2)"><B>reduceByKey(Partitioner, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.api.java.function.Function2, int)"><B>reduceByKey(Function2&lt;V, V, V&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.api.java.function.Function2)"><B>reduceByKey(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(org.apache.spark.Partitioner, scala.Function2)"><B>reduceByKey(Partitioner, Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2, int)"><B>reduceByKey(Function2&lt;V, V, V&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2)"><B>reduceByKey(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative reduce function.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2)"><B>reduceByKey(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2, int)"><B>reduceByKey(Function2&lt;V, V, V&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)"><B>reduceByKey(Function2&lt;V, V, V&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2)"><B>reduceByKey(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, int)"><B>reduceByKey(Function2&lt;V, V, V&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, org.apache.spark.Partitioner)"><B>reduceByKey(Function2&lt;V, V, V&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> to each RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Create a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by reducing over a using incremental computation.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, org.apache.spark.api.java.function.Function)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, int, Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner, Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.Function1)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, int, Function1&lt;Tuple2&lt;K, V&gt;, Object&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, scala.Function1)"><B>reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner, Function1&lt;Tuple2&lt;K, V&gt;, Object&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKeyLocally(org.apache.spark.api.java.function.Function2)"><B>reduceByKeyLocally(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyLocally(scala.Function2)"><B>reduceByKeyLocally(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyToDriver(scala.Function2)"><B>reduceByKeyToDriver(Function2&lt;V, V, V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Alias for reduceByKeyLocally
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByWindow(Function2&lt;T, T, T&gt;, Duration, Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD><B>Deprecated.</B>&nbsp;<I>As this API is not Java compatible.</I>
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByWindow(Function2&lt;T, T, T&gt;, Duration, Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByWindow(Function2&lt;T, T, T&gt;, Function2&lt;T, T, T&gt;, Duration, Duration)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#reduceByWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByWindow(Function2&lt;T, T, T&gt;, Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#reduceByWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>reduceByWindow(Function2&lt;T, T, T&gt;, Function2&lt;T, T, T&gt;, Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.
<DT><A HREF="./org/apache/spark/FetchFailed.html#reduceId()"><B>reduceId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html#reduceId()"><B>reduceId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html#reduceId()"><B>reduceId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage">ShuffleDataBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html#reduceId()"><B>reduceId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#refreshTable(java.lang.String)"><B>refreshTable(String)</B></A> - 
Method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>Invalidate and refresh all the cached the metadata of the given table.
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature"><B>RegexTokenizer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 A regex based tokenizer that extracts tokens either by using the provided regex pattern to split
 the text (default) or repeatedly matching the regex (if <code>gaps</code> is true).<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#RegexTokenizer(java.lang.String)"><B>RegexTokenizer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#RegexTokenizer()"><B>RegexTokenizer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function0, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function0&lt;RT&gt;, TypeTags.TypeTag&lt;RT&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 0 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function1&lt;A1, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 1 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function2&lt;A1, A2, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 2 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function3&lt;A1, A2, A3, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 3 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function4&lt;A1, A2, A3, A4, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 4 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function5&lt;A1, A2, A3, A4, A5, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 5 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function6&lt;A1, A2, A3, A4, A5, A6, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 6 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function7&lt;A1, A2, A3, A4, A5, A6, A7, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 7 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function8&lt;A1, A2, A3, A4, A5, A6, A7, A8, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 8 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function9&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 9 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function10&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 10 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function11&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 11 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function12&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 12 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function13&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 13 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function14&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 14 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function15&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 15 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function16&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 16 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function17&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 17 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function18&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;, TypeTags.TypeTag&lt;A18&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 18 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function19&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;, TypeTags.TypeTag&lt;A18&gt;, TypeTags.TypeTag&lt;A19&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 19 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function20&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;, TypeTags.TypeTag&lt;A18&gt;, TypeTags.TypeTag&lt;A19&gt;, TypeTags.TypeTag&lt;A20&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 20 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function21&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;, TypeTags.TypeTag&lt;A18&gt;, TypeTags.TypeTag&lt;A19&gt;, TypeTags.TypeTag&lt;A20&gt;, TypeTags.TypeTag&lt;A21&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 21 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>register(String, Function22&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;, TypeTags.TypeTag&lt;A11&gt;, TypeTags.TypeTag&lt;A12&gt;, TypeTags.TypeTag&lt;A13&gt;, TypeTags.TypeTag&lt;A14&gt;, TypeTags.TypeTag&lt;A15&gt;, TypeTags.TypeTag&lt;A16&gt;, TypeTags.TypeTag&lt;A17&gt;, TypeTags.TypeTag&lt;A18&gt;, TypeTags.TypeTag&lt;A19&gt;, TypeTags.TypeTag&lt;A20&gt;, TypeTags.TypeTag&lt;A21&gt;, TypeTags.TypeTag&lt;A22&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a Scala closure of 22 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF1, org.apache.spark.sql.types.DataType)"><B>register(String, UDF1&lt;?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 1 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF2, org.apache.spark.sql.types.DataType)"><B>register(String, UDF2&lt;?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 2 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF3, org.apache.spark.sql.types.DataType)"><B>register(String, UDF3&lt;?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 3 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF4, org.apache.spark.sql.types.DataType)"><B>register(String, UDF4&lt;?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 4 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF5, org.apache.spark.sql.types.DataType)"><B>register(String, UDF5&lt;?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 5 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF6, org.apache.spark.sql.types.DataType)"><B>register(String, UDF6&lt;?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 6 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF7, org.apache.spark.sql.types.DataType)"><B>register(String, UDF7&lt;?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 7 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF8, org.apache.spark.sql.types.DataType)"><B>register(String, UDF8&lt;?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 8 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF9, org.apache.spark.sql.types.DataType)"><B>register(String, UDF9&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 9 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF10, org.apache.spark.sql.types.DataType)"><B>register(String, UDF10&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 10 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF11, org.apache.spark.sql.types.DataType)"><B>register(String, UDF11&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 11 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF12, org.apache.spark.sql.types.DataType)"><B>register(String, UDF12&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 12 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF13, org.apache.spark.sql.types.DataType)"><B>register(String, UDF13&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 13 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF14, org.apache.spark.sql.types.DataType)"><B>register(String, UDF14&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 14 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF15, org.apache.spark.sql.types.DataType)"><B>register(String, UDF15&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 15 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF16, org.apache.spark.sql.types.DataType)"><B>register(String, UDF16&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 16 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF17, org.apache.spark.sql.types.DataType)"><B>register(String, UDF17&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 17 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF18, org.apache.spark.sql.types.DataType)"><B>register(String, UDF18&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 18 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF19, org.apache.spark.sql.types.DataType)"><B>register(String, UDF19&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 19 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF20, org.apache.spark.sql.types.DataType)"><B>register(String, UDF20&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 20 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF21, org.apache.spark.sql.types.DataType)"><B>register(String, UDF21&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 21 arguments.
<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html#register(java.lang.String, org.apache.spark.sql.api.java.UDF22, org.apache.spark.sql.types.DataType)"><B>register(String, UDF22&lt;?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?&gt;, DataType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</A>
<DD>Register a user-defined function with 22 arguments.
<DT><A HREF="./org/apache/spark/graphx/GraphKryoRegistrator.html#registerClasses(com.esotericsoftware.kryo.Kryo)"><B>registerClasses(Kryo)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphKryoRegistrator.html" title="class in org.apache.spark.graphx">GraphKryoRegistrator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/KryoRegistrator.html#registerClasses(com.esotericsoftware.kryo.Kryo)"><B>registerClasses(Kryo)</B></A> - 
Method in interface org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoRegistrator.html" title="interface in org.apache.spark.serializer">KryoRegistrator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html#registerDialect(org.apache.spark.sql.jdbc.JdbcDialect)"><B>registerDialect(JdbcDialect)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html" title="class in org.apache.spark.sql.jdbc">JdbcDialects</A>
<DD>Register a dialect for use on all new matching jdbc <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/graphx/GraphXUtils.html#registerKryoClasses(org.apache.spark.SparkConf)"><B>registerKryoClasses(SparkConf)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphXUtils.html" title="class in org.apache.spark.graphx">GraphXUtils</A>
<DD>Registers classes that GraphX uses with Kryo.
<DT><A HREF="./org/apache/spark/SparkConf.html#registerKryoClasses(java.lang.Class[])"><B>registerKryoClasses(Class&lt;?&gt;[])</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Use Kryo serialization and register the given set of classes with Kryo.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#registerTempTable(java.lang.String)"><B>registerTempTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Registers this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as a temporary table using the given name.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html#Regression()"><B>Regression()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation"><B>RegressionEvaluator</B></A> - Class in <A HREF="./org/apache/spark/ml/evaluation/package-summary.html">org.apache.spark.ml.evaluation</A><DD>:: Experimental ::
 Evaluator for regression, which expects two input columns: prediction and label.<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#RegressionEvaluator(java.lang.String)"><B>RegressionEvaluator(String)</B></A> - 
Constructor for class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#RegressionEvaluator()"><B>RegressionEvaluator()</B></A> - 
Constructor for class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation"><B>RegressionMetrics</B></A> - Class in <A HREF="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</A><DD>:: Experimental ::
 Evaluator for regression.<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#RegressionMetrics(org.apache.spark.rdd.RDD)"><B>RegressionMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="class in org.apache.spark.ml.regression"><B>RegressionModel</B></A>&lt;<A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="type parameter in RegressionModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="type parameter in RegressionModel">M</A> extends <A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="class in org.apache.spark.ml.regression">RegressionModel</A>&lt;<A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="type parameter in RegressionModel">FeaturesType</A>,<A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="type parameter in RegressionModel">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/regression/package-summary.html">org.apache.spark.ml.regression</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/ml/regression/RegressionModel.html#RegressionModel()"><B>RegressionModel()</B></A> - 
Constructor for class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RegressionModel.html" title="class in org.apache.spark.ml.regression">RegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression"><B>RegressionModel</B></A> - Interface in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#reindex()"><B>reindex()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#reindex()"><B>reindex()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Construct a new VertexRDD that is indexed by only the visible vertices.
<DT><A HREF="./org/apache/spark/sql/sources/RelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>RelationProvider</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 Implemented by objects that produce relations for a specific kind of data source.<DT><A HREF="./org/apache/spark/graphx/Edge.html#relativeDirection(long)"><B>relativeDirection(long)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>Return the relative direction of the edge to the corresponding
 vertex.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#remainder(org.apache.spark.sql.types.Decimal)"><B>remainder(Decimal)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#remember(org.apache.spark.streaming.Duration)"><B>remember(Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Sets each DStreams in this context to remember RDDs it generated in the last given duration.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#remember(org.apache.spark.streaming.Duration)"><B>remember(Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Set each DStreams in this context to remember RDDs it generated in the last given duration.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#rememberDuration()"><B>rememberDuration()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#remoteBlocksFetched()"><B>remoteBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#remoteBlocksFetched()"><B>remoteBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#remoteBytesRead()"><B>remoteBytesRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#remoteBytesRead()"><B>remoteBytesRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#remove(org.apache.spark.ml.param.Param)"><B>remove(Param&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Removes a key from this map and returns its value associated previously as an option.
<DT><A HREF="./org/apache/spark/SparkConf.html#remove(java.lang.String)"><B>remove(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Remove a parameter from the configuration
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a new RDD that has exactly numPartitions partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a new RDD that has exactly numPartitions partitions.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a new RDD that has exactly numPartitions partitions.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#repartition(int, scala.math.Ordering)"><B>repartition(int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a new RDD that has exactly numPartitions partitions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> that has exactly <code>numPartitions</code> partitions.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Return a new DStream with an increased or decreased level of parallelism.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream with an increased or decreased level of parallelism.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#repartition(int)"><B>repartition(int)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream with an increased or decreased level of parallelism.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#repartitionAndSortWithinPartitions(org.apache.spark.Partitioner)"><B>repartitionAndSortWithinPartitions(Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Repartition the RDD according to the given partitioner and, within each resulting partition,
 sort records by their keys.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#repartitionAndSortWithinPartitions(org.apache.spark.Partitioner, java.util.Comparator)"><B>repartitionAndSortWithinPartitions(Partitioner, Comparator&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Repartition the RDD according to the given partitioner and, within each resulting partition,
 sort records by their keys.
<DT><A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html#repartitionAndSortWithinPartitions(org.apache.spark.Partitioner)"><B>repartitionAndSortWithinPartitions(Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</A>
<DD>Repartition the RDD according to the given partitioner and, within each resulting partition,
 sort records by their keys.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#replace(java.lang.String, java.util.Map)"><B>replace(String, Map&lt;T, T&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Replaces values matching keys in <code>replacement</code> map with the corresponding values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#replace(java.lang.String[], java.util.Map)"><B>replace(String[], Map&lt;T, T&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>Replaces values matching keys in <code>replacement</code> map with the corresponding values.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#replace(java.lang.String, scala.collection.immutable.Map)"><B>replace(String, Map&lt;T, T&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Replaces values matching keys in <code>replacement</code> map.
<DT><A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html#replace(scala.collection.Seq, scala.collection.immutable.Map)"><B>replace(Seq&lt;String&gt;, Map&lt;T, T&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</A>
<DD>(Scala-specific) Replaces values matching keys in <code>replacement</code> map.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#replicatedVertexView()"><B>replicatedVertexView()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#replication()"><B>replication()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#reportError(java.lang.String, java.lang.Throwable)"><B>reportError(String, Throwable)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Report exceptions in receiving data.
<DT><A HREF="./org/apache/spark/SparkContext.html#requestExecutors(int)"><B>requestExecutors(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Request an additional number of executors from the cluster manager.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html#resetIterator()"><B>resetIterator()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.LocationIterator.html" title="class in org.apache.spark.rdd">PartitionCoalescer.LocationIterator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String)"><B>restart(String)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Restart the receiver.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String, java.lang.Throwable)"><B>restart(String, Throwable)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Restart the receiver.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String, java.lang.Throwable, int)"><B>restart(String, Throwable, int)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Restart the receiver.
<DT><A HREF="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark"><B>Resubmitted</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 A <CODE>ShuffleMapTask</CODE> that completed successfully earlier, but we
 lost the executor before the stage completed.<DT><A HREF="./org/apache/spark/Resubmitted.html#Resubmitted()"><B>Resubmitted()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark">Resubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>result(Duration, CanAwait)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>result(Duration, CanAwait)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>Awaits and returns the result (of type T) of this action.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)"><B>result(Duration, CanAwait)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#resultSerializationTime()"><B>resultSerializationTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#resultSerializationTime()"><B>resultSerializationTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/JdbcRDD.html#resultSetToObjectArray(java.sql.ResultSet)"><B>resultSetToObjectArray(ResultSet)</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#resultSize()"><B>resultSize()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#resultSize()"><B>resultSize()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#retainedJobs()"><B>retainedJobs()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#retainedStages()"><B>retainedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/RpcUtils.html#retryWaitMs(org.apache.spark.SparkConf)"><B>retryWaitMs(SparkConf)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>Returns the configured number of milliseconds to wait on each retry
<DT><A HREF="./org/apache/spark/util/ReturnStatementFinder.html" title="class in org.apache.spark.util"><B>ReturnStatementFinder</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/ReturnStatementFinder.html#ReturnStatementFinder()"><B>ReturnStatementFinder()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/ReturnStatementFinder.html" title="class in org.apache.spark.util">ReturnStatementFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#reverse()"><B>reverse()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>Reverse the direction of an edge.
<DT><A HREF="./org/apache/spark/graphx/EdgeRDD.html#reverse()"><B>reverse()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx">EdgeRDD</A>
<DD>Reverse all the edges in this RDD.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#reverse()"><B>reverse()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Reverses all edges in the graph.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#reverse()"><B>reverse()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#reverse()"><B>reverse()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#reverseRoutingTables()"><B>reverseRoutingTables()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#reverseRoutingTables()"><B>reverseRoutingTables()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Returns a new <code>VertexRDD</code> reflecting a reversal of all edge directions in the corresponding
 <A HREF="./org/apache/spark/graphx/EdgeRDD.html" title="class in org.apache.spark.graphx"><CODE>EdgeRDD</CODE></A>.
<DT><A HREF="./org/apache/spark/scheduler/local/ReviveOffers.html" title="class in org.apache.spark.scheduler.local"><B>ReviveOffers</B></A> - Class in <A HREF="./org/apache/spark/scheduler/local/package-summary.html">org.apache.spark.scheduler.local</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/local/ReviveOffers.html#ReviveOffers()"><B>ReviveOffers()</B></A> - 
Constructor for class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/ReviveOffers.html" title="class in org.apache.spark.scheduler.local">ReviveOffers</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression"><B>RidgeRegressionModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Regression model trained using RidgeRegression.<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#RidgeRegressionModel(org.apache.spark.mllib.linalg.Vector, double)"><B>RidgeRegressionModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><B>RidgeRegressionWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>Train a regression model with L2-regularization using Stochastic Gradient Descent.<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#RidgeRegressionWithSGD()"><B>RidgeRegressionWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>Construct a RidgeRegression object with default parameters: {stepSize: 1.0, numIterations: 100,
 regParam: 0.01, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/sql/sources/And.html#right()"><B>right()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/And.html" title="class in org.apache.spark.sql.sources">And</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/Or.html#right()"><B>right()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/Or.html" title="class in org.apache.spark.sql.sources">Or</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html#rightCategories()"><B>rightCategories()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/CategoricalSplit.html" title="class in org.apache.spark.ml.tree">CategoricalSplit</A>
<DD>Get sorted categories which split to the right
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#rightChild()"><B>rightChild()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#rightChildIndex(int)"><B>rightChildIndex(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return the index of the right child of this node.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#rightImpurity()"><B>rightImpurity()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#rightNode()"><B>rightNode()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>rightOuterJoin(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD)"><B>rightOuterJoin(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD, int)"><B>rightOuterJoin(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD)"><B>rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, int)"><B>rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Perform a right outer join of <code>this</code> and <code>other</code>.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>rightOuterJoin(JavaPairDStream&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, int)"><B>rightOuterJoin(JavaPairDStream&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)"><B>rightOuterJoin(JavaPairDStream&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)"><B>rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)"><B>rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#rightPredict()"><B>rightPredict()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#rint(org.apache.spark.sql.Column)"><B>rint(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.
<DT><A HREF="./org/apache/spark/sql/functions.html#rint(java.lang.String)"><B>rint(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Returns the double value that is closest in value to the argument and
 is equal to a mathematical integer.
<DT><A HREF="./org/apache/spark/sql/Column.html#rlike(java.lang.String)"><B>rlike(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>SQL RLIKE expression (LIKE with Regex).
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#RMATa()"><B>RMATa()</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#RMATb()"><B>RMATb()</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#RMATc()"><B>RMATc()</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#RMATd()"><B>RMATd()</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#rmatGraph(org.apache.spark.SparkContext, int, int)"><B>rmatGraph(SparkContext, int, int)</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>A random graph generator using the R-MAT model, proposed in
 "R-MAT: A Recursive Model for Graph Mining" by Chakrabarti et al.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#rnd()"><B>rnd()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#roc()"><B>roc()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns the receiver operating characteristic (ROC) curve,
 which is an RDD of (false positive rate, true positive rate)
 with (0.0, 0.0) prepended and (1.0, 1.0) appended to it.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#rollup(org.apache.spark.sql.Column...)"><B>rollup(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional rollup for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#rollup(java.lang.String, java.lang.String...)"><B>rollup(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional rollup for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#rollup(scala.collection.Seq)"><B>rollup(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional rollup for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#rollup(java.lang.String, scala.collection.Seq)"><B>rollup(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Create a multi-dimensional rollup for the current <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> using the specified columns,
 so we can run aggregation on them.
<DT><A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html#rootMeanSquaredError()"><B>rootMeanSquaredError()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/RegressionMetrics.html" title="class in org.apache.spark.mllib.evaluation">RegressionMetrics</A>
<DD>Returns the root mean squared error, which is defined as the square root of
 the mean squared error.
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html#rootNode()"><B>rootNode()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html#rootNode()"><B>rootNode()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><B>Row</B></A> - Interface in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>Represents one row of output from a relational operator.<DT><A HREF="./org/apache/spark/sql/RowFactory.html" title="class in org.apache.spark.sql"><B>RowFactory</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>A factory class used to construct <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A> objects.<DT><A HREF="./org/apache/spark/sql/RowFactory.html#RowFactory()"><B>RowFactory()</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/RowFactory.html" title="class in org.apache.spark.sql">RowFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#rowIndices()"><B>rowIndices()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><B>RowMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</A><DD>:: Experimental ::
 Represents a row-oriented distributed Matrix with no meaningful row indices.<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#RowMatrix(org.apache.spark.rdd.RDD, long, int)"><B>RowMatrix(RDD&lt;Vector&gt;, long, int)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#RowMatrix(org.apache.spark.rdd.RDD)"><B>RowMatrix(RDD&lt;Vector&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>Alternative constructor leaving matrix dimensions to be determined automatically.
<DT><A HREF="./org/apache/spark/sql/functions.html#rowNumber()"><B>rowNumber()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Window function: returns a sequential number starting at 1 within a window partition.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#rows()"><B>rows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#rows()"><B>rows()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html#rowsBetween(long, long)"><B>rowsBetween(long, long)</B></A> - 
Method in class org.apache.spark.sql.expressions.<A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions">WindowSpec</A>
<DD>Defines the frame boundaries, from <code>start</code> (inclusive) to <code>end</code> (inclusive).
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#rowsPerBlock()"><B>rowsPerBlock()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#rpcEnv()"><B>rpcEnv()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util"><B>RpcUtils</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/RpcUtils.html#RpcUtils()"><B>RpcUtils()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/RpcUtils.html" title="class in org.apache.spark.util">RpcUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r"><B>RRDD</B></A>&lt;<A HREF="./org/apache/spark/api/r/RRDD.html" title="type parameter in RRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/api/r/package-summary.html">org.apache.spark.api.r</A><DD>An RDD that stores serialized R objects as Array[Byte].<DT><A HREF="./org/apache/spark/api/r/RRDD.html#RRDD(org.apache.spark.rdd.RDD, byte[], java.lang.String, java.lang.String, byte[], java.lang.String, java.lang.Object[], scala.reflect.ClassTag)"><B>RRDD(RDD&lt;T&gt;, byte[], String, String, byte[], String, Object[], ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/RRDD.html" title="class in org.apache.spark.api.r">RRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#run(scala.Function0, scala.concurrent.ExecutionContext)"><B>run(Function0&lt;T&gt;, ExecutionContext)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>Executes some action enclosed in the closure.
<DT><A HREF="./org/apache/spark/graphx/lib/ConnectedComponents.html#run(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/ConnectedComponents.html" title="class in org.apache.spark.graphx.lib">ConnectedComponents</A>
<DD>Compute the connected component membership of each vertex and return a graph with the vertex
 value containing the lowest vertex id in the connected component containing that vertex.
<DT><A HREF="./org/apache/spark/graphx/lib/LabelPropagation.html#run(org.apache.spark.graphx.Graph, int, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, int, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/LabelPropagation.html" title="class in org.apache.spark.graphx.lib">LabelPropagation</A>
<DD>Run static Label Propagation for detecting communities in networks.
<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html#run(org.apache.spark.graphx.Graph, int, double, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, int, double, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib">PageRank</A>
<DD>Run PageRank for a fixed number of iterations returning a graph
 with vertex attributes containing the PageRank and edge
 attributes the normalized edge weight.
<DT><A HREF="./org/apache/spark/graphx/lib/ShortestPaths.html#run(org.apache.spark.graphx.Graph, scala.collection.Seq, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, Seq&lt;Object&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/ShortestPaths.html" title="class in org.apache.spark.graphx.lib">ShortestPaths</A>
<DD>Computes shortest paths to the given set of landmark vertices.
<DT><A HREF="./org/apache/spark/graphx/lib/StronglyConnectedComponents.html#run(org.apache.spark.graphx.Graph, int, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, int, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/StronglyConnectedComponents.html" title="class in org.apache.spark.graphx.lib">StronglyConnectedComponents</A>
<DD>Compute the strongly connected component (SCC) of each vertex and return a graph with the
 vertex value containing the lowest vertex id in the SCC containing that vertex.
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html#run(org.apache.spark.rdd.RDD, org.apache.spark.graphx.lib.SVDPlusPlus.Conf)"><B>run(RDD&lt;Edge&lt;Object&gt;&gt;, SVDPlusPlus.Conf)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus</A>
<DD>Implement SVD++ based on "Factorization Meets the Neighborhood:
 a Multifaceted Collaborative Filtering Model",
 available at <CODE>http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf</CODE>.
<DT><A HREF="./org/apache/spark/graphx/lib/TriangleCount.html#run(org.apache.spark.graphx.Graph, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>run(Graph&lt;VD, ED&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/TriangleCount.html" title="class in org.apache.spark.graphx.lib">TriangleCount</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Run the algorithm with the configured parameters on an input RDD of LabeledPoint entries.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Perform expectation maximization
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Java-friendly version of <CODE>run()</CODE>
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Train a K-means model on the given set of points; <code>data</code> should be cached for high
 performance, because this is an iterative algorithm.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Learn an LDA model using the given dataset.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#run(org.apache.spark.api.java.JavaPairRDD)"><B>run(JavaPairRDD&lt;Long, Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Java-friendly version of <CODE>run()</CODE>
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Tuple3&lt;Object, Object, Object&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>Run the PIC algorithm.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;Tuple3&lt;Long, Long, Double&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>A Java-friendly version of <CODE>PowerIterationClustering.run</CODE>.
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html#run(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>run(RDD&lt;Object&gt;, ClassTag&lt;Item&gt;)</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm">FPGrowth</A>
<DD>Computes an FP-Growth model that contains frequent itemsets.
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;Basket&gt;)</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm">FPGrowth</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Rating&gt;)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;Rating&gt;)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>Run the algorithm with the configured parameters on an input
 RDD of LabeledPoint entries.
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#run(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)"><B>run(RDD&lt;LabeledPoint&gt;, Vector)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>Run the algorithm with the configured parameters on an input RDD
 of LabeledPoint entries starting from the initial weights provided.
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;Tuple3&lt;Object, Object, Object&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html" title="class in org.apache.spark.mllib.regression">IsotonicRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;Tuple3&lt;Double, Double, Double&gt;&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html" title="class in org.apache.spark.mllib.regression">IsotonicRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model over an RDD
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Method to train a gradient boosting model
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#run(org.apache.spark.api.java.JavaRDD)"><B>run(JavaRDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Java-friendly API for <CODE>org.apache.spark.mllib.tree.GradientBoostedTrees!#run</CODE>.
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#run(org.apache.spark.rdd.RDD)"><B>run(RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Method to train a decision tree model over an RDD
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#run()"><B>run()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>Runs the packing algorithm and returns an array of PartitionGroups that if possible are
 load balanced and grouped by locality
<DT><A HREF="./org/apache/spark/util/SparkShutdownHook.html#run()"><B>run()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/SparkShutdownHook.html" title="class in org.apache.spark.util">SparkShutdownHook</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#runApproximateJob(org.apache.spark.rdd.RDD, scala.Function2, , long)"><B>runApproximateJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, &lt;any&gt;, long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Run a job that can return approximate results.
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, scala.Function2, scala.Function0)"><B>runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, Function2&lt;Object, U, BoxedUnit&gt;, Function0&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>Runs a Spark job.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.collection.Seq, boolean, scala.Function2, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a function on a given set of partitions in an RDD and pass the results to the given
 handler function.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.collection.Seq, boolean, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a function on a given set of partitions in an RDD and return the results as an array.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, boolean, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a job on a given set of partitions of an RDD, but take a function of type
 <code>Iterator[T] =&gt; U</code> instead of <code>(TaskContext, Iterator[T]) =&gt; U</code>.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a job on all partitions in an RDD and return the results in an array.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a job on all partitions in an RDD and return the results in an array.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.Function2, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a job on all partitions in an RDD and pass the results to a handler function.
<DT><A HREF="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.Function2, scala.reflect.ClassTag)"><B>runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Run a job on all partitions in an RDD and pass the results to a handler function.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#runLBFGS(org.apache.spark.rdd.RDD, org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater, int, double, int, double, org.apache.spark.mllib.linalg.Vector)"><B>runLBFGS(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Gradient, Updater, int, double, int, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Run Limited-memory BFGS (L-BFGS) in parallel.
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#runMiniBatchSGD(org.apache.spark.rdd.RDD, org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater, double, int, double, double, org.apache.spark.mllib.linalg.Vector)"><B>runMiniBatchSGD(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Gradient, Updater, double, int, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Run stochastic gradient descent (SGD) in parallel using mini batches.
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#running()"><B>running()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#runningLocally()"><B>runningLocally()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html#runSVDPlusPlus(org.apache.spark.rdd.RDD, org.apache.spark.graphx.lib.SVDPlusPlus.Conf)"><B>runSVDPlusPlus(RDD&lt;Edge&lt;Object&gt;&gt;, SVDPlusPlus.Conf)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus</A>
<DD>This method is now replaced by the updated version of <code>run()</code> and returns exactly
 the same result.
<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler"><B>RuntimePercentage</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/RuntimePercentage.html#RuntimePercentage(double, scala.Option, double)"><B>RuntimePercentage(double, Option&lt;Object&gt;, double)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/RuntimePercentage.html" title="class in org.apache.spark.scheduler">RuntimePercentage</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html#runUntilConvergence(org.apache.spark.graphx.Graph, double, double, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>runUntilConvergence(Graph&lt;VD, ED&gt;, double, double, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib">PageRank</A>
<DD>Run a dynamic version of PageRank returning a graph with vertex attributes containing the
 PageRank and edge attributes containing the normalized edge weight.
<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html#runUntilConvergenceWithOptions(org.apache.spark.graphx.Graph, double, double, scala.Option, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>runUntilConvergenceWithOptions(Graph&lt;VD, ED&gt;, double, double, Option&lt;Object&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib">PageRank</A>
<DD>Run a dynamic version of PageRank returning a graph with vertex attributes containing the
 PageRank and edge attributes containing the normalized edge weight.
<DT><A HREF="./org/apache/spark/graphx/lib/PageRank.html#runWithOptions(org.apache.spark.graphx.Graph, int, double, scala.Option, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>runWithOptions(Graph&lt;VD, ED&gt;, int, double, Option&lt;Object&gt;, ClassTag&lt;VD&gt;, ClassTag&lt;ED&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/PageRank.html" title="class in org.apache.spark.graphx.lib">PageRank</A>
<DD>Run PageRank for a fixed number of iterations returning a graph
 with vertex attributes containing the PageRank and edge
 attributes the normalized edge weight.
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#runWithValidation(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)"><B>runWithValidation(RDD&lt;LabeledPoint&gt;, RDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Method to validate a gradient boosting model
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#runWithValidation(org.apache.spark.api.java.JavaRDD, org.apache.spark.api.java.JavaRDD)"><B>runWithValidation(JavaRDD&lt;LabeledPoint&gt;, JavaRDD&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Java-friendly API for <CODE>org.apache.spark.mllib.tree.GradientBoostedTrees!#runWithValidation</CODE>.
</DL>
<HR>
<A NAME="_S_"><!-- --></A><H2>
<B>S</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#s()"><B>s()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sample(boolean, java.lang.Double)"><B>sample(boolean, Double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sample(boolean, java.lang.Double, long)"><B>sample(boolean, Double, long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sample(boolean, double)"><B>sample(boolean, double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sample(boolean, double, long)"><B>sample(boolean, double, long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#sample(boolean, double)"><B>sample(boolean, double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#sample(boolean, double, long)"><B>sample(boolean, double, long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#sample(boolean, double, long)"><B>sample(boolean, double, long)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a sampled subset of this RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sample(boolean, double, long)"><B>sample(boolean, double, long)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> by sampling a fraction of rows.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sample(boolean, double)"><B>sample(boolean, double)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> by sampling a fraction of rows, using a random seed.
<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html#sample(scala.collection.Iterator)"><B>sample(Iterator&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random">BernoulliCellSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliSampler.html#sample(scala.collection.Iterator)"><B>sample(Iterator&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/PoissonSampler.html#sample(scala.collection.Iterator)"><B>sample(Iterator&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/RandomSampler.html#sample(scala.collection.Iterator)"><B>sample(Iterator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random">RandomSampler</A>
<DD>take a random sample
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKey(boolean, java.util.Map, long)"><B>sampleByKey(boolean, Map&lt;K, Object&gt;, long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a subset of this RDD sampled by key (via stratified sampling).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKey(boolean, java.util.Map)"><B>sampleByKey(boolean, Map&lt;K, Object&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return a subset of this RDD sampled by key (via stratified sampling).
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#sampleByKey(boolean, scala.collection.Map, long)"><B>sampleByKey(boolean, Map&lt;K, Object&gt;, long)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return a subset of this RDD sampled by key (via stratified sampling).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKeyExact(boolean, java.util.Map, long)"><B>sampleByKeyExact(boolean, Map&lt;K, Object&gt;, long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKeyExact(boolean, java.util.Map)"><B>sampleByKeyExact(boolean, Map&lt;K, Object&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#sampleByKeyExact(boolean, scala.collection.Map, long)"><B>sampleByKeyExact(boolean, Map&lt;K, Object&gt;, long)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sampleStdev()"><B>sampleStdev()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute the sample standard deviation of this RDD's elements (which corrects for bias in
 estimating the standard deviation by dividing by N-1 instead of N).
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#sampleStdev()"><B>sampleStdev()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute the sample standard deviation of this RDD's elements (which corrects for bias in
 estimating the standard deviation by dividing by N-1 instead of N).
<DT><A HREF="./org/apache/spark/util/StatCounter.html#sampleStdev()"><B>sampleStdev()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Return the sample standard deviation of the values, which corrects for bias in estimating the
 variance by dividing by N-1 instead of N.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sampleVariance()"><B>sampleVariance()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute the sample variance of this RDD's elements (which corrects for bias in
 estimating the standard variance by dividing by N-1 instead of N).
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#sampleVariance()"><B>sampleVariance()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute the sample variance of this RDD's elements (which corrects for bias in
 estimating the variance by dividing by N-1 instead of N).
<DT><A HREF="./org/apache/spark/util/StatCounter.html#sampleVariance()"><B>sampleVariance()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Return the sample variance, which corrects for bias in estimating the variance by dividing
 by N-1 instead of N.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClusteringModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegressionModel.html" title="class in org.apache.spark.mllib.regression">IsotonicRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model">RandomForestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/Saveable.html#save(org.apache.spark.SparkContext, java.lang.String)"><B>save(SparkContext, String)</B></A> - 
Method in interface org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/Saveable.html" title="interface in org.apache.spark.mllib.util">Saveable</A>
<DD>Save this model to the given path.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String)"><B>save(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode)"><B>save(String, SaveMode)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String, java.lang.String)"><B>save(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode)"><B>save(String, String, SaveMode)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).mode(mode).save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode, java.util.Map)"><B>save(String, SaveMode, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#save(java.lang.String, org.apache.spark.sql.SaveMode, scala.collection.immutable.Map)"><B>save(String, SaveMode, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).save(path)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#save(java.lang.String)"><B>save(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> at the specified path.
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#save()"><B>save()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as the specified table.
<DT><A HREF="./org/apache/spark/mllib/util/Saveable.html" title="interface in org.apache.spark.mllib.util"><B>Saveable</B></A> - Interface in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)"><B>saveAsHadoopDataset(JobConf)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)"><B>saveAsHadoopDataset(JobConf)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)"><B>saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, JobConf)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported file system.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported file system.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, Class&lt;? extends CompressionCodec&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported file system, compressing with the supplied codec.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, scala.reflect.ClassTag)"><B>saveAsHadoopFile(String, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, scala.reflect.ClassTag)"><B>saveAsHadoopFile(String, Class&lt;? extends CompressionCodec&gt;, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Class&lt;? extends CompressionCodec&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf, scala.Option)"><B>saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, JobConf, Option&lt;Class&lt;? extends CompressionCodec&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String)"><B>saveAsHadoopFiles(String, String)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)"><B>saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, JobConf)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)"><B>saveAsHadoopFiles(String, String, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)"><B>saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, JobConf)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#saveAsLibSVMFile(org.apache.spark.rdd.RDD, java.lang.String)"><B>saveAsLibSVMFile(RDD&lt;LabeledPoint&gt;, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD>Save labeled data in LIBSVM format.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopDataset(Configuration)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported storage system, using
 a Configuration object for that storage system.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopDataset(Configuration)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported storage system with new Hadoop API, using a Hadoop
 Configuration object for that storage system.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported file system.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Output the RDD to any Hadoop-supported file system.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, scala.reflect.ClassTag)"><B>saveAsNewAPIHadoopFile(String, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String)"><B>saveAsNewAPIHadoopFiles(String, String)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)"><B>saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)"><B>saveAsNewAPIHadoopFiles(String, String, ClassTag&lt;F&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)"><B>saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Configuration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Save each RDD in <code>this</code> DStream as a Hadoop file.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#saveAsObjectFile(java.lang.String)"><B>saveAsObjectFile(String)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Save this RDD as a SequenceFile of serialized objects.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)"><B>saveAsObjectFile(String)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Save this RDD as a SequenceFile of serialized objects.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#saveAsObjectFiles(java.lang.String, java.lang.String)"><B>saveAsObjectFiles(String, String)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Save each RDD in this DStream as a Sequence file of serialized objects.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsParquetFile(java.lang.String)"><B>saveAsParquetFile(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().parquet()</code>.</I>
<DT><A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html#saveAsSequenceFile(java.lang.String, scala.Option)"><B>saveAsSequenceFile(String, Option&lt;Class&lt;? extends CompressionCodec&gt;&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd">SequenceFileRDDFunctions</A>
<DD>Output the RDD as a Hadoop SequenceFile using the Writable types we infer from the RDD's key
 and value types.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String)"><B>saveAsTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, org.apache.spark.sql.SaveMode)"><B>saveAsTable(String, SaveMode)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String)"><B>saveAsTable(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().format(source).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode)"><B>saveAsTable(String, String, SaveMode)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by <code>write().mode(mode).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode, java.util.Map)"><B>saveAsTable(String, String, SaveMode, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#saveAsTable(java.lang.String, java.lang.String, org.apache.spark.sql.SaveMode, scala.collection.immutable.Map)"><B>saveAsTable(String, String, SaveMode, Map&lt;String, String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.4.0, replaced by
            <code>write().format(source).mode(mode).options(options).saveAsTable(tableName)</code>.</I>
<DT><A HREF="./org/apache/spark/sql/DataFrameWriter.html#saveAsTable(java.lang.String)"><B>saveAsTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</A>
<DD>Saves the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as the specified table.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String)"><B>saveAsTextFile(String)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Save this RDD as a text file, using string representations of elements.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String, java.lang.Class)"><B>saveAsTextFile(String, Class&lt;? extends CompressionCodec&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Save this RDD as a compressed text file, using string representations of elements.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><B>saveAsTextFile(String)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Save this RDD as a text file, using string representations of elements.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String, java.lang.Class)"><B>saveAsTextFile(String, Class&lt;? extends CompressionCodec&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Save this RDD as a compressed text file, using string representations of elements.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#saveAsTextFiles(java.lang.String, java.lang.String)"><B>saveAsTextFiles(String, String)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Save each RDD in this DStream as at text file, using string representation
 of elements.
<DT><A HREF="./org/apache/spark/mllib/util/MLUtils.html#saveLabeledData(org.apache.spark.rdd.RDD, java.lang.String)"><B>saveLabeledData(RDD&lt;LabeledPoint&gt;, String)</B></A> - 
Static method in class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</A>
<DD><B>Deprecated.</B>&nbsp;<I>Should use <A HREF="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><CODE>RDD.saveAsTextFile(java.lang.String)</CODE></A> for saving and
            <A HREF="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><CODE>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</CODE></A> for loading.</I>
<DT><A HREF="./org/apache/spark/sql/SaveMode.html" title="enum in org.apache.spark.sql"><B>SaveMode</B></A> - Enum in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>SaveMode is used to specify the expected behavior of saving a DataFrame to a data source.<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#sc()"><B>sc()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.StringToColumn.html#sc()"><B>sc()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.StringToColumn.html" title="class in org.apache.spark.sql">SQLContext.implicits$.StringToColumn</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#sc()"><B>sc()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 0.9.0, replaced by <code>sparkContext</code></I>
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#sc()"><B>sc()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#scalaIntToJavaLong(org.apache.spark.streaming.dstream.DStream)"><B>scalaIntToJavaLong(DStream&lt;Object&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#scalaToJavaLong(org.apache.spark.streaming.api.java.JavaPairDStream, scala.reflect.ClassTag)"><B>scalaToJavaLong(JavaPairDStream&lt;K, Object&gt;, ClassTag&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#scale()"><B>scale()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#scale()"><B>scale()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#scale()"><B>scale()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/PrecisionInfo.html#scale()"><B>scale()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/PrecisionInfo.html" title="class in org.apache.spark.sql.types">PrecisionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#scalingVec()"><B>scalingVec()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>the vector to multiply with input vectors
<DT><A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html#scalingVec()"><B>scalingVec()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html" title="class in org.apache.spark.mllib.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#scheduler()"><B>scheduler()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#schedulingDelay()"><B>schedulingDelay()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>Time taken for the first job of this batch to start processing from the time this batch
 was submitted to the streaming scheduler.
<DT><A HREF="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler"><B>SchedulingMode</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>"FAIR" and "FIFO" determines which policy is used
    to order tasks amongst a Schedulable's sub-queues
  "NONE" is used when the a Schedulable has no sub-queues.<DT><A HREF="./org/apache/spark/scheduler/SchedulingMode.html#SchedulingMode()"><B>SchedulingMode()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#schedulingMode()"><B>schedulingMode()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#schedulingPool()"><B>schedulingPool()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#schema()"><B>schema()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the schema of this <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#schema(org.apache.spark.sql.types.StructType)"><B>schema(StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Specifies the input schema.
<DT><A HREF="./org/apache/spark/sql/Row.html#schema()"><B>schema()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Schema for the row.
<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html#schema()"><B>schema()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#schema()"><B>schema()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Schema of this relation.
<DT><A HREF="./org/apache/spark/sql/sources/SchemaRelationProvider.html" title="interface in org.apache.spark.sql.sources"><B>SchemaRelationProvider</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 Implemented by objects that produce relations for a specific kind of data source
 with a given schema.<DT><A HREF="./org/apache/spark/rdd/RDD.html#scope()"><B>scope()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>The scope associated with the operation that created this RDD.
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#scope()"><B>scope()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#scoreAndLabels()"><B>scoreAndLabels()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#seconds()"><B>seconds()</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Durations.html#seconds(long)"><B>seconds(long)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Durations.html" title="class in org.apache.spark.streaming">Durations</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming"><B>Seconds</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>Helper object that creates instance of <A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><CODE>Duration</CODE></A> representing
 a given number of seconds.<DT><A HREF="./org/apache/spark/streaming/Seconds.html#Seconds()"><B>Seconds()</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming">Seconds</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#securityManager()"><B>securityManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#select(org.apache.spark.sql.Column...)"><B>select(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of column based expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#select(java.lang.String, java.lang.String...)"><B>select(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of columns.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#select(scala.collection.Seq)"><B>select(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of column based expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#select(java.lang.String, scala.collection.Seq)"><B>select(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of columns.
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html#selectedFeatures()"><B>selectedFeatures()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html" title="class in org.apache.spark.mllib.feature">ChiSqSelectorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#selectExpr(java.lang.String...)"><B>selectExpr(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of SQL expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#selectExpr(scala.collection.Seq)"><B>selectExpr(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Selects a set of SQL expressions.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#sendMessages(java.lang.String, java.util.Map)"><B>sendMessages(String, Map&lt;String, Integer&gt;)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Java-friendly function for sending messages to the Kafka broker
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#sendMessages(java.lang.String, scala.collection.immutable.Map)"><B>sendMessages(String, Map&lt;String, Object&gt;)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Send the messages to the Kafka broker
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#sendMessages(java.lang.String, java.lang.String[])"><B>sendMessages(String, String[])</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Send the array of messages to the Kafka broker
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#sendToDst(A)"><B>sendToDst(A)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>Sends a message to the destination vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#sendToDst(A)"><B>sendToDst(A)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#sendToSrc(A)"><B>sendToSrc(A)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>Sends a message to the source vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#sendToSrc(A)"><B>sendToSrc(A)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class, int)"><B>sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop SequenceFile with given key and value types.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class)"><B>sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Get an RDD for a Hadoop SequenceFile.
<DT><A HREF="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class, int)"><B>sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a Hadoop SequenceFile with given key and value types.
<DT><A HREF="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class)"><B>sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Get an RDD for a Hadoop SequenceFile with given key and value types.
<DT><A HREF="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, int, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Function0, scala.Function0)"><B>sequenceFile(String, int, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Function0&lt;WritableConverter&lt;K&gt;&gt;, Function0&lt;WritableConverter&lt;V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Version of sequenceFile() for types implicitly convertible to Writables through a
 WritableConverter.
<DT><A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd"><B>SequenceFileRDDFunctions</B></A>&lt;<A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="type parameter in SequenceFileRDDFunctions">K</A>,<A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="type parameter in SequenceFileRDDFunctions">V</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>Extra functions available on RDDs of (key, value) pairs to create a Hadoop SequenceFile,
 through an implicit conversion.<DT><A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html#SequenceFileRDDFunctions(org.apache.spark.rdd.RDD, java.lang.Class, java.lang.Class, scala.Function1, scala.reflect.ClassTag, scala.Function1, scala.reflect.ClassTag)"><B>SequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Class&lt;? extends Writable&gt;, Class&lt;? extends Writable&gt;, Function1&lt;K, Writable&gt;, ClassTag&lt;K&gt;, Function1&lt;V, Writable&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd">SequenceFileRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html#SequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag, scala.Function1, scala.reflect.ClassTag)"><B>SequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Function1&lt;K, Writable&gt;, ClassTag&lt;K&gt;, Function1&lt;V, Writable&gt;, ClassTag&lt;V&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd">SequenceFileRDDFunctions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark"><B>SerializableWritable</B></A>&lt;<A HREF="./org/apache/spark/SerializableWritable.html" title="type parameter in SerializableWritable">T</A> extends org.apache.hadoop.io.Writable&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SerializableWritable.html#SerializableWritable(T)"><B>SerializableWritable(T)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer"><B>SerializationStream</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>:: DeveloperApi ::
 A stream for writing serialized objects.<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#SerializationStream()"><B>SerializationStream()</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#serialize(T, scala.reflect.ClassTag)"><B>serialize(T, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#serialize(java.lang.Object)"><B>serialize(Object)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>Convert the user type to a SQL datum
<DT><A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html#serializedData()"><B>serializedData()</B></A> - 
Method in class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html" title="class in org.apache.spark.scheduler.local">StatusUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer"><B>Serializer</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>:: DeveloperApi ::
 A serializer.<DT><A HREF="./org/apache/spark/serializer/Serializer.html#Serializer()"><B>Serializer()</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#serializer()"><B>serializer()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#serializer()"><B>serializer()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer"><B>SerializerInstance</B></A> - Class in <A HREF="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</A><DD>:: DeveloperApi ::
 An instance of a serializer, for use by one thread at a time.<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#SerializerInstance()"><B>SerializerInstance()</B></A> - 
Constructor for class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializerInstance.html#serializeStream(java.io.OutputStream)"><B>serializeStream(OutputStream)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#set(long, long, int, int, VD, VD, ED)"><B>set(long, long, int, int, VD, VD, ED)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Params.html#set(org.apache.spark.ml.param.Param, T)"><B>set(Param&lt;T&gt;, T)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets a parameter in the embedded param map.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#set(java.lang.String, java.lang.Object)"><B>set(String, Object)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets a parameter (by name) in the embedded param map.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#set(org.apache.spark.ml.param.ParamPair)"><B>set(ParamPair&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets a parameter in the embedded param map.
<DT><A HREF="./org/apache/spark/SparkConf.html#set(java.lang.String, java.lang.String)"><B>set(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set a configuration variable.
<DT><A HREF="./org/apache/spark/SparkEnv.html#set(org.apache.spark.SparkEnv)"><B>set(SparkEnv)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(long)"><B>set(long)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given Long.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(int)"><B>set(int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given Int.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(long, int, int)"><B>set(long, int, int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given unscaled Long, with a given precision and scale.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(scala.math.BigDecimal, int, int)"><B>set(BigDecimal, int, int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given BigDecimal value, with a given precision and scale.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(scala.math.BigDecimal)"><B>set(BigDecimal)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given BigDecimal value, inheriting its precision and scale.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#set(org.apache.spark.sql.types.Decimal)"><B>set(Decimal)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given Decimal value.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#set(java.lang.String)"><B>set(String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Update the UTF8String with String.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#set(byte[])"><B>set(byte[])</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Update the UTF8String with Array[Byte], which should be encoded in UTF-8
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#setAggregator(org.apache.spark.Aggregator)"><B>setAggregator(Aggregator&lt;K, V, C&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>Set aggregator for RDD's shuffle.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setAlgo(java.lang.String)"><B>setAlgo(String)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Sets Algorithm using a String.
<DT><A HREF="./org/apache/spark/SparkConf.html#setAll(scala.collection.Traversable)"><B>setAll(Traversable&lt;Tuple2&lt;String, String&gt;&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set multiple parameters together
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setAlpha(double)"><B>setAlpha(double)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setAlpha(double)"><B>setAlpha(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Alias for <CODE>setDocConcentration()</CODE>
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setAlpha(double)"><B>setAlpha(double)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setAppName(java.lang.String)"><B>setAppName(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set the application name.
<DT><A HREF="./org/apache/spark/SparkConf.html#setAppName(java.lang.String)"><B>setAppName(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set a name for your application.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setAppResource(java.lang.String)"><B>setAppResource(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set the main application resource.
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#setBandwidth(double)"><B>setBandwidth(double)</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>Sets the bandwidth (standard deviation) of the Gaussian kernel (default: <code>1.0</code>).
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setBeta(double)"><B>setBeta(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Alias for <CODE>setTopicConcentration()</CODE>
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setBlocks(int)"><B>setBlocks(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setCacheNodeIds(boolean)"><B>setCacheNodeIds(boolean)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setCallSite(java.lang.String)"><B>setCallSite(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Pass-through to SparkContext.setCallSite.
<DT><A HREF="./org/apache/spark/SparkContext.html#setCallSite(java.lang.String)"><B>setCallSite(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Set the thread-local property for overriding the call sites
 of actions and RDDs.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setCategoricalFeaturesInfo(java.util.Map)"><B>setCategoricalFeaturesInfo(Map&lt;Integer, Integer&gt;)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Sets categoricalFeaturesInfo using a Java Map.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setCheckpointDir(java.lang.String)"><B>setCheckpointDir(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Set the directory under which RDDs are going to be checkpointed.
<DT><A HREF="./org/apache/spark/SparkContext.html#setCheckpointDir(java.lang.String)"><B>setCheckpointDir(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Set the directory under which RDDs are going to be checkpointed.
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Period (in iterations) between checkpoints (default = 10).
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setCheckpointInterval(int)"><B>setCheckpointInterval(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#setClassifier(org.apache.spark.ml.classification.Classifier)"><B>setClassifier(Classifier&lt;?, ?, ?&gt;)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setConf(java.lang.String, java.lang.String)"><B>setConf(String, String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set a single configuration value for the application.
<DT><A HREF="./org/apache/spark/sql/hive/HiveContext.html#setConf(java.lang.String, java.lang.String)"><B>setConf(String, String)</B></A> - 
Method in class org.apache.spark.sql.hive.<A HREF="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#setConf(java.util.Properties)"><B>setConf(Properties)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Set Spark SQL configuration properties.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#setConf(java.lang.String, java.lang.String)"><B>setConf(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Set the given Spark SQL configuration property.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#setConvergenceTol(double)"><B>setConvergenceTol(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Set the largest change in log-likelihood at which convergence is
 considered to have occurred.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setConvergenceTol(double)"><B>setConvergenceTol(double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the convergence tolerance of iterations for L-BFGS.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#setDecayFactor(double)"><B>setDecayFactor(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Set the decay factor directly (for forgetful algorithms).
<DT><A HREF="./org/apache/spark/ml/param/Params.html#setDefault(org.apache.spark.ml.param.ParamPair...)"><B>setDefault(ParamPair&lt;?&gt;...)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets default values for a list of params.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#setDefault(org.apache.spark.ml.param.Param, T)"><B>setDefault(Param&lt;T&gt;, T)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets a default value for a param.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#setDefault(scala.collection.Seq)"><B>setDefault(Seq&lt;ParamPair&lt;?&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Sets default values for a list of params.
<DT><A HREF="./org/apache/spark/serializer/Serializer.html#setDefaultClassLoader(java.lang.ClassLoader)"><B>setDefaultClassLoader(ClassLoader)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</A>
<DD>Sets a class loader for the serializer to use in deserialization.
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#setDegree(int)"><B>setDegree(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setDeployMode(java.lang.String)"><B>setDeployMode(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set the deploy mode for the application.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setDocConcentration(double)"><B>setDocConcentration(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Concentration parameter (commonly named "alpha") for the prior placed on documents'
 distributions over topics ("theta").
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#setDropLast(boolean)"><B>setDropLast(boolean)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setElasticNetParam(double)"><B>setElasticNetParam(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>Set the ElasticNet mixing parameter.
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#setElasticNetParam(double)"><B>setElasticNetParam(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>Set the ElasticNet mixing parameter.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setEpsilon(double)"><B>setEpsilon(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set the distance threshold within which we've consider centers to have converged.
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#setEstimator(org.apache.spark.ml.Estimator)"><B>setEstimator(Estimator&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#setEstimatorParamMaps(org.apache.spark.ml.param.ParamMap[])"><B>setEstimatorParamMaps(ParamMap[])</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#setEvaluator(org.apache.spark.ml.evaluation.Evaluator)"><B>setEvaluator(Evaluator)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#setExecutorEnv(java.lang.String, java.lang.String)"><B>setExecutorEnv(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set an environment variable to be used when launching executors for this application.
<DT><A HREF="./org/apache/spark/SparkConf.html#setExecutorEnv(scala.collection.Seq)"><B>setExecutorEnv(Seq&lt;Tuple2&lt;String, String&gt;&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set multiple environment variables to be used when launching executors.
<DT><A HREF="./org/apache/spark/SparkConf.html#setExecutorEnv(scala.Tuple2[])"><B>setExecutorEnv(Tuple2&lt;String, String&gt;[])</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set multiple environment variables to be used when launching executors.
<DT><A HREF="./org/apache/spark/ml/PredictionModel.html#setFeaturesCol(java.lang.String)"><B>setFeaturesCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Predictor.html#setFeaturesCol(java.lang.String)"><B>setFeaturesCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setFeatureSubsetStrategy(java.lang.String)"><B>setFeatureSubsetStrategy(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setFeatureSubsetStrategy(java.lang.String)"><B>setFeatureSubsetStrategy(String)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setFinalRDDStorageLevel(org.apache.spark.storage.StorageLevel)"><B>setFinalRDDStorageLevel(StorageLevel)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setFitIntercept(boolean)"><B>setFitIntercept(boolean)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>Whether to fit an intercept term.
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#setGaps(boolean)"><B>setGaps(boolean)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setGradient(org.apache.spark.mllib.optimization.Gradient)"><B>setGradient(Gradient)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Set the gradient function (of the loss function of one single data example)
 to be used for SGD.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setGradient(org.apache.spark.mllib.optimization.Gradient)"><B>setGradient(Gradient)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the gradient function (of the loss function of one single data example)
 to be used for L-BFGS.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#setHalfLife(double, java.lang.String)"><B>setHalfLife(double, String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Set the half life and time unit ("batches" or "points") for forgetful algorithms.
<DT><A HREF="./org/apache/spark/SparkConf.html#setIfMissing(java.lang.String, java.lang.String)"><B>setIfMissing(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set a parameter if it isn't already configured
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setImplicitPrefs(boolean)"><B>setImplicitPrefs(boolean)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setImplicitPrefs(boolean)"><B>setImplicitPrefs(boolean)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>The impurity setting is ignored for GBT models.
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>The impurity setting is ignored for GBT models.
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setImpurity(java.lang.String)"><B>setImpurity(String)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setImpurity(org.apache.spark.mllib.tree.impurity.Impurity)"><B>setImpurity(Impurity)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#setInitialCenters(org.apache.spark.mllib.linalg.Vector[], double[])"><B>setInitialCenters(Vector[], double[])</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Specify initial centers directly.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setInitializationMode(java.lang.String)"><B>setInitializationMode(String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set the initialization algorithm.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#setInitializationMode(java.lang.String)"><B>setInitializationMode(String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>Set the initialization mode.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setInitializationSteps(int)"><B>setInitializationSteps(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set the number of steps for the k-means|| initialization mode.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#setInitialModel(org.apache.spark.mllib.clustering.GaussianMixtureModel)"><B>setInitialModel(GaussianMixtureModel)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Set the initial GMM starting point, bypassing the random initialization.
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#setInitialWeights(org.apache.spark.mllib.linalg.Vector)"><B>setInitialWeights(Vector)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Set the initial weights.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setInitialWeights(org.apache.spark.mllib.linalg.Vector)"><B>setInitialWeights(Vector)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>Set the initial weights.
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#setInputCol(java.lang.String)"><B>setInputCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#setInputCols(java.lang.String[])"><B>setInputCols(String[])</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#setIntercept(boolean)"><B>setIntercept(boolean)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>Set if the algorithm should add an intercept.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setIntermediateRDDStorageLevel(org.apache.spark.storage.StorageLevel)"><B>setIntermediateRDDStorageLevel(StorageLevel)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html#setIsotonic(boolean)"><B>setIsotonic(boolean)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/IsotonicRegression.html" title="class in org.apache.spark.mllib.regression">IsotonicRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setItemCol(java.lang.String)"><B>setItemCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#setItemCol(java.lang.String)"><B>setItemCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setIterations(int)"><B>setIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#setJars(scala.collection.Seq)"><B>setJars(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set JAR files to distribute to the cluster.
<DT><A HREF="./org/apache/spark/SparkConf.html#setJars(java.lang.String[])"><B>setJars(String[])</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set JAR files to distribute to the cluster.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setJavaHome(java.lang.String)"><B>setJavaHome(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set a custom JAVA_HOME for launching the Spark application.
<DT><A HREF="./org/apache/spark/SparkContext.html#setJobDescription(java.lang.String)"><B>setJobDescription(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Set a human readable description of the current job.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setJobGroup(java.lang.String, java.lang.String, boolean)"><B>setJobGroup(String, String, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setJobGroup(java.lang.String, java.lang.String)"><B>setJobGroup(String, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.
<DT><A HREF="./org/apache/spark/SparkContext.html#setJobGroup(java.lang.String, java.lang.String, boolean)"><B>setJobGroup(String, String, boolean)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#setK(int)"><B>setK(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Set the number of Gaussians in the mixture model.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setK(int)"><B>setK(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set the number of clusters to create (k).
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setK(int)"><B>setK(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Number of topics to infer.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#setK(int)"><B>setK(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#setK(int)"><B>setK(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Set the number of clusters.
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#setKappa(double)"><B>setKappa(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>Learning rate: exponential decay rate---should be between
 (0.5, 1.0] to guarantee asymptotic convergence.
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#setKeyOrdering(scala.math.Ordering)"><B>setKeyOrdering(Ordering&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>Set key ordering for RDD's shuffle.
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#setLabelCol(java.lang.String)"><B>setLabelCol(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#setLabelCol(java.lang.String)"><B>setLabelCol(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Predictor.html#setLabelCol(java.lang.String)"><B>setLabelCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#setLambda(double)"><B>setLambda(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Set the smoothing parameter.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setLambda(double)"><B>setLambda(double)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setLearningRate(double)"><B>setLearningRate(double)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#setLearningRate(double)"><B>setLearningRate(double)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setLocalProperty(java.lang.String, java.lang.String)"><B>setLocalProperty(String, String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Set a local property that affects jobs submitted from this thread, such as the
 Spark fair scheduler pool.
<DT><A HREF="./org/apache/spark/SparkContext.html#setLocalProperty(java.lang.String, java.lang.String)"><B>setLocalProperty(String, String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Set a local property that affects jobs submitted from this thread, such as the
 Spark fair scheduler pool.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#setLogLevel(java.lang.String)"><B>setLogLevel(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Control our logLevel.
<DT><A HREF="./org/apache/spark/SparkContext.html#setLogLevel(java.lang.String)"><B>setLogLevel(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Control our logLevel.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#setLoss(org.apache.spark.mllib.tree.loss.Loss)"><B>setLoss(Loss)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setLossType(java.lang.String)"><B>setLossType(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setLossType(java.lang.String)"><B>setLossType(String)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setMainClass(java.lang.String)"><B>setMainClass(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Sets the application class name for Java/Scala applications.
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#setMapSideCombine(boolean)"><B>setMapSideCombine(boolean)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>Set mapSideCombine flag for RDD's shuffle.
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setMaster(java.lang.String)"><B>setMaster(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set the Spark master for the application.
<DT><A HREF="./org/apache/spark/SparkConf.html#setMaster(java.lang.String)"><B>setMaster(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>The master URL to connect to, such as "local" to run locally with one thread, "local[4]" to
 run locally with 4 cores, or "spark://master:7077" to run on a Spark standalone cluster.
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setMaxBins(int)"><B>setMaxBins(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#setMaxCategories(int)"><B>setMaxCategories(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setMaxDepth(int)"><B>setMaxDepth(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>Set the maximum number of iterations.
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#setMaxIter(int)"><B>setMaxIter(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>Set the maximum number of iterations.
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#setMaxIterations(int)"><B>setMaxIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Set the maximum number of iterations to run.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setMaxIterations(int)"><B>setMaxIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set maximum number of iterations to run.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setMaxIterations(int)"><B>setMaxIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Maximum number of iterations for learning.
<DT><A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html#setMaxIterations(int)"><B>setMaxIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/PowerIterationClustering.html" title="class in org.apache.spark.mllib.clustering">PowerIterationClustering</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setMaxMemoryInMB(int)"><B>setMaxMemoryInMB(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setMaxNumIterations(int)"><B>setMaxNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD><B>Deprecated.</B>&nbsp;<I>use <A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setNumIterations(int)"><CODE>LBFGS.setNumIterations(int)</CODE></A> instead</I>
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#setMetricName(java.lang.String)"><B>setMetricName(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#setMetricName(java.lang.String)"><B>setMetricName(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setMinCount(int)"><B>setMinCount(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setMinCount(int)"><B>setMinCount(int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#setMinDocFreq(int)"><B>setMinDocFreq(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#setMiniBatchFraction(double)"><B>setMiniBatchFraction(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Set the fraction of each batch to use for updates.
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#setMiniBatchFraction(double)"><B>setMiniBatchFraction(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>Mini-batch fraction in (0, 1], which sets the fraction of document sampled and used in
 each iteration.
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setMiniBatchFraction(double)"><B>setMiniBatchFraction(double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>:: Experimental ::
 Set fraction of data to be used for each SGD iteration.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setMiniBatchFraction(double)"><B>setMiniBatchFraction(double)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>Set the fraction of each batch to use for updates.
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setMinInfoGain(double)"><B>setMinInfoGain(double)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setMinInstancesPerNode(int)"><B>setMinInstancesPerNode(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html#setMinSupport(double)"><B>setMinSupport(double)</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm">FPGrowth</A>
<DD>Sets the minimal support level (default: <code>0.3</code>).
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#setMinTokenLength(int)"><B>setMinTokenLength(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#setModelType(java.lang.String)"><B>setModelType(String)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Set the model type using a string (case-sensitive).
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Assign a name to this RDD
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Assign a name to this RDD
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Assign a name to this RDD
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Assign a name to this RDD
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setNonnegative(boolean)"><B>setNonnegative(boolean)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setNonnegative(boolean)"><B>setNonnegative(boolean)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setNumBlocks(int)"><B>setNumBlocks(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>Sets both numUserBlocks and numItemBlocks to the specific value.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html#setNumClasses(int)"><B>setNumClasses(int)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithLBFGS</A>
<DD>:: Experimental ::
 Set the number of possible outcomes for k classes classification problem in
 Multinomial Logistic Regression.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setNumClasses(int)"><B>setNumClasses(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setNumCorrections(int)"><B>setNumCorrections(int)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the number of corrections used in the LBFGS update.
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#setNumFeatures(int)"><B>setNumFeatures(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#setNumFolds(int)"><B>setNumFolds(int)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setNumItemBlocks(int)"><B>setNumItemBlocks(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Set the number of iterations of gradient descent to run per update.
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Set the number of iterations for SGD.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the maximal number of iterations for L-BFGS.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>Set the number of iterations of gradient descent to run per update.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#setNumIterations(int)"><B>setNumIterations(int)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setNumPartitions(int)"><B>setNumPartitions(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setNumPartitions(int)"><B>setNumPartitions(int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html#setNumPartitions(int)"><B>setNumPartitions(int)</B></A> - 
Method in class org.apache.spark.mllib.fpm.<A HREF="./org/apache/spark/mllib/fpm/FPGrowth.html" title="class in org.apache.spark.mllib.fpm">FPGrowth</A>
<DD>Sets the number of partitions used by parallel FP-growth (default: same as input data).
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setNumTrees(int)"><B>setNumTrees(int)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setNumTrees(int)"><B>setNumTrees(int)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setNumUserBlocks(int)"><B>setNumUserBlocks(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setOptimizer(org.apache.spark.mllib.clustering.LDAOptimizer)"><B>setOptimizer(LDAOptimizer)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>:: DeveloperApi ::
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setOptimizer(java.lang.String)"><B>setOptimizer(String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Set the LDAOptimizer used to perform the actual calculation by algorithm name.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#setOrNull(long, int, int)"><B>setOrNull(long, int, int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>Set this Decimal to the given unscaled Long, with a given precision and scale,
 and return it, or return null if it cannot be set due to overflow.
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#setOutputCol(java.lang.String)"><B>setOutputCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#setP(double)"><B>setP(double)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Model.html#setParent(org.apache.spark.ml.Estimator)"><B>setParent(Estimator&lt;M&gt;)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Model.html" title="class in org.apache.spark.ml">Model</A>
<DD>Sets the parent of this model (Java API).
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#setPattern(java.lang.String)"><B>setPattern(String)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#setPredictionCol(java.lang.String)"><B>setPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PredictionModel.html#setPredictionCol(java.lang.String)"><B>setPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Predictor.html#setPredictionCol(java.lang.String)"><B>setPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setPredictionCol(java.lang.String)"><B>setPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#setPredictionCol(java.lang.String)"><B>setPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setProductBlocks(int)"><B>setProductBlocks(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setPropertiesFile(java.lang.String)"><B>setPropertiesFile(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set a custom properties file with Spark configuration for the application.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setQuantileCalculationStrategy(scala.Enumeration.Value)"><B>setQuantileCalculationStrategy(Enumeration.Value)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#setRandomCenters(int, double, long)"><B>setRandomCenters(int, double, long)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Initialize random centers, requiring only the number of dimensions.
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setRank(int)"><B>setRank(int)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setRank(int)"><B>setRank(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setRatingCol(java.lang.String)"><B>setRatingCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/ClassificationModel.html#setRawPredictionCol(java.lang.String)"><B>setRawPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/Classifier.html#setRawPredictionCol(java.lang.String)"><B>setRawPredictionCol(String)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/Classifier.html" title="class in org.apache.spark.ml.classification">Classifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>Set the regularization parameter.
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>Set the regularization parameter.
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Set the regularization parameter.
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Set the regularization parameter.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setRegParam(double)"><B>setRegParam(double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the regularization parameter.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#setRest(long, int, VD, ED)"><B>setRest(long, int, VD, ED)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setRuns(int)"><B>setRuns(int)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>:: Experimental ::
 Set the number of runs of the algorithm to execute in parallel.
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#setSample(org.apache.spark.rdd.RDD)"><B>setSample(RDD&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>Sets the sample to use for density estimation.
<DT><A HREF="./org/apache/spark/mllib/stat/KernelDensity.html#setSample(org.apache.spark.api.java.JavaRDD)"><B>setSample(JavaRDD&lt;Double&gt;)</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/KernelDensity.html" title="class in org.apache.spark.mllib.stat">KernelDensity</A>
<DD>Sets the sample to use for density estimation (for Java users).
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#setScalingVec(org.apache.spark.mllib.linalg.Vector)"><B>setScalingVec(Vector)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#setScoreCol(java.lang.String)"><B>setScoreCol(String)</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixture.html" title="class in org.apache.spark.mllib.clustering">GaussianMixture</A>
<DD>Set the random seed
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Set the random seed for cluster initialization.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Random seed
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/ExponentialGenerator.html" title="class in org.apache.spark.mllib.random">ExponentialGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/UniformGenerator.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliCellSampler.html" title="class in org.apache.spark.util.random">BernoulliCellSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/BernoulliSampler.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/PoissonSampler.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in class org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/random/Pseudorandom.html#setSeed(long)"><B>setSeed(long)</B></A> - 
Method in interface org.apache.spark.util.random.<A HREF="./org/apache/spark/util/random/Pseudorandom.html" title="interface in org.apache.spark.util.random">Pseudorandom</A>
<DD>Set random seed.
<DT><A HREF="./org/apache/spark/rdd/CoGroupedRDD.html#setSerializer(org.apache.spark.serializer.Serializer)"><B>setSerializer(Serializer)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</A>
<DD>Set a serializer for this RDD's shuffle, or null to use the default (spark.serializer)
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#setSerializer(org.apache.spark.serializer.Serializer)"><B>setSerializer(Serializer)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>Set a serializer for this RDD's shuffle, or null to use the default (spark.serializer)
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setSparkHome(java.lang.String)"><B>setSparkHome(String)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Set a custom Spark installation location for the application.
<DT><A HREF="./org/apache/spark/SparkConf.html#setSparkHome(java.lang.String)"><B>setSparkHome(String)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Set the location where Spark is installed on worker nodes.
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#setSplits(double[])"><B>setSplits(double[])</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#setSrcOnly(long, int, VD)"><B>setSrcOnly(long, int, VD)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#setStages(org.apache.spark.ml.PipelineStage[])"><B>setStages(PipelineStage[])</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Set the step size for gradient descent.
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Set the initial step size of SGD for the first step.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setStepSize(double)"><B>setStepSize(double)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>Set the step size for gradient descent.
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#setSubsamplingRate(double)"><B>setSubsamplingRate(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#setSubsamplingRate(double)"><B>setSubsamplingRate(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#setSubsamplingRate(double)"><B>setSubsamplingRate(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#setSubsamplingRate(double)"><B>setSubsamplingRate(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setSubsamplingRate(double)"><B>setSubsamplingRate(double)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html#setTau0(double)"><B>setTau0(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">OnlineLDAOptimizer</A>
<DD>A (positive) learning parameter that downweights early iterations.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setThreshold(double)"><B>setThreshold(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#setThreshold(double)"><B>setThreshold(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#setThreshold(double)"><B>setThreshold(double)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#setThreshold(double)"><B>setThreshold(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>:: Experimental ::
 Sets the threshold that separates positive predictions from negative predictions
 in Binary Logistic Regression.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#setThreshold(double)"><B>setThreshold(double)</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>:: Experimental ::
 Sets the threshold that separates positive predictions from negative predictions.
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#setTol(double)"><B>setTol(double)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>Set the convergence tolerance of iterations.
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#setTol(double)"><B>setTol(double)</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>Set the convergence tolerance of iterations.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDA.html#setTopicConcentration(double)"><B>setTopicConcentration(double)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDA.html" title="class in org.apache.spark.mllib.clustering">LDA</A>
<DD>Concentration parameter (commonly named "beta" or "eta") for the prior placed on topics'
 distributions over terms.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#setTreeStrategy(org.apache.spark.mllib.tree.configuration.Strategy)"><B>setTreeStrategy(Strategy)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#setup()"><B>setup()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>setup the whole embedded servers, including Zookeeper and Kafka brokers
<DT><A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html#setUpdater(org.apache.spark.mllib.optimization.Updater)"><B>setUpdater(Updater)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</A>
<DD>Set the updater function to actually perform a gradient step in a given direction.
<DT><A HREF="./org/apache/spark/mllib/optimization/LBFGS.html#setUpdater(org.apache.spark.mllib.optimization.Updater)"><B>setUpdater(Updater)</B></A> - 
Method in class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</A>
<DD>Set the updater function to actually perform a gradient step in a given direction.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#setupGroups(int)"><B>setupGroups(int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>Initializes targetLen partition groups and assigns a preferredLocation
 This uses coupon collector to estimate how many preferredLocations it must rotate through
 until it has seen most of the preferred locations (2 * n log(n))
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#setUseNodeIdCache(boolean)"><B>setUseNodeIdCache(boolean)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#setUserBlocks(int)"><B>setUserBlocks(int)</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#setUserCol(java.lang.String)"><B>setUserCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#setUserCol(java.lang.String)"><B>setUserCol(String)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#setValidateData(boolean)"><B>setValidateData(boolean)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>
<DD>Set if the algorithm should validate data before training.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#setValidationTol(double)"><B>setValidationTol(double)</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#setValue(R)"><B>setValue(R)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>Set the accumulator's value; only allowed on master
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#setVectorSize(int)"><B>setVectorSize(int)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#setVectorSize(int)"><B>setVectorSize(int)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#setVerbose(boolean)"><B>setVerbose(boolean)</B></A> - 
Method in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Enables verbose reporting for SparkSubmit.
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#setWithMean(boolean)"><B>setWithMean(boolean)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#setWithMean(boolean)"><B>setWithMean(boolean)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#setWithStd(boolean)"><B>setWithStd(boolean)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#setWithStd(boolean)"><B>setWithStd(boolean)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/GammaGenerator.html#shape()"><B>shape()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/GammaGenerator.html" title="class in org.apache.spark.mllib.random">GammaGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/ShortestPaths.html" title="class in org.apache.spark.graphx.lib"><B>ShortestPaths</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Computes shortest paths to the given set of landmark vertices, returning a graph where each
 vertex attribute is a map containing the shortest-path distance to each reachable landmark.<DT><A HREF="./org/apache/spark/graphx/lib/ShortestPaths.html#ShortestPaths()"><B>ShortestPaths()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/ShortestPaths.html" title="class in org.apache.spark.graphx.lib">ShortestPaths</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#ShortType"><B>ShortType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the ShortType object.
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types"><B>ShortType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>Short</code> values.<DT><A HREF="./org/apache/spark/ml/tree/Split.html#shouldGoLeft(org.apache.spark.mllib.linalg.Vector)"><B>shouldGoLeft(Vector)</B></A> - 
Method in interface org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Split.html" title="interface in org.apache.spark.ml.tree">Split</A>
<DD>Return true (split to left) or false (split to right)
<DT><A HREF="./org/apache/spark/ml/param/Params.html#shouldOwn(org.apache.spark.ml.param.Param)"><B>shouldOwn(Param&lt;?&gt;)</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Validates that the input param belongs to this instance.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#show(int)"><B>show(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Displays the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> in a tabular form.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#show()"><B>show()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Displays the top 20 rows of <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> in a tabular form.
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, scala.Function2, scala.collection.Seq)"><B>showBytesDistribution(String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, scala.Option)"><B>showBytesDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, org.apache.spark.util.Distribution)"><B>showBytesDistribution(String, org.apache.spark.util.Distribution)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, org.apache.spark.util.Distribution, scala.Function1)"><B>showDistribution(String, org.apache.spark.util.Distribution, Function1&lt;Object, String&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, scala.Option, scala.Function1)"><B>showDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;, Function1&lt;Object, String&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, scala.Option, java.lang.String)"><B>showDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;, String)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, java.lang.String, scala.Function2, scala.collection.Seq)"><B>showDistribution(String, String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Option)"><B>showMillisDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Function2, scala.collection.Seq)"><B>showMillisDistribution(String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Function1)"><B>showMillisDistribution(String, Function1&lt;BatchInfo, Option&lt;Object&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#SHUFFLE()"><B>SHUFFLE()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#SHUFFLE_DATA()"><B>SHUFFLE_DATA()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#SHUFFLE_INDEX()"><B>SHUFFLE_INDEX()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage"><B>ShuffleBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html#ShuffleBlockId(int, int, int)"><B>ShuffleBlockId(int, int, int)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage"><B>ShuffleDataBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html#ShuffleDataBlockId(int, int, int)"><B>ShuffleDataBlockId(int, int, int)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage">ShuffleDataBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark"><B>ShuffleDependency</B></A>&lt;<A HREF="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">K</A>,<A HREF="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">V</A>,<A HREF="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">C</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Represents a dependency on the output of a shuffle stage.<DT><A HREF="./org/apache/spark/ShuffleDependency.html#ShuffleDependency(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.Option, scala.Option, scala.Option, boolean)"><B>ShuffleDependency(RDD&lt;? extends Product2&lt;K, V&gt;&gt;, Partitioner, Option&lt;Serializer&gt;, Option&lt;Ordering&lt;K&gt;&gt;, Option&lt;Aggregator&lt;K, V, C&gt;&gt;, boolean)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd"><B>ShuffledRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">K</A>,<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">V</A>,<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">C</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>:: DeveloperApi ::
 The resulting RDD from a shuffle (e.g.<DT><A HREF="./org/apache/spark/rdd/ShuffledRDD.html#ShuffledRDD(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)"><B>ShuffledRDD(RDD&lt;? extends Product2&lt;K, V&gt;&gt;, Partitioner)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#shuffleHandle()"><B>shuffleHandle()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanShuffle.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanShuffle.html" title="class in org.apache.spark">CleanShuffle</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ShuffleDependency.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleBlockId.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleDataBlockId.html" title="class in org.apache.spark.storage">ShuffleDataBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html#shuffleId()"><B>shuffleId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage"><B>ShuffleIndexBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html#ShuffleIndexBlockId(int, int, int)"><B>ShuffleIndexBlockId(int, int, int)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#shuffleManager()"><B>shuffleManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#shuffleMemoryManager()"><B>shuffleMemoryManager()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#shuffleRead()"><B>shuffleRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#shuffleReadBytes()"><B>shuffleReadBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1"><B>ShuffleReadMetricDistributions</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1"><B>ShuffleReadMetrics</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#shuffleReadMetrics()"><B>shuffleReadMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#shuffleReadMetrics()"><B>shuffleReadMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#shuffleReadRecords()"><B>shuffleReadRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#shuffleWrite()"><B>shuffleWrite()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#shuffleWriteBytes()"><B>shuffleWriteBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html" title="class in org.apache.spark.status.api.v1"><B>ShuffleWriteMetricDistributions</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html" title="class in org.apache.spark.status.api.v1"><B>ShuffleWriteMetrics</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html#shuffleWriteMetrics()"><B>shuffleWriteMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1">TaskMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html#shuffleWriteMetrics()"><B>shuffleWriteMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1">TaskMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#shuffleWriteRecords()"><B>shuffleWriteRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html#sigma()"><B>sigma()</B></A> - 
Method in class org.apache.spark.mllib.stat.distribution.<A HREF="./org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html" title="class in org.apache.spark.mllib.stat.distribution">MultivariateGaussian</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#sigmas()"><B>sigmas()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/SignalLoggerHandler.html" title="class in org.apache.spark.util"><B>SignalLoggerHandler</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/SignalLoggerHandler.html#SignalLoggerHandler(java.lang.String, org.slf4j.Logger)"><B>SignalLoggerHandler(String, Logger)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/SignalLoggerHandler.html" title="class in org.apache.spark.util">SignalLoggerHandler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#signum(org.apache.spark.sql.Column)"><B>signum(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the signum of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#signum(java.lang.String)"><B>signum(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the signum of the given column.
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark"><B>SimpleFutureAction</B></A>&lt;<A HREF="./org/apache/spark/SimpleFutureAction.html" title="type parameter in SimpleFutureAction">T</A>&gt; - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>A <A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><CODE>FutureAction</CODE></A> holding the result of an action that triggers a single job.<DT><A HREF="./org/apache/spark/sql/types/ArrayType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ArrayType.html" title="class in org.apache.spark.sql.types">ArrayType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>Readable string representation for the type.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#simpleString()"><B>simpleString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization"><B>SimpleUpdater</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 A simple updater for gradient descent *without* any regularization.<DT><A HREF="./org/apache/spark/mllib/optimization/SimpleUpdater.html#SimpleUpdater()"><B>SimpleUpdater()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization">SimpleUpdater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#sin(org.apache.spark.sql.Column)"><B>sin(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the sine of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#sin(java.lang.String)"><B>sin(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the sine of the given column.
<DT><A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg"><B>SingularValueDecomposition</B></A>&lt;<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="type parameter in SingularValueDecomposition">UType</A>,<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="type parameter in SingularValueDecomposition">VType</A>&gt; - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>:: Experimental ::
 Represents singular value decomposition (SVD) factors.<DT><A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#SingularValueDecomposition(UType, org.apache.spark.mllib.linalg.Vector, VType)"><B>SingularValueDecomposition(UType, Vector, VType)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#sinh(org.apache.spark.sql.Column)"><B>sinh(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic sine of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#sinh(java.lang.String)"><B>sinh(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic sine of the given column.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Size of the attribute group.
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Number of param pairs in this map.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#size()"><B>size()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Size of the vector.
<DT><A HREF="./org/apache/spark/rdd/PartitionGroup.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionGroup.html" title="class in org.apache.spark.rdd">PartitionGroup</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#size()"><B>size()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Number of elements in the Row.
<DT><A HREF="./org/apache/spark/storage/MemoryEntry.html#size()"><B>size()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/MemoryEntry.html" title="class in org.apache.spark.storage">MemoryEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/SizeEstimator.html" title="class in org.apache.spark.util"><B>SizeEstimator</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>:: DeveloperApi ::
 Estimates the sizes of Java objects (number of bytes of memory they occupy), for use in
 memory-aware caches.<DT><A HREF="./org/apache/spark/util/SizeEstimator.html#SizeEstimator()"><B>SizeEstimator()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/SizeEstimator.html" title="class in org.apache.spark.util">SizeEstimator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()"><B>sizeInBytes()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A>
<DD>Returns an estimated size of this relation in bytes.
<DT><A HREF="./org/apache/spark/RangePartitioner.html#sketch(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)"><B>sketch(RDD&lt;K&gt;, int, ClassTag&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</A>
<DD>Sketches the input RDD via reservoir sampling on each partition.
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#skippedStages()"><B>skippedStages()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#slack()"><B>slack()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#slice(int, int)"><B>slice(int, int)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>Return a substring of this,
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#slice(org.apache.spark.streaming.Time, org.apache.spark.streaming.Time)"><B>slice(Time, Time)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return all the RDDs between 'fromDuration' to 'toDuration' (both included)
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#slice(org.apache.spark.streaming.Interval)"><B>slice(org.apache.spark.streaming.Interval)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return all the RDDs defined by the Interval object (both end times included)
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#slice(org.apache.spark.streaming.Time, org.apache.spark.streaming.Time)"><B>slice(Time, Time)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return all the RDDs between 'fromTime' to 'toTime' (both included)
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#slideDuration()"><B>slideDuration()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Time interval after which the DStream generates a RDD
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#slideDuration()"><B>slideDuration()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html#sliding(int)"><B>sliding(int)</B></A> - 
Method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd">RDDFunctions</A>
<DD>Returns a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding
 window over them.
<DT><A HREF="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io"><B>SnappyCompressionCodec</B></A> - Class in <A HREF="./org/apache/spark/io/package-summary.html">org.apache.spark.io</A><DD>:: DeveloperApi ::
 Snappy implementation of <A HREF="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><CODE>CompressionCodec</CODE></A>.<DT><A HREF="./org/apache/spark/io/SnappyCompressionCodec.html#SnappyCompressionCodec(org.apache.spark.SparkConf)"><B>SnappyCompressionCodec(SparkConf)</B></A> - 
Constructor for class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io"><B>SnappyOutputStreamWrapper</B></A> - Class in <A HREF="./org/apache/spark/io/package-summary.html">org.apache.spark.io</A><DD>Wrapper over <CODE>SnappyOutputStream</CODE> which guards against write-after-close and double-close
 issues.<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#SnappyOutputStreamWrapper(org.xerial.snappy.SnappyOutputStream)"><B>SnappyOutputStreamWrapper(SnappyOutputStream)</B></A> - 
Constructor for class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketStream(java.lang.String, int, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)"><B>socketStream(String, int, Function&lt;InputStream, Iterable&lt;T&gt;&gt;, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from network source hostname:port.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#socketStream(java.lang.String, int, scala.Function1, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)"><B>socketStream(String, int, Function1&lt;InputStream, Iterator&lt;T&gt;&gt;, StorageLevel, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream from TCP source hostname:port.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>socketTextStream(String, int, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from network source hostname:port.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int)"><B>socketTextStream(String, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream from network source hostname:port.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)"><B>socketTextStream(String, int, StorageLevel)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream from TCP source hostname:port.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#Sort()"><B>Sort()</B></A> - 
Static method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sort(java.lang.String, java.lang.String...)"><B>sort(String, String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the specified column, all in ascending order.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sort(org.apache.spark.sql.Column...)"><B>sort(Column...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sort(java.lang.String, scala.collection.Seq)"><B>sort(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the specified column, all in ascending order.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sort(scala.collection.Seq)"><B>sort(Seq&lt;Column&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> sorted by the given expressions.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#sortBy(org.apache.spark.api.java.function.Function, boolean, int)"><B>sortBy(Function&lt;T, S&gt;, boolean, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return this RDD sorted by the given key function.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#sortBy(scala.Function1, boolean, int, scala.math.Ordering, scala.reflect.ClassTag)"><B>sortBy(Function1&lt;T, K&gt;, boolean, int, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return this RDD sorted by the given key function.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey()"><B>sortByKey()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements in
 ascending order.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(boolean)"><B>sortByKey(boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(boolean, int)"><B>sortByKey(boolean, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator)"><B>sortByKey(Comparator&lt;K&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator, boolean)"><B>sortByKey(Comparator&lt;K&gt;, boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator, boolean, int)"><B>sortByKey(Comparator&lt;K&gt;, boolean, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html#sortByKey(boolean, int)"><B>sortByKey(boolean, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</A>
<DD>Sort the RDD by key, so that each partition contains a sorted range of the elements.
<DT><A HREF="./org/apache/spark/SparkContext.html#SPARK_JOB_DESCRIPTION()"><B>SPARK_JOB_DESCRIPTION()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#SPARK_JOB_GROUP_ID()"><B>SPARK_JOB_GROUP_ID()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#SPARK_JOB_INTERRUPT_ON_CANCEL()"><B>SPARK_JOB_INTERRUPT_ON_CANCEL()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#SPARK_MASTER"><B>SPARK_MASTER</B></A> - 
Static variable in class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>The Spark master.
<DT><A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark"><B>SparkConf</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Configuration for a Spark application.<DT><A HREF="./org/apache/spark/SparkConf.html#SparkConf(boolean)"><B>SparkConf(boolean)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkConf.html#SparkConf()"><B>SparkConf()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Create a SparkConf that loads defaults from system properties and the classpath
<DT><A HREF="./org/apache/spark/rdd/RDD.html#sparkContext()"><B>sparkContext()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>The SparkContext that created this RDD.
<DT><A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><B>SparkContext</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Main entry point for Spark functionality.<DT><A HREF="./org/apache/spark/SparkContext.html#SparkContext(org.apache.spark.SparkConf)"><B>SparkContext(SparkConf)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#SparkContext()"><B>SparkContext()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Create a SparkContext that loads settings from system properties (for instance, when
 launching with ./bin/spark-submit).
<DT><A HREF="./org/apache/spark/SparkContext.html#SparkContext(org.apache.spark.SparkConf, scala.collection.Map)"><B>SparkContext(SparkConf, Map&lt;String, Set&lt;SplitInfo&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: DeveloperApi ::
 Alternative constructor for setting preferred locations where Spark will create executors.
<DT><A HREF="./org/apache/spark/SparkContext.html#SparkContext(java.lang.String, java.lang.String, org.apache.spark.SparkConf)"><B>SparkContext(String, String, SparkConf)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Alternative constructor that allows setting common Spark properties directly
<DT><A HREF="./org/apache/spark/SparkContext.html#SparkContext(java.lang.String, java.lang.String, java.lang.String, scala.collection.Seq, scala.collection.Map, scala.collection.Map)"><B>SparkContext(String, String, String, Seq&lt;String&gt;, Map&lt;String, String&gt;, Map&lt;String, Set&lt;SplitInfo&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Alternative constructor that allows setting common Spark properties directly
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#sparkContext()"><B>sparkContext()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#sparkContext()"><B>sparkContext()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>The underlying SparkContext
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#sparkContext()"><B>sparkContext()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Return the associated Spark context
<DT><A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark"><B>SparkContext.DoubleAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#SparkContext.DoubleAccumulatorParam$()"><B>SparkContext.DoubleAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark"><B>SparkContext.FloatAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#SparkContext.FloatAccumulatorParam$()"><B>SparkContext.FloatAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark"><B>SparkContext.IntAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#SparkContext.IntAccumulatorParam$()"><B>SparkContext.IntAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark"><B>SparkContext.LongAccumulatorParam$</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#SparkContext.LongAccumulatorParam$()"><B>SparkContext.LongAccumulatorParam$()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark"><B>SparkEnv</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Holds all the runtime environment objects for a running Spark instance (either master or worker),
 including the serializer, Akka actor system, block manager, map output tracker, etc.<DT><A HREF="./org/apache/spark/SparkEnv.html#SparkEnv(java.lang.String, org.apache.spark.rpc.RpcEnv, org.apache.spark.serializer.Serializer, org.apache.spark.serializer.Serializer, org.apache.spark.CacheManager, org.apache.spark.MapOutputTracker, org.apache.spark.shuffle.ShuffleManager, org.apache.spark.broadcast.BroadcastManager, org.apache.spark.network.BlockTransferService, org.apache.spark.storage.BlockManager, org.apache.spark.SecurityManager, org.apache.spark.HttpFileServer, java.lang.String, org.apache.spark.metrics.MetricsSystem, org.apache.spark.shuffle.ShuffleMemoryManager, org.apache.spark.unsafe.memory.ExecutorMemoryManager, org.apache.spark.scheduler.OutputCommitCoordinator, org.apache.spark.SparkConf)"><B>SparkEnv(String, org.apache.spark.rpc.RpcEnv, Serializer, Serializer, CacheManager, MapOutputTracker, ShuffleManager, org.apache.spark.broadcast.BroadcastManager, BlockTransferService, org.apache.spark.storage.BlockManager, SecurityManager, HttpFileServer, String, org.apache.spark.metrics.MetricsSystem, ShuffleMemoryManager, ExecutorMemoryManager, org.apache.spark.scheduler.OutputCommitCoordinator, SparkConf)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkException.html" title="class in org.apache.spark"><B>SparkException</B></A> - Exception in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkException.html#SparkException(java.lang.String, java.lang.Throwable)"><B>SparkException(String, Throwable)</B></A> - 
Constructor for exception org.apache.spark.<A HREF="./org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkException.html#SparkException(java.lang.String)"><B>SparkException(String)</B></A> - 
Constructor for exception org.apache.spark.<A HREF="./org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark"><B>SparkFiles</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Resolves paths to files added through <code>SparkContext.addFile()</code>.<DT><A HREF="./org/apache/spark/SparkFiles.html#SparkFiles()"><B>SparkFiles()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkEnv.html#sparkFilesDir()"><B>sparkFilesDir()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark"><B>SparkFirehoseListener</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Class that allows users to receive all SparkListener events.<DT><A HREF="./org/apache/spark/SparkFirehoseListener.html#SparkFirehoseListener()"><B>SparkFirehoseListener()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkFirehoseListener.html" title="class in org.apache.spark">SparkFirehoseListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume"><B>SparkFlumeEvent</B></A> - Class in <A HREF="./org/apache/spark/streaming/flume/package-summary.html">org.apache.spark.streaming.flume</A><DD>A wrapper class for AvroFlumeEvent's with a custom serialization format.<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#SparkFlumeEvent()"><B>SparkFlumeEvent()</B></A> - 
Constructor for class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html#sparkJobId()"><B>sparkJobId()</B></A> - 
Method in class org.apache.spark.streaming.ui.<A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html" title="class in org.apache.spark.streaming.ui">SparkJobIdWithUIData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html" title="class in org.apache.spark.streaming.ui"><B>SparkJobIdWithUIData</B></A> - Class in <A HREF="./org/apache/spark/streaming/ui/package-summary.html">org.apache.spark.streaming.ui</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html#SparkJobIdWithUIData(int, scala.Option)"><B>SparkJobIdWithUIData(int, Option&lt;org.apache.spark.ui.jobs.UIData.JobUIData&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.ui.<A HREF="./org/apache/spark/streaming/ui/SparkJobIdWithUIData.html" title="class in org.apache.spark.streaming.ui">SparkJobIdWithUIData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfo.html" title="interface in org.apache.spark"><B>SparkJobInfo</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Exposes information about Spark Jobs.<DT><A HREF="./org/apache/spark/SparkJobInfoImpl.html" title="class in org.apache.spark"><B>SparkJobInfoImpl</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkJobInfoImpl.html#SparkJobInfoImpl(int, int[], org.apache.spark.JobExecutionStatus)"><B>SparkJobInfoImpl(int, int[], JobExecutionStatus)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfoImpl.html" title="class in org.apache.spark">SparkJobInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher"><B>SparkLauncher</B></A> - Class in <A HREF="./org/apache/spark/launcher/package-summary.html">org.apache.spark.launcher</A><DD>Launcher for Spark applications.<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#SparkLauncher()"><B>SparkLauncher()</B></A> - 
Constructor for class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/launcher/SparkLauncher.html#SparkLauncher(java.util.Map)"><B>SparkLauncher(Map&lt;String, String&gt;)</B></A> - 
Constructor for class org.apache.spark.launcher.<A HREF="./org/apache/spark/launcher/SparkLauncher.html" title="class in org.apache.spark.launcher">SparkLauncher</A>
<DD>Creates a launcher that will set the given environment variables in the child.
<DT><A HREF="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler"><B>SparkListener</B></A> - Interface in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Interface for listening to events from the Spark scheduler.<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler"><B>SparkListenerApplicationEnd</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html#SparkListenerApplicationEnd(long)"><B>SparkListenerApplicationEnd(long)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler"><B>SparkListenerApplicationStart</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#SparkListenerApplicationStart(java.lang.String, scala.Option, long, java.lang.String, scala.Option)"><B>SparkListenerApplicationStart(String, Option&lt;String&gt;, long, String, Option&lt;String&gt;)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler"><B>SparkListenerBlockManagerAdded</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#SparkListenerBlockManagerAdded(long, org.apache.spark.storage.BlockManagerId, long)"><B>SparkListenerBlockManagerAdded(long, BlockManagerId, long)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler"><B>SparkListenerBlockManagerRemoved</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html#SparkListenerBlockManagerRemoved(long, org.apache.spark.storage.BlockManagerId)"><B>SparkListenerBlockManagerRemoved(long, BlockManagerId)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler"><B>SparkListenerEnvironmentUpdate</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html#SparkListenerEnvironmentUpdate(scala.collection.Map)"><B>SparkListenerEnvironmentUpdate(Map&lt;String, Seq&lt;Tuple2&lt;String, String&gt;&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerEnvironmentUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerEvent.html" title="interface in org.apache.spark.scheduler"><B>SparkListenerEvent</B></A> - Interface in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html" title="class in org.apache.spark.scheduler"><B>SparkListenerExecutorAdded</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html#SparkListenerExecutorAdded(long, java.lang.String, org.apache.spark.scheduler.cluster.ExecutorInfo)"><B>SparkListenerExecutorAdded(long, String, ExecutorInfo)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler"><B>SparkListenerExecutorMetricsUpdate</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>Periodic updates from executors.<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#SparkListenerExecutorMetricsUpdate(java.lang.String, scala.collection.Seq)"><B>SparkListenerExecutorMetricsUpdate(String, Seq&lt;Tuple4&lt;Object, Object, Object, TaskMetrics&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html" title="class in org.apache.spark.scheduler"><B>SparkListenerExecutorRemoved</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html#SparkListenerExecutorRemoved(long, java.lang.String, java.lang.String)"><B>SparkListenerExecutorRemoved(long, String, String)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler"><B>SparkListenerJobEnd</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html#SparkListenerJobEnd(int, long, org.apache.spark.scheduler.JobResult)"><B>SparkListenerJobEnd(int, long, JobResult)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler"><B>SparkListenerJobStart</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#SparkListenerJobStart(int, long, scala.collection.Seq, java.util.Properties)"><B>SparkListenerJobStart(int, long, Seq&lt;StageInfo&gt;, Properties)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler"><B>SparkListenerStageCompleted</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageCompleted.html#SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo)"><B>SparkListenerStageCompleted(StageInfo)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler">SparkListenerStageCompleted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler"><B>SparkListenerStageSubmitted</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo, java.util.Properties)"><B>SparkListenerStageSubmitted(StageInfo, Properties)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler"><B>SparkListenerTaskEnd</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#SparkListenerTaskEnd(int, int, java.lang.String, org.apache.spark.TaskEndReason, org.apache.spark.scheduler.TaskInfo, org.apache.spark.executor.TaskMetrics)"><B>SparkListenerTaskEnd(int, int, String, TaskEndReason, TaskInfo, TaskMetrics)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler"><B>SparkListenerTaskGettingResult</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html#SparkListenerTaskGettingResult(org.apache.spark.scheduler.TaskInfo)"><B>SparkListenerTaskGettingResult(TaskInfo)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler">SparkListenerTaskGettingResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler"><B>SparkListenerTaskStart</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html#SparkListenerTaskStart(int, int, org.apache.spark.scheduler.TaskInfo)"><B>SparkListenerTaskStart(int, int, TaskInfo)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler"><B>SparkListenerUnpersistRDD</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html#SparkListenerUnpersistRDD(int)"><B>SparkListenerUnpersistRDD(int)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler">SparkListenerUnpersistRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#sparkPartitionId()"><B>sparkPartitionId()</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Partition ID of the Spark task.
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#sparkProperties()"><B>sparkProperties()</B></A> - 
Method in class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/SparkShutdownHook.html" title="class in org.apache.spark.util"><B>SparkShutdownHook</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/SparkShutdownHook.html#SparkShutdownHook(int, scala.Function0)"><B>SparkShutdownHook(int, Function0&lt;BoxedUnit&gt;)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/SparkShutdownHook.html" title="class in org.apache.spark.util">SparkShutdownHook</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark"><B>SparkStageInfo</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Exposes information about Spark Stages.<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark"><B>SparkStageInfoImpl</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#SparkStageInfoImpl(int, int, long, java.lang.String, int, int, int, int)"><B>SparkStageInfoImpl(int, int, long, String, int, int, int, int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStatusTracker.html" title="class in org.apache.spark"><B>SparkStatusTracker</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Low-level status reporting APIs for monitoring job and stage progress.<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#sparkUser()"><B>sparkUser()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#sparkUser()"><B>sparkUser()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#sparkUser()"><B>sparkUser()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html#sparkUser()"><B>sparkUser()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationAttemptInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#sparse(int, int, int[], int[], double[])"><B>sparse(int, int, int[], int[], double[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Creates a column-major sparse matrix in Compressed Sparse Column (CSC) format.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, int[], double[])"><B>sparse(int, int[], double[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a sparse vector providing its index array and value array.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, scala.collection.Seq)"><B>sparse(int, Seq&lt;Tuple2&lt;Object, Object&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a sparse vector using unordered (index, value) pairs.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, java.lang.Iterable)"><B>sparse(int, Iterable&lt;Tuple2&lt;Integer, Double&gt;&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a sparse vector using unordered (index, value) pairs in a Java friendly way.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg"><B>SparseMatrix</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>Column-major sparse matrix.<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#SparseMatrix(int, int, int[], int[], double[], boolean)"><B>SparseMatrix(int, int, int[], int[], double[], boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#SparseMatrix(int, int, int[], int[], double[])"><B>SparseMatrix(int, int, int[], int[], double[])</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Column-major sparse matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg"><B>SparseVector</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>A sparse vector represented by an index array and an value array.<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#SparseVector(int, int[], double[])"><B>SparseVector(int, int[], double[])</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#sparsity()"><B>sparsity()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#spdiag(org.apache.spark.mllib.linalg.Vector)"><B>spdiag(Vector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate a diagonal matrix in <code>SparseMatrix</code> format from the supplied values.
<DT><A HREF="./org/apache/spark/api/r/SpecialLengths.html" title="class in org.apache.spark.api.r"><B>SpecialLengths</B></A> - Class in <A HREF="./org/apache/spark/api/r/package-summary.html">org.apache.spark.api.r</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/api/r/SpecialLengths.html#SpecialLengths()"><B>SpecialLengths()</B></A> - 
Constructor for class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/SpecialLengths.html" title="class in org.apache.spark.api.r">SpecialLengths</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#speculative()"><B>speculative()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#speculative()"><B>speculative()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#speye(int)"><B>speye(int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a sparse Identity Matrix in <code>Matrix</code> format.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#speye(int)"><B>speye(int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate an Identity Matrix in <code>SparseMatrix</code> format.
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#split()"><B>split()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/Split.html" title="interface in org.apache.spark.ml.tree"><B>Split</B></A> - Interface in <A HREF="./org/apache/spark/ml/tree/package-summary.html">org.apache.spark.ml.tree</A><DD>:: DeveloperApi ::
 Interface for a "Split," which specifies a test made at a decision tree node
 to choose the left or right path.<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#split()"><B>split()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model"><B>Split</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</A><DD>:: DeveloperApi ::
 Split applied to a feature
 param:  feature feature index
 param:  threshold Threshold for continuous feature.<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#Split(int, double, scala.Enumeration.Value, scala.collection.immutable.List)"><B>Split(int, double, Enumeration.Value, List&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/HadoopRDD.html#SPLIT_INFO_REFLECTIONS()"><B>SPLIT_INFO_REFLECTIONS()</B></A> - 
Static method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDBlockId.html#splitIndex()"><B>splitIndex()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler"><B>SplitInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#SplitInfo(java.lang.Class, java.lang.String, java.lang.String, long, java.lang.Object)"><B>SplitInfo(Class&lt;?&gt;, String, String, long, Object)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#splits()"><B>splits()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#splits()"><B>splits()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>Parameter for mapping continuous features into buckets.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#sprand(int, int, double, java.util.Random)"><B>sprand(int, int, double, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>SparseMatrix</code> consisting of <code>i.i.d.</code> gaussian random numbers.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#sprand(int, int, double, java.util.Random)"><B>sprand(int, int, double, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate a <code>SparseMatrix</code> consisting of <code>i.i.d</code>.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#sprandn(int, int, double, java.util.Random)"><B>sprandn(int, int, double, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>SparseMatrix</code> consisting of <code>i.i.d.</code> gaussian random numbers.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#sprandn(int, int, double, java.util.Random)"><B>sprandn(int, int, double, Random)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate a <code>SparseMatrix</code> consisting of <code>i.i.d</code>.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#sqdist(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>sqdist(Vector, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Returns the squared distance between two Vectors.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#sql(java.lang.String)"><B>sql(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#sqlContext()"><B>sqlContext()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/BaseRelation.html#sqlContext()"><B>sqlContext()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><B>SQLContext</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>The entry point for working with structured data (rows and columns) in Spark.<DT><A HREF="./org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)"><B>SQLContext(SparkContext)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.api.java.JavaSparkContext)"><B>SQLContext(JavaSparkContext)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><B>SQLContext.implicits$</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>:: Experimental ::
 (Scala-specific) Implicit methods available in Scala for converting
 common Scala objects into <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>s.<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#SQLContext.implicits$()"><B>SQLContext.implicits$()</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.StringToColumn.html" title="class in org.apache.spark.sql"><B>SQLContext.implicits$.StringToColumn</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>Converts $"col name" into an <A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><CODE>Column</CODE></A>.<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.StringToColumn.html#SQLContext.implicits$.StringToColumn(scala.StringContext)"><B>SQLContext.implicits$.StringToColumn(StringContext)</B></A> - 
Constructor for class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.StringToColumn.html" title="class in org.apache.spark.sql">SQLContext.implicits$.StringToColumn</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#sqlType()"><B>sqlType()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>Underlying storage type for this UDT
<DT><A HREF="./org/apache/spark/sql/types/SQLUserDefinedType.html" title="annotation in org.apache.spark.sql.types"><B>SQLUserDefinedType</B></A> - Annotation Type in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>::DeveloperApi::
 A user-defined type which can be automatically recognized by a SQLContext and registered.<DT><A HREF="./org/apache/spark/sql/functions.html#sqrt(org.apache.spark.sql.Column)"><B>sqrt(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the square root of the specified float value.
<DT><A HREF="./org/apache/spark/util/Vector.html#squaredDist(org.apache.spark.util.Vector)"><B>squaredDist(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/loss/SquaredError.html" title="class in org.apache.spark.mllib.tree.loss"><B>SquaredError</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/loss/package-summary.html">org.apache.spark.mllib.tree.loss</A><DD>:: DeveloperApi ::
 Class for squared error loss calculation.<DT><A HREF="./org/apache/spark/mllib/tree/loss/SquaredError.html#SquaredError()"><B>SquaredError()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.loss.<A HREF="./org/apache/spark/mllib/tree/loss/SquaredError.html" title="class in org.apache.spark.mllib.tree.loss">SquaredError</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization"><B>SquaredL2Updater</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Updater for L2 regularized problems.<DT><A HREF="./org/apache/spark/mllib/optimization/SquaredL2Updater.html#SquaredL2Updater()"><B>SquaredL2Updater()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization">SquaredL2Updater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#Src"><B>Src</B></A> - 
Static variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Expose the source and edge fields but not the destination field.
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#srcAttr()"><B>srcAttr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>The vertex attribute of the edge's source vertex.
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#srcAttr()"><B>srcAttr()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>The source vertex attribute
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#srcAttr()"><B>srcAttr()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Edge.html#srcId()"><B>srcId()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Edge.html" title="class in org.apache.spark.graphx">Edge</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#srcId()"><B>srcId()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>The vertex id of the edge's source vertex.
<DT><A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html#srcId()"><B>srcId()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/AggregatingEdgeContext.html" title="class in org.apache.spark.graphx.impl">AggregatingEdgeContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#srdd()"><B>srdd()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#ssc()"><B>ssc()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#ssc()"><B>ssc()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#stackTrace()"><B>stackTrace()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html#stage()"><B>stage()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html" title="class in org.apache.spark.scheduler">AskPermissionToCommitOutput</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#stageAttemptId()"><B>stageAttemptId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html#stageAttemptId()"><B>stageAttemptId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1"><B>StageData</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#stageFailed(java.lang.String)"><B>stageFailed(String)</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#stageId()"><B>stageId()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#stageId()"><B>stageId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>The ID of the stage that this task belong to.
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#stageIds()"><B>stageIds()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfo.html#stageIds()"><B>stageIds()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfo.html" title="interface in org.apache.spark">SparkJobInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfoImpl.html#stageIds()"><B>stageIds()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfoImpl.html" title="class in org.apache.spark">SparkJobInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#stageIds()"><B>stageIds()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#stageIdToActiveJobIds()"><B>stageIdToActiveJobIds()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#stageIdToData()"><B>stageIdToData()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#stageIdToInfo()"><B>stageIdToInfo()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageCompleted.html#stageInfo()"><B>stageInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler">SparkListenerStageCompleted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#stageInfo()"><B>stageInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler"><B>StageInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Stores information about a stage to pass from the scheduler to SparkListeners.<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#StageInfo(int, int, java.lang.String, int, scala.collection.Seq, scala.collection.Seq, java.lang.String)"><B>StageInfo(int, int, String, int, Seq&lt;RDDInfo&gt;, Seq&lt;Object&gt;, String)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#stageInfos()"><B>stageInfos()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#stages()"><B>stages()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>param for pipeline stages
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#stages()"><B>stages()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageStatus.html" title="enum in org.apache.spark.status.api.v1"><B>StageStatus</B></A> - Enum in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random"><B>StandardNormalGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html#StandardNormalGenerator()"><B>StandardNormalGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature"><B>StandardScaler</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Standardizes features by removing the mean and scaling to unit variance using column summary
 statistics on the samples in the training set.<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#StandardScaler(java.lang.String)"><B>StandardScaler(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#StandardScaler()"><B>StandardScaler()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature"><B>StandardScaler</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Standardizes features by removing the mean and scaling to unit std using column summary
 statistics on the samples in the training set.<DT><A HREF="./org/apache/spark/mllib/feature/StandardScaler.html#StandardScaler(boolean, boolean)"><B>StandardScaler(boolean, boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScaler.html#StandardScaler()"><B>StandardScaler()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature"><B>StandardScalerModel</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature"><B>StandardScalerModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Represents a StandardScaler model that can transform vectors.<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#StandardScalerModel(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, boolean, boolean)"><B>StandardScalerModel(Vector, Vector, boolean, boolean)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#StandardScalerModel(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)"><B>StandardScalerModel(Vector, Vector)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#StandardScalerModel(org.apache.spark.mllib.linalg.Vector)"><B>StandardScalerModel(Vector)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/util/GraphGenerators.html#starGraph(org.apache.spark.SparkContext, int)"><B>starGraph(SparkContext, int)</B></A> - 
Static method in class org.apache.spark.graphx.util.<A HREF="./org/apache/spark/graphx/util/GraphGenerators.html" title="class in org.apache.spark.graphx.util">GraphGenerators</A>
<DD>Create a star graph with vertex 0 being the center.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#start()"><B>start()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Start the execution of the streams.
<DT><A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#start()"><B>start()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#start()"><B>start()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>Method called to start receiving data.
<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#start()"><B>start()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#start()"><B>start()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Start the execution of the streams.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#startIndexInLevel(int)"><B>startIndexInLevel(int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>Return the index of the first node in the given level.
<DT><A HREF="./org/apache/spark/sql/AnalysisException.html#startPosition()"><B>startPosition()</B></A> - 
Method in exception org.apache.spark.sql.<A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#startsWith(org.apache.spark.sql.Column)"><B>startsWith(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>String starts with.
<DT><A HREF="./org/apache/spark/sql/Column.html#startsWith(java.lang.String)"><B>startsWith(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>String starts with another string literal.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#startsWith(org.apache.spark.sql.types.UTF8String)"><B>startsWith(UTF8String)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#startTime()"><B>startTime()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#startTime()"><B>startTime()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html#startTime()"><B>startTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationAttemptInfo.html" title="class in org.apache.spark.status.api.v1">ApplicationAttemptInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#startTime()"><B>startTime()</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#stat()"><B>stat()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a <A HREF="./org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><CODE>DataFrameStatFunctions</CODE></A> for working statistic functions support.
<DT><A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><B>StatCounter</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>A class for tracking the statistics of a set of numbers (count, mean and variance) in a
 numerically robust way.<DT><A HREF="./org/apache/spark/util/StatCounter.html#StatCounter(scala.collection.TraversableOnce)"><B>StatCounter(TraversableOnce&lt;Object&gt;)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#StatCounter()"><B>StatCounter()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Initialize the StatCounter with no values.
<DT><A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html#state()"><B>state()</B></A> - 
Method in class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html" title="class in org.apache.spark.scheduler.local">StatusUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#staticPageRank(int, double)"><B>staticPageRank(int, double)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Run PageRank for a fixed number of iterations returning a graph with vertex attributes
 containing the PageRank and edge attributes the normalized edge weight.
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#staticPersonalizedPageRank(long, int, double)"><B>staticPersonalizedPageRank(long, int, double)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Run Personalized PageRank for a fixed number of iterations with
 with all iterations originating at the source node
 returning a graph with vertex attributes
 containing the PageRank and edge attributes the normalized edge weight.
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#statistic()"><B>statistic()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html#statistic()"><B>statistic()</B></A> - 
Method in interface org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</A>
<DD>Test statistic.
<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat"><B>Statistics</B></A> - Class in <A HREF="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</A><DD>:: Experimental ::
 API for statistical functions in MLlib.<DT><A HREF="./org/apache/spark/mllib/stat/Statistics.html#Statistics()"><B>Statistics()</B></A> - 
Constructor for class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver"><B>Statistics</B></A> - Class in <A HREF="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</A><DD>:: DeveloperApi ::
 Statistics for querying the supervisor about state of workers.<DT><A HREF="./org/apache/spark/streaming/receiver/Statistics.html#Statistics(int, int, int, java.lang.String)"><B>Statistics(int, int, int, String)</B></A> - 
Constructor for class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#stats()"><B>stats()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return a <A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><CODE>StatCounter</CODE></A> object that captures the mean, variance and
 count of the RDD's elements in one operation.
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#stats()"><B>stats()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#stats()"><B>stats()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Return a <A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><CODE>StatCounter</CODE></A> object that captures the mean, variance and
 count of the RDD's elements in one operation.
<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler"><B>StatsReportListener</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Simple SparkListener that logs a few summary statistics when each stage completes<DT><A HREF="./org/apache/spark/scheduler/StatsReportListener.html#StatsReportListener()"><B>StatsReportListener()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler"><B>StatsReportListener</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>:: DeveloperApi ::
 A simple StreamingListener that logs summary statistics across Spark Streaming batches
 param:  numBatchInfos Number of last batches to consider for generating statistics (default: 10)<DT><A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html#StatsReportListener(int)"><B>StatsReportListener(int)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#status()"><B>status()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfo.html#status()"><B>status()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfo.html" title="interface in org.apache.spark">SparkJobInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkJobInfoImpl.html#status()"><B>status()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkJobInfoImpl.html" title="class in org.apache.spark">SparkJobInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#status()"><B>status()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#status()"><B>status()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#statusTracker()"><B>statusTracker()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#statusTracker()"><B>statusTracker()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html" title="class in org.apache.spark.scheduler.local"><B>StatusUpdate</B></A> - Class in <A HREF="./org/apache/spark/scheduler/local/package-summary.html">org.apache.spark.scheduler.local</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html#StatusUpdate(long, scala.Enumeration.Value, java.nio.ByteBuffer)"><B>StatusUpdate(long, Enumeration.Value, ByteBuffer)</B></A> - 
Constructor for class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html" title="class in org.apache.spark.scheduler.local">StatusUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#std()"><B>std()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#std()"><B>std()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html#std()"><B>std()</B></A> - 
Method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/LogNormalGenerator.html" title="class in org.apache.spark.mllib.random">LogNormalGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#stdev()"><B>stdev()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute the standard deviation of this RDD's elements.
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#stdev()"><B>stdev()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute the standard deviation of this RDD's elements.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#stdev()"><B>stdev()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Return the standard deviation of the values.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Shut down the SparkContext.
<DT><A HREF="./org/apache/spark/broadcast/BroadcastFactory.html#stop()"><B>stop()</B></A> - 
Method in interface org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Stop the execution of the streams.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean)"><B>stop(boolean)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Stop the execution of the streams.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean, boolean)"><B>stop(boolean, boolean)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Stop the execution of the streams.
<DT><A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/InputDStream.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</A>
<DD>Method called to stop receiving data.
<DT><A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#stop()"><B>stop()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#stop(java.lang.String)"><B>stop(String)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Stop the receiver completely.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#stop(java.lang.String, java.lang.Throwable)"><B>stop(String, Throwable)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Stop the receiver completely due to an exception
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#stop(boolean)"><B>stop(boolean)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Stop the execution of the streams immediately (does not wait for all received data
 to be processed).
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#stop(boolean, boolean)"><B>stop(boolean, boolean)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Stop the execution of the streams, with option of ensuring all received data
 has been processed.
<DT><A HREF="./org/apache/spark/scheduler/StopCoordinator.html" title="class in org.apache.spark.scheduler"><B>StopCoordinator</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/StopCoordinator.html#StopCoordinator()"><B>StopCoordinator()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StopCoordinator.html" title="class in org.apache.spark.scheduler">StopCoordinator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/local/StopExecutor.html" title="class in org.apache.spark.scheduler.local"><B>StopExecutor</B></A> - Class in <A HREF="./org/apache/spark/scheduler/local/package-summary.html">org.apache.spark.scheduler.local</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/local/StopExecutor.html#StopExecutor()"><B>StopExecutor()</B></A> - 
Constructor for class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/StopExecutor.html" title="class in org.apache.spark.scheduler.local">StopExecutor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDPartitionInfo.html" title="class in org.apache.spark.status.api.v1">RDDPartitionInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/RDDStorageInfo.html" title="class in org.apache.spark.status.api.v1">RDDStorageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockStatus.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage"><B>StorageLevel</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>:: DeveloperApi ::
 Flags for controlling the storage of an RDD.<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#StorageLevel()"><B>StorageLevel()</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#storageLevel()"><B>storageLevel()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#storageLevelCache()"><B>storageLevelCache()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>:: DeveloperApi ::
 Read StorageLevel object from ObjectInput stream.
<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java"><B>StorageLevels</B></A> - Class in <A HREF="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</A><DD>Expose some commonly useful storage level constants.<DT><A HREF="./org/apache/spark/api/java/StorageLevels.html#StorageLevels()"><B>StorageLevels()</B></A> - 
Constructor for class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage"><B>StorageListener</B></A> - Class in <A HREF="./org/apache/spark/ui/storage/package-summary.html">org.apache.spark.ui.storage</A><DD>:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the BlockManagerUI.<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#StorageListener(org.apache.spark.storage.StorageStatusListener)"><B>StorageListener(StorageStatusListener)</B></A> - 
Constructor for class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage"><B>StorageStatus</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>:: DeveloperApi ::
 Storage information for each BlockManager.<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#StorageStatus(org.apache.spark.storage.BlockManagerId, long)"><B>StorageStatus(BlockManagerId, long)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatus.html#StorageStatus(org.apache.spark.storage.BlockManagerId, long, scala.collection.Map)"><B>StorageStatus(BlockManagerId, long, Map&lt;BlockId, BlockStatus&gt;)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</A>
<DD>Create a storage status with an initial set of blocks, leaving the source unmodified.
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#storageStatusList()"><B>storageStatusList()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html#storageStatusList()"><B>storageStatusList()</B></A> - 
Method in class org.apache.spark.ui.exec.<A HREF="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#storageStatusList()"><B>storageStatusList()</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage"><B>StorageStatusListener</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>:: DeveloperApi ::
 A SparkListener that maintains executor storage status.<DT><A HREF="./org/apache/spark/storage/StorageStatusListener.html#StorageStatusListener()"><B>StorageStatusListener()</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html#store(scala.collection.Iterator)"><B>store(Iterator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</A>
<DD>Store an iterator of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html#store(java.nio.ByteBuffer)"><B>store(ByteBuffer)</B></A> - 
Method in interface org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</A>
<DD>Store the bytes of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html#store(T)"><B>store(T)</B></A> - 
Method in interface org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</A>
<DD>Store a single item of received data to Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(T)"><B>store(T)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store a single item of received data to Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.mutable.ArrayBuffer)"><B>store(ArrayBuffer&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an ArrayBuffer of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.mutable.ArrayBuffer, java.lang.Object)"><B>store(ArrayBuffer&lt;T&gt;, Object)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an ArrayBuffer of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.Iterator)"><B>store(Iterator&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an iterator of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(java.util.Iterator, java.lang.Object)"><B>store(Iterator&lt;T&gt;, Object)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an iterator of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(java.util.Iterator)"><B>store(Iterator&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an iterator of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.Iterator, java.lang.Object)"><B>store(Iterator&lt;T&gt;, Object)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store an iterator of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(java.nio.ByteBuffer)"><B>store(ByteBuffer)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store the bytes of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#store(java.nio.ByteBuffer, java.lang.Object)"><B>store(ByteBuffer, Object)</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Store the bytes of received data as a data block into Spark's memory.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration"><B>Strategy</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</A><DD>:: Experimental ::
 Stores all the configuration options for tree construction
 param:  algo  Learning goal.<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#Strategy(scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int, int, scala.Enumeration.Value, scala.collection.immutable.Map, int, double, int, double, boolean, int)"><B>Strategy(Enumeration.Value, Impurity, int, int, int, Enumeration.Value, Map&lt;Object, Object&gt;, int, double, int, double, boolean, int)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#Strategy(scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int, int, java.util.Map)"><B>Strategy(Enumeration.Value, Impurity, int, int, int, Map&lt;Integer, Integer&gt;)</B></A> - 
Constructor for class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>Java-friendly constructor for <A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration"><CODE>Strategy</CODE></A>
<DT><A HREF="./org/apache/spark/storage/BlockId.html#STREAM()"><B>STREAM()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage"><B>StreamBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/StreamBlockId.html#StreamBlockId(int, long)"><B>StreamBlockId(int, long)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StreamBlockId.html#streamId()"><B>streamId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/receiver/Receiver.html#streamId()"><B>streamId()</B></A> - 
Method in class org.apache.spark.streaming.receiver.<A HREF="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</A>
<DD>Get the unique identifier the receiver input stream that this
 receiver is associated with.
<DT><A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#streamId()"><B>streamId()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#streamIdToNumRecords()"><B>streamIdToNumRecords()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><B>StreamingContext</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>Main entry point for Spark Streaming functionality.<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(org.apache.spark.SparkContext, org.apache.spark.streaming.Duration)"><B>StreamingContext(SparkContext, Duration)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a StreamingContext using an existing SparkContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)"><B>StreamingContext(SparkConf, Duration)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a StreamingContext by providing the configuration necessary for a new SparkContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, scala.collection.Seq, scala.collection.Map)"><B>StreamingContext(String, String, Duration, String, Seq&lt;String&gt;, Map&lt;String, String&gt;)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a StreamingContext by providing the details necessary for creating a new SparkContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)"><B>StreamingContext(String, Configuration)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Recreate a StreamingContext from a checkpoint file.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String)"><B>StreamingContext(String)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Recreate a StreamingContext from a checkpoint file.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String, org.apache.spark.SparkContext)"><B>StreamingContext(String, SparkContext)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Recreate a StreamingContext from a checkpoint file using an existing SparkContext.
<DT><A HREF="./org/apache/spark/streaming/StreamingContextState.html" title="enum in org.apache.spark.streaming"><B>StreamingContextState</B></A> - Enum in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>:: DeveloperApi ::

 Represents the state of a StreamingContext.<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering"><B>StreamingKMeans</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#StreamingKMeans(int, double, java.lang.String)"><B>StreamingKMeans(int, double, String)</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#StreamingKMeans()"><B>StreamingKMeans()</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html" title="class in org.apache.spark.mllib.clustering"><B>StreamingKMeansModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</A><DD>:: Experimental ::<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html#StreamingKMeansModel(org.apache.spark.mllib.linalg.Vector[], double[])"><B>StreamingKMeansModel(Vector[], double[])</B></A> - 
Constructor for class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeansModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression"><B>StreamingLinearAlgorithm</B></A>&lt;<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">M</A> extends <A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>,<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">A</A> extends <A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</A>&lt;<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">M</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>:: DeveloperApi ::
 StreamingLinearAlgorithm implements methods for continuously
 training a generalized linear model model on streaming data,
 and using it for prediction on (possibly different) streaming data.<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#StreamingLinearAlgorithm()"><B>StreamingLinearAlgorithm()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><B>StreamingLinearRegressionWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</A><DD>:: Experimental ::
 Train or predict a linear regression model on streaming data.<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#StreamingLinearRegressionWithSGD()"><B>StreamingLinearRegressionWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</A>
<DD>Construct a StreamingLinearRegression object with default parameters:
 {stepSize: 0.1, numIterations: 50, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><B>StreamingListener</B></A> - Interface in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>:: DeveloperApi ::
 A listener interface for receiving information about an ongoing streaming
 computation.<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerBatchCompleted</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html#StreamingListenerBatchCompleted(org.apache.spark.streaming.scheduler.BatchInfo)"><B>StreamingListenerBatchCompleted(BatchInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchCompleted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerBatchStarted</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html#StreamingListenerBatchStarted(org.apache.spark.streaming.scheduler.BatchInfo)"><B>StreamingListenerBatchStarted(BatchInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchStarted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerBatchSubmitted</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html#StreamingListenerBatchSubmitted(org.apache.spark.streaming.scheduler.BatchInfo)"><B>StreamingListenerBatchSubmitted(BatchInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchSubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerEvent.html" title="interface in org.apache.spark.streaming.scheduler"><B>StreamingListenerEvent</B></A> - Interface in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>:: DeveloperApi ::
 Base trait for events related to StreamingListener<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerReceiverError</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html#StreamingListenerReceiverError(org.apache.spark.streaming.scheduler.ReceiverInfo)"><B>StreamingListenerReceiverError(ReceiverInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverError</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerReceiverStarted</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html#StreamingListenerReceiverStarted(org.apache.spark.streaming.scheduler.ReceiverInfo)"><B>StreamingListenerReceiverStarted(ReceiverInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStarted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler"><B>StreamingListenerReceiverStopped</B></A> - Class in <A HREF="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html#StreamingListenerReceiverStopped(org.apache.spark.streaming.scheduler.ReceiverInfo)"><B>StreamingListenerReceiverStopped(ReceiverInfo)</B></A> - 
Constructor for class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStopped</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification"><B>StreamingLogisticRegressionWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>:: Experimental ::
 Train or predict a logistic regression model on streaming data.<DT><A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html#StreamingLogisticRegressionWithSGD()"><B>StreamingLogisticRegressionWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">StreamingLogisticRegressionWithSGD</A>
<DD>Construct a StreamingLogisticRegression object with default parameters:
 {stepSize: 0.1, numIterations: 50, miniBatchFraction: 1.0, regParam: 0.0}.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#string()"><B>string()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type string.
<DT><A HREF="./org/apache/spark/ml/param/StringArrayParam.html" title="class in org.apache.spark.ml.param"><B>StringArrayParam</B></A> - Class in <A HREF="./org/apache/spark/ml/param/package-summary.html">org.apache.spark.ml.param</A><DD>:: DeveloperApi ::
 Specialized version of <CODE>Param[Array[String</CODE>} for Java.<DT><A HREF="./org/apache/spark/ml/param/StringArrayParam.html#StringArrayParam(org.apache.spark.ml.param.Params, java.lang.String, java.lang.String, scala.Function1)"><B>StringArrayParam(Params, String, String, Function1&lt;String[], Object&gt;)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/StringArrayParam.html" title="class in org.apache.spark.ml.param">StringArrayParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/StringArrayParam.html#StringArrayParam(org.apache.spark.ml.param.Params, java.lang.String, java.lang.String)"><B>StringArrayParam(Params, String, String)</B></A> - 
Constructor for class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/StringArrayParam.html" title="class in org.apache.spark.ml.param">StringArrayParam</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringContains.html" title="class in org.apache.spark.sql.sources"><B>StringContains</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to
 a string that contains the string <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/StringContains.html#StringContains(java.lang.String, java.lang.String)"><B>StringContains(String, String)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringContains.html" title="class in org.apache.spark.sql.sources">StringContains</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringEndsWith.html" title="class in org.apache.spark.sql.sources"><B>StringEndsWith</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to
 a string that starts with <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/StringEndsWith.html#StringEndsWith(java.lang.String, java.lang.String)"><B>StringEndsWith(String, String)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringEndsWith.html" title="class in org.apache.spark.sql.sources">StringEndsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature"><B>StringIndexer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 A label indexer that maps a string column of labels to an ML column of label indices.<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#StringIndexer(java.lang.String)"><B>StringIndexer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#StringIndexer()"><B>StringIndexer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature"><B>StringIndexerModel</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Model fitted by <A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature"><CODE>StringIndexer</CODE></A>.<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#stringRddToDataFrameHolder(org.apache.spark.rdd.RDD)"><B>stringRddToDataFrameHolder(RDD&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/StringRRDD.html" title="class in org.apache.spark.api.r"><B>StringRRDD</B></A>&lt;<A HREF="./org/apache/spark/api/r/StringRRDD.html" title="type parameter in StringRRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/api/r/package-summary.html">org.apache.spark.api.r</A><DD>An RDD that stores R objects as Array[String].<DT><A HREF="./org/apache/spark/api/r/StringRRDD.html#StringRRDD(org.apache.spark.rdd.RDD, byte[], java.lang.String, byte[], java.lang.String, java.lang.Object[], scala.reflect.ClassTag)"><B>StringRRDD(RDD&lt;T&gt;, byte[], String, byte[], String, Object[], ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/StringRRDD.html" title="class in org.apache.spark.api.r">StringRRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringStartsWith.html" title="class in org.apache.spark.sql.sources"><B>StringStartsWith</B></A> - Class in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>A filter that evaluates to <code>true</code> iff the attribute evaluates to
 a string that starts with <code>value</code>.<DT><A HREF="./org/apache/spark/sql/sources/StringStartsWith.html#StringStartsWith(java.lang.String, java.lang.String)"><B>StringStartsWith(String, String)</B></A> - 
Constructor for class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringStartsWith.html" title="class in org.apache.spark.sql.sources">StringStartsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#stringToText(java.lang.String)"><B>stringToText(String)</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#StringType"><B>StringType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the StringType object.
<DT><A HREF="./org/apache/spark/sql/types/StringType.html" title="class in org.apache.spark.sql.types"><B>StringType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>String</code> values.<DT><A HREF="./org/apache/spark/SparkContext.html#stringWritableConverter()"><B>stringWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#stronglyConnectedComponents(int)"><B>stronglyConnectedComponents(int)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Compute the strongly connected component (SCC) of each vertex and return a graph with the
 vertex value containing the lowest vertex id in the SCC containing that vertex.
<DT><A HREF="./org/apache/spark/graphx/lib/StronglyConnectedComponents.html" title="class in org.apache.spark.graphx.lib"><B>StronglyConnectedComponents</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Strongly connected components algorithm implementation.<DT><A HREF="./org/apache/spark/graphx/lib/StronglyConnectedComponents.html#StronglyConnectedComponents()"><B>StronglyConnectedComponents()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/StronglyConnectedComponents.html" title="class in org.apache.spark.graphx.lib">StronglyConnectedComponents</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#struct(scala.collection.Seq)"><B>struct(Seq&lt;StructField&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type struct.
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#struct(org.apache.spark.sql.types.StructType)"><B>struct(StructType)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type struct.
<DT><A HREF="./org/apache/spark/sql/functions.html#struct(org.apache.spark.sql.Column...)"><B>struct(Column...)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new struct column.
<DT><A HREF="./org/apache/spark/sql/functions.html#struct(scala.collection.Seq)"><B>struct(Seq&lt;Column&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new struct column.
<DT><A HREF="./org/apache/spark/sql/functions.html#struct(java.lang.String, scala.collection.Seq)"><B>struct(String, Seq&lt;String&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Creates a new struct column that composes multiple input columns.
<DT><A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types"><B>StructField</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>A field inside a StructType.<DT><A HREF="./org/apache/spark/sql/types/StructField.html#StructField(java.lang.String, org.apache.spark.sql.types.DataType, boolean, org.apache.spark.sql.types.Metadata)"><B>StructField(String, DataType, boolean, Metadata)</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types"><B>StructType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 A <A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types"><CODE>StructType</CODE></A> object can be constructed by<DT><A HREF="./org/apache/spark/sql/types/StructType.html#StructType(org.apache.spark.sql.types.StructField[])"><B>StructType(StructField[])</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#subgraph(scala.Function1, scala.Function2)"><B>subgraph(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Object&gt;, Function2&lt;Object, VD, Object&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Restricts the graph to only the vertices and edges satisfying the predicates.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#subgraph(scala.Function1, scala.Function2)"><B>subgraph(Function1&lt;EdgeTriplet&lt;VD, ED&gt;, Object&gt;, Function2&lt;Object, VD, Object&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/StageInfo.html#submissionTime()"><B>submissionTime()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</A>
<DD>When this stage was submitted from the DAGScheduler to a TaskScheduler.
<DT><A HREF="./org/apache/spark/SparkStageInfo.html#submissionTime()"><B>submissionTime()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfo.html" title="interface in org.apache.spark">SparkStageInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkStageInfoImpl.html#submissionTime()"><B>submissionTime()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkStageInfoImpl.html" title="class in org.apache.spark">SparkStageInfoImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/JobData.html#submissionTime()"><B>submissionTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/JobData.html" title="class in org.apache.spark.status.api.v1">JobData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#submissionTime()"><B>submissionTime()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#submitJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, scala.Function2, scala.Function0)"><B>submitJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, Function2&lt;Object, U, BoxedUnit&gt;, Function0&lt;R&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>:: Experimental ::
 Submit a job for execution and return a FutureJob holding the result.
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#subsamplingRate()"><B>subsamplingRate()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html#subsetAccuracy()"><B>subsetAccuracy()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MultilabelMetrics.html" title="class in org.apache.spark.mllib.evaluation">MultilabelMetrics</A>
<DD>Returns subset accuracy
 (for equal sets of labels)
<DT><A HREF="./org/apache/spark/sql/Column.html#substr(org.apache.spark.sql.Column, org.apache.spark.sql.Column)"><B>substr(Column, Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>An expression that returns a substring.
<DT><A HREF="./org/apache/spark/sql/Column.html#substr(int, int)"><B>substr(int, int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>An expression that returns a substring.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD)"><B>subtract(JavaDoubleRDD)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD, int)"><B>subtract(JavaDoubleRDD, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD, org.apache.spark.Partitioner)"><B>subtract(JavaDoubleRDD, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD)"><B>subtract(JavaPairRDD&lt;K, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD, int)"><B>subtract(JavaPairRDD&lt;K, V&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>subtract(JavaPairRDD&lt;K, V&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD)"><B>subtract(JavaRDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD, int)"><B>subtract(JavaRDD&lt;T&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD, org.apache.spark.Partitioner)"><B>subtract(JavaRDD&lt;T&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)"><B>subtract(RDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, int)"><B>subtract(RDD&lt;T&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)"><B>subtract(RDD&lt;T&gt;, Partitioner, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/util/Vector.html#subtract(org.apache.spark.util.Vector)"><B>subtract(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD)"><B>subtractByKey(JavaPairRDD&lt;K, W&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD, int)"><B>subtractByKey(JavaPairRDD&lt;K, W&gt;, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the pairs from `this` whose keys are not in `other`.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)"><B>subtractByKey(JavaPairRDD&lt;K, W&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the pairs from `this` whose keys are not in `other`.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)"><B>subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD with the pairs from `this` whose keys are not in `other`.
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD with the pairs from `this` whose keys are not in `other`.
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#succeededTasks()"><B>succeededTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Success.html" title="class in org.apache.spark"><B>Success</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Task succeeded.<DT><A HREF="./org/apache/spark/Success.html#Success()"><B>Success()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/Success.html" title="class in org.apache.spark">Success</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#successful()"><B>successful()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sum()"><B>sum()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Add up the elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#sum()"><B>sum()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Add up the elements in this RDD.
<DT><A HREF="./org/apache/spark/sql/functions.html#sum(org.apache.spark.sql.Column)"><B>sum(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the sum of all values in the expression.
<DT><A HREF="./org/apache/spark/sql/functions.html#sum(java.lang.String)"><B>sum(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the sum of all values in the given column.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#sum(java.lang.String...)"><B>sum(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the sum for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/sql/GroupedData.html#sum(scala.collection.Seq)"><B>sum(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/GroupedData.html" title="class in org.apache.spark.sql">GroupedData</A>
<DD>Compute the sum for each numeric columns for each group.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#sum()"><B>sum()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#sum()"><B>sum()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sumApprox(long, java.lang.Double)"><B>sumApprox(long, Double)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>:: Experimental ::
 Approximate operation to return the sum within a timeout.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#sumApprox(long)"><B>sumApprox(long)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>:: Experimental ::
 Approximate operation to return the sum within a timeout.
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#sumApprox(long, double)"><B>sumApprox(long, double)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>:: Experimental ::
 Approximate operation to return the sum within a timeout.
<DT><A HREF="./org/apache/spark/sql/functions.html#sumDistinct(org.apache.spark.sql.Column)"><B>sumDistinct(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the sum of distinct values in the expression.
<DT><A HREF="./org/apache/spark/sql/functions.html#sumDistinct(java.lang.String)"><B>sumDistinct(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Aggregate function: returns the sum of distinct values in the expression.
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#supportedFeatureSubsetStrategies()"><B>supportedFeatureSubsetStrategies()</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>Accessor for supported featureSubsetStrategy settings: auto, all, onethird, sqrt, log2
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#supportedFeatureSubsetStrategies()"><B>supportedFeatureSubsetStrategies()</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>Accessor for supported featureSubsetStrategy settings: auto, all, onethird, sqrt, log2
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#supportedFeatureSubsetStrategies()"><B>supportedFeatureSubsetStrategies()</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>List of supported feature subset sampling strategies.
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#supportedImpurities()"><B>supportedImpurities()</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>Accessor for supported impurities: entropy, gini
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#supportedImpurities()"><B>supportedImpurities()</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>Accessor for supported impurity settings: entropy, gini
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#supportedImpurities()"><B>supportedImpurities()</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>Accessor for supported impurities: variance
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#supportedImpurities()"><B>supportedImpurities()</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>Accessor for supported impurity settings: variance
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#supportedLossTypes()"><B>supportedLossTypes()</B></A> - 
Static method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>Accessor for supported loss settings: logistic
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#supportedLossTypes()"><B>supportedLossTypes()</B></A> - 
Static method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>Accessor for supported loss settings: squared (L2), absolute (L1)
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#supportedModelTypes()"><B>supportedModelTypes()</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/KryoSerializer.html#supportsRelocationOfSerializedObjects()"><B>supportsRelocationOfSerializedObjects()</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html" title="class in org.apache.spark.graphx.lib"><B>SVDPlusPlus</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Implementation of SVD++ algorithm.<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html#SVDPlusPlus()"><B>SVDPlusPlus()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib"><B>SVDPlusPlus.Conf</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Configuration parameters for SVDPlusPlus.<DT><A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html#SVDPlusPlus.Conf(int, int, double, double, double, double, double, double)"><B>SVDPlusPlus.Conf(int, int, double, double, double, double, double, double)</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/SVDPlusPlus.Conf.html" title="class in org.apache.spark.graphx.lib">SVDPlusPlus.Conf</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util"><B>SVMDataGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</A><DD>:: DeveloperApi ::
 Generate sample data used for SVM.<DT><A HREF="./org/apache/spark/mllib/util/SVMDataGenerator.html#SVMDataGenerator()"><B>SVMDataGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.util.<A HREF="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util">SVMDataGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification"><B>SVMModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Model for Support Vector Machines (SVMs).<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#SVMModel(org.apache.spark.mllib.linalg.Vector, double)"><B>SVMModel(Vector, double)</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification"><B>SVMWithSGD</B></A> - Class in <A HREF="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</A><DD>Train a Support Vector Machine (SVM) using Stochastic Gradient Descent.<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#SVMWithSGD()"><B>SVMWithSGD()</B></A> - 
Constructor for class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>Construct a SVM object with default parameters: {stepSize: 1.0, numIterations: 100,
 regParm: 0.01, miniBatchFraction: 1.0}.
<DT><A HREF="./org/apache/spark/sql/SQLContext.implicits$.html#symbolToColumn(scala.Symbol)"><B>symbolToColumn(Symbol)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/env/EnvironmentListener.html#systemProperties()"><B>systemProperties()</B></A> - 
Method in class org.apache.spark.ui.env.<A HREF="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_T_"><!-- --></A><H2>
<B>T</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/SerializableWritable.html#t()"><B>t()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrameReader.html#table(java.lang.String)"><B>table(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</A>
<DD>Returns the specified table as a <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#table(java.lang.String)"><B>table(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#tableNames()"><B>tableNames()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#tableNames(java.lang.String)"><B>tableNames(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#tables()"><B>tables()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#tables(java.lang.String)"><B>tables(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/TableScan.html" title="interface in org.apache.spark.sql.sources"><B>TableScan</B></A> - Interface in <A HREF="./org/apache/spark/sql/sources/package-summary.html">org.apache.spark.sql.sources</A><DD>::DeveloperApi::
 A BaseRelation that can produce all of its tuples as an RDD of Row objects.<DT><A HREF="./org/apache/spark/SparkContext.html#tachyonFolderName()"><B>tachyonFolderName()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/BinaryType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BinaryType.html" title="class in org.apache.spark.sql.types">BinaryType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/BooleanType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/BooleanType.html" title="class in org.apache.spark.sql.types">BooleanType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ByteType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ByteType.html" title="class in org.apache.spark.sql.types">ByteType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DateType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DateType.html" title="class in org.apache.spark.sql.types">DateType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DoubleType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DoubleType.html" title="class in org.apache.spark.sql.types">DoubleType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/FloatType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/FloatType.html" title="class in org.apache.spark.sql.types">FloatType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/IntegerType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/IntegerType.html" title="class in org.apache.spark.sql.types">IntegerType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/LongType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/LongType.html" title="class in org.apache.spark.sql.types">LongType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/ShortType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/ShortType.html" title="class in org.apache.spark.sql.types">ShortType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StringType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StringType.html" title="class in org.apache.spark.sql.types">StringType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/TimestampType.html#tag()"><B>tag()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/TimestampType.html" title="class in org.apache.spark.sql.types">TimestampType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#take(int)"><B>take(int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Take the first num elements of the RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#take(int)"><B>take(int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Take the first num elements of the RDD.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#take(int)"><B>take(int)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the first <code>n</code> rows in the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A>.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#takeAsync(int)"><B>takeAsync(int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>The asynchronous version of the <code>take</code> action, which returns a
 future for retrieving the first <code>num</code> elements of this RDD.
<DT><A HREF="./org/apache/spark/rdd/AsyncRDDActions.html#takeAsync(int)"><B>takeAsync(int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</A>
<DD>Returns a future for retrieving the first num elements of the RDD.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int, java.util.Comparator)"><B>takeOrdered(int, Comparator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the first k (smallest) elements from this RDD as defined by
 the specified Comparator[T] and maintains the order.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int)"><B>takeOrdered(int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the first k (smallest) elements from this RDD using the
 natural ordering for T while maintain the order.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#takeOrdered(int, scala.math.Ordering)"><B>takeOrdered(int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Returns the first k (smallest) elements from this RDD as defined by the specified
 implicit Ordering[T] and maintains the ordering.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int)"><B>takeSample(boolean, int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int, long)"><B>takeSample(boolean, int, long)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#takeSample(boolean, int, long)"><B>takeSample(boolean, int, long)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return a fixed-size sampled subset of this RDD in an array
<DT><A HREF="./org/apache/spark/sql/functions.html#tan(org.apache.spark.sql.Column)"><B>tan(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the tangent of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#tan(java.lang.String)"><B>tan(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the tangent of the given column.
<DT><A HREF="./org/apache/spark/sql/functions.html#tanh(org.apache.spark.sql.Column)"><B>tanh(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic tangent of the given value.
<DT><A HREF="./org/apache/spark/sql/functions.html#tanh(java.lang.String)"><B>tanh(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Computes the hyperbolic tangent of the given column.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#targetStorageLevel()"><B>targetStorageLevel()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#targetStorageLevel()"><B>targetStorageLevel()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/CleanupTaskWeakReference.html#task()"><B>task()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/CleanupTaskWeakReference.html" title="class in org.apache.spark">CleanupTaskWeakReference</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html#task()"><B>task()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html" title="class in org.apache.spark.scheduler">AskPermissionToCommitOutput</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html#taskAttempt()"><B>taskAttempt()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AskPermissionToCommitOutput.html" title="class in org.apache.spark.scheduler">AskPermissionToCommitOutput</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskContext.html#taskAttemptId()"><B>taskAttemptId()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>An ID that is unique to this task attempt (within the same SparkContext, no two task attempts
 will share the same attempt ID).
<DT><A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark"><B>TaskCommitDenied</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Task requested the driver to commit, but was denied.<DT><A HREF="./org/apache/spark/TaskCommitDenied.html#TaskCommitDenied(int, int, int)"><B>TaskCommitDenied(int, int, int)</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark">TaskCommitDenied</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/TaskCompletionListener.html" title="interface in org.apache.spark.util"><B>TaskCompletionListener</B></A> - Interface in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>:: DeveloperApi ::<DT><A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark"><B>TaskContext</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>Contextual information about a task which can be read or mutated during
 execution.<DT><A HREF="./org/apache/spark/TaskContext.html#TaskContext()"><B>TaskContext()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1"><B>TaskData</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/TaskEndReason.html" title="interface in org.apache.spark"><B>TaskEndReason</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Various possible reasons why a task ended.<DT><A HREF="./org/apache/spark/TaskFailedReason.html" title="interface in org.apache.spark"><B>TaskFailedReason</B></A> - Interface in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Various possible reasons why a task failed.<DT><A HREF="./org/apache/spark/scheduler/local/KillTask.html#taskId()"><B>taskId()</B></A> - 
Method in class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/KillTask.html" title="class in org.apache.spark.scheduler.local">KillTask</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html#taskId()"><B>taskId()</B></A> - 
Method in class org.apache.spark.scheduler.local.<A HREF="./org/apache/spark/scheduler/local/StatusUpdate.html" title="class in org.apache.spark.scheduler.local">StatusUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#taskId()"><B>taskId()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#taskId()"><B>taskId()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TaskResultBlockId.html#taskId()"><B>taskId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskInfo()"><B>taskInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html#taskInfo()"><B>taskInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler">SparkListenerTaskGettingResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html#taskInfo()"><B>taskInfo()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler"><B>TaskInfo</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>:: DeveloperApi ::
 Information about a running task attempt inside a TaskSet.<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#TaskInfo(long, int, int, long, java.lang.String, java.lang.String, scala.Enumeration.Value, boolean)"><B>TaskInfo(long, int, int, long, String, String, Enumeration.Value, boolean)</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark"><B>TaskKilled</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Task was killed intentionally and needs to be rescheduled.<DT><A HREF="./org/apache/spark/TaskKilled.html#TaskKilled()"><B>TaskKilled()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark">TaskKilled</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskKilledException.html" title="class in org.apache.spark"><B>TaskKilledException</B></A> - Exception in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 Exception thrown when a task is explicitly killed (i.e., task failure is expected).<DT><A HREF="./org/apache/spark/TaskKilledException.html#TaskKilledException()"><B>TaskKilledException()</B></A> - 
Constructor for exception org.apache.spark.<A HREF="./org/apache/spark/TaskKilledException.html" title="class in org.apache.spark">TaskKilledException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskInfo.html#taskLocality()"><B>taskLocality()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler"><B>TaskLocality</B></A> - Class in <A HREF="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/TaskLocality.html#TaskLocality()"><B>TaskLocality()</B></A> - 
Constructor for class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#taskLocality()"><B>taskLocality()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetricDistributions.html" title="class in org.apache.spark.status.api.v1"><B>TaskMetricDistributions</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#taskMetrics()"><B>taskMetrics()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskMetrics()"><B>taskMetrics()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskData.html#taskMetrics()"><B>taskMetrics()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskData.html" title="class in org.apache.spark.status.api.v1">TaskData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskMetrics.html" title="class in org.apache.spark.status.api.v1"><B>TaskMetrics</B></A> - Class in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/TaskContext.html#taskMetrics()"><B>taskMetrics()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</A>
<DD>::DeveloperApi::
<DT><A HREF="./org/apache/spark/storage/BlockId.html#TASKRESULT()"><B>TASKRESULT()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage"><B>TaskResultBlockId</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/storage/TaskResultBlockId.html#TaskResultBlockId(long)"><B>TaskResultBlockId(long)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark"><B>TaskResultLost</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 The task finished successfully, but the result was lost from the executor's block manager before
 it was fetched.<DT><A HREF="./org/apache/spark/TaskResultLost.html#TaskResultLost()"><B>TaskResultLost()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark">TaskResultLost</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/StageData.html#tasks()"><B>tasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageData.html" title="class in org.apache.spark.status.api.v1">StageData</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/TaskSorting.html" title="enum in org.apache.spark.status.api.v1"><B>TaskSorting</B></A> - Enum in <A HREF="./org/apache/spark/status/api/v1/package-summary.html">org.apache.spark.status.api.v1</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html#taskTime()"><B>taskTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorStageSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorStageSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskType()"><B>taskType()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#teardown()"><B>teardown()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Teardown the whole servers, including Kafka broker and Zookeeper
<DT><A HREF="./org/apache/spark/storage/BlockId.html#TEST()"><B>TEST()</B></A> - 
Static method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test"><B>TestResult</B></A>&lt;<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="type parameter in TestResult">DF</A>&gt; - Interface in <A HREF="./org/apache/spark/mllib/stat/test/package-summary.html">org.apache.spark.mllib.stat.test</A><DD>:: Experimental ::
 Trait for hypothesis test results.<DT><A HREF="./org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test"><B>TestSQLContext</B></A> - Class in <A HREF="./org/apache/spark/sql/test/package-summary.html">org.apache.spark.sql.test</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/sql/test/TestSQLContext.html#TestSQLContext()"><B>TestSQLContext()</B></A> - 
Constructor for class org.apache.spark.sql.test.<A HREF="./org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test">TestSQLContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#textFile(java.lang.String)"><B>textFile(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#textFile(java.lang.String, int)"><B>textFile(String, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.
<DT><A HREF="./org/apache/spark/SparkContext.html#textFile(java.lang.String, int)"><B>textFile(String, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#textFileStream(java.lang.String)"><B>textFileStream(String)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat).
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#textFileStream(java.lang.String)"><B>textFileStream(String)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat).
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html#theta()"><B>theta()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#threshold()"><B>threshold()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>Param for threshold used to binarize continuous features.
<DT><A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html#threshold()"><B>threshold()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/ContinuousSplit.html" title="class in org.apache.spark.ml.tree">ContinuousSplit</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#threshold()"><B>threshold()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#thresholds()"><B>thresholds()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Returns thresholds in descending order.
<DT><A HREF="./org/apache/spark/rdd/PartitionCoalescer.html#throwBalls()"><B>throwBalls()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PartitionCoalescer.html" title="class in org.apache.spark.rdd">PartitionCoalescer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorAdded.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorAdded</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerExecutorRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorRemoved</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html#time()"><B>time()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming"><B>Time</B></A> - Class in <A HREF="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</A><DD>This is a simple class that represents an absolute instant of time.<DT><A HREF="./org/apache/spark/streaming/Time.html#Time(long)"><B>Time(long)</B></A> - 
Constructor for class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#times(int)"><B>times(int)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/ColumnName.html#timestamp()"><B>timestamp()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/ColumnName.html" title="class in org.apache.spark.sql">ColumnName</A>
<DD>Creates a new <CODE>StructField</CODE> of type timestamp.
<DT><A HREF="./org/apache/spark/sql/types/DataTypes.html#TimestampType"><B>TimestampType</B></A> - 
Static variable in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataTypes.html" title="class in org.apache.spark.sql.types">DataTypes</A>
<DD>Gets the TimestampType object.
<DT><A HREF="./org/apache/spark/sql/types/TimestampType.html" title="class in org.apache.spark.sql.types"><B>TimestampType</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 The data type representing <code>java.sql.Timestamp</code> values.<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage"><B>TimeTrackingOutputStream</B></A> - Class in <A HREF="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</A><DD>Intercepts write calls and tracks total time spent writing in order to update shuffle write
 metrics.<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#TimeTrackingOutputStream(org.apache.spark.executor.ShuffleWriteMetrics, java.io.OutputStream)"><B>TimeTrackingOutputStream(ShuffleWriteMetrics, OutputStream)</B></A> - 
Constructor for class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#timeUnit()"><B>timeUnit()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/r/SpecialLengths.html#TIMING_DATA()"><B>TIMING_DATA()</B></A> - 
Static method in class org.apache.spark.api.r.<A HREF="./org/apache/spark/api/r/SpecialLengths.html" title="class in org.apache.spark.api.r">SpecialLengths</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#to(org.apache.spark.streaming.Time, org.apache.spark.streaming.Duration)"><B>to(Time, Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#toArray()"><B>toArray()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of Spark 1.0.0, toArray() is deprecated, use <A HREF="./org/apache/spark/api/java/JavaRDDLike.html#collect()"><CODE>JavaRDDLike.collect()</CODE></A> instead</I>
<DT><A HREF="./org/apache/spark/input/PortableDataStream.html#toArray()"><B>toArray()</B></A> - 
Method in class org.apache.spark.input.<A HREF="./org/apache/spark/input/PortableDataStream.html" title="class in org.apache.spark.input">PortableDataStream</A>
<DD>Read the file as a byte array
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#toArray()"><B>toArray()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#toArray()"><B>toArray()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Converts to a dense array in column major.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#toArray()"><B>toArray()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#toArray()"><B>toArray()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Converts the instance to a double array.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#toArray()"><B>toArray()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an array that contains all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toBigDecimal()"><B>toBigDecimal()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toBlockMatrix()"><B>toBlockMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toBlockMatrix(int, int)"><B>toBlockMatrix(int, int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#toBlockMatrix()"><B>toBlockMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#toBlockMatrix(int, int)"><B>toBlockMatrix(int, int)</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#toBreeze()"><B>toBreeze()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</A>
<DD>Collects data and assembles a local dense breeze matrix (for test only).
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#toBreeze()"><B>toBreeze()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Converts to a breeze matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#toBreeze()"><B>toBreeze()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Converts the instance to a breeze vector.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toByte()"><B>toByte()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#toCoordinateMatrix()"><B>toCoordinateMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Converts to CoordinateMatrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#toCoordinateMatrix()"><B>toCoordinateMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#toDebugString()"><B>toDebugString()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>A description of this RDD and its recursive dependencies for debugging.
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#toDebugString()"><B>toDebugString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Print the full model to a string.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#toDebugString()"><B>toDebugString()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>A description of this RDD and its recursive dependencies for debugging.
<DT><A HREF="./org/apache/spark/SparkConf.html#toDebugString()"><B>toDebugString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</A>
<DD>Return a string listing all keys and values, one per line.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toDebugString()"><B>toDebugString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#toDegrees(org.apache.spark.sql.Column)"><B>toDegrees(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts an angle measured in radians to an approximately equivalent angle measured in degrees.
<DT><A HREF="./org/apache/spark/sql/functions.html#toDegrees(java.lang.String)"><B>toDegrees(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts an angle measured in radians to an approximately equivalent angle measured in degrees.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#toDense()"><B>toDense()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>Generate a <code>DenseMatrix</code> from the given <code>SparseMatrix</code>.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#toDense()"><B>toDense()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Converts this vector to a dense vector.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toDF(java.lang.String...)"><B>toDF(String...)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with columns renamed.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toDF()"><B>toDF()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the object itself.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toDF(scala.collection.Seq)"><B>toDF(Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with columns renamed.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toDouble()"><B>toDouble()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#toEdgeTriplet()"><B>toEdgeTriplet()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>Converts the edge and vertex properties into an <A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx"><CODE>EdgeTriplet</CODE></A> for convenience.
<DT><A HREF="./org/apache/spark/ExceptionFailure.html#toErrorString()"><B>toErrorString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ExecutorLostFailure.html#toErrorString()"><B>toErrorString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark">ExecutorLostFailure</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FetchFailed.html#toErrorString()"><B>toErrorString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Resubmitted.html#toErrorString()"><B>toErrorString()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark">Resubmitted</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskCommitDenied.html#toErrorString()"><B>toErrorString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/TaskCommitDenied.html" title="class in org.apache.spark">TaskCommitDenied</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskFailedReason.html#toErrorString()"><B>toErrorString()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/TaskFailedReason.html" title="interface in org.apache.spark">TaskFailedReason</A>
<DD>Error message displayed in the web UI.
<DT><A HREF="./org/apache/spark/TaskKilled.html#toErrorString()"><B>toErrorString()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark">TaskKilled</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/TaskResultLost.html#toErrorString()"><B>toErrorString()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark">TaskResultLost</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/UnknownReason.html#toErrorString()"><B>toErrorString()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark">UnknownReason</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toFloat()"><B>toFloat()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#toFormattedString()"><B>toFormattedString()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#toIndexedRowMatrix()"><B>toIndexedRowMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Converts to IndexedRowMatrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toIndexedRowMatrix()"><B>toIndexedRowMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toInt()"><B>toInt()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#toInt()"><B>toInt()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toJavaBigDecimal()"><B>toJavaBigDecimal()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#toJavaDStream()"><B>toJavaDStream()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Convert to a JavaDStream
<DT><A HREF="./org/apache/spark/rdd/RDD.html#toJavaRDD()"><B>toJavaRDD()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toJavaRDD()"><B>toJavaRDD()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as a <CODE>JavaRDD</CODE> of <A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><CODE>Row</CODE></A>s.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toJSON()"><B>toJSON()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> as a RDD of JSON strings.
<DT><A HREF="./org/apache/spark/ml/feature/Tokenizer.html" title="class in org.apache.spark.ml.feature"><B>Tokenizer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 A tokenizer that converts the input string to lowercase and then splits it by white spaces.<DT><A HREF="./org/apache/spark/ml/feature/Tokenizer.html#Tokenizer(java.lang.String)"><B>Tokenizer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Tokenizer.html" title="class in org.apache.spark.ml.feature">Tokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Tokenizer.html#Tokenizer()"><B>Tokenizer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Tokenizer.html" title="class in org.apache.spark.ml.feature">Tokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#toLocal()"><B>toLocal()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>Convert model to a local model.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#toLocalIterator()"><B>toLocalIterator()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Return an iterator that contains all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#toLocalIterator()"><B>toLocalIterator()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return an iterator that contains all of the elements in this RDD.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#toLocalMatrix()"><B>toLocalMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Collect the distributed matrix on the driver as a `DenseMatrix`.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toLong()"><B>toLong()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#toLowerCase()"><B>toLowerCase()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#toMetadata(org.apache.spark.sql.types.Metadata)"><B>toMetadata(Metadata)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Converts to ML metadata with some existing metadata.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#toMetadata()"><B>toMetadata()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Converts to ML metadata
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#toMetadata(org.apache.spark.sql.types.Metadata)"><B>toMetadata(Metadata)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Converts to ML metadata with some existing metadata.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#toMetadata()"><B>toMetadata()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Converts to ML metadata
<DT><A HREF="./org/apache/spark/ml/tree/Split.html#toOld()"><B>toOld()</B></A> - 
Method in interface org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/Split.html" title="interface in org.apache.spark.ml.tree">Split</A>
<DD>Convert to old Split format
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#top(int, java.util.Comparator)"><B>top(int, Comparator&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the top k (largest) elements from this RDD as defined by
 the specified Comparator[T].
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#top(int)"><B>top(int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Returns the top k (largest) elements from this RDD using the
 natural ordering for T.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#top(int, scala.math.Ordering)"><B>top(int, Ordering&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>toPairDStreamFunctions(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)"><B>toPairDStreamFunctions(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</B></A> - 
Static method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by implicit functions in the DStream companion object.
             This is kept here only for backward compatibility.</I>
<DT><A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html#topByKey(int, scala.math.Ordering)"><B>topByKey(int, Ordering&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/MLPairRDDFunctions.html" title="class in org.apache.spark.mllib.rdd">MLPairRDDFunctions</A>
<DD>Returns the top k (largest) elements for each key from this RDD as defined by the specified
 implicit Ordering[T].
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#topic()"><B>topic()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>Kafka topic name
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#topicConcentration()"><B>topicConcentration()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#topicDistributions()"><B>topicDistributions()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>For each document in the training set, return the distribution over topics for that document
 ("theta_doc").
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#topicsMatrix()"><B>topicsMatrix()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>Inferred topics, where each topic is represented by a distribution over terms.
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html#topicsMatrix()"><B>topicsMatrix()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering">LDAModel</A>
<DD>Inferred topics, where each topic is represented by a distribution over terms.
<DT><A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html#topicsMatrix()"><B>topicsMatrix()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html" title="class in org.apache.spark.mllib.clustering">LocalLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html#toPMML(javax.xml.transform.stream.StreamResult)"><B>toPMML(StreamResult)</B></A> - 
Method in interface org.apache.spark.mllib.pmml.<A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml">PMMLExportable</A>
<DD>Export the model to the stream result in PMML format
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html#toPMML(java.lang.String)"><B>toPMML(String)</B></A> - 
Method in interface org.apache.spark.mllib.pmml.<A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml">PMMLExportable</A>
<DD>:: Experimental ::
 Export the model to a local file in PMML format
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html#toPMML(org.apache.spark.SparkContext, java.lang.String)"><B>toPMML(SparkContext, String)</B></A> - 
Method in interface org.apache.spark.mllib.pmml.<A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml">PMMLExportable</A>
<DD>:: Experimental ::
 Export the model to a directory on a distributed file system in PMML format
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html#toPMML(java.io.OutputStream)"><B>toPMML(OutputStream)</B></A> - 
Method in interface org.apache.spark.mllib.pmml.<A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml">PMMLExportable</A>
<DD>:: Experimental ::
 Export the model to the OutputStream in PMML format
<DT><A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html#toPMML()"><B>toPMML()</B></A> - 
Method in interface org.apache.spark.mllib.pmml.<A HREF="./org/apache/spark/mllib/pmml/PMMLExportable.html" title="interface in org.apache.spark.mllib.pmml">PMMLExportable</A>
<DD>:: Experimental ::
 Export the model to a String in PMML format
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#topNode()"><B>topNode()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#toRadians(org.apache.spark.sql.Column)"><B>toRadians(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts an angle measured in degrees to an approximately equivalent angle measured in radians.
<DT><A HREF="./org/apache/spark/sql/functions.html#toRadians(java.lang.String)"><B>toRadians(String)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts an angle measured in degrees to an approximately equivalent angle measured in radians.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#toRDD(org.apache.spark.api.java.JavaDoubleRDD)"><B>toRDD(JavaDoubleRDD)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#toRDD(org.apache.spark.api.java.JavaPairRDD)"><B>toRDD(JavaPairRDD&lt;K, V&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#toRDD(org.apache.spark.api.java.JavaRDD)"><B>toRDD(JavaRDD&lt;T&gt;)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toRowMatrix()"><B>toRowMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#toRowMatrix()"><B>toRowMatrix()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast"><B>TorrentBroadcastFactory</B></A> - Class in <A HREF="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</A><DD>A <A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><CODE>Broadcast</CODE></A> implementation that uses a BitTorrent-like
 protocol to do a distributed transfer of the broadcasted data to the executors.<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#TorrentBroadcastFactory()"><B>TorrentBroadcastFactory()</B></A> - 
Constructor for class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toSchemaRDD()"><B>toSchemaRDD()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD><B>Deprecated.</B>&nbsp;<I>As of 1.3.0, replaced by <code>toDF()</code>.</I>
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#toSeq()"><B>toSeq()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>Converts this param map to a sequence of param pairs.
<DT><A HREF="./org/apache/spark/sql/Row.html#toSeq()"><B>toSeq()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>Return a Scala Seq representing the row.
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toShort()"><B>toShort()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#toSparkContext(org.apache.spark.api.java.JavaSparkContext)"><B>toSparkContext(JavaSparkContext)</B></A> - 
Static method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#toSparse()"><B>toSparse()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a <code>SparseMatrix</code> from the given <code>DenseMatrix</code>.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#toSparse()"><B>toSparse()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#toSparse()"><B>toSparse()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html#toSparse()"><B>toSparse()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</A>
<DD>Converts this vector to a sparse vector with all explicit zeros removed.
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#toSplitInfo(java.lang.Class, java.lang.String, org.apache.hadoop.mapred.InputSplit)"><B>toSplitInfo(Class&lt;?&gt;, String, InputSplit)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#toSplitInfo(java.lang.Class, java.lang.String, org.apache.hadoop.mapreduce.InputSplit)"><B>toSplitInfo(Class&lt;?&gt;, String, InputSplit)</B></A> - 
Static method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeDirection.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeDirection.html" title="class in org.apache.spark.graphx">EdgeDirection</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/Param.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/param/ParamMap.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamMap.html" title="class in org.apache.spark.ml.param">ParamMap</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/InternalNode.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/InternalNode.html" title="class in org.apache.spark.ml.tree">InternalNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tree/LeafNode.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.ml.tree.<A HREF="./org/apache/spark/ml/tree/LeafNode.html" title="class in org.apache.spark.ml.tree">LeafNode</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#toString()"><B>toString()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>A human readable representation of the matrix
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#toString(int, int)"><B>toString(int, int)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>A human readable representation of the matrix with maximum lines and width
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>Print a summary of the model.
<DT><A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/test/TestResult.html#toString()"><B>toString()</B></A> - 
Method in interface org.apache.spark.mllib.stat.test.<A HREF="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</A>
<DD>String explaining the hypothesis test result.
<DT><A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</A>
<DD>Print a summary of the model.
<DT><A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Node.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Predict.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Predict.html" title="class in org.apache.spark.mllib.tree.model">Predict</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/Split.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/BoundedDouble.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/partial/PartialResult.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.partial.<A HREF="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/InputFormatInfo.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SerializableWritable.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Row.html#toString()"><B>toString()</B></A> - 
Method in interface org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Metadata.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructField.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructField.html" title="class in org.apache.spark.sql.types">StructField</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockId.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/RDDInfo.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Duration.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/StatCounter.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.html#toString()"><B>toString()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#toStructField(org.apache.spark.sql.types.Metadata)"><B>toStructField(Metadata)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Converts to a <CODE>StructField</CODE> with some existing metadata.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#toStructField()"><B>toStructField()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Converts to a <CODE>StructField</CODE>.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#toStructField(org.apache.spark.sql.types.Metadata)"><B>toStructField(Metadata)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Converts to a StructField with some existing metadata.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html#toStructField()"><B>toStructField()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeGroup.html" title="class in org.apache.spark.ml.attribute">AttributeGroup</A>
<DD>Converts to a StructField.
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html#totalBlocksFetched()"><B>totalBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html#totalBlocksFetched()"><B>totalBlocksFetched()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleReadMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleReadMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html#totalCores()"><B>totalCores()</B></A> - 
Method in class org.apache.spark.scheduler.cluster.<A HREF="./org/apache/spark/scheduler/cluster/ExecutorInfo.html" title="class in org.apache.spark.scheduler.cluster">ExecutorInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html#totalDelay()"><B>totalDelay()</B></A> - 
Method in class org.apache.spark.streaming.scheduler.<A HREF="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</A>
<DD>Time taken for all the jobs of this batch to finish processing from the time they
 were submitted.
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#totalDuration()"><B>totalDuration()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#totalInputBytes()"><B>totalInputBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#totalShuffleRead()"><B>totalShuffleRead()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#totalShuffleWrite()"><B>totalShuffleWrite()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html#totalTasks()"><B>totalTasks()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ExecutorSummary.html" title="class in org.apache.spark.status.api.v1">ExecutorSummary</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#toTuple()"><B>toTuple()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/Decimal.html#toUnscaledLong()"><B>toUnscaledLong()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/Decimal.html" title="class in org.apache.spark.sql.types">Decimal</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#toUpperCase()"><B>toUpperCase()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, int, int, double, boolean, double, boolean, org.apache.spark.storage.StorageLevel, org.apache.spark.storage.StorageLevel, int, long, scala.reflect.ClassTag, scala.math.Ordering)"><B>train(RDD&lt;ALS.Rating&lt;ID&gt;&gt;, int, int, int, int, double, boolean, double, boolean, StorageLevel, StorageLevel, int, long, ClassTag&lt;ID&gt;, Ordering&lt;ID&gt;)</B></A> - 
Static method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>:: DeveloperApi ::
 Implementation of the ALS algorithm.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, org.apache.spark.mllib.linalg.Vector)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>Train a logistic regression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>Train a logistic regression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>Train a logistic regression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)"><B>train(RDD&lt;LabeledPoint&gt;, int)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</A>
<DD>Train a logistic regression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#train(org.apache.spark.rdd.RDD)"><B>train(RDD&lt;LabeledPoint&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#train(org.apache.spark.rdd.RDD, double)"><B>train(RDD&lt;LabeledPoint&gt;, double)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html#train(org.apache.spark.rdd.RDD, double, java.lang.String)"><B>train(RDD&lt;LabeledPoint&gt;, double, String)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</A>
<DD>Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>Train a SVM model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>Train a SVM model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>Train a SVM model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int)"><B>train(RDD&lt;LabeledPoint&gt;, int)</B></A> - 
Static method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</A>
<DD>Train a SVM model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int, int, java.lang.String, long)"><B>train(RDD&lt;Vector&gt;, int, int, int, String, long)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Trains a k-means model using the given set of parameters.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int, int, java.lang.String)"><B>train(RDD&lt;Vector&gt;, int, int, int, String)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Trains a k-means model using the given set of parameters.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int)"><B>train(RDD&lt;Vector&gt;, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Trains a k-means model using specified parameters and the default values for unspecified.
<DT><A HREF="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int, int)"><B>train(RDD&lt;Vector&gt;, int, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</A>
<DD>Trains a k-means model using specified parameters and the default values for unspecified.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double, int, long)"><B>train(RDD&lt;Rating&gt;, int, int, double, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double, int)"><B>train(RDD&lt;Rating&gt;, int, int, double, int)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double)"><B>train(RDD&lt;Rating&gt;, int, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int)"><B>train(RDD&lt;Rating&gt;, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>Train a Lasso model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>Train a Lasso model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>Train a Lasso model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int)"><B>train(RDD&lt;LabeledPoint&gt;, int)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</A>
<DD>Train a Lasso model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, org.apache.spark.mllib.linalg.Vector)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>Train a Linear Regression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>Train a LinearRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>Train a LinearRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)"><B>train(RDD&lt;LabeledPoint&gt;, int)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</A>
<DD>Train a LinearRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>Train a RidgeRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>Train a RidgeRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)"><B>train(RDD&lt;LabeledPoint&gt;, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>Train a RidgeRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)"><B>train(RDD&lt;LabeledPoint&gt;, int)</B></A> - 
Static method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</A>
<DD>Train a RidgeRegression model given an RDD of (label, features) pairs.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#train(org.apache.spark.rdd.RDD, org.apache.spark.mllib.tree.configuration.Strategy)"><B>train(RDD&lt;LabeledPoint&gt;, Strategy)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#train(org.apache.spark.rdd.RDD, scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int)"><B>train(RDD&lt;LabeledPoint&gt;, Enumeration.Value, Impurity, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#train(org.apache.spark.rdd.RDD, scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int)"><B>train(RDD&lt;LabeledPoint&gt;, Enumeration.Value, Impurity, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#train(org.apache.spark.rdd.RDD, scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int, int, scala.Enumeration.Value, scala.collection.immutable.Map)"><B>train(RDD&lt;LabeledPoint&gt;, Enumeration.Value, Impurity, int, int, int, Enumeration.Value, Map&lt;Object, Object&gt;)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model.
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#train(org.apache.spark.rdd.RDD, org.apache.spark.mllib.tree.configuration.BoostingStrategy)"><B>train(RDD&lt;LabeledPoint&gt;, BoostingStrategy)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Method to train a gradient boosting model.
<DT><A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html#train(org.apache.spark.api.java.JavaRDD, org.apache.spark.mllib.tree.configuration.BoostingStrategy)"><B>train(JavaRDD&lt;LabeledPoint&gt;, BoostingStrategy)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/GradientBoostedTrees.html" title="class in org.apache.spark.mllib.tree">GradientBoostedTrees</A>
<DD>Java-friendly API for <CODE>GradientBoostedTrees$.train(org.apache.spark.rdd.RDD<org.apache.spark.mllib.regression.LabeledPoint>, org.apache.spark.mllib.tree.configuration.BoostingStrategy)</CODE>
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#trainClassifier(org.apache.spark.rdd.RDD, int, scala.collection.immutable.Map, java.lang.String, int, int)"><B>trainClassifier(RDD&lt;LabeledPoint&gt;, int, Map&lt;Object, Object&gt;, String, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model for binary or multiclass classification.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#trainClassifier(org.apache.spark.api.java.JavaRDD, int, java.util.Map, java.lang.String, int, int)"><B>trainClassifier(JavaRDD&lt;LabeledPoint&gt;, int, Map&lt;Integer, Integer&gt;, String, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Java-friendly API for <CODE>DecisionTree$.trainClassifier(org.apache.spark.rdd.RDD<org.apache.spark.mllib.regression.LabeledPoint>, int, scala.collection.immutable.Map<java.lang.Object, java.lang.Object>, java.lang.String, int, int)</CODE>
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainClassifier(org.apache.spark.rdd.RDD, org.apache.spark.mllib.tree.configuration.Strategy, int, java.lang.String, int)"><B>trainClassifier(RDD&lt;LabeledPoint&gt;, Strategy, int, String, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Method to train a decision tree model for binary or multiclass classification.
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainClassifier(org.apache.spark.rdd.RDD, int, scala.collection.immutable.Map, int, java.lang.String, java.lang.String, int, int, int)"><B>trainClassifier(RDD&lt;LabeledPoint&gt;, int, Map&lt;Object, Object&gt;, int, String, String, int, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Method to train a decision tree model for binary or multiclass classification.
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainClassifier(org.apache.spark.api.java.JavaRDD, int, java.util.Map, int, java.lang.String, java.lang.String, int, int, int)"><B>trainClassifier(JavaRDD&lt;LabeledPoint&gt;, int, Map&lt;Integer, Integer&gt;, int, String, String, int, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Java-friendly API for <CODE>RandomForest$.trainClassifier(org.apache.spark.rdd.RDD<org.apache.spark.mllib.regression.LabeledPoint>, org.apache.spark.mllib.tree.configuration.Strategy, int, java.lang.String, int)</CODE>
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, int, double, long)"><B>trainImplicit(RDD&lt;Rating&gt;, int, int, double, int, double, long)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of 'implicit preferences' given by users
 to some products, in the form of (userID, productID, preference) pairs.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, int, double)"><B>trainImplicit(RDD&lt;Rating&gt;, int, int, double, int, double)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of 'implicit preferences' given by users
 to some products, in the form of (userID, productID, preference) pairs.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, double)"><B>trainImplicit(RDD&lt;Rating&gt;, int, int, double, double)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of 'implicit preferences' given by users to
 some products, in the form of (userID, productID, preference) pairs.
<DT><A HREF="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int)"><B>trainImplicit(RDD&lt;Rating&gt;, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</A>
<DD>Train a matrix factorization model given an RDD of 'implicit preferences' ratings given by
 users to some products, in the form of (userID, productID, rating) pairs.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#trainOn(org.apache.spark.streaming.dstream.DStream)"><B>trainOn(DStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Update the clustering model by training on batches of data from a DStream.
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html#trainOn(org.apache.spark.streaming.api.java.JavaDStream)"><B>trainOn(JavaDStream&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeans.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeans</A>
<DD>Java-friendly version of `trainOn`.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#trainOn(org.apache.spark.streaming.dstream.DStream)"><B>trainOn(DStream&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Update the model by training on batches of data from a DStream.
<DT><A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#trainOn(org.apache.spark.streaming.api.java.JavaDStream)"><B>trainOn(JavaDStream&lt;LabeledPoint&gt;)</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</A>
<DD>Java-friendly version of `trainOn`.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#trainRegressor(org.apache.spark.rdd.RDD, scala.collection.immutable.Map, java.lang.String, int, int)"><B>trainRegressor(RDD&lt;LabeledPoint&gt;, Map&lt;Object, Object&gt;, String, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Method to train a decision tree model for regression.
<DT><A HREF="./org/apache/spark/mllib/tree/DecisionTree.html#trainRegressor(org.apache.spark.api.java.JavaRDD, java.util.Map, java.lang.String, int, int)"><B>trainRegressor(JavaRDD&lt;LabeledPoint&gt;, Map&lt;Integer, Integer&gt;, String, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</A>
<DD>Java-friendly API for <CODE>DecisionTree$.trainRegressor(org.apache.spark.rdd.RDD<org.apache.spark.mllib.regression.LabeledPoint>, scala.collection.immutable.Map<java.lang.Object, java.lang.Object>, java.lang.String, int, int)</CODE>
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainRegressor(org.apache.spark.rdd.RDD, org.apache.spark.mllib.tree.configuration.Strategy, int, java.lang.String, int)"><B>trainRegressor(RDD&lt;LabeledPoint&gt;, Strategy, int, String, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Method to train a decision tree model for regression.
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainRegressor(org.apache.spark.rdd.RDD, scala.collection.immutable.Map, int, java.lang.String, java.lang.String, int, int, int)"><B>trainRegressor(RDD&lt;LabeledPoint&gt;, Map&lt;Object, Object&gt;, int, String, String, int, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Method to train a decision tree model for regression.
<DT><A HREF="./org/apache/spark/mllib/tree/RandomForest.html#trainRegressor(org.apache.spark.api.java.JavaRDD, java.util.Map, int, java.lang.String, java.lang.String, int, int, int)"><B>trainRegressor(JavaRDD&lt;LabeledPoint&gt;, Map&lt;Integer, Integer&gt;, int, String, String, int, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.tree.<A HREF="./org/apache/spark/mllib/tree/RandomForest.html" title="class in org.apache.spark.mllib.tree">RandomForest</A>
<DD>Java-friendly API for <CODE>RandomForest$.trainRegressor(org.apache.spark.rdd.RDD<org.apache.spark.mllib.regression.LabeledPoint>, org.apache.spark.mllib.tree.configuration.Strategy, int, java.lang.String, int)</CODE>
<DT><A HREF="./org/apache/spark/ml/classification/ClassificationModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/ClassificationModel.html" title="class in org.apache.spark.ml.classification">ClassificationModel</A>
<DD>Transforms dataset by reading from <CODE>featuresCol</CODE>, and appending new columns as specified by
 parameters:
  - predicted labels as <CODE>predictionCol</CODE> of type <CODE>Double</CODE>
  - raw predictions (confidences) as <CODE>rawPredictionCol</CODE> of type <CODE>Vector</CODE>.
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification">OneVsRestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>Transform a sentence column to a vector column to represent the whole sentence.
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PredictionModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>
<DD>Transforms dataset by reading from <CODE>featuresCol</CODE>, calling <CODE>predict()</CODE>, and storing
 the predictions as a new column <CODE>predictionCol</CODE>.
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Transformer.html#transform(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamPair, org.apache.spark.ml.param.ParamPair...)"><B>transform(DataFrame, ParamPair&lt;?&gt;, ParamPair&lt;?&gt;...)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>Transforms the dataset with optional parameters
<DT><A HREF="./org/apache/spark/ml/Transformer.html#transform(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamPair, scala.collection.Seq)"><B>transform(DataFrame, ParamPair&lt;?&gt;, Seq&lt;ParamPair&lt;?&gt;&gt;)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>Transforms the dataset with optional parameters
<DT><A HREF="./org/apache/spark/ml/Transformer.html#transform(org.apache.spark.sql.DataFrame, org.apache.spark.ml.param.ParamMap)"><B>transform(DataFrame, ParamMap)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>Transforms the dataset with provided parameter map as additional parameters.
<DT><A HREF="./org/apache/spark/ml/Transformer.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>Transforms the input dataset.
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#transform(org.apache.spark.sql.DataFrame)"><B>transform(DataFrame)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ChiSqSelectorModel.html" title="class in org.apache.spark.mllib.feature">ChiSqSelectorModel</A>
<DD>Applies transformation on a vector.
<DT><A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/ElementwiseProduct.html" title="class in org.apache.spark.mllib.feature">ElementwiseProduct</A>
<DD>Does the hadamard product transformation.
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#transform(scala.collection.Iterable)"><B>transform(Iterable&lt;Object&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>Transforms the input document into a sparse term frequency vector.
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#transform(java.lang.Iterable)"><B>transform(Iterable&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>Transforms the input document into a sparse term frequency vector (Java version).
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#transform(org.apache.spark.rdd.RDD)"><B>transform(RDD&lt;D&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>Transforms the input document to term frequency vectors.
<DT><A HREF="./org/apache/spark/mllib/feature/HashingTF.html#transform(org.apache.spark.api.java.JavaRDD)"><B>transform(JavaRDD&lt;D&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</A>
<DD>Transforms the input document to term frequency vectors (Java version).
<DT><A HREF="./org/apache/spark/mllib/feature/IDFModel.html#transform(org.apache.spark.rdd.RDD)"><B>transform(RDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</A>
<DD>Transforms term frequency (TF) vectors to TF-IDF vectors.
<DT><A HREF="./org/apache/spark/mllib/feature/IDFModel.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</A>
<DD>Transforms a term frequency (TF) vector to a TF-IDF vector
<DT><A HREF="./org/apache/spark/mllib/feature/IDFModel.html#transform(org.apache.spark.api.java.JavaRDD)"><B>transform(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</A>
<DD>Transforms term frequency (TF) vectors to TF-IDF vectors (Java version).
<DT><A HREF="./org/apache/spark/mllib/feature/Normalizer.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</A>
<DD>Applies unit length normalization on a vector.
<DT><A HREF="./org/apache/spark/mllib/feature/PCAModel.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/PCAModel.html" title="class in org.apache.spark.mllib.feature">PCAModel</A>
<DD>Transform a vector by computed Principal Components.
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>Applies standardization transformation on a vector.
<DT><A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html#transform(org.apache.spark.mllib.linalg.Vector)"><B>transform(Vector)</B></A> - 
Method in interface org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature">VectorTransformer</A>
<DD>Applies transformation on a vector.
<DT><A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html#transform(org.apache.spark.rdd.RDD)"><B>transform(RDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature">VectorTransformer</A>
<DD>Applies transformation on an RDD[Vector].
<DT><A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html#transform(org.apache.spark.api.java.JavaRDD)"><B>transform(JavaRDD&lt;Vector&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature">VectorTransformer</A>
<DD>Applies transformation on an JavaRDD[Vector].
<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html#transform(java.lang.String)"><B>transform(String)</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</A>
<DD>Transforms a word to its vector representation
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transform(org.apache.spark.api.java.function.Function)"><B>transform(Function&lt;R, JavaRDD&lt;U&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transform(org.apache.spark.api.java.function.Function2)"><B>transform(Function2&lt;R, Time, JavaRDD&lt;U&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#transform(java.util.List, org.apache.spark.api.java.function.Function2)"><B>transform(List&lt;JavaDStream&lt;?&gt;&gt;, Function2&lt;List&lt;JavaRDD&lt;?&gt;&gt;, Time, JavaRDD&lt;T&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#transform(scala.Function1, scala.reflect.ClassTag)"><B>transform(Function1&lt;RDD&lt;T&gt;, RDD&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#transform(scala.Function2, scala.reflect.ClassTag)"><B>transform(Function2&lt;RDD&lt;T&gt;, Time, RDD&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#transform(scala.collection.Seq, scala.Function2, scala.reflect.ClassTag)"><B>transform(Seq&lt;DStream&lt;?&gt;&gt;, Function2&lt;Seq&lt;RDD&lt;?&gt;&gt;, Time, RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.
<DT><A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml"><B>Transformer</B></A> - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 Abstract class for transformers that transform one dataset into another.<DT><A HREF="./org/apache/spark/ml/Transformer.html#Transformer()"><B>Transformer()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Transformer.html" title="class in org.apache.spark.ml">Transformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification">OneVsRestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineStage.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineStage.html" title="class in org.apache.spark.ml">PipelineStage</A>
<DD>:: DeveloperApi ::
<DT><A HREF="./org/apache/spark/ml/PredictionModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PredictionModel.html" title="class in org.apache.spark.ml">PredictionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Predictor.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Predictor.html" title="class in org.apache.spark.ml">Predictor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#transformSchema(org.apache.spark.sql.types.StructType)"><B>transformSchema(StructType)</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformToPair(org.apache.spark.api.java.function.Function)"><B>transformToPair(Function&lt;R, JavaPairRDD&lt;K2, V2&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformToPair(org.apache.spark.api.java.function.Function2)"><B>transformToPair(Function2&lt;R, Time, JavaPairRDD&lt;K2, V2&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#transformToPair(java.util.List, org.apache.spark.api.java.function.Function2)"><B>transformToPair(List&lt;JavaDStream&lt;?&gt;&gt;, Function2&lt;List&lt;JavaRDD&lt;?&gt;&gt;, Time, JavaPairRDD&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWith(org.apache.spark.streaming.api.java.JavaDStream, org.apache.spark.api.java.function.Function3)"><B>transformWith(JavaDStream&lt;U&gt;, Function3&lt;R, JavaRDD&lt;U&gt;, Time, JavaRDD&lt;W&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWith(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.api.java.function.Function3)"><B>transformWith(JavaPairDStream&lt;K2, V2&gt;, Function3&lt;R, JavaPairRDD&lt;K2, V2&gt;, Time, JavaRDD&lt;W&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#transformWith(org.apache.spark.streaming.dstream.DStream, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>transformWith(DStream&lt;U&gt;, Function2&lt;RDD&lt;T&gt;, RDD&lt;U&gt;, RDD&lt;V&gt;&gt;, ClassTag&lt;U&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#transformWith(org.apache.spark.streaming.dstream.DStream, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>transformWith(DStream&lt;U&gt;, Function3&lt;RDD&lt;T&gt;, RDD&lt;U&gt;, Time, RDD&lt;V&gt;&gt;, ClassTag&lt;U&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWithToPair(org.apache.spark.streaming.api.java.JavaDStream, org.apache.spark.api.java.function.Function3)"><B>transformWithToPair(JavaDStream&lt;U&gt;, Function3&lt;R, JavaRDD&lt;U&gt;, Time, JavaPairRDD&lt;K2, V2&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWithToPair(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.api.java.function.Function3)"><B>transformWithToPair(JavaPairDStream&lt;K2, V2&gt;, Function3&lt;R, JavaPairRDD&lt;K2, V2&gt;, Time, JavaPairRDD&lt;K3, V3&gt;&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#transpose()"><B>transpose()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#transpose()"><B>transpose()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Transpose this <code>BlockMatrix</code>.
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#transpose()"><B>transpose()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#transpose()"><B>transpose()</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Transpose the Matrix.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#transpose()"><B>transpose()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><B>treeAggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;, int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Aggregates the elements of this RDD in a multi-level tree pattern.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)"><B>treeAggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeAggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)"><CODE>JavaRDDLike.treeAggregate(U, org.apache.spark.api.java.function.Function2<U, T, U>, org.apache.spark.api.java.function.Function2<U, U, U>, int)</CODE></A> with suggested depth 2.
<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)"><B>treeAggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;, int, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd">RDDFunctions</A>
<DD><B>Deprecated.</B>&nbsp;<I>Use <A HREF="./org/apache/spark/rdd/RDD.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)"><CODE>RDD.treeAggregate(U, scala.Function2<U, T, U>, scala.Function2<U, U, U>, int, scala.reflect.ClassTag<U>)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/spark/rdd/RDD.html#treeAggregate(U, scala.Function2, scala.Function2, int, scala.reflect.ClassTag)"><B>treeAggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;, int, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Aggregates the elements of this RDD in a multi-level tree pattern.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2, int)"><B>treeReduce(Function2&lt;T, T, T&gt;, int)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Reduces the elements of this RDD in a multi-level tree pattern.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2)"><B>treeReduce(Function2&lt;T, T, T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#treeReduce(org.apache.spark.api.java.function.Function2, int)"><CODE>JavaRDDLike.treeReduce(org.apache.spark.api.java.function.Function2<T, T, T>, int)</CODE></A> with suggested depth 2.
<DT><A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html#treeReduce(scala.Function2, int)"><B>treeReduce(Function2&lt;T, T, T&gt;, int)</B></A> - 
Method in class org.apache.spark.mllib.rdd.<A HREF="./org/apache/spark/mllib/rdd/RDDFunctions.html" title="class in org.apache.spark.mllib.rdd">RDDFunctions</A>
<DD><B>Deprecated.</B>&nbsp;<I>Use <A HREF="./org/apache/spark/rdd/RDD.html#treeReduce(scala.Function2, int)"><CODE>RDD.treeReduce(scala.Function2<T, T, T>, int)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/spark/rdd/RDD.html#treeReduce(scala.Function2, int)"><B>treeReduce(Function2&lt;T, T, T&gt;, int)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Reduces the elements of this RDD in a multi-level tree pattern.
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html#trees()"><B>trees()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/RandomForestModel.html" title="class in org.apache.spark.mllib.tree.model">RandomForestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#treeStrategy()"><B>treeStrategy()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/StructType.html#treeString()"><B>treeString()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#treeWeights()"><B>treeWeights()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#treeWeights()"><B>treeWeights()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#treeWeights()"><B>treeWeights()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#treeWeights()"><B>treeWeights()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#treeWeights()"><B>treeWeights()</B></A> - 
Method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/GraphOps.html#triangleCount()"><B>triangleCount()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/GraphOps.html" title="class in org.apache.spark.graphx">GraphOps</A>
<DD>Compute the number of triangles passing through each vertex.
<DT><A HREF="./org/apache/spark/graphx/lib/TriangleCount.html" title="class in org.apache.spark.graphx.lib"><B>TriangleCount</B></A> - Class in <A HREF="./org/apache/spark/graphx/lib/package-summary.html">org.apache.spark.graphx.lib</A><DD>Compute the number of triangles passing through each vertex.<DT><A HREF="./org/apache/spark/graphx/lib/TriangleCount.html#TriangleCount()"><B>TriangleCount()</B></A> - 
Constructor for class org.apache.spark.graphx.lib.<A HREF="./org/apache/spark/graphx/lib/TriangleCount.html" title="class in org.apache.spark.graphx.lib">TriangleCount</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx"><B>TripletFields</B></A> - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Represents a subset of the fields of an [[EdgeTriplet]] or [[EdgeContext]].<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#TripletFields()"><B>TripletFields()</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Constructs a default TripletFields in which all fields are included.
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#TripletFields(boolean, boolean, boolean)"><B>TripletFields(boolean, boolean, boolean)</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#triplets()"><B>triplets()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>An RDD containing the edge triplets, which are edges along with the vertex data associated with
 the adjacent vertices.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#triplets()"><B>triplets()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>Return a RDD that brings edges together with their source and destination vertices.
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#truePositiveRate(double)"><B>truePositiveRate(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns true positive rate for a given label (category)
<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter"><B>TwitterUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/twitter/package-summary.html">org.apache.spark.streaming.twitter</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html#TwitterUtils()"><B>TwitterUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.twitter.<A HREF="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DataType.html#typeName()"><B>typeName()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</A>
<DD>Name of the type used in JSON serialization.
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#typeName()"><B>typeName()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_U_"><!-- --></A><H2>
<B>U</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#U()"><B>U()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function0, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function0&lt;RT&gt;, TypeTags.TypeTag&lt;RT&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 0 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function1, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function1&lt;A1, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 1 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function2, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function2&lt;A1, A2, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 2 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function3, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function3&lt;A1, A2, A3, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 3 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function4, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function4&lt;A1, A2, A3, A4, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 4 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function5, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function5&lt;A1, A2, A3, A4, A5, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 5 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function6, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function6&lt;A1, A2, A3, A4, A5, A6, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 6 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function7, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function7&lt;A1, A2, A3, A4, A5, A6, A7, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 7 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function8, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function8&lt;A1, A2, A3, A4, A5, A6, A7, A8, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 8 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function9, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function9&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 9 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/functions.html#udf(scala.Function10, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag, scala.reflect.api.TypeTags.TypeTag)"><B>udf(Function10&lt;A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, RT&gt;, TypeTags.TypeTag&lt;RT&gt;, TypeTags.TypeTag&lt;A1&gt;, TypeTags.TypeTag&lt;A2&gt;, TypeTags.TypeTag&lt;A3&gt;, TypeTags.TypeTag&lt;A4&gt;, TypeTags.TypeTag&lt;A5&gt;, TypeTags.TypeTag&lt;A6&gt;, TypeTags.TypeTag&lt;A7&gt;, TypeTags.TypeTag&lt;A8&gt;, TypeTags.TypeTag&lt;A9&gt;, TypeTags.TypeTag&lt;A10&gt;)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Defines a user-defined function of 10 arguments as user-defined function (UDF).
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#udf()"><B>udf()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>A collection of methods for registering user-defined functions (UDF).
<DT><A HREF="./org/apache/spark/sql/api/java/UDF1.html" title="interface in org.apache.spark.sql.api.java"><B>UDF1</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF1.html" title="type parameter in UDF1">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF1.html" title="type parameter in UDF1">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 1 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="interface in org.apache.spark.sql.api.java"><B>UDF10</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 10 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="interface in org.apache.spark.sql.api.java"><B>UDF11</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 11 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="interface in org.apache.spark.sql.api.java"><B>UDF12</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 12 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="interface in org.apache.spark.sql.api.java"><B>UDF13</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 13 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="interface in org.apache.spark.sql.api.java"><B>UDF14</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 14 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="interface in org.apache.spark.sql.api.java"><B>UDF15</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 15 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="interface in org.apache.spark.sql.api.java"><B>UDF16</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 16 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="interface in org.apache.spark.sql.api.java"><B>UDF17</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 17 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="interface in org.apache.spark.sql.api.java"><B>UDF18</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T18</A>,<A HREF="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 18 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="interface in org.apache.spark.sql.api.java"><B>UDF19</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T18</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T19</A>,<A HREF="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 19 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF2.html" title="interface in org.apache.spark.sql.api.java"><B>UDF2</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 2 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="interface in org.apache.spark.sql.api.java"><B>UDF20</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T18</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T19</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T20</A>,<A HREF="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 20 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="interface in org.apache.spark.sql.api.java"><B>UDF21</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T18</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T19</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T20</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T21</A>,<A HREF="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 21 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="interface in org.apache.spark.sql.api.java"><B>UDF22</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T10</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T11</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T12</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T13</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T14</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T15</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T16</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T17</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T18</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T19</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T20</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T21</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T22</A>,<A HREF="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 22 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="interface in org.apache.spark.sql.api.java"><B>UDF3</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 3 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="interface in org.apache.spark.sql.api.java"><B>UDF4</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 4 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="interface in org.apache.spark.sql.api.java"><B>UDF5</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 5 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="interface in org.apache.spark.sql.api.java"><B>UDF6</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 6 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="interface in org.apache.spark.sql.api.java"><B>UDF7</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 7 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="interface in org.apache.spark.sql.api.java"><B>UDF8</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 8 arguments.<DT><A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="interface in org.apache.spark.sql.api.java"><B>UDF9</B></A>&lt;<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T1</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T2</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T3</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T4</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T5</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T6</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T7</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T8</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T9</A>,<A HREF="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">R</A>&gt; - Interface in <A HREF="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</A><DD>A Spark SQL UDF that has 9 arguments.<DT><A HREF="./org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql"><B>UDFRegistration</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>Functions for registering user-defined functions.<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassificationModel.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/DecisionTreeClassifier.html" title="class in org.apache.spark.ml.classification">DecisionTreeClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassificationModel.html" title="class in org.apache.spark.ml.classification">GBTClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/GBTClassifier.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/GBTClassifier.html" title="class in org.apache.spark.ml.classification">GBTClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegression.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegression.html" title="class in org.apache.spark.ml.classification">LogisticRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRest.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRest.html" title="class in org.apache.spark.ml.classification">OneVsRest</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/OneVsRestModel.html" title="class in org.apache.spark.ml.classification">OneVsRestModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassificationModel.html" title="class in org.apache.spark.ml.classification">RandomForestClassificationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/RandomForestClassifier.html" title="class in org.apache.spark.ml.classification">RandomForestClassifier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html" title="class in org.apache.spark.ml.evaluation">BinaryClassificationEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.evaluation.<A HREF="./org/apache/spark/ml/evaluation/RegressionEvaluator.html" title="class in org.apache.spark.ml.evaluation">RegressionEvaluator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Binarizer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Binarizer.html" title="class in org.apache.spark.ml.feature">Binarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Bucketizer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Bucketizer.html" title="class in org.apache.spark.ml.feature">Bucketizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/ElementwiseProduct.html" title="class in org.apache.spark.ml.feature">ElementwiseProduct</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/HashingTF.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/HashingTF.html" title="class in org.apache.spark.ml.feature">HashingTF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDF.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDF.html" title="class in org.apache.spark.ml.feature">IDF</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/IDFModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/IDFModel.html" title="class in org.apache.spark.ml.feature">IDFModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Normalizer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Normalizer.html" title="class in org.apache.spark.ml.feature">Normalizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/OneHotEncoder.html" title="class in org.apache.spark.ml.feature">OneHotEncoder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/PolynomialExpansion.html" title="class in org.apache.spark.ml.feature">PolynomialExpansion</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/RegexTokenizer.html" title="class in org.apache.spark.ml.feature">RegexTokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScaler.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScaler.html" title="class in org.apache.spark.ml.feature">StandardScaler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StandardScalerModel.html" title="class in org.apache.spark.ml.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexer.html" title="class in org.apache.spark.ml.feature">StringIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/StringIndexerModel.html" title="class in org.apache.spark.ml.feature">StringIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Tokenizer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Tokenizer.html" title="class in org.apache.spark.ml.feature">Tokenizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature">VectorIndexerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature">Word2VecModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.html" title="class in org.apache.spark.ml.recommendation">ALS</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressionModel.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/DecisionTreeRegressor.html" title="class in org.apache.spark.ml.regression">DecisionTreeRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressionModel.html" title="class in org.apache.spark.ml.regression">GBTRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/GBTRegressor.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/GBTRegressor.html" title="class in org.apache.spark.ml.regression">GBTRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegression.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegression.html" title="class in org.apache.spark.ml.regression">LinearRegression</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html" title="class in org.apache.spark.ml.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressionModel.html" title="class in org.apache.spark.ml.regression">RandomForestRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/RandomForestRegressor.html" title="class in org.apache.spark.ml.regression">RandomForestRegressor</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#uid()"><B>uid()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#uiTab()"><B>uiTab()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/EdgeContext.html#unapply(org.apache.spark.graphx.EdgeContext)"><B>unapply(EdgeContext&lt;VD, ED, A&gt;)</B></A> - 
Static method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeContext.html" title="class in org.apache.spark.graphx">EdgeContext</A>
<DD>Extractor mainly used for Graph#aggregateMessages*.
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#unapply(org.apache.spark.mllib.linalg.DenseVector)"><B>unapply(DenseVector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>Extracts the value array from a dense vector.
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#unapply(org.apache.spark.mllib.linalg.SparseVector)"><B>unapply(SparseVector)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#unapply(org.apache.spark.sql.Column)"><B>unapply(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#unapply(org.apache.spark.sql.types.DataType)"><B>unapply(DataType)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#unapply(org.apache.spark.sql.catalyst.expressions.Expression)"><B>unapply(Expression)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/NumericType.html#unapply(org.apache.spark.sql.catalyst.expressions.Expression)"><B>unapply(Expression)</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/NumericType.html" title="class in org.apache.spark.sql.types">NumericType</A>
<DD>Enables matching against NumericType for expressions:
<DT><A HREF="./org/apache/spark/streaming/kafka/Broker.html#unapply(org.apache.spark.streaming.kafka.Broker)"><B>unapply(Broker)</B></A> - 
Static method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/Broker.html" title="class in org.apache.spark.streaming.kafka">Broker</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml"><B>UnaryTransformer</B></A>&lt;<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">IN</A>,<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">OUT</A>,<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">T</A> extends <A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>&lt;<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">IN</A>,<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">OUT</A>,<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="type parameter in UnaryTransformer">T</A>&gt;&gt; - Class in <A HREF="./org/apache/spark/ml/package-summary.html">org.apache.spark.ml</A><DD>:: DeveloperApi ::
 Abstract class for transformers that take one input column, apply transformation, and output the
 result as a new column.<DT><A HREF="./org/apache/spark/ml/UnaryTransformer.html#UnaryTransformer()"><B>UnaryTransformer()</B></A> - 
Constructor for class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/UnaryTransformer.html" title="class in org.apache.spark.ml">UnaryTransformer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/BroadcastFactory.html#unbroadcast(long, boolean, boolean)"><B>unbroadcast(long, boolean, boolean)</B></A> - 
Method in interface org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html#unbroadcast(long, boolean, boolean)"><B>unbroadcast(long, boolean, boolean)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</A>
<DD>Remove all persisted state associated with the HTTP broadcast with the given ID.
<DT><A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#unbroadcast(long, boolean, boolean)"><B>unbroadcast(long, boolean, boolean)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</A>
<DD>Remove all persisted state associated with the torrent broadcast with the given ID.
<DT><A HREF="./org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)"><B>uncacheTable(String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</A>
<DD>Removes the specified table from the in-memory cache.
<DT><A HREF="./org/apache/spark/scheduler/SplitInfo.html#underlyingSplit()"><B>underlyingSplit()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random"><B>UniformGenerator</B></A> - Class in <A HREF="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</A><DD>:: DeveloperApi ::
 Generates i.i.d.<DT><A HREF="./org/apache/spark/mllib/random/UniformGenerator.html#UniformGenerator()"><B>UniformGenerator()</B></A> - 
Constructor for class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><B>uniformJavaRDD(JavaSparkContext, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformRDD(org.apache.spark.SparkContext, long, int, long)"><CODE>RandomRDDs.uniformRDD(org.apache.spark.SparkContext, long, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int)"><B>uniformJavaRDD(JavaSparkContext, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><CODE>RandomRDDs.uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long)"><B>uniformJavaRDD(JavaSparkContext, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><CODE>RandomRDDs.uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><B>uniformJavaVectorRDD(JavaSparkContext, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Java-friendly version of <A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><CODE>RandomRDDs.uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)</CODE></A>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int)"><B>uniformJavaVectorRDD(JavaSparkContext, long, int, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><CODE>RandomRDDs.uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</CODE></A> with the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int)"><B>uniformJavaVectorRDD(JavaSparkContext, long, int)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><CODE>RandomRDDs.uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</CODE></A> with the default number of partitions and the default seed.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformRDD(org.apache.spark.SparkContext, long, int, long)"><B>uniformRDD(SparkContext, long, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD comprised of <code>i.i.d.</code> samples from the uniform distribution <code>U(0.0, 1.0)</code>.
<DT><A HREF="./org/apache/spark/mllib/random/RandomRDDs.html#uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><B>uniformVectorRDD(SparkContext, long, int, int, long)</B></A> - 
Static method in class org.apache.spark.mllib.random.<A HREF="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</A>
<DD>Generates an RDD[Vector] with vectors containing <code>i.i.d.</code> samples drawn from the
 uniform distribution on <code>U(0.0, 1.0)</code>.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#union(org.apache.spark.api.java.JavaDoubleRDD)"><B>union(JavaDoubleRDD)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Return the union of this RDD and another one.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#union(org.apache.spark.api.java.JavaPairRDD)"><B>union(JavaPairRDD&lt;K, V&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return the union of this RDD and another one.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#union(org.apache.spark.api.java.JavaRDD)"><B>union(JavaRDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Return the union of this RDD and another one.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaRDD, java.util.List)"><B>union(JavaRDD&lt;T&gt;, List&lt;JavaRDD&lt;T&gt;&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Build the union of two or more RDDs.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaPairRDD, java.util.List)"><B>union(JavaPairRDD&lt;K, V&gt;, List&lt;JavaPairRDD&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Build the union of two or more RDDs.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaDoubleRDD, java.util.List)"><B>union(JavaDoubleRDD, List&lt;JavaDoubleRDD&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Build the union of two or more RDDs.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)"><B>union(RDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Return the union of this RDD and another one.
<DT><A HREF="./org/apache/spark/SparkContext.html#union(scala.collection.Seq, scala.reflect.ClassTag)"><B>union(Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Build the union of a list of RDDs.
<DT><A HREF="./org/apache/spark/SparkContext.html#union(org.apache.spark.rdd.RDD, scala.collection.Seq, scala.reflect.ClassTag)"><B>union(RDD&lt;T&gt;, Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Build the union of a list of RDDs passed as variable-length arguments.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#union(org.apache.spark.streaming.api.java.JavaDStream)"><B>union(JavaDStream&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Return a new DStream by unifying data of another DStream with this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#union(org.apache.spark.streaming.api.java.JavaPairDStream)"><B>union(JavaPairDStream&lt;K, V&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream by unifying data of another DStream with this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaDStream, java.util.List)"><B>union(JavaDStream&lt;T&gt;, List&lt;JavaDStream&lt;T&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a unified DStream from multiple DStreams of the same type and same slide duration.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaPairDStream, java.util.List)"><B>union(JavaPairDStream&lt;K, V&gt;, List&lt;JavaPairDStream&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</A>
<DD>Create a unified DStream from multiple DStreams of the same type and same slide duration.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#union(org.apache.spark.streaming.dstream.DStream)"><B>union(DStream&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream by unifying data of another DStream with this DStream.
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#union(scala.collection.Seq, scala.reflect.ClassTag)"><B>union(Seq&lt;DStream&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>Create a unified DStream from multiple DStreams of the same type and same slide duration.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#unionAll(org.apache.spark.sql.DataFrame)"><B>unionAll(DataFrame)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> containing union of rows in this frame and another frame.
<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd"><B>UnionRDD</B></A>&lt;<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="type parameter in UnionRDD">T</A>&gt; - Class in <A HREF="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/rdd/UnionRDD.html#UnionRDD(org.apache.spark.SparkContext, scala.collection.Seq, scala.reflect.ClassTag)"><B>UnionRDD(SparkContext, Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</B></A> - 
Constructor for class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StreamBlockId.html#uniqueId()"><B>uniqueId()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark"><B>UnknownReason</B></A> - Class in <A HREF="./org/apache/spark/package-summary.html">org.apache.spark</A><DD>:: DeveloperApi ::
 We don't know why the task ended -- for example, because of a ClassNotFound exception when
 deserializing the task result.<DT><A HREF="./org/apache/spark/UnknownReason.html#UnknownReason()"><B>UnknownReason()</B></A> - 
Constructor for class org.apache.spark.<A HREF="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark">UnknownReason</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/DecimalType.html#Unlimited()"><B>Unlimited()</B></A> - 
Static method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/DecimalType.html" title="class in org.apache.spark.sql.types">DecimalType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>Asynchronously delete cached copies of this broadcast on the executors.
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>Delete cached copies of this broadcast on the executors.
<DT><A HREF="./org/apache/spark/graphx/Graph.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Uncaches both vertices and edges of this graph.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeRDDImpl.html" title="class in org.apache.spark.graphx.impl">EdgeRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</A>
<DD>Unpersist intermediate RDDs used in the computation.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#unpersist(boolean)"><B>unpersist(boolean)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#unpersist()"><B>unpersist()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/Graph.html#unpersistVertices(boolean)"><B>unpersistVertices(boolean)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>Uncaches only the vertices of this graph, leaving the edges alone.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#unpersistVertices(boolean)"><B>unpersistVertices(boolean)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html#unregisterDialect(org.apache.spark.sql.jdbc.JdbcDialect)"><B>unregisterDialect(JdbcDialect)</B></A> - 
Static method in class org.apache.spark.sql.jdbc.<A HREF="./org/apache/spark/sql/jdbc/JdbcDialects.html" title="class in org.apache.spark.sql.jdbc">JdbcDialects</A>
<DD>Unregister a dialect.
<DT><A HREF="./org/apache/spark/ml/attribute/AttributeType.html#Unresolved()"><B>Unresolved()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/AttributeType.html" title="class in org.apache.spark.ml.attribute">AttributeType</A>
<DD>Unresolved type.
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute"><B>UnresolvedAttribute</B></A> - Class in <A HREF="./org/apache/spark/ml/attribute/package-summary.html">org.apache.spark.ml.attribute</A><DD>:: DeveloperApi ::
 An unresolved attribute.<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#UnresolvedAttribute()"><B>UnresolvedAttribute()</B></A> - 
Constructor for class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/Time.html#until(org.apache.spark.streaming.Time, org.apache.spark.streaming.Duration)"><B>until(Time, Duration)</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html#untilOffset()"><B>untilOffset()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/OffsetRange.html" title="class in org.apache.spark.streaming.kafka">OffsetRange</A>
<DD>exclusive ending offset
<DT><A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html#update(org.apache.spark.rdd.RDD, double, java.lang.String)"><B>update(RDD&lt;Vector&gt;, double, String)</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/StreamingKMeansModel.html" title="class in org.apache.spark.mllib.clustering">StreamingKMeansModel</A>
<DD>Perform a k-means update on a batch of data.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#update(int, int, double)"><B>update(int, int, double)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Update element at (i, j)
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrix.html#update(scala.Function1)"><B>update(Function1&lt;Object, Object&gt;)</B></A> - 
Method in interface org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</A>
<DD>Update all the values of this matrix using the function f.
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#update()"><B>update()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html#update()"><B>update()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html" title="class in org.apache.spark.status.api.v1">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html#update(T1, T2)"><B>update(T1, T2)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>Updates this pair with new values and returns itself
<DT><A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html#updateAggregateMetrics(org.apache.spark.ui.jobs.UIData.StageUIData, java.lang.String, org.apache.spark.executor.TaskMetrics, scala.Option)"><B>updateAggregateMetrics(UIData.StageUIData, String, TaskMetrics, Option&lt;TaskMetrics&gt;)</B></A> - 
Method in class org.apache.spark.ui.jobs.<A HREF="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</A>
<DD>Upon receiving new metrics for a task, updates the per-stage and per-executor-per-stage
 aggregate metrics by calculating deltas between the currently recorded metrics and the new
 metrics.
<DT><A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html#updatePredictionError(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, double, org.apache.spark.mllib.tree.model.DecisionTreeModel, org.apache.spark.mllib.tree.loss.Loss)"><B>updatePredictionError(RDD&lt;LabeledPoint&gt;, RDD&lt;Tuple2&lt;Object, Object&gt;&gt;, double, DecisionTreeModel, Loss)</B></A> - 
Static method in class org.apache.spark.mllib.tree.model.<A HREF="./org/apache/spark/mllib/tree/model/GradientBoostedTreesModel.html" title="class in org.apache.spark.mllib.tree.model">GradientBoostedTreesModel</A>
<DD>Update a zipped predictionError RDD
 (as obtained with computeInitialPredictionAndError)
<DT><A HREF="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization"><B>Updater</B></A> - Class in <A HREF="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</A><DD>:: DeveloperApi ::
 Class used to perform steps (weight update) using Gradient Descent methods.<DT><A HREF="./org/apache/spark/mllib/optimization/Updater.html#Updater()"><B>Updater()</B></A> - 
Constructor for class org.apache.spark.mllib.optimization.<A HREF="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization">Updater</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2)"><B>updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2, int)"><B>updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;, int)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)"><B>updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;, Partitioner)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner, org.apache.spark.api.java.JavaPairRDD)"><B>updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;, Partitioner, JavaPairRDD&lt;K, S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, scala.reflect.ClassTag)"><B>updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, int, scala.reflect.ClassTag)"><B>updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, int, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, org.apache.spark.Partitioner, scala.reflect.ClassTag)"><B>updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, Partitioner, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)"><B>updateStateByKey(Function1&lt;Iterator&lt;Tuple3&lt;K, Seq&lt;V&gt;, Option&lt;S&gt;&gt;&gt;, Iterator&lt;Tuple2&lt;K, S&gt;&gt;&gt;, Partitioner, boolean, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, org.apache.spark.Partitioner, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, Partitioner, RDD&lt;Tuple2&lt;K, S&gt;&gt;, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
<DT><A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>updateStateByKey(Function1&lt;Iterator&lt;Tuple3&lt;K, Seq&lt;V&gt;, Option&lt;S&gt;&gt;&gt;, Iterator&lt;Tuple2&lt;K, S&gt;&gt;&gt;, Partitioner, boolean, RDD&lt;Tuple2&lt;K, S&gt;&gt;, ClassTag&lt;S&gt;)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</A>
<DD>Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
<DT><A HREF="./org/apache/spark/sql/functions.html#upper(org.apache.spark.sql.Column)"><B>upper(Column)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Converts a string expression to upper case.
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#useDisk()"><B>useDisk()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#useDst"><B>useDst</B></A> - 
Variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Indicates whether the destination vertex attribute is included.
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#useEdge"><B>useEdge</B></A> - 
Variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Indicates whether the edge attribute is included.
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#useMemory()"><B>useMemory()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html#useNodeIdCache()"><B>useNodeIdCache()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#useOffHeap()"><B>useOffHeap()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html#user()"><B>user()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALS.Rating.html" title="class in org.apache.spark.ml.recommendation">ALS.Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/Rating.html#user()"><B>user()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/JobLogger.html#user()"><B>user()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#userClass()"><B>userClass()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>Class object for the UserType
<DT><A HREF="./org/apache/spark/sql/UserDefinedFunction.html" title="class in org.apache.spark.sql"><B>UserDefinedFunction</B></A> - Class in <A HREF="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</A><DD>A user-defined function.<DT><A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html#userDefinedPartitionColumns()"><B>userDefinedPartitionColumns()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/HadoopFsRelation.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation</A>
<DD>Optional user defined partition columns.
<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types"><B>UserDefinedType</B></A>&lt;<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="type parameter in UserDefinedType">UserType</A>&gt; - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>::DeveloperApi::
 The data type for User Defined Types (UDTs).<DT><A HREF="./org/apache/spark/sql/types/UserDefinedType.html#UserDefinedType()"><B>UserDefinedType()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UserDefinedType.html" title="class in org.apache.spark.sql.types">UserDefinedType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/recommendation/ALSModel.html#userFactors()"><B>userFactors()</B></A> - 
Method in class org.apache.spark.ml.recommendation.<A HREF="./org/apache/spark/ml/recommendation/ALSModel.html" title="class in org.apache.spark.ml.recommendation">ALSModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#userFeatures()"><B>userFeatures()</B></A> - 
Method in class org.apache.spark.mllib.recommendation.<A HREF="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/TripletFields.html#useSrc"><B>useSrc</B></A> - 
Variable in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/TripletFields.html" title="class in org.apache.spark.graphx">TripletFields</A>
<DD>Indicates whether the source vertex attribute is included.
<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types"><B>UTF8String</B></A> - Class in <A HREF="./org/apache/spark/sql/types/package-summary.html">org.apache.spark.sql.types</A><DD>:: DeveloperApi ::
 A UTF-8 String, as internal representation of StringType in SparkSQL<DT><A HREF="./org/apache/spark/sql/types/UTF8String.html#UTF8String()"><B>UTF8String()</B></A> - 
Constructor for class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/UTF8String.html" title="class in org.apache.spark.sql.types">UTF8String</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="_V_"><!-- --></A><H2>
<B>V</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#V()"><B>V()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#validate()"><B>validate()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/BlockMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">BlockMatrix</A>
<DD>Validates the block matrix info against the matrix data (<code>blocks</code>) and throws an exception if
 any error is found.
<DT><A HREF="./org/apache/spark/ml/param/Params.html#validateParams()"><B>validateParams()</B></A> - 
Method in interface org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Params.html" title="interface in org.apache.spark.ml.param">Params</A>
<DD>Validates parameter values stored internally.
<DT><A HREF="./org/apache/spark/ml/Pipeline.html#validateParams()"><B>validateParams()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/Pipeline.html" title="class in org.apache.spark.ml">Pipeline</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/PipelineModel.html#validateParams()"><B>validateParams()</B></A> - 
Method in class org.apache.spark.ml.<A HREF="./org/apache/spark/ml/PipelineModel.html" title="class in org.apache.spark.ml">PipelineModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidator.html#validateParams()"><B>validateParams()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidator.html" title="class in org.apache.spark.ml.tuning">CrossValidator</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html#validateParams()"><B>validateParams()</B></A> - 
Method in class org.apache.spark.ml.tuning.<A HREF="./org/apache/spark/ml/tuning/CrossValidatorModel.html" title="class in org.apache.spark.ml.tuning">CrossValidatorModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html#validationTol()"><B>validationTol()</B></A> - 
Method in class org.apache.spark.mllib.tree.configuration.<A HREF="./org/apache/spark/mllib/tree/configuration/BoostingStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">BoostingStrategy</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/Accumulable.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>Access the accumulator's current value; only allowed on master.
<DT><A HREF="./org/apache/spark/broadcast/Broadcast.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.broadcast.<A HREF="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</A>
<DD>Get the broadcasted value.
<DT><A HREF="./org/apache/spark/ComplexFutureAction.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/FutureAction.html#value()"><B>value()</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</A>
<DD>The value of this Future.
<DT><A HREF="./org/apache/spark/ml/param/ParamPair.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/ParamPair.html" title="class in org.apache.spark.ml.param">ParamPair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/scheduler/AccumulableInfo.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.scheduler.<A HREF="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SerializableWritable.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SimpleFutureAction.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/EqualTo.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/EqualTo.html" title="class in org.apache.spark.sql.sources">EqualTo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThan.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThan.html" title="class in org.apache.spark.sql.sources">GreaterThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources">GreaterThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThan.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThan.html" title="class in org.apache.spark.sql.sources">LessThan</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/LessThanOrEqual.html" title="class in org.apache.spark.sql.sources">LessThanOrEqual</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringContains.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringContains.html" title="class in org.apache.spark.sql.sources">StringContains</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringEndsWith.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringEndsWith.html" title="class in org.apache.spark.sql.sources">StringEndsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/sources/StringStartsWith.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/StringStartsWith.html" title="class in org.apache.spark.sql.sources">StringStartsWith</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/AccumulableInfo.html" title="class in org.apache.spark.status.api.v1">AccumulableInfo</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/MemoryEntry.html#value()"><B>value()</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/MemoryEntry.html" title="class in org.apache.spark.storage">MemoryEntry</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#valueContainsNull()"><B>valueContainsNull()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeActiveness.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeActiveness.html" title="enum in org.apache.spark.graphx.impl">EdgeActiveness</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/JobExecutionStatus.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.<A HREF="./org/apache/spark/JobExecutionStatus.html" title="enum in org.apache.spark">JobExecutionStatus</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/sql/SaveMode.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SaveMode.html" title="enum in org.apache.spark.sql">SaveMode</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html" title="enum in org.apache.spark.status.api.v1">ApplicationStatus</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/status/api/v1/StageStatus.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageStatus.html" title="enum in org.apache.spark.status.api.v1">StageStatus</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/status/api/v1/TaskSorting.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskSorting.html" title="enum in org.apache.spark.status.api.v1">TaskSorting</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/streaming/StreamingContextState.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
Static method in enum org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContextState.html" title="enum in org.apache.spark.streaming">StreamingContextState</A>
<DD>Returns the enum constant of this type with the specified name.
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>Return an RDD with the values of each tuple.
<DT><A HREF="./org/apache/spark/graphx/impl/EdgeActiveness.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/EdgeActiveness.html" title="enum in org.apache.spark.graphx.impl">EdgeActiveness</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/JobExecutionStatus.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.<A HREF="./org/apache/spark/JobExecutionStatus.html" title="enum in org.apache.spark">JobExecutionStatus</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseVector.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseMatrix.html" title="class in org.apache.spark.mllib.linalg">SparseMatrix</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/SparseVector.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/PairRDDFunctions.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</A>
<DD>Return an RDD with the values of each tuple.
<DT><A HREF="./org/apache/spark/sql/SaveMode.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.sql.<A HREF="./org/apache/spark/sql/SaveMode.html" title="enum in org.apache.spark.sql">SaveMode</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/sql/sources/In.html#values()"><B>values()</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/In.html" title="class in org.apache.spark.sql.sources">In</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ApplicationStatus.html" title="enum in org.apache.spark.status.api.v1">ApplicationStatus</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/status/api/v1/StageStatus.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/StageStatus.html" title="enum in org.apache.spark.status.api.v1">StageStatus</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/status/api/v1/TaskSorting.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/TaskSorting.html" title="enum in org.apache.spark.status.api.v1">TaskSorting</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/streaming/StreamingContextState.html#values()"><B>values()</B></A> - 
Static method in enum org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContextState.html" title="enum in org.apache.spark.streaming">StreamingContextState</A>
<DD>Returns an array containing the constants of this enum type, in
the order they are declared.
<DT><A HREF="./org/apache/spark/sql/types/MapType.html#valueType()"><B>valueType()</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MapType.html" title="class in org.apache.spark.sql.types">MapType</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#variance()"><B>variance()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>Compute the variance of this RDD's elements.
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#variance()"><B>variance()</B></A> - 
Method in class org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#variance()"><B>variance()</B></A> - 
Method in interface org.apache.spark.mllib.stat.<A HREF="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</A>
<DD>Sample variance vector.
<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity"><B>Variance</B></A> - Class in <A HREF="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</A><DD>:: Experimental ::
 Class for calculating variance during regression<DT><A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html#Variance()"><B>Variance()</B></A> - 
Constructor for class org.apache.spark.mllib.tree.impurity.<A HREF="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html#variance()"><B>variance()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</A>
<DD>Compute the variance of this RDD's elements.
<DT><A HREF="./org/apache/spark/util/StatCounter.html#variance()"><B>variance()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</A>
<DD>Return the variance of the values.
<DT><A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html#vClassTag()"><B>vClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html#vClassTag()"><B>vClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#vClassTag()"><B>vClassTag()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#vClassTag()"><B>vClassTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#vClassTag()"><B>vClassTag()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#vector()"><B>vector()</B></A> - 
Method in class org.apache.spark.mllib.linalg.distributed.<A HREF="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg"><B>Vector</B></A> - Interface in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>Represents a numeric vector, whose index type is Int and value type is Double.<DT><A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util"><B>Vector</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/Vector.html#Vector(double[])"><B>Vector(double[])</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.Multiplier.html" title="class in org.apache.spark.util"><B>Vector.Multiplier</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/Vector.Multiplier.html#Vector.Multiplier(double)"><B>Vector.Multiplier(double)</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.Multiplier.html" title="class in org.apache.spark.util">Vector.Multiplier</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util"><B>Vector.VectorAccumParam$</B></A> - Class in <A HREF="./org/apache/spark/util/package-summary.html">org.apache.spark.util</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html#Vector.VectorAccumParam$()"><B>Vector.VectorAccumParam$()</B></A> - 
Constructor for class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature"><B>VectorAssembler</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 A feature transformer that merges multiple columns into a vector column.<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#VectorAssembler(java.lang.String)"><B>VectorAssembler(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorAssembler.html#VectorAssembler()"><B>VectorAssembler()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorAssembler.html" title="class in org.apache.spark.ml.feature">VectorAssembler</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature"><B>VectorIndexer</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Class for indexing categorical feature columns in a dataset of <CODE>Vector</CODE>.<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#VectorIndexer(java.lang.String)"><B>VectorIndexer(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.html#VectorIndexer()"><B>VectorIndexer()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.html" title="class in org.apache.spark.ml.feature">VectorIndexer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html" title="class in org.apache.spark.ml.feature"><B>VectorIndexer.CategoryStats</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>Helper class for tracking unique values for each feature.<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html#VectorIndexer.CategoryStats(int, int)"><B>VectorIndexer.CategoryStats(int, int)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/VectorIndexer.CategoryStats.html" title="class in org.apache.spark.ml.feature">VectorIndexer.CategoryStats</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/VectorIndexerModel.html" title="class in org.apache.spark.ml.feature"><B>VectorIndexerModel</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Transform categorical features to use 0-based indices instead of their original values.<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg"><B>Vectors</B></A> - Class in <A HREF="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#Vectors()"><B>Vectors()</B></A> - 
Constructor for class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature"><B>VectorTransformer</B></A> - Interface in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: DeveloperApi ::
 Trait for transformation of a vector<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#version()"><B>version()</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>The version of Spark on which this application is running.
<DT><A HREF="./org/apache/spark/SparkContext.html#version()"><B>version()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>The version of Spark on which this application is running.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#vertcat(org.apache.spark.mllib.linalg.Matrix[])"><B>vertcat(Matrix[])</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Vertically concatenate a sequence of matrices.
<DT><A HREF="./org/apache/spark/graphx/EdgeTriplet.html#vertexAttr(long)"><B>vertexAttr(long)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/EdgeTriplet.html" title="class in org.apache.spark.graphx">EdgeTriplet</A>
<DD>Get the vertex object for the given vertex in the edge.
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx"><B>VertexRDD</B></A>&lt;<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="type parameter in VertexRDD">VD</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/package-summary.html">org.apache.spark.graphx</A><DD>Extends <code>RDD[(VertexId, VD)]</code> by ensuring that there is only one entry for each vertex and by
 pre-indexing the entries for fast, efficient joins.<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#VertexRDD(org.apache.spark.SparkContext, scala.collection.Seq)"><B>VertexRDD(SparkContext, Seq&lt;Dependency&lt;?&gt;&gt;)</B></A> - 
Constructor for class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl"><B>VertexRDDImpl</B></A>&lt;<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="type parameter in VertexRDDImpl">VD</A>&gt; - Class in <A HREF="./org/apache/spark/graphx/impl/package-summary.html">org.apache.spark.graphx.impl</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/graphx/Graph.html#vertices()"><B>vertices()</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/Graph.html" title="class in org.apache.spark.graphx">Graph</A>
<DD>An RDD containing the vertices and their associated attributes.
<DT><A HREF="./org/apache/spark/graphx/impl/GraphImpl.html#vertices()"><B>vertices()</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/GraphImpl.html" title="class in org.apache.spark.graphx.impl">GraphImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/InnerClosureFinder.html#visit(int, int, java.lang.String, java.lang.String, java.lang.String, java.lang.String[])"><B>visit(int, int, String, String, String, String[])</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/InnerClosureFinder.html" title="class in org.apache.spark.util">InnerClosureFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/InnerClosureFinder.html#visitMethod(int, java.lang.String, java.lang.String, java.lang.String, java.lang.String[])"><B>visitMethod(int, String, String, String, String[])</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/InnerClosureFinder.html" title="class in org.apache.spark.util">InnerClosureFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/ReturnStatementFinder.html#visitMethod(int, java.lang.String, java.lang.String, java.lang.String, java.lang.String[])"><B>visitMethod(int, String, String, String, String[])</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/ReturnStatementFinder.html" title="class in org.apache.spark.util">ReturnStatementFinder</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#vManifest()"><B>vManifest()</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html#vocabSize()"><B>vocabSize()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/DistributedLDAModel.html" title="class in org.apache.spark.mllib.clustering">DistributedLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html#vocabSize()"><B>vocabSize()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/EMLDAOptimizer.html" title="class in org.apache.spark.mllib.clustering">EMLDAOptimizer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/LDAModel.html#vocabSize()"><B>vocabSize()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LDAModel.html" title="class in org.apache.spark.mllib.clustering">LDAModel</A>
<DD>Vocabulary size (number of terms or terms in the vocabulary)
<DT><A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html#vocabSize()"><B>vocabSize()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/LocalLDAModel.html" title="class in org.apache.spark.mllib.clustering">LocalLDAModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature"><B>VocabWord</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>Entry in vocabulary<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#VocabWord(java.lang.String, int, int[], int[], int)"><B>VocabWord(String, int, int[], int[], int)</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function"><B>VoidFunction</B></A>&lt;<A HREF="./org/apache/spark/api/java/function/VoidFunction.html" title="type parameter in VoidFunction">T</A>&gt; - Interface in <A HREF="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</A><DD>A function with no return value.</DL>
<HR>
<A NAME="_W_"><!-- --></A><H2>
<B>W</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/ml/param/BooleanParam.html#w(boolean)"><B>w(boolean)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/BooleanParam.html" title="class in org.apache.spark.ml.param">BooleanParam</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html#w(java.util.List)"><B>w(List&lt;Double&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleArrayParam.html" title="class in org.apache.spark.ml.param">DoubleArrayParam</A>
<DD>Creates a param pair with a <CODE>List</CODE> of values (for Java and Python).
<DT><A HREF="./org/apache/spark/ml/param/DoubleParam.html#w(double)"><B>w(double)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/DoubleParam.html" title="class in org.apache.spark.ml.param">DoubleParam</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/FloatParam.html#w(float)"><B>w(float)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/FloatParam.html" title="class in org.apache.spark.ml.param">FloatParam</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/IntParam.html#w(int)"><B>w(int)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/IntParam.html" title="class in org.apache.spark.ml.param">IntParam</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/LongParam.html#w(long)"><B>w(long)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/LongParam.html" title="class in org.apache.spark.ml.param">LongParam</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/Param.html#w(T)"><B>w(T)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/Param.html" title="class in org.apache.spark.ml.param">Param</A>
<DD>Creates a param pair with the given value (for Java).
<DT><A HREF="./org/apache/spark/ml/param/StringArrayParam.html#w(java.util.List)"><B>w(List&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.ml.param.<A HREF="./org/apache/spark/ml/param/StringArrayParam.html" title="class in org.apache.spark.ml.param">StringArrayParam</A>
<DD>Creates a param pair with a <CODE>List</CODE> of values (for Java and Python).
<DT><A HREF="./org/apache/spark/streaming/StreamingContext.html#waiter()"><B>waiter()</B></A> - 
Method in class org.apache.spark.streaming.<A HREF="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#waitUntilLeaderOffset(java.lang.String, int, long)"><B>waitUntilLeaderOffset(String, int, long)</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>Wait until the leader offset for the given topic/partition equals the specified offset
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFalsePositiveRate()"><B>weightedFalsePositiveRate()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted false positive rate
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFMeasure(double)"><B>weightedFMeasure(double)</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted averaged f-measure
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFMeasure()"><B>weightedFMeasure()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted averaged f1-measure
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedPrecision()"><B>weightedPrecision()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted averaged precision
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedRecall()"><B>weightedRecall()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted averaged recall
 (equals to precision, recall and f-measure)
<DT><A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedTruePositiveRate()"><B>weightedTruePositiveRate()</B></A> - 
Method in class org.apache.spark.mllib.evaluation.<A HREF="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</A>
<DD>Returns weighted true positive rate
 (equals to precision, recall and f-measure)
<DT><A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.ml.classification.<A HREF="./org/apache/spark/ml/classification/LogisticRegressionModel.html" title="class in org.apache.spark.ml.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.ml.regression.<A HREF="./org/apache/spark/ml/regression/LinearRegressionModel.html" title="class in org.apache.spark.ml.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/classification/SVMModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.classification.<A HREF="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/GaussianMixtureModel.html" title="class in org.apache.spark.mllib.clustering">GaussianMixtureModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LassoModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#weights()"><B>weights()</B></A> - 
Method in class org.apache.spark.mllib.regression.<A HREF="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/Column.html#when(org.apache.spark.sql.Column, java.lang.Object)"><B>when(Column, Object)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</A>
<DD>Evaluates a list of conditions and returns one of multiple possible result expressions.
<DT><A HREF="./org/apache/spark/sql/functions.html#when(org.apache.spark.sql.Column, java.lang.Object)"><B>when(Column, Object)</B></A> - 
Static method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/functions.html" title="class in org.apache.spark.sql">functions</A>
<DD>Evaluates a list of conditions and returns one of multiple possible result expressions.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#where(org.apache.spark.sql.Column)"><B>where(Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Filters rows using the given condition.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#wholeTextFiles(java.lang.String, int)"><B>wholeTextFiles(String, int)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.
<DT><A HREF="./org/apache/spark/api/java/JavaSparkContext.html#wholeTextFiles(java.lang.String)"><B>wholeTextFiles(String)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</A>
<DD>Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.
<DT><A HREF="./org/apache/spark/SparkContext.html#wholeTextFiles(java.lang.String, int)"><B>wholeTextFiles(String, int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.
<DT><A HREF="./org/apache/spark/sql/expressions/Window.html" title="class in org.apache.spark.sql.expressions"><B>Window</B></A> - Class in <A HREF="./org/apache/spark/sql/expressions/package-summary.html">org.apache.spark.sql.expressions</A><DD>:: Experimental ::
 Utility functions for defining window in DataFrames.<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#window(org.apache.spark.streaming.Duration)"><B>window(Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>window(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#window(org.apache.spark.streaming.Duration)"><B>window(Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream which is computed based on windowed batches of this DStream.
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>window(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>Return a new DStream which is computed based on windowed batches of this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#window(org.apache.spark.streaming.Duration)"><B>window(Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)"><B>window(Duration, Duration)</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.
<DT><A HREF="./org/apache/spark/sql/expressions/WindowSpec.html" title="class in org.apache.spark.sql.expressions"><B>WindowSpec</B></A> - Class in <A HREF="./org/apache/spark/sql/expressions/package-summary.html">org.apache.spark.sql.expressions</A><DD>:: Experimental ::
 A window specification that defines the partitioning, ordering, and frame boundaries.<DT><A HREF="./org/apache/spark/sql/DataFrame.html#withColumn(java.lang.String, org.apache.spark.sql.Column)"><B>withColumn(String, Column)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> by adding a column.
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#withColumnRenamed(java.lang.String, java.lang.String)"><B>withColumnRenamed(String, String)</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>Returns a new <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> with a column renamed.
<DT><A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html#withEdges(org.apache.spark.graphx.EdgeRDD)"><B>withEdges(EdgeRDD&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.graphx.impl.<A HREF="./org/apache/spark/graphx/impl/VertexRDDImpl.html" title="class in org.apache.spark.graphx.impl">VertexRDDImpl</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/graphx/VertexRDD.html#withEdges(org.apache.spark.graphx.EdgeRDD)"><B>withEdges(EdgeRDD&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.graphx.<A HREF="./org/apache/spark/graphx/VertexRDD.html" title="class in org.apache.spark.graphx">VertexRDD</A>
<DD>Prepares this VertexRDD for efficient joins with the given EdgeRDD.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#withIndex(int)"><B>withIndex(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Copy with a new index.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withIndex(int)"><B>withIndex(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withIndex(int)"><B>withIndex(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withIndex(int)"><B>withIndex(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#withIndex(int)"><B>withIndex(int)</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withMax(double)"><B>withMax(double)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy with a new max value.
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#withMean()"><B>withMean()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/types/MetadataBuilder.html#withMetadata(org.apache.spark.sql.types.Metadata)"><B>withMetadata(Metadata)</B></A> - 
Method in class org.apache.spark.sql.types.<A HREF="./org/apache/spark/sql/types/MetadataBuilder.html" title="class in org.apache.spark.sql.types">MetadataBuilder</A>
<DD>Include the content of an existing <A HREF="./org/apache/spark/sql/types/Metadata.html" title="class in org.apache.spark.sql.types"><CODE>Metadata</CODE></A> instance.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withMin(double)"><B>withMin(double)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy with a new min value.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#withName(java.lang.String)"><B>withName(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Copy with a new name.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withName(java.lang.String)"><B>withName(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withName(java.lang.String)"><B>withName(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withName(java.lang.String)"><B>withName(String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#withName(java.lang.String)"><B>withName(String)</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withNumValues(int)"><B>withNumValues(int)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy with a new `numValues` and empty `values`.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#withoutIndex()"><B>withoutIndex()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Copy without the index.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withoutIndex()"><B>withoutIndex()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withoutIndex()"><B>withoutIndex()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutIndex()"><B>withoutIndex()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#withoutIndex()"><B>withoutIndex()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutMax()"><B>withoutMax()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy without the max value.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutMin()"><B>withoutMin()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy without the min value.
<DT><A HREF="./org/apache/spark/ml/attribute/Attribute.html#withoutName()"><B>withoutName()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/Attribute.html" title="class in org.apache.spark.ml.attribute">Attribute</A>
<DD>Copy without the name.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withoutName()"><B>withoutName()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withoutName()"><B>withoutName()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutName()"><B>withoutName()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html#withoutName()"><B>withoutName()</B></A> - 
Static method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/UnresolvedAttribute.html" title="class in org.apache.spark.ml.attribute">UnresolvedAttribute</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withoutNumValues()"><B>withoutNumValues()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy without the `numValues`.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutSparsity()"><B>withoutSparsity()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy without the sparsity.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutStd()"><B>withoutStd()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy without the standard deviation.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withoutSummary()"><B>withoutSummary()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy without summary statistics.
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withoutValues()"><B>withoutValues()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>Copy without the values.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withoutValues()"><B>withoutValues()</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy without the values.
<DT><A HREF="./org/apache/spark/sql/AnalysisException.html#withPosition(scala.Option, scala.Option)"><B>withPosition(Option&lt;Object&gt;, Option&lt;Object&gt;)</B></A> - 
Method in exception org.apache.spark.sql.<A HREF="./org/apache/spark/sql/AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withSparsity(double)"><B>withSparsity(double)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy with a new sparsity.
<DT><A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html#withStd(double)"><B>withStd(double)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NumericAttribute.html" title="class in org.apache.spark.ml.attribute">NumericAttribute</A>
<DD>Copy with a new standard deviation.
<DT><A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html#withStd()"><B>withStd()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html#withValues(java.lang.String, java.lang.String)"><B>withValues(String, String)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/BinaryAttribute.html" title="class in org.apache.spark.ml.attribute">BinaryAttribute</A>
<DD>Copy with new values.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withValues(java.lang.String, java.lang.String...)"><B>withValues(String, String...)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy with new values and empty `numValues`.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withValues(java.lang.String[])"><B>withValues(String[])</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy with new values and empty `numValues`.
<DT><A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html#withValues(java.lang.String, scala.collection.Seq)"><B>withValues(String, Seq&lt;String&gt;)</B></A> - 
Method in class org.apache.spark.ml.attribute.<A HREF="./org/apache/spark/ml/attribute/NominalAttribute.html" title="class in org.apache.spark.ml.attribute">NominalAttribute</A>
<DD>Copy with new values and empty `numValues`.
<DT><A HREF="./org/apache/spark/mllib/feature/VocabWord.html#word()"><B>word()</B></A> - 
Method in class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/VocabWord.html" title="class in org.apache.spark.mllib.feature">VocabWord</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature"><B>Word2Vec</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Word2Vec trains a model of <code>Map(String, Vector)</code>, i.e.<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#Word2Vec(java.lang.String)"><B>Word2Vec(String)</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2Vec.html#Word2Vec()"><B>Word2Vec()</B></A> - 
Constructor for class org.apache.spark.ml.feature.<A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature"><B>Word2Vec</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/mllib/feature/Word2Vec.html#Word2Vec()"><B>Word2Vec()</B></A> - 
Constructor for class org.apache.spark.mllib.feature.<A HREF="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ml/feature/Word2VecModel.html" title="class in org.apache.spark.ml.feature"><B>Word2VecModel</B></A> - Class in <A HREF="./org/apache/spark/ml/feature/package-summary.html">org.apache.spark.ml.feature</A><DD>:: Experimental ::
 Model fitted by <A HREF="./org/apache/spark/ml/feature/Word2Vec.html" title="class in org.apache.spark.ml.feature"><CODE>Word2Vec</CODE></A>.<DT><A HREF="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature"><B>Word2VecModel</B></A> - Class in <A HREF="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</A><DD>:: Experimental ::
 Word2Vec model<DT><A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html#wrapperClass()"><B>wrapperClass()</B></A> - 
Static method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html" title="class in org.apache.spark.serializer">JavaIterableWrapperSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;Double&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaPairRDD.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDD.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;T&gt;)</B></A> - 
Method in interface org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html#wrapRDD(org.apache.spark.rdd.RDD)"><B>wrapRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;)</B></A> - 
Method in class org.apache.spark.streaming.api.java.<A HREF="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.html#writableWritableConverter()"><B>writableWritableConverter()</B></A> - 
Static method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#write(int)"><B>write(int)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#write(byte[])"><B>write(byte[])</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html#write(byte[], int, int)"><B>write(byte[], int, int)</B></A> - 
Method in class org.apache.spark.io.<A HREF="./org/apache/spark/io/SnappyOutputStreamWrapper.html" title="class in org.apache.spark.io">SnappyOutputStreamWrapper</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html#write(com.esotericsoftware.kryo.Kryo, com.esotericsoftware.kryo.io.Output, java.lang.Iterable)"><B>write(Kryo, Output, Iterable&lt;?&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaIterableWrapperSerializer.html" title="class in org.apache.spark.serializer">JavaIterableWrapperSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/sql/DataFrame.html#write()"><B>write()</B></A> - 
Method in class org.apache.spark.sql.<A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</A>
<DD>:: Experimental ::
 Interface for saving the content of the <A HREF="./org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><CODE>DataFrame</CODE></A> out into external storage.
<DT><A HREF="./org/apache/spark/sql/sources/OutputWriter.html#write(org.apache.spark.sql.Row)"><B>write(Row)</B></A> - 
Method in class org.apache.spark.sql.sources.<A HREF="./org/apache/spark/sql/sources/OutputWriter.html" title="class in org.apache.spark.sql.sources">OutputWriter</A>
<DD>Persists a single row.
<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#write(int)"><B>write(int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#write(byte[])"><B>write(byte[])</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html#write(byte[], int, int)"><B>write(byte[], int, int)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/TimeTrackingOutputStream.html" title="class in org.apache.spark.storage">TimeTrackingOutputStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#write(java.nio.ByteBuffer, long)"><B>write(ByteBuffer, long)</B></A> - 
Method in class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>Write the record to the log and return a record handle, which contains all the information
 necessary to read back the written record.
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util"><B>WriteAheadLog</B></A> - Class in <A HREF="./org/apache/spark/streaming/util/package-summary.html">org.apache.spark.streaming.util</A><DD>This abstract class represents a write ahead log (aka journal) that is used by Spark Streaming
 to save the received data (by receivers) and associated metadata to a reliable storage, so that
 they can be recovered after driver failures.<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html#WriteAheadLog()"><B>WriteAheadLog()</B></A> - 
Constructor for class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util">WriteAheadLog</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLogRecordHandle.html" title="class in org.apache.spark.streaming.util"><B>WriteAheadLogRecordHandle</B></A> - Class in <A HREF="./org/apache/spark/streaming/util/package-summary.html">org.apache.spark.streaming.util</A><DD>This abstract class represents a handle that refers to a record written in a
 <A HREF="./org/apache/spark/streaming/util/WriteAheadLog.html" title="class in org.apache.spark.streaming.util"><CODE>WriteAheadLog</CODE></A>.<DT><A HREF="./org/apache/spark/streaming/util/WriteAheadLogRecordHandle.html#WriteAheadLogRecordHandle()"><B>WriteAheadLogRecordHandle()</B></A> - 
Constructor for class org.apache.spark.streaming.util.<A HREF="./org/apache/spark/streaming/util/WriteAheadLogRecordHandle.html" title="class in org.apache.spark.streaming.util">WriteAheadLogRecordHandle</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#writeAll(scala.collection.Iterator, scala.reflect.ClassTag)"><B>writeAll(Iterator&lt;T&gt;, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html#writeBytes()"><B>writeBytes()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/JavaSerializer.html#writeExternal(java.io.ObjectOutput)"><B>writeExternal(ObjectOutput)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/BlockManagerId.html#writeExternal(java.io.ObjectOutput)"><B>writeExternal(ObjectOutput)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/storage/StorageLevel.html#writeExternal(java.io.ObjectOutput)"><B>writeExternal(ObjectOutput)</B></A> - 
Method in class org.apache.spark.storage.<A HREF="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#writeExternal(java.io.ObjectOutput)"><B>writeExternal(ObjectOutput)</B></A> - 
Method in class org.apache.spark.streaming.flume.<A HREF="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#writeKey(T, scala.reflect.ClassTag)"><B>writeKey(T, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>Writes the object representing the key of a key-value pair.
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#writeObject(T, scala.reflect.ClassTag)"><B>writeObject(T, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>The most general-purpose method to write an object.
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html#writeRecords()"><B>writeRecords()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html#writeTime()"><B>writeTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetricDistributions.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetricDistributions</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html#writeTime()"><B>writeTime()</B></A> - 
Method in class org.apache.spark.status.api.v1.<A HREF="./org/apache/spark/status/api/v1/ShuffleWriteMetrics.html" title="class in org.apache.spark.status.api.v1">ShuffleWriteMetrics</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/serializer/SerializationStream.html#writeValue(T, scala.reflect.ClassTag)"><B>writeValue(T, ClassTag&lt;T&gt;)</B></A> - 
Method in class org.apache.spark.serializer.<A HREF="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</A>
<DD>Writes the object representing the value of a key-value pair.
</DL>
<HR>
<A NAME="_Z_"><!-- --></A><H2>
<B>Z</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/Accumulable.html#zero()"><B>zero()</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulableParam.html#zero(R)"><B>zero(R)</B></A> - 
Method in interface org.apache.spark.<A HREF="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</A>
<DD>Return the "zero" (identity) value for an accumulator type, given its initial value.
<DT><A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html#zero(double)"><B>zero(double)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.DoubleAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html#zero(float)"><B>zero(float)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.FloatAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html#zero(int)"><B>zero(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.IntAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html#zero(long)"><B>zero(long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/AccumulatorParam.LongAccumulatorParam$.html" title="class in org.apache.spark">AccumulatorParam.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html#zero(int, int)"><B>zero(int, int)</B></A> - 
Static method in class org.apache.spark.mllib.clustering.<A HREF="./org/apache/spark/mllib/clustering/ExpectationSum.html" title="class in org.apache.spark.mllib.clustering">ExpectationSum</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#zero(double)"><B>zero(double)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#zero(float)"><B>zero(float)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#zero(int)"><B>zero(int)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#zero(long)"><B>zero(long)</B></A> - 
Method in class org.apache.spark.<A HREF="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html#zero(org.apache.spark.util.Vector)"><B>zero(Vector)</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq"><B>ZeroMQUtils</B></A> - Class in <A HREF="./org/apache/spark/streaming/zeromq/package-summary.html">org.apache.spark.streaming.zeromq</A><DD>&nbsp;<DT><A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#ZeroMQUtils()"><B>ZeroMQUtils()</B></A> - 
Constructor for class org.apache.spark.streaming.zeromq.<A HREF="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html#zeros(int, int)"><B>zeros(int, int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</A>
<DD>Generate a <code>DenseMatrix</code> consisting of zeros.
<DT><A HREF="./org/apache/spark/mllib/linalg/Matrices.html#zeros(int, int)"><B>zeros(int, int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</A>
<DD>Generate a <code>Matrix</code> consisting of zeros.
<DT><A HREF="./org/apache/spark/mllib/linalg/Vectors.html#zeros(int)"><B>zeros(int)</B></A> - 
Static method in class org.apache.spark.mllib.linalg.<A HREF="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</A>
<DD>Creates a vector of all zeros.
<DT><A HREF="./org/apache/spark/util/Vector.html#zeros(int)"><B>zeros(int)</B></A> - 
Static method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/dstream/DStream.html#zeroTime()"><B>zeroTime()</B></A> - 
Method in class org.apache.spark.streaming.dstream.<A HREF="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#zip(org.apache.spark.api.java.JavaRDDLike)"><B>zip(JavaRDDLike&lt;U, ?&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)"><B>zip(RDD&lt;U&gt;, ClassTag&lt;U&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#zipPartitions(org.apache.spark.api.java.JavaRDDLike, org.apache.spark.api.java.function.FlatMapFunction2)"><B>zipPartitions(JavaRDDLike&lt;U, ?&gt;, FlatMapFunction2&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;, V&gt;)</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, boolean, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, boolean, Function2&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, Function2&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, boolean, Function3&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, Function3&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, RDD&lt;D&gt;, boolean, Function4&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;D&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;D&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)"><B>zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, RDD&lt;D&gt;, Function4&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;D&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;D&gt;, ClassTag&lt;V&gt;)</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#zipWithIndex()"><B>zipWithIndex()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Zips this RDD with its element indices.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipWithIndex()"><B>zipWithIndex()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Zips this RDD with its element indices.
<DT><A HREF="./org/apache/spark/api/java/JavaRDDLike.html#zipWithUniqueId()"><B>zipWithUniqueId()</B></A> - 
Method in interface org.apache.spark.api.java.<A HREF="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</A>
<DD>Zips this RDD with generated unique Long ids.
<DT><A HREF="./org/apache/spark/rdd/RDD.html#zipWithUniqueId()"><B>zipWithUniqueId()</B></A> - 
Method in class org.apache.spark.rdd.<A HREF="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</A>
<DD>Zips this RDD with generated unique Long ids.
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#zkAddress()"><B>zkAddress()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html#zookeeperClient()"><B>zookeeperClient()</B></A> - 
Method in class org.apache.spark.streaming.kafka.<A HREF="./org/apache/spark/streaming/kafka/KafkaTestUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaTestUtils</A>
<DD>&nbsp;
</DL>
<HR>
<A NAME="___"><!-- --></A><H2>
<B>_</B></H2>
<DL>
<DT><A HREF="./org/apache/spark/util/MutablePair.html#_1()"><B>_1()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/util/MutablePair.html#_2()"><B>_2()</B></A> - 
Method in class org.apache.spark.util.<A HREF="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</A>
<DD>&nbsp;
<DT><A HREF="./org/apache/spark/ui/storage/StorageListener.html#_rddInfoMap()"><B>_rddInfoMap()</B></A> - 
Method in class org.apache.spark.ui.storage.<A HREF="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</A>
<DD>&nbsp;
</DL>
<HR>
<A HREF="#_A_">A</A> <A HREF="#_B_">B</A> <A HREF="#_C_">C</A> <A HREF="#_D_">D</A> <A HREF="#_E_">E</A> <A HREF="#_F_">F</A> <A HREF="#_G_">G</A> <A HREF="#_H_">H</A> <A HREF="#_I_">I</A> <A HREF="#_J_">J</A> <A HREF="#_K_">K</A> <A HREF="#_L_">L</A> <A HREF="#_M_">M</A> <A HREF="#_N_">N</A> <A HREF="#_O_">O</A> <A HREF="#_P_">P</A> <A HREF="#_Q_">Q</A> <A HREF="#_R_">R</A> <A HREF="#_S_">S</A> <A HREF="#_T_">T</A> <A HREF="#_U_">U</A> <A HREF="#_V_">V</A> <A HREF="#_W_">W</A> <A HREF="#_Z_">Z</A> <A HREF="#___">_</A> 

<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Index</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="./index.html?index-all.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="index-all.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="./allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="./allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
